references copy
Item type;Authors;Title;Journal;Publication year;Volume;Issue;Pages;Edition;Publisher;Address;Book title;Proceedings title;Conference location;Date published;ISBN;ISSN;URLs;DOI;Abstract;Keywords;Notes;Sub-type;Series
Conference Paper;Ullah F,Raft AJ,Shahin M,Zahedi M,Ali Babar M;Security Support in Continuous Deployment Pipeline;;2017;;;57–68;;SCITEPRESS - Science and Technology Publications, Lda;Setubal, PRT;;Proceedings of the 12th International Conference on Evaluation of Novel Approaches to Software Engineering;Porto, Portugal;2017;9789897582509;;"https://doi-org.proxy.bnl.lu/10.5220/0006318200570068;http://dx.doi.org/10.5220/0006318200570068";10.5220/0006318200570068;Continuous Deployment (CD) has emerged as a new practice in the software industry to continuously and automatically deploy software changes into production. Continuous Deployment Pipeline (CDP) supports CD practice by transferring the changes from the repository to production. Since most of the CDP components run in an environment that has several interfaces to the Internet, these components are vulnerable to various kinds of malicious attacks. This paper reports our work aimed at designing secure CDP by utilizing security tactics. We have demonstrated the effectiveness of five security tactics in designing a secure pipeline by conducting an experiment on two CDPs- one incorporates security tactics while the other does not. Both CDPs have been analysed qualitatively and quantitatively. We used assurance cases with goal-structured notations for qualitative analysis. For quantitative analysis, we used penetration tools. Our findings indicate that the applied tactics improve the security of the major components (i.e., repository, continuous integration server, main server) of a CDP by controlling access to the components and establishing secure connections. p>;Continuous Integration., Continuous Deployment, Continuous Deployment Pipeline, Security;;;ENASE 2017
Conference Paper;Greising L,Bartel A,Hagel G;Introducing a Deployment Pipeline for Continuous Delivery in a Software Architecture Course;;2018;;;102–107;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 3rd European Conference of Software Engineering Education;Seeon/ Bavaria, Germany;2018;9781450363839;;"https://doi-org.proxy.bnl.lu/10.1145/3209087.3209091;http://dx.doi.org/10.1145/3209087.3209091";10.1145/3209087.3209091;Continuous Delivery (CD) has emerged to an important concept of software architecture in the last few years. The goal of a CD strategy is to decrease the time to market of an application while increasing the quality of that software. However, literature shows that teaching CD practices in higher education is in an infancy stage. Therefore a new concept for teaching CD practices is developed and demonstrated. In this concept students have to master several different tools and technologies to create an automated software delivery system. This can be achieved by guiding the students through a hands-on project, in which they develop stage by stage a CD pipeline. This paper introduces necessary background information as well as the CD teaching concept with its scaffolded learning approach for implementing a CD pipeline in a software architecture course.;Scaffolded Learning, Software Architecture, Continuous Delivery, Continuous Integration, Pipeline;;;ECSEE'18
Conference Paper;Shahin M,Babar MA,Zahedi M,Zhu L;Beyond Continuous Delivery: An Empirical Investigation of Continuous Deployment Challenges;;2017;;;111–120;;IEEE Press;Markham, Ontario, Canada;;Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;;2017;9781509040391;;"https://doi-org.proxy.bnl.lu/10.1109/ESEM.2017.18;http://dx.doi.org/10.1109/ESEM.2017.18";10.1109/ESEM.2017.18;"Context: A growing number of software organizations have been adopting Continuous DElivery (CDE) and Continuous Deployment (CD) practices. Researchers have started investing significant efforts in studying different aspects of CDE and CD. Many studies refer to CDE (i.e., where an application is potentially capable of being deployed) and CD (i.e., where an application is automatically deployed to production on every update) as synonyms and do not distinguish them from each other. Despite CDE being successfully adopted by a large number of organizations, it is not empirically known why organizations still are unable or demotivated to have automatic and continuous deployment (i.e., CD practice). Goal: This study aims at empirically investigating and classifying the factors that may impact on adopting and implementing CD practice. Method: We conducted a mixed-method empirical study consisting of interviewing 21 software practitioners, followed by a survey with 98 respondents. Results: Our study reveals 11 confounding factors that limit or demotivate software organizations to push changes automatically and continuously to production. The most important ones are ""lack of automated (user) acceptance test"", ""manual quality check"", ""deployment as business decision"", ""insufficient level of automated test coverage"", and ""highly bureaucratic deployment process"". Conclusion: Our findings highlight several areas for future research and provide suggestions for practitioners to streamline deployment process.";continuous delivery, continuous deployment, DevOps, empirical study;;;ESEM '17
Conference Paper;Bass L,Holz R,Rimba P,Tran AB,Zhu L;Securing a Deployment Pipeline;;2015;;;4–7;;IEEE Press;Florence, Italy;;Proceedings of the Third International Workshop on Release Engineering;;2015;;;;;"At the RELENG 2014 Q&A, the question was asked, ""What is your greatest concern?"" and the response was ""someone subverting our deployment pipeline"". That is the motivation for this paper. We explore what it means to subvert a pipeline and provide several different scenarios of subversion. We then focus on the issue of securing a pipeline. As a result, we provide an engineering process that is based on having trusted components mediate access to sensitive portions of the pipeline from other components, which can remain untrusted. Applying our process to a pipeline we constructed involving Chef, Jenkins, Docker, Github, and AWS, we find that some aspects of our process result in easy to make changes to the pipeline, whereas others are more difficult. Consequently, we have developed a design that hardens the pipeline, although it does not yet completely secure it.";DevOps, continuous deployment, supply chain;;;RELENG '15
Journal Article;Chen L;Continuous Delivery;J. Syst. Softw.;2017;128;C;72–86;;Elsevier Science Inc.;USA;;;;2017-06;;0164-1212;"https://doi-org.proxy.bnl.lu/10.1016/j.jss.2017.02.013;http://dx.doi.org/10.1016/j.jss.2017.02.013";10.1016/j.jss.2017.02.013;"Present six strategies to overcome Continuous Delivery (CD) adoption challenges.Identify and elaborate eight further challenges for research.They are based on four years CD adoption experience at a multi-billion-euro company. Continuous Delivery (CD) is a relatively new software development approach. Companies that have adopted CD have reported significant benefits. Motivated by these benefits, many companies would like to adopt CD. However, adopting CD can be very challenging for a number of reasons, such as obtaining buy-in from a wide range of stakeholders whose goals may seemingly be different fromor even conflict withour own; gaining sustained support in a dynamic complex enterprise environment; maintaining an application development team's momentum when their application's migration to CD requires an additional strenuous effort over a long period of time; and so on. To help overcome the adoption challenges, I present six strategies: (1) selling CD as a painkiller; (2) establishing a dedicated team with multi-disciplinary members; (3) continuous delivery of continuous delivery; (4) starting with the easy but important applications; (5) visual CD pipeline skeleton; (6) expert drop. These strategies were derived from four years of experience in implementing CD at a multi-billion-euro company. Additionally, our experience led to the identification of eight further challenges for research. The information contributes toward building a body of knowledge for CD adoption.";Adoption, Agile Software Development, Continuous Deployment, Continuous Delivery, DevOps, Continuous Software Engineering;;;
Conference Paper;Bass L,Holz R,Rimba P,Tran AB,Zhu L;Securing a Deployment Pipeline;;2015;;;4–7;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 3rd International Workshop on Release Engineering;;2015;9781467370707;;"https://doi-org.proxy.bnl.lu/10.1109/RELENG.2015.11;http://dx.doi.org/10.1109/RELENG.2015.11";10.1109/RELENG.2015.11;"At the RELENG 2014 Q&A, the question was asked, ""What is your greatest concern?"" and the response was ""someone subverting our deployment pipeline"". That is the motivation for this paper. We explore what it means to subvert a pipeline and provide several different scenarios of subversion. We then focus on the issue of securing a pipeline. As a result, we provide an engineering process that is based on having trustworthy components mediate access to sensitive portions of the pipeline from other components, which can remain untrustworthy. Applying our process to a pipeline involving Chef, Jenkins, Docker, Github, and AWS, we find that some aspects of our process result in easy to make changes to the pipeline, whereas others are more difficult. Consequently, we have developed a design that hardens the pipeline, although it does not yet completely secure it.";continuous deployment, DevOps, supply chain;;;RELENG '15
Conference Paper;Armenise V;Continuous Delivery with Jenkins: Jenkins Solutions to Implement Continuous Delivery;;2015;;;24–27;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 3rd International Workshop on Release Engineering;;2015;9781467370707;;"https://doi-org.proxy.bnl.lu/10.1109/RELENG.2015.19;http://dx.doi.org/10.1109/RELENG.2015.19";10.1109/RELENG.2015.19;This paper illustrates how Jenkins evolved from being a pure Continuous Integration Platform to a Continuous Delivery one, embracing the new design tendency where not only the build but also the release and the delivery process of the product is automated. In this scenario Jenkins becomes the orchestrator tool for all the teams/roles involved in the software lifecycle, thanks to which Development, Quality&Assurance and Operations teams can work closely together.Goal of this paper is not only to position Jenkins as hub for CD, but also introduce the challenges that still need to be solved in order to strengthen Jenkins' tracking capabilities.;;;;RELENG '15
Conference Paper;Armenise V;Continuous Delivery with Jenkins: Jenkins Solutions to Implement Continuous Delivery;;2015;;;24–27;;IEEE Press;Florence, Italy;;Proceedings of the Third International Workshop on Release Engineering;;2015;;;;;This paper illustrates how Jenkins evolved from being a pure Continuous Integration Platform to a Continuous Delivery one, embracing the new design tendency where not only the build but also the release and the delivery process of the product is automated. In this scenario Jenkins becomes the orchestrator tool for all the teams/roles involved in the software lifecycle, thanks to which Development, Quality&Assurance and Operations teams can work closely together.Goal of this paper is not only to position Jenkins as hub for CD, but also introduce the challenges that still need to be solved in order to strengthen Jenkins' tracking capabilities.;;;;RELENG '15
Book;Humble J,Farley D;Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation;;2010;;;;1st;Addison-Wesley Professional;;;;;2010;9780321601919;;;;Getting software released to users is often a painful, risky, and time-consuming process. This groundbreaking new book sets out the principles and technical practices that enable rapid, incremental delivery of high quality, valuable new functionality to users. Through automation of the build, deployment, and testing process, and improved collaboration between developers, testers, and operations, delivery teams can get changes released in a matter of hours sometimes even minutesno matter what the size of a project or the complexity of its code base. Jez Humble and David Farley begin by presenting the foundations of a rapid, reliable, low-risk delivery process. Next, they introduce the deployment pipeline, an automated process for managing all changes, from check-in to release. Finally, they discuss the ecosystem needed to support continuous delivery, from infrastructure, data and configuration management to governance. The authors introduce state-of-the-art techniques, including automated infrastructure management and data migration, and the use of virtualization. For each, they review key issues, identify best practices, and demonstrate how to mitigate risks. Coverage includes Automating all facets of building, integrating, testing, and deploying software Implementing deployment pipelines at team and organizational levels Improving collaboration between developers, testers, and operations Developing features incrementally on large and distributed teams Implementing an effective configuration management strategy Automating acceptance testing, from analysis to implementation Testing capacity and other non-functional requirements Implementing continuous deployment and zero-downtime releases Managing infrastructure, data, components and dependencies Navigating risk management, compliance, and auditing Whether youre a developer, systems administrator, tester, or manager, this book will help your organization move from idea to release faster than everso you can deliver value to your business rapidly and reliably.;;;;
Conference Paper;Chen L;Continuous Delivery: Overcoming Adoption Obstacles;;2016;;;84;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the International Workshop on Continuous Software Evolution and Delivery;Austin, Texas;2016;9781450341578;;"https://doi-org.proxy.bnl.lu/10.1145/2896941.2896956;http://dx.doi.org/10.1145/2896941.2896956";10.1145/2896941.2896956;Continuous Delivery (CD) can bring huge benefits, but implementing CD is challenging. For some challenges, one can only see them when he/she travels on the journey far enough. Paddy Power has been implementing CD for more than three years. In this talk, I will present the major obstacles we encountered and how we addressed them. These obstacles cover various areas, including organizational, cultural, process, and technical. I will also discuss the areas where I see researchers can help.;continuous delivery, continuous deployment, continuous software engineering, agile software development;;;CSED '16
Book;Pathania N;Pro Continuous Delivery: With Jenkins 2.0;;2017;;;;1st;Apress;USA;;;;2017;9781484229125;;;;Follow this step-by-step guide for creating a continuous delivery pipeline using all of the new features in Jenkins 2.0 such as Pipeline as a Code, multi-branch pipeline, and more. You will learnthree crucial elements for achieving a faster software delivery pipeline: a fungible build/test environment, manageable and reproducible pipelines, and a scalable build/test infrastructure. Pro Continuous Delivery demonstrates how to create a highly available, active/passive Jenkins server using some niche technologies. What You'll Learn Create a highly available, active/passive Jenkins server using CoreOS and Docker, and using Pacemaker and Corosync Use a Jenkins multi-branch pipeline to automatically perform continuous integration whenever there is a new branch in your source control system Describe your continuous delivery pipeline with Jenkinsfile Host Jenkins server on a cloud solution Run Jenkins inside a container using Docker Discover how the distributed nature of Git and the merge before build feature of Jenkins can be used to implement gated check-in Implement a scalable build farm using Docker and Kubernetes Who This Book Is For You have experience implementing continuous integration and continuous delivery using Jenkins freestyle Jobs and wish to use the new Pipeline as a Code feature introduced in Jenkins 2.0 Yoursource code is on a Git-like version control system (Git, GitHub, GitLab, etc.) and you wish to leverage the advantages of a multi-branch pipeline in Jenkins Your infrastructure is on a Unix-like platform and you wish to create a scalable, distributed build/test farm using Docker or Kubernetes You arein need of a highly available system for your Jenkins Server using open source tools and technologies;;;;
Conference Paper;Shahin M;Architecting for DevOps and Continuous Deployment;;2015;;;147–148;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference;Adelaide, SA, Australia;2015;9781450337960;;"https://doi-org.proxy.bnl.lu/10.1145/2811681.2824996;http://dx.doi.org/10.1145/2811681.2824996";10.1145/2811681.2824996;Development and Operations (DevOps) in the context of Continuous Deployment (CD) have emerged as an attractive software development movement, which tries to establish a strong connection between development and operations teams. CD is defined as the ability to quickly put new releases into production. We believe that DevOps/CD brings new challenges for architects, which considerably impacts both on their (architectural) design decisions and their organizational responsibilities. We assert that there is an important and urgent need of sufficient research work to gain a deep understanding of how DevOps/CD adoption can influence architecting, architectural decision-making processes and their outcomes in an organization. This PhD research is aimed at understanding and addressing new challenges for designing architectures for supporting DevOps in the context of CD.;continuous deployment, DevOps, Software architecture;;;ASWEC ' 15 Vol. II
Book;Fleming S;Continuous Delivery Handbook: Non Programmers Guide to DevOps, Microservices and Kubernetes;;2018;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2018;9781727257359;;;;"Are you a non-coder looking for insight into Continuous Delivery with DevOps, Microservices Architecture and Kubernetes?- You may be a Consultant, Advisor, Project Manager or a novice into IT industry; after going through this guide you would be able to appreciate Continuous Delivery through DevOps, Microservices and other related concepts like Kanban, Scrum, Agile, SOA, Monolith Architecture, DevOps, Docker, Kubernetes etc.- This guide will clarify your conceptual queries with case studies, examples and diagrams.- You would also get to know about the leaders in DevOps and Microservices adoption and impact it had on the overall agility and hyper-growth of the adopters. This book covers the complete lifecycle for your understanding like Integrating, Testing, Deploying DevOps and Microservices architecture and the Security concerns while deploying it.- I am confident that after going through the book you would be able to navigate the discussion with any stakeholder and take your agenda ahead as per your role. Additionally, if you are new to the industry, and looking for an application development job, this book will help you to prepare with all the relevant information and understanding of the topic.- So, as Charles Darwin Said It is not the strongest of the species that survive, or the most intelligent, but the one most responsive to change. Be adaptive to the changes in the software Development Industry and ride ahead with Continuous Delivery.- ** I am also providing additional booklet containing all the relevant news, trends, and resources for DevOps and Microservices Architecture.";;;;
Conference Paper;Kärpänoja P,Virtanen A,Lehtonen T,Mikkonen T;Exploring Peopleware in Continuous Delivery;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Scientific Workshop Proceedings of XP2016;Edinburgh, Scotland, UK;2016;9781450341349;;"https://doi-org.proxy.bnl.lu/10.1145/2962695.2962708;http://dx.doi.org/10.1145/2962695.2962708";10.1145/2962695.2962708;Traditionally, releasing new software has been a fragile and painful procedure. This view has been challenged by a new approach to software deployment, where the goal is to always be able to deploy the system. The transition from manual releases to instant deployments requires a high degree of automation. Furthermore, the transition requires a new mindset, where both developers and operators act together to deliver value to end users. As this process involves humans and cooperation, developers and their attitude towards the new way of working is important. To this end, in this paper we study the developer perspective of applying continuous delivery in the light of interviewing practitioners working for projects where continuous delivery practices are applied. More precisely, we place the focus on how continuous delivery practices affect software developers and what are the prerequisites for achieving continuous delivery. Based on our research, higher quality and other benefits of continuous delivery can be achieved by giving developers more responsibility. Still, the added responsibilities do not necessarily increase stress, but can actually decrease it, and at the same time improve motivation and job satisfaction.;peopleware, lead time, continuous delivery, deployment pipeline, Lean development;;;XP '16 Workshops
Conference Paper;Mäkinen S,Lehtonen T,Kilamo T,Puonti M,Mikkonen T,Männistö T;Revisiting Continuous Deployment Maturity: A Two-Year Perspective;;2019;;;1810–1817;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing;Limassol, Cyprus;2019;9781450359337;;"https://doi-org.proxy.bnl.lu/10.1145/3297280.3297458;http://dx.doi.org/10.1145/3297280.3297458";10.1145/3297280.3297458;Background: Achieving a steady stream of small releases and employing practices such as continuous deployment requires maturity in company processes. Maturity models provide one approach for companies to pinpoint areas of improvement by providing a position and hints to reflect on. Incorporating maturity models with agile software development and continuous deployment has its challenges, though. Aims: The focus of the study is in understanding the evolution of software processes towards continuous deployment in an industry organization over time when a maturity model is used as a yardstick in evaluation. Method: An embedded case study by design, the study utilizes and replicates a survey on the state of software projects in a large Finnish software company, Solita. The survey was initially conducted in 2015 with responses from 35 projects and now replicated in 2017 with responses from 43 projects. Both quantitative and qualitative approaches for survey responses are used in the analysis. Results: Maturity of software processes in the case company show improvement in deployment and in monitoring, albeit short of statistical significance. Technological advances in the application of cloud computing have likely spurred development in these areas. Capability in processes related to test automation and quality has not changed much in two years. Conclusions: Maintaining maturity in software processes requires constant attention as impressions on process quality can gradually diminish. Projects which are built on a compatible technology stack have a greater chance in achieving continuous deployment and thus being more mature. Customer preferences also make a difference in the ability to reach certain maturity levels.;;;;SAC '19
Conference Paper;Savor T,Douglas M,Gentili M,Williams L,Beck K,Stumm M;Continuous Deployment at Facebook and OANDA;;2016;;;21–30;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 38th International Conference on Software Engineering Companion;Austin, Texas;2016;9781450342056;;"https://doi-org.proxy.bnl.lu/10.1145/2889160.2889223;http://dx.doi.org/10.1145/2889160.2889223";10.1145/2889160.2889223;Continuous deployment is the software engineering practice of deploying many small incremental software updates into production, leading to a continuous stream of 10s, 100s, or even 1,000s of deployments per day. High-profile Internet firms such as Amazon, Etsy, Facebook, Flickr, Google, and Netflix have embraced continuous deployment. However, the practice has not been covered in textbooks and no scientific publication has presented an analysis of continuous deployment.In this paper, we describe the continuous deployment practices at two very different firms: Facebook and OANDA. We show that continuous deployment does not inhibit productivity or quality even in the face of substantial engineering team and code size growth. To the best of our knowledge, this is the first study to show it is possible to scale the size of an engineering team by 20X and the size of the code base by 50X without negatively impacting developer productivity or software quality. Our experience suggests that top-level management support of continuous deployment is necessary, and that given a choice, developers prefer faster deployment. We identify elements we feel make continuous deployment viable and present observations from operating in a continuous deployment environment.;;;;ICSE '16
Journal Article;Leppanen M,Makinen S,Pagels M,Eloranta VP,Itkonen J,Mantyla MV,Mannisto T;The Highways and Country Roads to Continuous Deployment;IEEE Softw.;2015;32;2;64–72;;IEEE Computer Society Press;Washington, DC, USA;;;;2015-03;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2015.50;http://dx.doi.org/10.1109/MS.2015.50";10.1109/MS.2015.50;As part of a Finnish research program, researchers interviewed 15 information and communications technology companies to determine the extent to which the companies adopted continuous deployment. They also aimed to find out why continuous deployment is considered beneficial and what the obstacles are to its full adoption. The benefits mentioned the most often were the ability to get faster feedback, the ability to deploy more often to keep customers satisfied, and improved quality and productivity. Despite understanding the benefits, none of the companies adopted a fully automatic deployment pipeline. The companies also had higher continuous-deployment capability than what they practiced. In many cases, they consciously chose to not aim for full continuous deployment. Obstacles to full adoption included domain-imposed restrictions, resistance to change, customer desires, and developers' skill and confidence.;;;;
Conference Paper;Artač M,Borovšak T,Di Nitto E,Guerriero M,Tamburri DA;Model-Driven Continuous Deployment for Quality DevOps;;2016;;;40–41;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2nd International Workshop on Quality-Aware DevOps;Saarbrücken, Germany;2016;9781450344111;;"https://doi-org.proxy.bnl.lu/10.1145/2945408.2945417;http://dx.doi.org/10.1145/2945408.2945417";10.1145/2945408.2945417;DevOps entails a series of software engineering strategies and tools that promise to deliver quality and speed at the same time with little or no additional expense. In our work we strived to enable a DevOps way of working, combining Model-Driven Engineering tenets with the challenges of delivering a model-driven continuous deployment tool that allows quick (re-)deployment of cloud applications for the purpose of continuous improvement. This paper illustrates the DICER tool and elaborates on how it can bring about the DevOps promise and enable the quality-awareness.;Quality-Aware DevOps, Model-Driven Engineering, Continuous Deployment;;;QUDOS 2016
Conference Paper;Chen L;Continuous Delivery at Scale: Challenges and Opportunities;;2018;;;42;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 4th International Workshop on Rapid Continuous Software Engineering;Gothenburg, Sweden;2018;9781450357456;;"https://doi-org.proxy.bnl.lu/10.1145/3194760.3194764;http://dx.doi.org/10.1145/3194760.3194764";10.1145/3194760.3194764;Continuous Delivery (CD) can bring huge benefits, but implementing CD is challenging. This is particularly true for implementing CD at an ultra-large-scale (across an R&D organization of tens of thousands of staff) for mission critical systems. In this talk, I will present the challenges in implementing CD in such a large scale and discuss the potential research opportunities.;agile software development, continuous deployment, continuous delivery, devops, continuous software engineering;;;RCoSE '18
Conference Paper;Itkonen J,Udd R,Lassenius C,Lehtonen T;Perceived Benefits of Adopting Continuous Delivery Practices;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Ciudad Real, Spain;2016;9781450344272;;"https://doi-org.proxy.bnl.lu/10.1145/2961111.2962627;http://dx.doi.org/10.1145/2961111.2962627";10.1145/2961111.2962627;Context: In continuous delivery, the aim is that every feature passes through the integration and deployment pipeline, resulting in an immediately deployable product. This practice has been proposed to accelerate value delivery, improve software quality and increase developer productivity.Goal: We investigate the adoption of continuous delivery practices and evaluate the related benefits in a single customer-supplier organization. We focus on the perceived benefits of supplier and customer organizations during a five-year transition period.Method: We performed an exploratory case study. We used semi-structured interviews and thematic analysis.Results: Increased communication and collaboration between developers and customer was perceived as one of the core benefits. Other reported benefits were increased productivity, improved product quality, improved developer morale as well as infrastructural independence and organizational agnosticism.Conclusions: The results indicate that the adoption of continuous software engineering practices bring various benefits for both customers and developers, beyond mere increased pace of production deployments.;case study, continuous delivery;;;ESEM '16
Book;Mason S,Blackburn C,Swarts E,Ashton S,Winter D,Foster R,MacDonald R,Morton L,Wood N,Dudhia F;A Field Guide To Continuous Delivery;;2016;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2016;9781530121410;;;;For teams of software engineers, it's important to be able to deliver great software reliably and quickly, whilst keeping pain points to an absolute minimum. Contrary to traditional software delivery practices, Continuous Delivery allows teams to get software into the hands of their customers at a much faster rate by encouraging greater communication, more frequent collaboration and by automating as much of your deployment process as possible. Written by the team at Made Tech, this book consists of ten chapters, each of which covers a different facet of Continuous Delivery. Over the course of the book, youll learn: What Continuous Delivery is:Discover how and why it was created, and what it ultimately means to practice Continuous Delivery. What the benefits areContinuous Delivery can impact your business in many different, positive ways, and this book discusses the most significant benefits you'll encounter, from minimising risk during deployments, to bringing new features to market much more quickly. How to prepare your team for the transition to a new way of workingPracticing Continuous Delivery brings with it fundamental changes to the way work is approached, and change can famously be difficult at times. Learn how to deal with the most concerns you'll face. The tools you'll needContinuous Delivery falls under the huge umbrella that is DevOps, so it's important to know which tools you should be looking out for to get you started, and what options you have available. How to setup the most important tool: the pipelineThe pipeline is the backbone of any team that practices Continuous Delivery, and this book will teach you how to build yours from the ground up, from development to production. How to keep quality highGood Continuous Delivery allows you to spend more time writing quality software, and the book details a number of best practices worth adopting that will facilitate great code, from feature toggles to test-driven development. The challenges you may faceA single team adopting Continuous Delivery may find it relatively simple, but an entire organisation will face significantly more challenges. This book will teach you how to overcome those challenges, and how you can keep evolving your Continuous Delivery practices to negate any new problems that may arise.;;;;
Conference Paper;Chen L;Towards Architecting for Continuous Delivery;;2015;;;131–134;;IEEE Computer Society;USA;;Proceedings of the 2015 12th Working IEEE/IFIP Conference on Software Architecture;;2015;9781479919222;;"https://doi-org.proxy.bnl.lu/10.1109/WICSA.2015.23;http://dx.doi.org/10.1109/WICSA.2015.23";10.1109/WICSA.2015.23;Continuous Delivery (CD) has emerged as an auspicious software development discipline, with the promise of providing organizations the capability to release valuable software continuously to customers. Our organization has been implementing CD for the last two years. Thus far, we have moved 22 software applications to CD. I observed that CD has created a new context for architecting these applications. In this paper, I will try to characterize such a context of CD, explain why we need to architect for CD, describe the implications of architecting for CD, and discuss the challenges this new context creates. This information can provide insights to other practitioners for architecting their software applications, and provide researchers with input for developing their research agendas to further study this increasingly important topic.;non-functional requirements, architecturally significant requirements, continuous deployment, software architecture, DevOps, quality attributes, continuous software engineering, continuous delivery;;;WICSA '15
Book Chapter;Pereira IM,Carneiro TG,Figueiredo E;Investigating Continuous Delivery on IoT Systems;;2021;;;;;Association for Computing Machinery;New York, NY, USA;XX Brazilian Symposium on Software Quality;;;2021;9781450395533;;https://doi-org.proxy.bnl.lu/10.1145/3493244.3493261;;IoT systems have continuous delivery challenges related to development, operations, and hardware teams. Therefore, scientific research and industry professionals have investigated approaches to integrate these areas and overcome these challenges. This study investigates how IoT systems projects adapt to perform Continuous Deliveries (CD) through thirty-one semi-structured interviews and a questionnaire with thirty professionals working in these areas. Inspired by grounded theory, we applied open coding to categorize the results of both interview and questionnaire studies. As contributions, we identified differences in IoT systems development compared to traditional development. We also discuss quality practices used in IoT projects that drive continuous delivery and how teams handle the quest for continuous delivery challenges.;;;;
Conference Paper;Yaman SG,Sauvola T,Riungu-Kalliosaari L,Hokkanen L,Kuvaja P,Oivo M,Männistö T;Customer Involvement in Continuous Deployment: A Systematic Literature Review;;2016;;;249–265;;Springer-Verlag;Berlin, Heidelberg;;Proceedings of the 22nd International Working Conference on Requirements Engineering: Foundation for Software Quality - Volume 9619;Gothenburg, Sweden;2016;9783319302812;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-319-30282-9_18;http://dx.doi.org/10.1007/978-3-319-30282-9_18";10.1007/978-3-319-30282-9_18;[Context and motivation] In order to build successful software products and services, customer involvement and an understanding of customers' requirements and behaviours during the development process are essential. [Question/Problem] Although continuous deployment is gaining attention in the software industry as an approach for continuously learning from customers, there is no common overview of the topic yet. [Principal ideas/results] To provide a common overview, we conduct a secondary study that explores the state of reported evidence on customer input during continuous deployment in software engineering, including the potential benefits, challenges, methods and tools of the field. [Contribution] We report on a systematic literature review covering 25 primary studies. Our analysis of these studies reveals that although customer involvement in continuous deployment is highly relevant in the software industry today, it has been relatively unexplored in academic research. The field is seen as beneficial, but there are a number of challenges related to it, such as misperceptions among customers. In addition to providing a comprehensive overview of the research field, we clarify the gaps in knowledge that need to be studied further.;Continuous deployment, User feedback, Customer feedback, User involvement, Customer involvement, Software development, Continuous delivery;;;REFSQ 2016
Journal Article;Parnin C,Helms E,Atlee C,Boughton H,Ghattas M,Glover A,Holman J,Micco J,Murphy B,Savor T,Stumm M,Whitaker S,Williams L;The Top 10 Adages in Continuous Deployment;IEEE Softw.;2017;34;3;86–95;;IEEE Computer Society Press;Washington, DC, USA;;;;2017-05;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2017.86;http://dx.doi.org/10.1109/MS.2017.86";10.1109/MS.2017.86;Continuous deployment involves automatically testing incremental software changes and frequently deploying them to production environments. With it, developers' changes can reach customers in days or even hours. Such ultrafast changes create a new reality in software development. To understand the emerging practices surrounding continuous deployment, researchers facilitated a one-day Continuous Deployment Summit at the Facebook campus in July 2015, at which participants from 10 companies described how they used continuous deployment. From the resulting conversation, the researchers derived 10 adages about continuous-deployment practices. These adages represent a working set of approaches and beliefs that guide current practice and establish a tangible target for empirical validation by the research community.;;;;
Book;Olausson M,Ehn J;Continuous Delivery with Visual Studio ALM 2015;;2015;;;;1st;Apress;USA;;;;2015;9781484212738;;;;This book is the authoritative source on implementing Continuous Delivery practices using Microsofts Visual Studio and TFS 2015. Microsoft MVP authors Mathias Olausson and Jakob Ehn translate the theory behind this methodology and show step by step how to implement Continuous Delivery in a real world environment. Building good software is challenging. Building high-quality software on a tight schedule can be close to impossible. Continuous Delivery is an agile and iterative technique that enables developers to deliver solid, working software in every iteration. Continuous delivery practices help IT organizations reduce risk and potentially become as nimble, agile, and innovative as startups. In this book, you'll learn: What Continuous Delivery is and how to use it to create better software more efficiently using Visual Studio 2015 How to use Team Foundation Server 2015 and Visual Studio Online to plan, design, and implement powerful and reliable deployment pipelines Detailed step-by-step instructions for implementing Continuous Delivery on a real project;;;;
Conference Paper;Virtanen A,Kuusinen K,Leppänen M,Luoto A,Kilamo T,Mikkonen T;On Continuous Deployment Maturity in Customer Projects;;2017;;;1205–1212;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Symposium on Applied Computing;Marrakech, Morocco;2017;9781450344869;;"https://doi-org.proxy.bnl.lu/10.1145/3019612.3019777;http://dx.doi.org/10.1145/3019612.3019777";10.1145/3019612.3019777;The practice of making new software available to end users as soon as it gets implemented is becoming commonplace. This paper investigates a set of projects and their development practices in a mid-sized Finnish software company Solita Ltd. to understand how continuous deployment practices are applied in development teams. This was done by establishing a maturity scale and using it to survey the teams. In addition, we interviewed members of selected teams to understand why a particular level of maturity is desirable for a project, and to reveal the issues that impact team's ability to improve. We found that while the team, the customer, and the product all benefit from mature development practices associated with continuous deployment, some obstacles can be solved only by changing the organizational modus operandi.;DevOps, systems thinking, lean software development, agile, maturity model, continuous delivery;;;SAC '17
Conference Paper;Rahman AA,Helms E,Williams L,Parnin C;Synthesizing Continuous Deployment Practices Used in Software Development;;2015;;;1–10;;IEEE Computer Society;USA;;Proceedings of the 2015 Agile Conference;;2015;9781467371537;;"https://doi-org.proxy.bnl.lu/10.1109/Agile.2015.12;http://dx.doi.org/10.1109/Agile.2015.12";10.1109/Agile.2015.12;Continuous deployment speeds up the process of existing agile methods, such as Scrum, and Extreme Programming (XP) through the automatic deployment of software changes to end-users upon passing of automated tests. Continuous deployment has become an emerging software engineering process amongst numerous software companies, such as Facebook, Github, Netflix, and Rally Software. A systematic analysis of software practices used in continuous deployment can facilitate a better understanding of continuous deployment as a software engineering process. Such analysis can also help software practitioners in having a shared vocabulary of practices and in choosing the software practices that they can use to implement continuous deployment. The goal of this paper is to aid software practitioners in implementing continuous deployment through a systematic analysis of software practices that are used by software companies. We studied the continuous deployment practices of 19 software companies by performing a qualitative analysis of Internet artifacts and by conducting follow-up inquiries. In total, we found 11 software practices that are used by 19 software companies. We also found that in terms of use, eight of the 11 software practices are common across 14 software companies. We observe that continuous deployment necessitates the consistent use of sound software engineering practices such as automated testing, automated deployment, and code review.;follow-up inquiries, industry practices, agile, internet artifacts, continuous delivery, continuous deployment;;;AGILE '15
Book;Leszko R;Continuous Delivery with Docker and Jenkins: Delivering Software at Scale;;2017;;;;;Packt Publishing;;;;;2017;9781787125230;;;;Key Features Build reliable and secure applications using Docker containers. Create a complete Continuous Delivery pipeline using Docker, Jenkins, and Ansible. Deliver your applications directly on the Docker Swarm cluster. Create more complex solutions using multi-containers and database migrations. Book Description The combination of Docker and Jenkins improves your Continuous Delivery pipeline using fewer resources. It also helps you scale up your builds, automate tasks and speed up Jenkins performance with the benefits of Docker containerization. This book will explain the advantages of combining Jenkins and Docker to improve the continuous integration and delivery process of app development. It will start with setting up a Docker server and configuring Jenkins on it. It will then provide steps to build applications on Docker files and integrate them with Jenkins using continuous delivery processes such as continuous integration, automated acceptance testing, and configuration management. Moving on you will learn how to ensure quick application deployment with Docker containers along with scaling Jenkins using Docker Swarm. Next, you will get to know how to deploy applications using Docker images and testing them with Jenkins. By the end of the book, you will be enhancing the DevOps workflow by integrating the functionalities of Docker and Jenkins. What you will learnGet to grips with docker fundamentals and how to dockerize an application for the Continuous Delivery process Configure Jenkins and scale it using Docker-based agents Understand the principles and the technical aspects of a successful Continuous Delivery;;;;
Conference Paper;Jong M,van Deursen A;Continuous Deployment and Schema Evolution in SQL Databases;;2015;;;16–19;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 3rd International Workshop on Release Engineering;;2015;9781467370707;;"https://doi-org.proxy.bnl.lu/10.1109/RELENG.2015.14;http://dx.doi.org/10.1109/RELENG.2015.14";10.1109/RELENG.2015.14;Continuous Deployment is an important enabler of rapid delivery of business value and early end user feedback. While frequent code deployment is well understood, the impact of frequent change on persistent data is less understood and supported. SQL schema evolutions in particular can make it expensive to deploy a new version, and may even lead to downtime if schema changes can only be applied by blocking operations. In this paper we study the problem of continuous deployment in the presence of database schema evolution in more detail. We identify a number of shortcomings to existing solutions and tools, mostly related to avoidable downtime and support for foreign keys. We propose a novel approach to address these problems, and provide an open source implementation. Initial evaluation suggests the approach is effective and sufficiently efficient.;SQL databases, schema evolution, Continuous Deployment;;;RELENG '15
Conference Paper;Austel P,Chen H,Mikalsen T,Rouvellou I,Sharma U,Silva-Lepe I,Subramanian R;Continuous Delivery of Composite Solutions: A Case for Collaborative Software Defined PaaS Environments;;2015;;;3–6;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2nd International Workshop on Software-Defined Ecosystems;Portland, Oregon, USA;2015;9781450335683;;"https://doi-org.proxy.bnl.lu/10.1145/2756594.2756595;http://dx.doi.org/10.1145/2756594.2756595";10.1145/2756594.2756595;To help drive top line growth of their businesses, the development and IT organizations are under increasing pressure to create and deliver applications at ever faster paces. The advent of Cloud Computing has not only lowered the cost of IT operations but also enabled the notion of continuous delivery, which promises to radically reduce frictions in DevOps processes and speed up the product delivery cycle. With increased demand on functionality and feature, we have also seen these applications becoming more sophisticated, often integrating multiple modern programming models and techniques with the traditional n-tier web application into a composite application. This paper proposes an architectural blueprint for improved continuous delivery of these complex composite applications. It treats a solution as a holistic entity comprised of application logic and software-defined environment that the logic relies on. It also proposes a collaborative approach to software-defined Platform-as-a-Service environment building. This being an ongoing research project, this paper also briefly describes prototype, work-in-progress and thoughts on future directions.;continuous delivery, solution lifecycle, software-defined environment, platform-as-a-service, cloud computing;;;BigSystem '15
Conference Paper;Chen L;Research Opportunities in Continuous Delivery: Reflections from Two Years' Experiences in a Large Bookmaking Company;;2015;;;2;;IEEE Press;Florence, Italy;;Proceedings of the Third International Workshop on Release Engineering;;2015;;;;;We have been implementing continuous delivery in Paddy Power, a large organization in the bookmaking industry, for more than two years. In this talk, I will reflect on our journey to continuous delivery and discuss the research opportunities I see.;release engineering, continuous software engineering, DevOps, continuous delivery, agile software development, continuous deployment;;;RELENG '15
Conference Paper;Chen L;Research Opportunities in Continuous Delivery: Reflections from Two Years' Experiences in a Large Bookmaking Company;;2015;;;2;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 3rd International Workshop on Release Engineering;;2015;9781467370707;;"https://doi-org.proxy.bnl.lu/10.1109/RELENG.2015.9;http://dx.doi.org/10.1109/RELENG.2015.9";10.1109/RELENG.2015.9;We have been implementing continuous delivery in Paddy Power, a large organization in the bookmaking industry, for more than two years. In this talk, I will reflect on our journey to continuous delivery and discuss the research opportunities I see.;agile software development, continuous deployment, Continuous delivery, continuous software engineering, DevOps, release engineering;;;RELENG '15
Journal Article;Chen L;Continuous Delivery: Huge Benefits, but Challenges Too;IEEE Softw.;2015;32;2;50–54;;IEEE Computer Society Press;Washington, DC, USA;;;;2015-03;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2015.27;http://dx.doi.org/10.1109/MS.2015.27";10.1109/MS.2015.27;Continuous delivery (CD) has emerged as an auspicious alternative to traditional release engineering, promising to provide the capability to release valuable software continuously to customers. Paddy Power has been implementing CD for the past two years. This article explains why Paddy Power decided to adopt CD, describes the resulting CD capability, and reports the huge benefits and challenges involved. These experiences can provide fellow practitioners with insights for their adoption of CD, and the identified challenges can provide researchers valuable input for developing their research agendas.;;;;
Conference Paper;Kevic K,Murphy B,Williams L,Beckmann J;Characterizing Experimentation in Continuous Deployment: A Case Study on Bing;;2017;;;123–132;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track;;2017;9781538627174;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP.2017.19;http://dx.doi.org/10.1109/ICSE-SEIP.2017.19";10.1109/ICSE-SEIP.2017.19;The practice of continuous deployment enables product teams to release content to end users within hours or days, rather than months or years. These faster deployment cycles, along with rich product instrumentation, allows product teams to capture and analyze feature usage measurements. Product teams define a hypothesis and a set of metrics to assess how a code or feature change will impact the user. Supported by a framework, a team can deploy that change to subsets of users, enabling randomized controlled experiments. Based on the impact of the change, the product team may decide to modify the change, to deploy the change to all users, or to abandon the change. This experimentation process enables product teams to only deploy the changes that positively impact the user experience.The goal of this research is to aid product teams to improve their deployment process through providing an empirical characterization of an experimentation process when applied to a large-scale and mature service. Through an analysis of 21,220 experiments applied in Bing since 2014, we observed the complexity of the experimental process and characterized the full deployment cycle (from code change to deployment to all users). The analysis identified that the experimentation process takes an average of 42 days, including multiple iterations of one or two week experiment runs. Such iterations typically indicate that problems were found that could have hurt the users or business if the feature was just launched, hence the experiment provided real value to the organization.Further, we discovered that code changes for experiments are four times larger than other code changes. We identify that the code associated with 33.4% of the experiments is eventually shipped to all users. These fully-deployed code changes are significantly larger than the code changes for the other experiments, in terms of files (35.7%), changesets (80.4%) and contributors (20.0%).;full deployment cycle, empirical analysis, experimentation, continuous deployment;;;ICSE-SEIP '17
Conference Paper;Huijgens H,Spadini D,Stevens D,Visser N,van Deursen A;Software Analytics in Continuous Delivery: A Case Study on Success Factors;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Oulu, Finland;2018;9781450358231;;"https://doi-org.proxy.bnl.lu/10.1145/3239235.3240505;http://dx.doi.org/10.1145/3239235.3240505";10.1145/3239235.3240505;Background: During the period of one year, ING developed an approach for software analytics within an environment of a large number of software engineering teams working in a Continuous Delivery as a Service setting. Goal: Our objective is to examine what factors helped and hindered the implementation of software analytics in such an environment, in order to improve future software analytics activities. Method: We analyzed artifacts delivered by the software analytics project, and performed semi-structured interviews with 15 stakeholders. Results: We identified 16 factors that helped the implementation of software analytics, and 20 factors that hindered the project. Conclusions: Upfront defining and communicating the aims, standardization of data at an early stage, build efficient visualizations, and an empirical approach help companies to improve software analytics projects.;ING, software analytics, devops, software economics, experience report, continuous delivery;;;ESEM '18
Book;Farcic V;The DevOps 2.0 Toolkit: Automating the Continuous Deployment Pipeline with Containerized Microservices;;2016;;;;1st;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2016;9781523917440;;;;This book is about different techniques that help us architect software in a better and more efficient way with microservices packed as immutable containers, tested and deployed continuously to servers that are automatically provisioned with configuration management tools. It's about fast, reliable and continuous deployments with zero-downtime and ability to roll-back. It's about scaling to any number of servers, design of self-healing systems capable of recuperation from both hardware and software failures and about centralized logging and monitoring of the cluster. In other words, this book envelops the whole microservices development and deployment lifecycle using some of the latest and greatest practices and tools. We'll use Docker, Kubernetes, Ansible, Ubuntu, Docker Swarm and Docker Compose, Consul, etcd, Registrator, confd, and so on. We'll go through many practices and even more tools. Finally, while there will be a lot of theory, this is a hands-on book. You won't be able to complete it by reading it in a metro on a way to work. You'll have to read this book while in front of the computer and get your hands dirty.;;;;
Journal Article;Wettinger J,Breitenbücher U,Falkenthal M,Leymann F;Collaborative Gathering and Continuous Delivery of DevOps Solutions through Repositories;Comput. Sci.;2017;32;3–4;281–290;;Springer-Verlag;Berlin, Heidelberg;;;;2017-07;;1865-2034;"https://doi-org.proxy.bnl.lu/10.1007/s00450-016-0338-z;http://dx.doi.org/10.1007/s00450-016-0338-z";10.1007/s00450-016-0338-z;Collaboration is a key aspect for establishing DevOps-oriented processes because diverse experts such as developers and operations personnel need to efficiently work together to deliver applications. For this purpose, highly automated continuous delivery pipelines are established, consisting of several stages and their corresponding application environments (development, test, production, etc.). The DevOps community provides a huge variety of tools and reusable artifacts (i.e. DevOps solutions such as deployment engines, configuration definitions, container images, etc.) to implement such application environments. This paper presents the concept of collaborative solution repositories, which are based on established software engineering practices. This helps to systematically maintain and link diverse solutions. We further discuss how discovery and capturing of such solutions can be automated. To utilize this knowledge (made of linked DevOps solutions), we apply continuous delivery principles to create diverse knowledge base instances through corresponding pipelines. Finally, an integrated architecture is outlined and validated using a prototype implementation.;Solution repository, Knowledge, DevOps, Continuous delivery;;;
Conference Paper;de Jong M,van Deursen A;Continuous Deployment and Schema Evolution in SQL Databases;;2015;;;16–19;;IEEE Press;Florence, Italy;;Proceedings of the Third International Workshop on Release Engineering;;2015;;;;;Continuous Deployment is an important enabler of rapid delivery of business value and early end user feedback. While frequent code deployment is well understood, the impact of frequent change on persistent data is less understood and supported. SQL schema evolutions in particular can make it expensive to deploy a new version, and may even lead to downtime if schema changes can only be applied by blocking operations.In this paper we study the problem of continuous deployment in the presence of database schema evolution in more detail. We identify a number of shortcomings to existing solutions and tools, mostly related to avoidable downtime and support for foreign keys. We propose a novel approach to address these problems, and provide an open source implementation. Initial evaluation suggests the approach is effective and sufficiently efficient.;;;;RELENG '15
Conference Paper;Wettinger J,Andrikopoulos V,Leymann F;Enabling DevOps Collaboration and Continuous Delivery Using Diverse Application Environments;;2015;;;348–358;;Springer-Verlag;Berlin, Heidelberg;;Proceedings of the Confederated International Conferences on On the Move to Meaningful Internet Systems: OTM 2015 Conferences - Volume 9415;;2015;9783319261478;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-319-26148-5_23;http://dx.doi.org/10.1007/978-3-319-26148-5_23";10.1007/978-3-319-26148-5_23;Aiming to provide the means for efficient collaboration between development and operations personnel, the DevOps paradigm is backed by an increasingly growing collection of tools and reusable artifacts for application management. Continuous delivery pipelines are established based on these building blocks by implementing fully automated, end-to-end application delivery processes, which significantly shorten release cycles to reduce risks and costs as well as gaining a critical competitive advantage. Diverse application environments need to be managed along the pipeline such as development, build, test, and production environments. In this work we address the need for systematically specifying and maintaining diverse application environment topologies enriched with environment-specific requirements in order to implement continuous delivery pipelines. Beside the representation of such requirements, we focus on their systematic and collaborative resolution with respect to the individual needs of the involved application environments.;Requirements, Topology, DevOps, Pipeline, Continuous delivery;;;
Conference Paper;Rossi C,Shibley E,Su S,Beck K,Savor T,Stumm M;Continuous Deployment of Mobile Software at Facebook (Showcase);;2016;;;12–23;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering;Seattle, WA, USA;2016;9781450342186;;"https://doi-org.proxy.bnl.lu/10.1145/2950290.2994157;http://dx.doi.org/10.1145/2950290.2994157";10.1145/2950290.2994157;Continuous deployment is the practice of releasing software updates to production as soon as it is ready, which is receiving increased adoption in industry. The frequency of updates of mobile software has traditionally lagged the state of practice for cloud-based services for a number of reasons. Mobile versions can only be released periodically. Users can choose when and if to upgrade, which means that several different releases coexist in production. There are hundreds of Android hardware variants, which increases the risk of having errors in the software being deployed. Facebook has made significant progress in increasing the frequency of its mobile deployments. Over a period of 4 years, the Android release has gone from a deployment every 8 weeks to a deployment every week. In this paper, we describe in detail the mobile deployment process at FB. We present our findings from an extensive analysis of software engineering metrics based on data collected over a period of 7 years. A key finding is that the frequency of deployment does not directly affect developer productivity or software quality. We argue that this finding is due to the fact that increasing the frequency of continuous deployment forces improved release and deployment automation, which in turn reduces developer workload. Additionally, the data we present shows that dog-fooding and obtaining feedback from alpha and beta customers is critical to maintaining release quality.;Mobile code testing, Software release, Continuous deployment, Agile development, Continuous delivery;;;FSE 2016
Conference Paper;Toh MZ,Sahibuddin S,Mahrin MN;Adoption Issues in DevOps from the Perspective of Continuous Delivery Pipeline;;2019;;;173–177;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2019 8th International Conference on Software and Computer Applications;Penang, Malaysia;2019;9781450365734;;"https://doi-org.proxy.bnl.lu/10.1145/3316615.3316619;http://dx.doi.org/10.1145/3316615.3316619";10.1145/3316615.3316619;DevOps and Continuous Delivery (CD) are the terms that are always related to each other in Software Delivery and Operation Process area. DevOps introduces a significant agile perspective to deliver the software product in short cycle time that will reduce technical debt that is caused by delay. Continuous Delivery is one of the DevOps' practices that enables software organization to release new features and new products rapidly. However, the correct practices are still in ambiguity to the current CD process. This paper investigates the advantages and limitation of DevOps adoption to improve the CD process. A qualitative web survey has been conducted to identify the DevOps and Continuous Delivery advantages and adoption problems. 13 respondents' feedbacks have been collected and analyzed. Based on the survey, there are four significant DevOps' practices that need to be considered and developed as a proper guideline to introduce to practitioners.;continuous delivery, software operation, continuous integration, agile, continuous software engineering, agile operations, DevOps;;;ICSCA '19
Conference Paper;Giorgi F,Paulisch F;Transition towards Continuous Delivery in the Healthcare Domain;;2019;;;253–254;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP.2019.00035;http://dx.doi.org/10.1109/ICSE-SEIP.2019.00035";10.1109/ICSE-SEIP.2019.00035;Continuous Delivery is meanwhile well-established in many parts of the software industry. In a transition towards continuous delivery in the healthcare domain, there are a number of additional challenges that should be addressed. We present how we have addressed some of these challenges and highlight some potential research topics that could be addressed in this space to make further progress in this important area. Although our focus is on the healthcare domain, the approach and the research topics are applicable also to a broad range of other application domains.;behavior-driven development, pair-programming, domain-driven design, test-driven development, deployment pipeline, test automation, agile, continuous delivery;;;ICSE-SEIP '19
Book;Swartout P;Continuous Delivery and DevOps A Quickstart Guide: Start Your Journey to Successful Adoption of CD and DevOps, 3rd Edition;;2018;;;;3rd;Packt Publishing;;;;;2018;9781788995474;;;;A practical and engaging guide to help map out, plan and navigate through the journey to successful CD and DevOps adoption. Key Features Identify and overcome the issues that stifle the delivery of quality software Learn how Continuous Delivery and DevOps work together with other agile tools Real-world examples, tricks and tips that will help the successful adoption of CD & DevOps Book Description Over the past few years, Continuous Delivery (CD) and DevOps have been in the spotlight in tech media, at conferences, and in boardrooms alike. Many articles and books have been written covering the technical aspects of CD and DevOps, yet the vast majority of the industry doesn't fully understand what they actually are and how, if adopted correctly they can help organizations drastically change the way they deliver value. This book will help you figure out how CD and DevOps can help you to optimize, streamline, and improve the way you work to consistently deliver quality software. In this edition, you'll be introduced to modern tools, techniques, and examples to help you understand what the adoption of CD and DevOps entails. It provides clear and concise insights in to what CD and DevOps are all about, how to go about both preparing for and adopting them, and what quantifiable value they bring. You will be guided through the various stages of adoption, the impact they will have on your business and those working within it, how to overcome common problems, and what to do once CD and DevOps have become truly embedded. Included within this book are some real-world examples, tricks, and tips that will help ease the adoption process and allow you to fully utilize the power of CD and DevOps What you will learn Explore Continuous Delivery and DevOps in depth Discover how CD and DevOps fits in with recent trends such as DataOps, SecOps, pipelines and CI Understand the root causes of the pain points within your existing product delivery process Understand the human elements of CD and DevOps and how intrinsic they are to your success Avoid common traps, pitfalls and hurdles as you implement CD and DevOps Monitor and communicate the relative success of DevOps and CD adoption Extend and reuse CD and DevOps approaches Who this book is for Whether you are a software developer, a system administrator, an agile coach, a product manager, a project manager, a CTO, a VP, a CEO or anyone else involved in software delivery, you will have a common problem which is delivering quality software. This book has been written for anyone and everyone who wants to understand how to regularly deliver quality software to their customers without said pain.;;;;
Conference Paper;Shahin M,Zahedi M,Babar MA,Zhu L;Adopting Continuous Delivery and Deployment: Impacts on Team Structures, Collaboration and Responsibilities;;2017;;;384–393;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering;Karlskrona, Sweden;2017;9781450348041;;"https://doi-org.proxy.bnl.lu/10.1145/3084226.3084263;http://dx.doi.org/10.1145/3084226.3084263";10.1145/3084226.3084263;"Context: Continuous Delivery and Deployment (CD) practices aim to deliver software features more frequently and reliably. While some efforts have been made to study different aspects of CD practices, a little empirical work has been reported on the impact of CD on team structures, collaboration and team members' responsibilities. Goal: Our goal is to empirically investigate how Development (Dev) and Operations (Ops) teams are organized in software industry for adopting CD practices. Furthermore, we explore the potential impact of practicing CD on collaboration and team members' responsibilities. Method:We conducted a mixed-method empirical study, which collected data from 21 in-depth, semi-structured interviews in 19 organizations and a survey with 93 software practitioners. Results: There are four common types of team structures (i.e., (1) separate Dev and Ops teams with higher collaboration; (2) separate Dev and Ops teams with facilitator(s) in the middle; (3) small Ops team with more responsibilities for Dev team; (4) no visible Ops team) for organizing Dev and Ops teams to effectively initiate and adopt CD practices. Our study also provides insights into how software organizations actually improve collaboration among teams and team members for practicing CD. Furthermore, we highlight new responsibilities and skills (e.g., monitoring and logging skills), which are needed in this regard.";Continuous delivery and deployment, empirical study, collaboration, development and operations teams;;;EASE'17
Conference Paper;Soltani J;Adopting Continuous Delivery in AAA Console Games;;2016;;;5–6;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 4th International Workshop on Release Engineering;Seattle, WA, USA;2016;9781450343992;;"https://doi-org.proxy.bnl.lu/10.1145/2993274.2993276;http://dx.doi.org/10.1145/2993274.2993276";10.1145/2993274.2993276;Introduction Games are traditionally developed as a boxed-product. There is a development phase, followed by a bug-fixing phase. Once the level of quality is acceptable, game is released, development team moves on to a new project. They rarely need to maintain the product and release updates after the first few months. Games are architected as a monolithic application, developed in C++. Game package contains the executable and all the art contents, which makes up most of the package. During the development phase, the level of quality is generally low, game crashes a lot. Developers mainly care about implementing their own feature and do not think too much about the stability and quality of the game as a whole. Developers spend very little time writing automated tests and rely on manual testers to verify features. It's a common practice to develop features on feature branches. The perceived benefit is developers are productive because they can submit their work to feature branches. All features come together in the bug-fixing phase when all different parts are integrated together. At this stage, many things are broken. This is a clear example of local optimisation, as a feature submitted in a feature branch does not provide any values until it’s integrated with the rest of the game and can be released. Number of bugs could be several thousands. Everyone crunches whilst getting the game to an acceptable level. Rare’s Approach At Rare, we decided to change our approach and adopt Continuous Delivery. The main advantages compared to traditional approach are: •Sustainably delivering new features that are useful to players over a long period of time. •Minimising crunch and having happier and productive developers. •Applying hypothesis-driven development mind-set and getting rapid feedback on whether a feature is achieving the intended outcome. This allows us to listen to user feedback and deliver a better quality game that’s more fun and enjoyable for players. •Reduce the cost of having a large manual test team.;Trunk-based development, Video Games, C++, Large scale systems, Agile, Continuous Delivery;;;RELENG 2016
Conference Paper;Akerele O,Ramachandran M,Dixon M;System Dynamics Modeling of Agile Continuous Delivery Process;;2013;;;60–63;;IEEE Computer Society;USA;;Proceedings of the 2013 Agile Conference;;2013;9780769550763;;"https://doi-org.proxy.bnl.lu/10.1109/AGILE.2013.28;http://dx.doi.org/10.1109/AGILE.2013.28";10.1109/AGILE.2013.28;The popularization of agile development as well as the recent prevalence of virtualization and cloud computing has revolutionized the software delivery process- making it faster and affordable for businesses to release their software continuously. Hence, the need for a reliable and predictable delivery process for software applications. The aim of this paper is to develop a System Dynamics (SD) model to achieve a repetitive, risk-free and effortless Continuous Delivery process to reduce the perils of delayed delivery, delivery cost overrun and poor quality delivered software.;System Dynamics, Continuous Delivery, Delivery Pipeline, Agile software development;;;AGILE '13
Conference Paper;Shahin M,Babar MA,Zhu L;The Intersection of Continuous Deployment and Architecting Process: Practitioners' Perspectives;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Ciudad Real, Spain;2016;9781450344272;;"https://doi-org.proxy.bnl.lu/10.1145/2961111.2962587;http://dx.doi.org/10.1145/2961111.2962587";10.1145/2961111.2962587;Context: Development and Operations (DevOps) is an emerging software industry movement to bridge the gap between software development and operations teams. DevOps supports frequently and reliably releasing new features and products-- thus subsuming Continuous Deployment (CD) practice. Goal: This research aims at empirically exploring the potential impact of CD practice on architecting process. Method: We carried out a case study involving interviews with 16 software practitioners. Results: We have identified (1) a range of recurring architectural challenges (i.e., highly coupled monolithic architecture, team dependencies, and ever-changing operational environments and tools) and (2) five main architectural principles (i.e., small and independent deployment units, not too much focus on reusability, aggregating logs, isolating changes, and testability inside the architecture) that should be considered when an application is (re-) architected for CD practice. This study also supports that software architecture can better support operations if an operations team is engaged at an early stage of software development for taking operational aspects into considerations. Conclusion: These findings provide evidence that software architecture plays a significant role in successfully and efficiently adopting continuous deployment. The findings contribute to establish an evidential body of knowledge about the state of the art of architecting for CD practice;Software architecture, DevOps, continuous deployment, empirical study;;;ESEM '16
Book Chapter;Ferry N,Nguyen PH;Towards Model-Based Continuous Deployment of Secure IoT Systems;;2019;;;613–618;;IEEE Press;;Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems;;;2019;9781728151250;;https://doi-org.proxy.bnl.lu/10.1109/MODELS-C.2019.00093;;Software development and delivery of IoT systems would greatly benefit from DevOps as their requirements for reliability, quality, security and privacy are paramount. The ability to continuously evolve these systems to adapt to their environment is decisive to ensure and increase their trustworthiness (including security and privacy) and quality. In particular, there is a need for supporting the continuous deployment of secure IoT systems over IoT, Edge, and Cloud infrastructures. However, our recent survey shows a lack of specific support for deploying security and privacy mechanisms as part of the system. This position paper reports on an on-going extension of the modelling language and models@runtime implementation of the Generation and Deployment of Smart IoT Systems (GeneSIS) tool for supporting continuous deployment of IoT security and privacy mechanisms on the Edge. In particular, we present our early design of the extended version of GeneSIS with the new concepts of port, security capability, and privacy capability.;;;;
Conference Paper;Dlugi M,Brunnert A,Krcmar H;Model-Based Performance Evaluations in Continuous Delivery Pipelines;;2015;;;25–26;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1st International Workshop on Quality-Aware DevOps;Bergamo, Italy;2015;9781450338172;;"https://doi-org.proxy.bnl.lu/10.1145/2804371.2804376;http://dx.doi.org/10.1145/2804371.2804376";10.1145/2804371.2804376;In order to increase the frequency of software releases and to improve their quality, continuous integration (CI) systems became widely used in recent years. Unfortunately, it is not easy to evaluate the performance of a software release in such systems. One of the main reasons for this difficulty is often the lack of a test environment that is comparable to a production system. Performance models can help in this scenario by eliminating the need for a production-sized environment. Building upon these capabilities of performance models, we have introduced a model-based performance change detection process for continuous delivery pipelines in a previous work. This work presents an implementation of the process as plug-in for the CI system Jenkins.;Palladio Component Model, Performance Evaluation, Continuous Delivery, Performance Change Detection;;;QUDOS 2015
Conference Paper;Düllmann TF,Paule C,van Hoorn A;Exploiting Devops Practices for Dependable and Secure Continuous Delivery Pipelines;;2018;;;27–30;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 4th International Workshop on Rapid Continuous Software Engineering;Gothenburg, Sweden;2018;9781450357456;;"https://doi-org.proxy.bnl.lu/10.1145/3194760.3194763;http://dx.doi.org/10.1145/3194760.3194763";10.1145/3194760.3194763;Continuous delivery (CD) pipelines recently gained wide adoption. They provide means for short and high-frequent development cycles in DevOps by automating many steps after a commit has been issued and bringing it into production. CD pipelines have become essential for development and delivery. Hence, they are crucial and business-critical assets that need to be protected from harm in terms of dependability and security. DevOps practices like canary releasing and A/B testing aim to improve the quality of the software that is built by CD pipelines while keeping a high pace of development. Although CD is a part of DevOps, the DevOps practices have primarily been applied to the artifacts that are processed but not on the pipelines themselves. We outline our vision of using these DevOps practices to improve the dependability and security of CD pipelines. The goal is to detect, diagnose, and resolve dependability and security issues in the CD pipeline behavior. In this paper, we outline our envisioned roadmap and preliminary results from an ongoing industrial case study.;;;;RCoSE '18
Book Chapter;Nehls H,Ratiu D;Towards Continuous Delivery for Domain Experts: Using MDE to Integrate Non-Programmers into a Software Delivery Pipeline;;2019;;;598–604;;IEEE Press;;Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems;;;2019;9781728151250;;https://doi-org.proxy.bnl.lu/10.1109/MODELS-C.2019.00091;;"Modern computed tomography (CT) scanners are complex, software-intensive systems whose correct functioning is governed by over 100 parameters which depend on the concrete hardware configurations and on the addressed clinical use-cases. To tame the intrinsic complexity of the parameters configurations, over the last four years, Siemens Healthineers (SHS) have been developing and deploying a set of domain specific languages and tooling based on Jetbrains' Meta-Programming System.In this paper, we report on the challenges and experiences we made while building two delivery pipelines. At meta-level, we built a continuous delivery pipeline such that new versions of our domain specific modeling tool can be deployed continuously based on the feedback of domain experts. At model-level we have integrated the developed domain-specific tool in the continuous delivery pipeline for the computed tomography software and thereby bring the Continuous Delivery mind-set with advantages and challenges to domain experts who are working traditionally ""outside"" of the software development.";;;;
Conference Paper;Krusche S,Alperowitz L;Introduction of Continuous Delivery in Multi-Customer Project Courses;;2014;;;335–343;;Association for Computing Machinery;New York, NY, USA;;Companion Proceedings of the 36th International Conference on Software Engineering;Hyderabad, India;2014;9781450327688;;"https://doi-org.proxy.bnl.lu/10.1145/2591062.2591163;http://dx.doi.org/10.1145/2591062.2591163";10.1145/2591062.2591163;Continuous delivery is a set of practices and principles to release software faster and more frequently. While it helps to bridge the gap between developers and operations for software in production, it can also improve the communication between developers and customers in the development phase, i.e. before software is in production. It shortens the feedback cycle and developers ideally use it right from the beginning of a software development project. In this paper we describe the implementation of a customized continuous delivery workflow and its benefits in a multi-customer project course in summer 2013. Our workflow focuses on the ability to deliver software with only a few clicks to the customer in order to obtain feedback as early as possible. This helps developers to validate their understanding about requirements, which is especially helpful in agile projects where requirements might change often. We describe how we integrated this workflow and the role of the release manager into our project-based organization and how we introduced it using different teaching methods. Within three months 90 students worked in 10 different projects with real customers from industry and delivered 490 releases. After the project course we evaluated our approach in an online questionnaire and in personal interviews. Our findings and observations show that participating students understood and applied the concepts and are convinced about the benefits of continuous delivery.;Executable Prototypes, Release Management, Continuous Delivery, User Involvement, Continuous Integration, Version Control System, DevOps, Feedback;;;ICSE Companion 2014
Conference Paper;de Jong M,van Deursen A,Cleve A;Zero-Downtime SQL Database Schema Evolution for Continuous Deployment;;2017;;;143–152;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track;;2017;9781538627174;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP.2017.5;http://dx.doi.org/10.1109/ICSE-SEIP.2017.5";10.1109/ICSE-SEIP.2017.5;When a web service or application evolves, its database schema --- tables, constraints, and indices --- often need to evolve along with it. Depending on the database, some of these changes require a full table lock, preventing the service from accessing the tables under change. To deal with this, web services are typically taken offline momentarily to modify the database schema. However with the introduction of concepts like Continuous Deployment, web services are deployed into their production environments every time the source code is modified. Having to take the service offline --- potentially several times a day --- to perform schema changes is undesirable. In this paper we introduce QuantumDB--- a tool-supported approach that abstracts this evolution process away from the web service without locking tables. This allows us to redeploy a web service without needing to take it offline even when a database schema change is necessary. In addition QuantumDB puts no restrictions on the method of deployment, supports schema changes to multiple tables using changesets, and does not subvert foreign key constraints during the evolution process. We evaluate QuantumDB by applying 19 synthetic and 95 industrial evolution scenarios to our open source implementation of QuantumDB. These experiments demonstrate that QuantumDB realizes zerodowntime migrations at the cost of acceptable overhead, and is applicable in industrial continuous deployment contexts.;;;;ICSE-SEIP '17
Conference Paper;Klemets J,Storholmen TC;Towards Super User-Centred Continuous Delivery: A Case Study;;2020;;;152–165;;Springer-Verlag;Berlin, Heidelberg;;Human-Centered Software Engineering: 8th IFIP WG 13.2 International Working Conference, HCSE 2020, Eindhoven, The Netherlands, November 30 – December 2, 2020, Proceedings;Eindhoven, The Netherlands;2020;9783030642655;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-64266-2_9;http://dx.doi.org/10.1007/978-3-030-64266-2_9";10.1007/978-3-030-64266-2_9;To develop well designed socio-technical systems for a particular context user involvement is essential. Emerging software development approaches that enable continuous delivery of software functionalities provide new opportunities as to how users can be involved in shaping the design. We present a case study of a software project at a Norwegian engineering and construction company in their effort to move towards a user-centred development approach that leverages on continuous delivery principles. We investigate how user representatives in form of super users have been involved in the process and their role in forming and implementing new digital technology in practice. We conclude that utilising super users have been instrumental to design a system that meet users’ needs. Providing opportunities to test the system in a production environment gave rise to new ideas on how to further refine the design. Involving super users also facilitated system adoption among workers.;Continuous software engineering, Qualitative research, User-centred design, Super users, Agile development;;;
Conference Paper;Krusche S,Alperowitz L,Bruegge B,Wagner MO;Rugby: An Agile Process Model Based on Continuous Delivery;;2014;;;42–50;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1st International Workshop on Rapid Continuous Software Engineering;Hyderabad, India;2014;9781450328562;;"https://doi-org.proxy.bnl.lu/10.1145/2593812.2593818;http://dx.doi.org/10.1145/2593812.2593818";10.1145/2593812.2593818;In this paper we introduce Rugby, an agile process model that includes workflows for the continuous delivery of software. It allows part-timers to work in a project-based organization with multiple projects for the rapid delivery of prototypes and products. We show how continuous delivery improves the development process in two ways: First, Rugby improves the interaction between developers and customers with a continuous feedback mechanism. Second, Rugby improves the coordination and communication with stakeholders and across multiple teams in project-based organizations with event based releases. We have evaluated Rugby in two large university software engineering capstone courses with up to 100 participants working in 10 simultaneous projects with industry partners in 2012 and 2013. We describe the metrics used in the evaluation. First results indicate that Rugby increases the frequency and quality of the interaction between developers and customers leading to improved results in the delivered products.;Continuous Integration, Feedback, Software Evolution, Agile Methods, Version Control System, Continuous Delivery, Executable Prototypes, Release Management, Communication Models, User Involvement;;;RCoSE 2014
Journal Article;Shahin M,Zahedi M,Babar MA,Zhu L;An Empirical Study of Architecting for Continuous Delivery and Deployment;Empirical Softw. Engg.;2019;24;3;1061–1108;;Kluwer Academic Publishers;USA;;;;2019-06;;1382-3256;"https://doi-org.proxy.bnl.lu/10.1007/s10664-018-9651-4;http://dx.doi.org/10.1007/s10664-018-9651-4";10.1007/s10664-018-9651-4;"Recently, many software organizations have been adopting Continuous Delivery and Continuous Deployment (CD) practices to develop and deliver quality software more frequently and reliably. Whilst an increasing amount of the literature covers different aspects of CD, little is known about the role of software architecture in CD and how an application should be (re-) architected to enable and support CD. We have conducted a mixed-methods empirical study that collected data through in-depth, semi-structured interviews with 21 industrial practitioners from 19 organizations, and a survey of 91 professional software practitioners. Based on a systematic and rigorous analysis of the gathered qualitative and quantitative data, we present a conceptual framework to support the process of (re-) architecting for CD. We provide evidence-based insights about practicing CD within monolithic systems and characterize the principle of ""small and independent deployment units"" as an alternative to the monoliths. Our framework supplements the architecting process in a CD context through introducing the quality attributes (e.g., resilience) that require more attention and demonstrating the strategies (e.g., prioritizing operations concerns) to design operations-friendly architectures. We discuss the key insights (e.g., monoliths and CD are not intrinsically oxymoronic) gained from our study and draw implications for research and practice.";Continuous deployment, DevOps, Continuous delivery, Empirical study, Software architecture;;;
Conference Paper;Bentes J;Service Platform for Continuous Delivery of Assisted Living Systems;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Doctoral Symposium of the 17th International Middleware Conference;Trento, Italy;2016;9781450346658;;"https://doi-org.proxy.bnl.lu/10.1145/3009925.3009931;http://dx.doi.org/10.1145/3009925.3009931";10.1145/3009925.3009931;A smart home has potential to support independent living of elderly people in their preferred living environments. However, smart home systems do not fully address the aims of Ambient assisted living (AAL), mainly due to limited support outside the home. This need of continuous delivery of assistance for elderly people on the go require technology which extends the home into the society. This ongoing work proposes to identify the architectural requirements for a service platform being able to continuously deliver assistive services at home and beyond.;Distributed Computing, Continuous Assistance, Smart Home, Intelligent Environment, Ambient Assisted Living;;;Middleware Doctoral Symposium'16
Book Chapter;Prens D,Alfonso I,Garcés K,Guerra-Gomez J;Continuous Delivery of Software on IoT Devices;;2019;;;734–735;;IEEE Press;;Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems;;;2019;9781728151250;;https://doi-org.proxy.bnl.lu/10.1109/MODELS-C.2019.00112;;Given the dynamic environment and changing conditions on the Internet of Things (IoT), developers need to periodically update software and deploy new versions on smart devices and edge devices such as gateways. A software update can generate unforeseen downtimes, or can also alter the device resource consumption. Therefore, we propose an approach that deals with the need for (semi)automating deployment, monitoring and visualization of the impact of software updates on devices operation. We use modeling to abstract the concepts that matter in the domain of continuous software delivery for IoT devices. This abstraction was implemented on top of time series and document-oriented databases.;;;;
Conference Paper;Gardner P;Microfabricated Silicon NanoPORE Membranes Provide Continuous Delivery of Biopharmaceuticals;;2005;;;179;;IEEE Computer Society;USA;;Proceedings of the 2005 International Conference on MEMS,NANO and Smart Systems;;2005;9780769523989;;"https://doi-org.proxy.bnl.lu/10.1109/ICMENS.2005.70;http://dx.doi.org/10.1109/ICMENS.2005.70";10.1109/ICMENS.2005.70;Continuous delivery of bio-pharmaceuticals can provide important patient benefits including improved safety, better compliance, more convenience and, in some instance, improved efficacy. Drugs released from devices implanted under the skin, including mechanical pumps, are able to reach a steady state level in plasma which, in theory, can be maintained for months. In practice, however, mechanical pumps face two key limitations: small volume/drug carrying capacity and formulation instability. In general, for proper pumping action, the drug must be in solution within the device reservoir, either in an aqueous medium or in a biocompatible, water-miscible solvent such as ethanol or DMSO. Solubility of the drug and its compatibility with the solvent thus profoundly influence the amount of the agent that can be loaded. Drugs with limited solubility are inappropriate for devices intended to act for months. In fact, even among soluble drugs, only the most potent can be considered for such a delivery option. Moreover, most biopharmaceuticals are unstable in solution at body temperature and thus drug degradation limits the duration of time the device will can be expected to function. The non-mechanical drug delivery device described here (NanoGATE) is designed to address these limitations. The mechanism of delivery relies on the unexpected finding that diffusion from a reservoir containing a high concentration of a solute to a reservoir of lower concentration through microfabricated nanochannels which, in their smallest demission are only 2 to 3 times the hydrodynamic diameter of solute itself, is physically constrained and thus does not obey Fickian predictions. Indeed, under proper conditions, zero-order diffusion is seen despite the existence of large concentration gradients across the nanochannels.;;;;ICMENS '05
Conference Paper;Laukkanen E,Paasivaara M,Itkonen J,Lassenius C,Arvonen T;Towards Continuous Delivery by Reducing the Feature Freeze Period: A Case Study;;2017;;;23–32;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track;;2017;9781538627174;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP.2017.21;http://dx.doi.org/10.1109/ICSE-SEIP.2017.21";10.1109/ICSE-SEIP.2017.21;Today, many software companies continuously deliver and deploy new features to their customers. However, many software systems are still released traditionally with long feature freeze periods and time-based releases due to historical reasons. Currently, only a few empirical inquiries of transformations towards continuous delivery exist. In this paper, we aim to understand how feature freeze was practiced and the feature freeze period reduced in an R&D program at Ericsson. The case organization has struggled with the feature freeze approach and is now moving towards the continuous delivery paradigm. We investigated the intended and actual effects of the feature freeze practice, how the feature freeze period was reduced and what effects the reduction had. We interviewed 11 employees, covering all the development teams at the largest site of the distributed organization. In addition, we analyzed data from software repositories to get quantitative triangulation of the qualitative results. Historically, the organization was not able to comply with the intended feature freeze practice, due to pressure for new feature development and long feature freeze periods leaving little time to perform actual development. By implementing test automation, the organization was able to reduce the feature freeze period by 56%, after which the amount of changes during the freeze decreased by 63% and the amount of changes close to the release date by 59%. We conclude that reducing the feature freeze period is possible using test automation, and reducing the freeze time can increase conformance to the intended feature freeze practice. To further reduce feature freeze, attention must be paid to deployment automation and collaboration between development and operations, in addition to test automation.;continuous delivery, code freeze, feature freeze, devops, release stabilization, continuous integration, continuous deployment, case study;;;ICSE-SEIP '17
Conference Paper;Bolscher R,Daneva M;Designing Software Architecture to Support Continuous Delivery and DevOps: A Systematic Literature Review;;2019;;;27–39;;SCITEPRESS - Science and Technology Publications, Lda;Setubal, PRT;;Proceedings of the 14th International Conference on Software Technologies;Prague, Czech Republic;2019;9789897583797;;"https://doi-org.proxy.bnl.lu/10.5220/0007837000270039;http://dx.doi.org/10.5220/0007837000270039";10.5220/0007837000270039;This paper presents a systematic literature review of software architecture approaches that support the implementation of Continuous Delivery (CD) and DevOps. Its goal is to provide an understanding of the stateof-the-art on the topic, which is informative for both researchers and practitioners. We found 17 characteristics of a software architecture that are beneficial for CD and DevOps adoption and identified ten potential software architecture obstacles in adopting CD and DevOps in the case of an existing software system. Moreover, our review indicated that micro-services are a dominant architectural style in this context. Our literature review has some implications: for researchers, it provides a map of the recent research efforts on software architecture in the CD and DevOps domain. For practitioners, it describes a set of software architecture principles that possibly can guide the process of creating or adapting software systems to fit in the CD and DevOps context.;DevOps, Continuous Delivery, Deployability, Micro-services., Systematic Literature Review, Software Architecture, Continuous Integration;;;ICSOFT 2019
Conference Paper;Bae J,Kim J;An Experimental Continuous Delivery Framework for SmartX-Mini IoT-Cloud Playground;;2016;;;348–350;;IEEE Computer Society;USA;;Proceedings of the 2016 International Conference on Information Networking (ICOIN);;2016;9781509017249;;"https://doi-org.proxy.bnl.lu/10.1109/ICOIN.2016.7427129;http://dx.doi.org/10.1109/ICOIN.2016.7427129";10.1109/ICOIN.2016.7427129;Internet of Things (IoT), one of the hottest research targets, needs the systematic leverage from cloud-centric ICT infrastructure. Among several challenges for fast and economic IoT-Cloud service enablement, the continuous integration and delivery (CI/CD) framework is one of commonly wanted capabilities. In this paper, we introduce early experience with deploying an experimental continuous delivery framework for SmartX-mini IoT-Cloud Playground.;;;;ICOIN '16
Conference Paper;Klepper S,Krusche S,Peters S,Bruegge B,Alperowitz L;Introducing Continuous Delivery of Mobile Apps in a Corporate Environment: A Case Study;;2015;;;5–11;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 2nd International Workshop on Rapid Continuous Software Engineering;;2015;9781467370677;;"https://doi-org.proxy.bnl.lu/10.1109/RCoSE.2015.9;http://dx.doi.org/10.1109/RCoSE.2015.9";10.1109/RCoSE.2015.9;Software development is conducted in increasingly dynamic business environments. Organizations need the capability to develop, release and learn from software in rapid parallel cycles. The abilities to continuously deliver software, to involve users, and to collect and prioritize their feedback are necessary for software evolution. In 2014, we introduced Rugby, an agile process model with workflows for continuous delivery and feedback management, and evaluated it in university projects together with industrial clients. Based on Rugby's release management workflow we identified the specific needs for project-based organizations developing mobile applications. Varying characteristics and restrictions in projects teams in corporate environments impact both process and infrastructure. We found that applicability and acceptance of continuous delivery in industry depend on its adaptability. To address issues in industrial projects with respect to delivery process, infrastructure, neglected testing and continuity, we extended Rugby's workflow and made it tailor able. Eight projects at Cap Gemini, a global provider of consulting, technology and outsourcing services, applied a tailored version of the workflow. The evaluation of these projects shows anecdotal evidence that the application of the workflow significantly reduces the time required to build and deliver mobile applications in industrial projects, while at the same time increasing the number of builds and internal deliveries for feedback.;Agile Methods, Release Management, Continuous Delivery, Software Evolution, User Feedback, Configuration Management, Continuous Integration, User Involvement;;;RCOSE '15
Book Chapter;Leite L,Kon F,Pinto G,Meirelles P;Building a Theory of Software Teams Organization in a Continuous Delivery Context;;2020;;;296–297;;Association for Computing Machinery;New York, NY, USA;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings;;;2020;9781450371223;;https://doi-org.proxy.bnl.lu/10.1145/3377812.3390807;;Based on Grounded Theory guidelines, we interviewed 27 IT professionals to investigate how organizations pursuing continuous delivery should organize their development and operations teams. In this paper, we present the discovered organizational structures: (1) siloed departments, (2) classical DevOps, (3) cross-functional teams, and (4) platform teams.;;;;
Conference Paper;Klepper S,Krusche S,Peters S,Bruegge B,Alperowitz L;Introducing Continuous Delivery of Mobile Apps in a Corporate Environment: A Case Study;;2015;;;5–11;;IEEE Press;Florence, Italy;;Proceedings of the Second International Workshop on Rapid Continuous Software Engineering;;2015;;;;;Software development is conducted in increasingly dynamic business environments. Organizations need the capability to develop, release and learn from software in rapid parallel cycles. The abilities to continuously deliver software, to involve users, and to collect and prioritize their feedback are necessary for software evolution. In 2014, we introduced Rugby, an agile process model with workflows for continuous delivery and feedback management, and evaluated it in university projects together with industrial clients.Based on Rugby's release management workflow we identified the specific needs for project-based organizations developing mobile applications. Varying characteristics and restrictions in projects teams in corporate environments impact both process and infrastructure. We found that applicability and acceptance of continuous delivery in industry depend on its adaptability. To address issues in industrial projects with respect to delivery process, infrastructure, neglected testing and continuity, we extended Rugby's workflow and made it tailorable.Eight projects at Capgemini, a global provider of consulting, technology and outsourcing services, applied a tailored version of the workflow. The evaluation of these projects shows anecdotal evidence that the application of the workflow significantly reduces the time required to build and deliver mobile applications in industrial projects, while at the same time increasing the number of builds and internal deliveries for feedback.;software evolution, user feedback, continuous delivery, continuous integration, agile methods, user involvement, configuration management, release management;;;RCoSE '15
Journal Article;Humble J;Continuous Delivery Sounds Great, but Will It Work Here? It’s Not Magic, It Just Requires Continuous, Daily Improvement at All Levels;Queue;2017;15;6;57–76;;Association for Computing Machinery;New York, NY, USA;;;;2017-12;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/3178368.3190610;http://dx.doi.org/10.1145/3178368.3190610";10.1145/3178368.3190610;Continuous delivery is a set of principles, patterns, and practices designed to make deployments predictable, routine affairs that can be performed on demand at any time. This article introduces continuous delivery, presents both common objections and actual obstacles to implementing it, and describes how to overcome them using real-life examples. Continuous delivery is not magic. It’s about continuous, daily improvement at all levels of the organization.;;;;
Conference Paper;Gupta RK,Venkatachalapathy M,Jeberla FK;Challenges in Adopting Continuous Delivery and DevOps in a Globally Distributed Product Team: A Case Study of a Healthcare Organization;;2019;;;30–34;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 14th International Conference on Global Software Engineering;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICGSE.2019.00-10;http://dx.doi.org/10.1109/ICGSE.2019.00-10";10.1109/ICGSE.2019.00-10;"This paper presents our experiences in a project of a software engineering team spread across three countries that successfully established continuous delivery, DevOps and short release cycles with agile scrum. We had the challenge to find a way from established regulatory heavy-weight processes, long release strategies, legacy tools and technologies and people mindset towards adopting continuous delivery and DevOps.We are describing our experiences in the journey towards timeboxed release strategies compared to legacy fixed scope-based releases; value stream-based execution compared to traditional milestone-based execution; operation, test, and infrastructure as a code compared to executing these activities manually. This paper also describes experiences in transforming traditional scrum team into a DevOps team, technological landscape into lightweight tools. The authors bring their experiences as a Project Manager, Quality Manager, and an Architect, who has been an integral part of this journey.These practices have helped in stabilizing processes and methods to an extent where we have released several products versions within a year. The other business units are adopting our practices for continuous delivery and DevOps. This paper also summaries our lessons learned, and recommendations.";test as code, operation as code, continuous delivery, DevOps;;;ICGSE '19
Journal Article;Humble J;Continuous Delivery Sounds Great, but Will It Work Here?;Commun. ACM;2018;61;4;34–39;;Association for Computing Machinery;New York, NY, USA;;;;2018-03;;0001-0782;"https://doi-org.proxy.bnl.lu/10.1145/3173553;http://dx.doi.org/10.1145/3173553";10.1145/3173553;It's not magic, it just requires continuous, daily improvement at all levels.;;;;
Journal Article;Sabau AR,Hacks S,Steffens A;Implementation of a Continuous Delivery Pipeline for Enterprise Architecture Model Evolution;Softw. Syst. Model.;2021;20;1;117–145;;Springer-Verlag;Berlin, Heidelberg;;;;2021-02;;1619-1366;"https://doi-org.proxy.bnl.lu/10.1007/s10270-020-00828-z;http://dx.doi.org/10.1007/s10270-020-00828-z";10.1007/s10270-020-00828-z;The discipline of enterprise architecture (EA) is an established approach to model and manage the interaction of business processes and IT in an organization. Thereby, the EA model as a central artifact of EA is subject to a continuous evolution caused by multiple sources of changes. The continuous evolution requires a lot of effort in controlling and managing the evolution of the EA model. This is especially true when merging the induced changes from different sources in the EA model. Additionally, the lack of tool and automation support makes this a very time-consuming and error-prone task. The evolutionary character and the automated quality assessment of artifacts is a well-known challenge in the software development domain as well. To meet these challenges, the discipline of continuous delivery (CD) has emerged to be very useful. The evolution of EA model artifacts shows similarities to the evolution of software artifacts. Therefore, we leveraged practices of CD to practices of EA maintenance. Thus, we created a conceptual framework for automated EA model maintenance. The concepts were realized in a first prototype and were evaluated in a fictitious case study against equivalence classes based on EA model metrics and a set of several requirements for automated EA model maintenance from research. Overall, the concepts prove to be a promising basis for further refinement, implementation, and evaluation in research in an industrial context.;Continuous delivery, Enterprise architecture model maintenance, Enterprise architecture model evolution;;;
Journal Article;Leite L,Pinto G,Kon F,Meirelles P;The Organization of Software Teams in the Quest for Continuous Delivery: A Grounded Theory Approach;Inf. Softw. Technol.;2021;139;C;;;Butterworth-Heinemann;USA;;;;2021-11;;0950-5849;"https://doi-org.proxy.bnl.lu/10.1016/j.infsof.2021.106672;http://dx.doi.org/10.1016/j.infsof.2021.106672";10.1016/j.infsof.2021.106672;;Release process, Software teams, Continuous delivery, DevOps;;;
Conference Paper;Bai X,Li M,Pei D,Li S,Ye D;Continuous Delivery of Personalized Assessment and Feedback in Agile Software Engineering Projects;;2018;;;58–67;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 40th International Conference on Software Engineering: Software Engineering Education and Training;Gothenburg, Sweden;2018;9781450356602;;"https://doi-org.proxy.bnl.lu/10.1145/3183377.3183387;http://dx.doi.org/10.1145/3183377.3183387";10.1145/3183377.3183387;"In recent years, Agile development has been adopted in project practices of Software Engineering (SE) courses. However, it is a great challenge to provide timely assessment and feedback to project teams and individual students with a frequency that catches up with iterative, incremental, and cooperative software development with continuous deliveries. Conventional project reviews are mostly dependent upon instructors and teaching assistants in a manual reviewing/mentoring approach, which are simply not scalable.In this paper, we argue that agile projects warrant a ""continuous delivery"" of personalized assessment and feedback. To this end, we propose an online-offline combined approach and built a system upon GitLab. An online platform was built by integrating DevOps tool chains so that personalized reports and assessments are delivered automatically to the teams/students, which serve as the very efficient trigger and basis for the close and targeted offline interactions between students and TAs: daily discussion over instant messaging and weekly in person meeting. This system has been in operation since 2014 for an undergraduate SE course, with over 500 students participating in over 130 project teams in total. Our results show that such a continuous assessment/feedback delivery system is very effective in educating Agile projects in SE courses.";project, agile, assessment, software engineering course, devops;;;ICSE-SEET '18
Conference Paper;Neely S,Stolt S;Continuous Delivery? Easy! Just Change Everything (Well, Maybe It Is Not That Easy);;2013;;;121–128;;IEEE Computer Society;USA;;Proceedings of the 2013 Agile Conference;;2013;9780769550763;;"https://doi-org.proxy.bnl.lu/10.1109/AGILE.2013.17;http://dx.doi.org/10.1109/AGILE.2013.17";10.1109/AGILE.2013.17;Rally Software transitioned from shipping code every eight-weeks, with time-boxed Scrum sprints, to a model of continuous delivery with Kanban. The team encountered complex challenges with their build systems, automated test suites, customer enablement, and internal communication. But there was light at the end of the tunnel - greater control and flexibility over feature releases, incremental delivery of value, lower risks, fewer defects, easier on-boarding of new developers, less off-hours work, and a considerable up tick in confidence. This experience report describes the journey to continuous delivery with the aim that others can learn from our mistakes and get their teams deploying more frequently. We will describe and contrast this transition from the business (product management) and engineering perspectives.;;;;AGILE '13
Conference Paper;Ünlü A,Armaundefinedan Ö,Levi A,Savas E,Erçetin Ö;Key Predistribution Schemes for Sensor Networks for Continuous Deployment Scenario;;2007;;;239–250;;Springer-Verlag;Berlin, Heidelberg;;Proceedings of the 6th International IFIP-TC6 Conference on Ad Hoc and Sensor Networks, Wireless Networks, next Generation Internet;Atlanta, GA, USA;2007;9783540726050;;;;In sensor networks, secure communication among sensor nodes requires secure links and consequently secure key establishment. Due to resource constraints, achieving such key establishment is non-trivial. Recently some random key predistribution techniques have been proposed to establish pairwise keys. Some of these approaches assume certain deployment knowledge is available prior to deployment and nodes are deployed in groups/bundles. In this paper, we propose another practical deployment model where nodes are deployed over a line one by one in a continuous fashion. In this model, sensor nodes can also be deployed over multiple parallel lines to cover two-dimensional area. Based on this model, we develop two key predistribution schemes. Analysis and simulation results show that our key predistribution schemes make use of the deployment knowledge better than the existing schemes. Thus they perform better than other location-aware protocols using the metrics of connectivity, resiliency, memory usage and communication cost for key establishment.;;;;NETWORKING'07
Conference Paper;Bisegna A,Carbone R,Ranise S;Integrating A Pentesting Tool For IdM Protocols In A Continuous Delivery Pipeline;;2021;;;94–110;;Springer-Verlag;Berlin, Heidelberg;;Emerging Technologies for Authorization and Authentication: 4th International Workshop, ETAA 2021, Darmstadt, Germany, October 8, 2021, Revised Selected Papers;Darmstadt, Germany;2021;9783030937461;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-93747-8_7;http://dx.doi.org/10.1007/978-3-030-93747-8_7";10.1007/978-3-030-93747-8_7;Identity Management (IdM) solutions are increasingly important for digital infrastructures of both enterprises and public administrations. Their security is a mandatory prerequisite for building trust in current and future digital ecosystems. IdM solutions are usually large-scale complex software systems maintained and developed by several groups of ICT professionals. Continuous Delivery (CD) pipeline is adopted to make maintenance, extension, and deployment of such solutions as efficient and repeatable as possible. For security, CD pipeline is also used as a continuous risk assessment to quickly evaluate the security impact of changes. Several tools have been developed and integrated in the CD pipeline to support this view in the so called DevSecOps approach with the notable exception of a tool for protocol pentesting and compliance against standards such as SAML 2.0, OAuth 2.0 and OpenID Connect. To fill this gap, we propose an approach to integrate Micro-Id-Gym—a tool for the automated pentesting of IdM deployments—in a CD pipeline. We report our experience in doing this and discuss the advantages of using the tool in the context of a joint effort with Poligrafico e Zecca dello Stato Italiano to build a digital identity infrastructure.;;;;
Conference Paper;Kuusinen K,Albertsen S;Industry-Academy Collaboration in Teaching DevOps and Continuous Delivery to Software Engineering Students: Towards Improved Industrial Relevance in Higher Education;;2019;;;23–27;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEET.2019.00011;http://dx.doi.org/10.1109/ICSE-SEET.2019.00011";10.1109/ICSE-SEET.2019.00011;Global industrial demand for highly skilled professional software engineers is increasing. Many countries already experience shortage of developer workforce and it is predicted that the industrial need for software engineers will grow on a higher rate than educational institutes are able to train new workforce. The main reasons for this deficit are in the education system's inability to adapt to current market needs and in difficulties in matching available skills with existing jobs. Therefore, increasing the industrial and market relevance of the education can be a key solution. Another significant contributor is teaching more efficient working methods such as automating repetitive parts of developer work to help to concentrate on tasks that directly create customer and business value. This paper presents the design and execution of a Continuous Delivery and DevOps course organized in company-university collaboration. The objective is to investigate how university courses requiring multidisciplinary lecturer skills and complex execution architectures can be organized in industry-academia collaboration to improve the industrial relevance of higher education.;agile software development, education courses, engineering education;;;ICSE-SEET '19
Journal Article;Gonzalez TF;Continuous Delivery Message Dissemination Problems under the Multicasting Communication Mode;IEEE Trans. Parallel Distrib. Syst.;2008;19;8;1034–1043;;IEEE Press;;;;;2008-08;;1045-9219;"https://doi-org.proxy.bnl.lu/10.1109/TPDS.2007.70801;http://dx.doi.org/10.1109/TPDS.2007.70801";10.1109/TPDS.2007.70801;We consider the Continuously Delivery Message Dissemination (CDMD) problem over the n processor single-port complete (all links are present and are bi-directional) static network with the multicasting communication primitive. This problem has been shown to be NP-complete even when all messages have equal length. For the CDMD problem we present an efficient approximation algorithm to construct a message routing schedule with total communication time at most 3.5d, where d is the total length of the messages that each processor needs to send or receive. The algorithm takes O(qn) time, where n is the number of processors and q is the total number of messages that the processors receive.;Routing and layout, Parallelism and concurrency, Graph algorithms, Data communications aspects;;;
Journal Article;Akerele O;System Dynamics Modelling of the Impact of Agile Practice on the Quality of Continuous Delivery Projects;Innov. Syst. Softw. Eng.;2018;14;3;183–208;;Springer-Verlag;Berlin, Heidelberg;;;;2018-09;;1614-5046;"https://doi-org.proxy.bnl.lu/10.1007/s11334-017-0296-z;http://dx.doi.org/10.1007/s11334-017-0296-z";10.1007/s11334-017-0296-z;The adoption of agile practices in software projects has been faced with scepticism by practitioners, with concerns about the actual effectiveness of these practices. Using system dynamics, this study investigates the impact of four popular agile practices, Test-Driven Development, Pair Programming, On-site Customer Involvement and Pair Testing, on the quality of continuous delivery projects. The developed system dynamic model, called the predictive continuous delivery model, was developed with an extensive use of existing literature, supported by survey, interviews, historical data and expert's judgement. Simulation results showed all the investigated agile practices except pair programming have a significant impact on the quality of continuous delivery projects.;System dynamics, Agile practices, Software quality, Continuous delivery;;;
Conference Paper;Laukkanen E,Lehtinen TO,Itkonen J,Paasivaara M,Lassenius C;Bottom-up Adoption of Continuous Delivery in a Stage-Gate Managed Software Organization;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Ciudad Real, Spain;2016;9781450344272;;"https://doi-org.proxy.bnl.lu/10.1145/2961111.2962608;http://dx.doi.org/10.1145/2961111.2962608";10.1145/2961111.2962608;Context: Continuous delivery (CD) is a development practice for decreasing the time-to-market by keeping software releasable all the time. Adopting CD within a stage-gate managed development process might be useful, although scientific evidence of such adoption is not available. In a stage-gate process, new releases pass through stages and gates protect low-quality output from progressing. Large organizations with stage-gate processes are often hierarchical and the adoption can be either top-down, driven by the management, or bottom-up, driven by the development unit.Goal: We investigate the perceived problems of bottom-up CD adoption in a large global software development unit at Nokia Networks. Our goal is to understand how the stage-gate development process used by the unit affects the adoption.Method: The overall research approach is a qualitative single case study on one of the several geographical sites of the development unit. We organized two 2-hour workshops with altogether 15 participants to discover how the stage-gate process affected the adoption.Results: The stage-gate development process caused tight schedules for development and process overhead because of the gate requirements. Moreover, the process required using multiple version control branches for different stages in the process, which increased development complexity and caused additional branch overhead. Together, tight schedule, process overhead and branch overhead caused the lack of time to adopt CD. In addition, the use of multiple branches limited the available hardware resources and caused delayed integration.Conclusions: Adopting CD in a development organization that needs to conform to a stage-gate development process is challenging. Practitioners should either gain support from the management to relax the required process or reduce their expectations on what can be achieved while conforming to the process. To simplify the development process, the use of multiple version control branches could be replaced with feature toggles.;continuous delivery, stage-gate process, case study;;;ESEM '16
Conference Paper;Zhang Y,Vasilescu B,Wang H,Filkov V;One Size Does Not Fit All: An Empirical Study of Containerized Continuous Deployment Workflows;;2018;;;295–306;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Lake Buena Vista, FL, USA;2018;9781450355735;;"https://doi-org.proxy.bnl.lu/10.1145/3236024.3236033;http://dx.doi.org/10.1145/3236024.3236033";10.1145/3236024.3236033;Continuous deployment (CD) is a software development practice aimed at automating delivery and deployment of a software product, following any changes to its code. If properly implemented, CD together with other automation in the development process can bring numerous benefits, including higher control and flexibility over release schedules, lower risks, fewer defects, and easier on-boarding of new developers. Here we focus on the (r)evolution in CD workflows caused by containerization, the virtualization technology that enables packaging an application together with all its dependencies and execution environment in a light-weight, self-contained unit, of which Docker has become the de-facto industry standard. There are many available choices for containerized CD workflows, some more appropriate than others for a given project. Owing to cross-listing of GitHub projects on Docker Hub, in this paper we report on a mixed-methods study to shed light on developers' experiences and expectations with containerized CD workflows. Starting from a survey, we explore the motivations, specific workflows, needs, and barriers with containerized CD. We find two prominent workflows, based on the automated builds feature on Docker Hub or continuous integration services, with different trade-offs. We then propose hypotheses and test them in a large-scale quantitative study.;Continuous Deployment, GitHub, Containerization, Docker;;;ESEC/FSE 2018
Conference Paper;Lwakatare LE,Crnkovic I,R\range E,Bosch J;From a Data Science Driven Process to a Continuous Delivery Process for Machine Learning Systems;;2020;;;185–201;;Springer-Verlag;Berlin, Heidelberg;;Product-Focused Software Process Improvement: 21st International Conference, PROFES 2020, Turin, Italy, November 25–27, 2020, Proceedings;Turin, Italy;2020;9783030641474;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-64148-1_12;http://dx.doi.org/10.1007/978-3-030-64148-1_12";10.1007/978-3-030-64148-1_12;Development of machine learning (ML) enabled applications in real-world settings is challenging and requires the consideration of sound software engineering (SE) principles and practices. A large body of knowledge exists on the use of modern approaches to developing traditional software components, but not ML components. Using exploratory case study approach, this study investigates the adoption and use of existing software development approaches, specifically continuous delivery (CD), to development of ML components. Research data was collected using a multivocal literature review (MLR) and focus group technique with ten practitioners involved in developing ML-enabled systems at a large telecommunication company. The results of our MLR show that companies do not outright apply CD to the development of ML components rather as a result of improving their development practices and infrastructure over time. A process improvement conceptual model, that includes the description of CD application to ML components is developed and initially validated in the study.;Continuous delivery, Software process, Machine learning system;;;
Conference Paper;Rayana RB,Killian S,Trangez N,Calmettes A;GitWaterFlow: A Successful Branching Model and Tooling, for Achieving Continuous Delivery with Multiple Version Branches;;2016;;;17–20;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 4th International Workshop on Release Engineering;Seattle, WA, USA;2016;9781450343992;;"https://doi-org.proxy.bnl.lu/10.1145/2993274.2993277;http://dx.doi.org/10.1145/2993274.2993277";10.1145/2993274.2993277;Collaborative software development presents organizations with a near-constant flow of day-to-day challenges, and there is no available off-the-shelf solution that covers all needs. This paper provides insight into the hurdles that Scality's Engineering team faced in developing and extending a sophisticated storage solution, while coping with ever-growing development teams, challenging - and regularly shifting - business requirements, and non-trivial new feature development. The authors present a novel combination of a Git-based Version Control and Branching model with a set of innovative tools dubbed GitWaterFlow to cope with the issues encountered, including the need to both support old product versions and to provide time-critical delivery of bug fixes. In the spirit of Continuous Delivery, Scality Release Engineering aims to ensure high quality and stability, to present short and predictable release cycles, and to minimize development disruption. The team's experience with the GitWaterFlow model suggests that the approach has been effective in meeting these goals in the given setting, with room for unceasing fine-tuning and improvement of processes and tools.;version control, gatekeeper, continuous integration, workflow automation, branching model, concurrent release cycles;;;RELENG 2016
Conference Paper;Rashitov V,Ivanou M;Continuous Integration and Continuous Delivery in the Process of Developing Robotic Systems;;;;;342–348;;Springer-Verlag;Berlin, Heidelberg;;Software Technology: Methods and Tools;Innopolis Russia;;9783030298517;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-29852-4_29;http://dx.doi.org/10.1007/978-3-030-29852-4_29";10.1007/978-3-030-29852-4_29;There are hundreds of companies out there that are bringing new solutions in the field of robotics and trying to get rid of a thousand problems they face. Nevertheless, most of their results do not leave the doors of the lab and remain without any decent attention from society. Institutions and companies require highly qualified personnel to accelerate the development of new solutions and products. High expenses deter broad masses from participating in this activity. It is not only the high price that keeps people away from being a part of the community but also a high entry level to the field. In our paper we consider an approach that makes the process of developing and integration of robotic systems faster and more accessible to the others. At first, the idea implies removing a technical barrier between science labs and other individuals. Secondly, all processes must be automatized by different tools to the greatest possible extent. As a result, we get a cloud web application where anyone can add or edit robotic systems algorithms. There are open technologies that can help us to implement this solution: virtualization, dockerization, web 3d simulator Gazebo, robot operation system (ROS).;Cloud, CI/CD, Docker, Web application, Virtualization, Robot system;;;
Journal Article;Dixon B;Simplifying Teaching Continuous Integration and Continuous Deployment with Hands-on Application in a Web Development Course;J. Comput. Sci. Coll.;2020;35;10;15–20;;Consortium for Computing Sciences in Colleges;Evansville, IN, USA;;;;2020-04;;1937-4771;;;Teaching web programming can lend itself as a course where students can learn to develop with version control, containers, continuous integration (CI), and continuous deployment or delivery (CD). In my web programming course, I built a starter repo that simplifies the initial setup and helps students become familiar with CI/CD and containers. Using the GitLab/GitHub APIs allows me to automate the creation of private mirrored repos across these sites for each student, with each private repo including the starter repo I developed. Students gain access to their repo by submitting a form through my website. This paper will discuss the motivation and benefit of this approach, as well as describe how I have been able to successfully implement it. The conclusions of the impact of this approach in part come from student feedback since I started doing this approach over the past 3 semesters.;;;;
Conference Paper;Makki M,Van Landuyt D,Joosen W;Automated Regression Testing of BPMN 2.0 Processes: A Capture and Replay Framework for Continuous Delivery;;2016;;;178–189;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences;Amsterdam, Netherlands;2016;9781450344463;;"https://doi-org.proxy.bnl.lu/10.1145/2993236.2993257;http://dx.doi.org/10.1145/2993236.2993257";10.1145/2993236.2993257;Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers. In this paper, we present a regression testing automation framework that implements the capture & replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired side-effects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer. We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-tolerance. The results, indicating 3.9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services.;Business Process Execution, Test Automation, BPMN 2.0, Regression Testing, Node Mocking, Performance Overhead, jBPM;;;GPCE 2016
Conference Paper;Huijgens H,Lamping R,Stevens D,Rothengatter H,Gousios G,Romano D;Strong Agile Metrics: Mining Log Data to Determine Predictive Power of Software Metrics for Continuous Delivery Teams;;2017;;;866–871;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering;Paderborn, Germany;2017;9781450351058;;"https://doi-org.proxy.bnl.lu/10.1145/3106237.3117779;http://dx.doi.org/10.1145/3106237.3117779";10.1145/3106237.3117779;ING Bank, a large Netherlands-based internationally operating bank, implemented a fully automated continuous delivery pipe-line for its software engineering activities in more than 300 teams, that perform more than 2500 deployments to production each month on more than 750 different applications. Our objective is to examine how strong metrics for agile (Scrum) DevOps teams can be set in an iterative fashion. We perform an exploratory case study that focuses on the classification based on predictive power of software metrics, in which we analyze log data derived from two initial sources within this pipeline. We analyzed a subset of 16 metrics from 59 squads. We identified two lagging metrics and assessed four leading metrics to be strong.;Agile Metrics, DevOps, Scrum, Data Mining, Prediction Modelling, Software Economics, Continuous Delivery, Software Analytics;;;ESEC/FSE 2017
Conference Paper;Olsson HH,Alahyari H,Bosch J;"Climbing the ""Stairway to Heaven"" -- A Mulitiple-Case Study Exploring Barriers in the Transition from Agile Development towards Continuous Deployment of Software";;2012;;;392–399;;IEEE Computer Society;USA;;Proceedings of the 2012 38th Euromicro Conference on Software Engineering and Advanced Applications;;2012;9780769547909;;"https://doi-org.proxy.bnl.lu/10.1109/SEAA.2012.54;http://dx.doi.org/10.1109/SEAA.2012.54";10.1109/SEAA.2012.54;Agile software development is well-known for its focus on close customer collaboration and customer feedback. In emphasizing flexibility, efficiency and speed, agile practices have lead to a paradigm shift in how software is developed. However, while agile practices have succeeded in involving the customer in the development cycle, there is an urgent need to learn from customer usage of software also after delivering and deployment of the software product. The concept of continuous deployment, i.e. the ability to deliver software functionality frequently to customers and subsequently, the ability to continuously learn from real-time customer usage of software, has become attractive to companies realizing the potential in having even shorter feedback loops. However, the transition towards continuous deployment involves a number of barriers. This paper presents a multiple-case study in which we explore barriers associated with the transition towards continuous deployment. Based on interviews at four different software development companies we present key barriers in this transition as well as actions that need to be taken to address these.;continuous deployment, customer collaboration, agile software development, continuous integration;;;SEAA '12
Conference Paper;Vassallo C,Proksch S,Jancso A,Gall HC,Di Penta M;Configuration Smells in Continuous Delivery Pipelines: A Linter and a Six-Month Study on GitLab;;2020;;;327–337;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Virtual Event, USA;2020;9781450370431;;"https://doi-org.proxy.bnl.lu/10.1145/3368089.3409709;http://dx.doi.org/10.1145/3368089.3409709";10.1145/3368089.3409709;An effective and efficient application of Continuous Integration (CI) and Delivery (CD) requires software projects to follow certain principles and good practices. Configuring such a CI/CD pipeline is challenging and error-prone. Therefore, automated linters have been proposed to detect errors in the pipeline. While existing linters identify syntactic errors, detect security vulnerabilities or misuse of the features provided by build servers, they do not support developers that want to prevent common misconfigurations of a CD pipeline that potentially violate CD principles (“CD smells”). To this end, we propose CD-Linter, a semantic linter that can automatically identify four different smells in pipeline configuration files. We have evaluated our approach through a large-scale and long-term study that consists of (i) monitoring 145 issues (opened in as many open-source projects) over a period of 6 months, (ii) manually validating the detection precision and recall on a representative sample of issues, and (iii) assessing the magnitude of the observed smells on 5,312 open-source projects on GitLab. Our results show that CD smells are accepted and fixed by most of the developers and our linter achieves a precision of 87% and a recall of 94%. Those smells can be frequently observed in the wild, as 31% of projects with long configurations are affected by at least one smell.;Linter, Anti-pattern, Configuration, Continuous Delivery, Continuous Integration, DevOps;;;ESEC/FSE 2020
Conference Paper;Eddy BP,Wilde N,Cooper NA,Mishra B,Gamboa VS,Patel KN,Shah KM;CDEP: Continuous Delivery Educational Pipeline;;2017;;;55–62;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the SouthEast Conference;Kennesaw, GA, USA;2017;9781450350242;;"https://doi-org.proxy.bnl.lu/10.1145/3077286.3077301;http://dx.doi.org/10.1145/3077286.3077301";10.1145/3077286.3077301;Due to the desire to decrease the time to market of modern applications and software, a number of new agile processes have emerged. Continuous integration and continuous delivery which allow developers to easily push changes to software are common practices in industry, however in education there seems to be a lack of teaching in these practices. This is because of the complexity that these practices entail by having to create an automated software development pipeline that tests and deploys software. These pipelines are often difficult to understand and the setup, configuration, and instruction of such a pipeline is often difficult to include in a traditional software engineering course. A lightweight and portable pipeline for educational purposes is required. This pipeline needs to be simple enough for easy setup and detailed enough to teach various aspects of continuous integration and delivery. This paper introduces the design and implementation of such a pipeline as well as the proposed usage in academia.;Software Engineering, Education, Continuous Integration, Agile, Continuous Delivery;;;ACM SE '17
Book Chapter;Leite L,Kon F,Pinto G,Meirelles P;Platform Teams: An Organizational Structure for Continuous Delivery;;2020;;;505–511;;Association for Computing Machinery;New York, NY, USA;Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops;;;2020;9781450379632;;https://doi-org.proxy.bnl.lu/10.1145/3387940.3391455;;"Software-producing organizations are seeking to release faster and more efficiently new versions of their products to their customers to remain competitive in the fierce software market. Continuous delivery practices arise as a potential solution since every commit to the repository could result in a production-candidate version of a product, accelerating time to market, and improving customer satisfaction. In this work, we employed Grounded Theory to investigate how organizations pursuing continuous delivery should organize their development and operations teams. We collected data from 27 IT professionals. After a careful analysis, we started the elaboration of a taxonomy with four patterns of organizational structures: (1) siloed departments, (2) classical DevOps, (3) cross-functional teams, and (4) platform teams. We observed that the platform team structure is the most distinctive classification of our taxonomy, and it has promising results regarding delivery performance. Some relevant aspects we found out about platform teams include: infrastructure specialists need coding skills; product teams have to operate their business services; and much of the non-functional concerns are handled by the platform, alleviating product teams.";;;;
Book;Raheja Y,Borgese G,Felsen N;Effective DevOps with AWS: Implement Continuous Delivery and Integration in the AWS Environment, 2nd Edition;;2018;;;;;Packt Publishing;;;;;2018;9781789539974;;;;Scale and maintain outstanding performance in your AWS-based infrastructure using DevOps principles Key Features Implement continuous integration and continuous deployment pipelines on AWS Gain insight from an expert who has worked with Silicon Valley's most high-profile companies Implement DevOps principles to take full advantage of the AWS stack and services Book Description The DevOps movement has transformed the way modern tech companies work. Amazon Web Services (AWS), which has been at the forefront of the cloud computing revolution, has also been a key contributor to the DevOps movement, creating a huge range of managed services that help you implement DevOps principles. Effective DevOps with AWS, Second Edition will help you to understand how the most successful tech start-ups launch and scale their services on AWS, and will teach you how you can do the same. This book explains how to treat infrastructure as code, meaning you can bring resources online and offline as easily as you control your software. You will also build a continuous integration and continuous deployment pipeline to keep your app up to date. Once you have gotten to grips will all this, we'll move on to how to scale your applications to offer maximum performance to users even when traffic spikes, by using the latest technologies, such as containers. In addition to this, you'll get insights into monitoring and alerting, so you can make sure your users have the best experience when using your service. In the concluding chapters, we'll cover inbuilt AWS tools such as CodeDeploy and Cloud Formation, which are used by many AWS administrators to perform DevOps. By the end of this book, you'll have learned how to ensure the security of your platform and data, using the latest and most prominent AWS tools. What you will learn Implement automatic AWS instance provisioning using Cloud Formation Deploy your application on a provisioned infrastructure with Ansible Manage infrastructure using Terraform Build and deploy a CI/CD pipeline with Automated Testing on AWS Understand the container journey for a CI/CD pipeline using AWS ECS Monitor and secure your AWS environment Who this book is for Effective DevOps with AWS is for you if you are a developer, DevOps engineer, or you work in a team which wants to build and use AWS for software infrastructure. Basic computer science knowledge is required to get the most out of this book.;;;;
Conference Paper;Souza R,Oliveira A;GuideAutomator: Continuous Delivery of End User Documentation;;2017;;;31–34;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 39th International Conference on Software Engineering: New Ideas and Emerging Results Track;;2017;9781538626757;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-NIER.2017.10;http://dx.doi.org/10.1109/ICSE-NIER.2017.10";10.1109/ICSE-NIER.2017.10;User guides, also known as user manuals, are a type of documentation aimed at helping a user operate a specific system. For software systems, user guides usually include screenshots that show users how to interact with the user interface. Because creating such screenshots is a slow, manual process, keeping the user guide up-to-date with changes in the user interface is challenging. We propose an approach in which the documentation writer interleaves the user guide text with source code that automates screen capturing. As a result, screenshots always reflect the latest software version, which makes the approach suitable for a project that uses continuous delivery. The approach was implemented as a prototype, called GuideAutomator.;"automated documentation generator, software documentation, literate programming; continuous delivery";;;ICSE-NIER '17
Book;Laster B;Jenkins 2: Up and Running Evolve Your Deployment Pipeline for Next Generation Automation;;2018;;;;1st;O'Reilly Media, Inc.;;;;;2018;9781491979594;;;;Design, implement, and execute continuous delivery pipelines with a level of flexibility, control, and ease of maintenance that was not possible with Jenkins before. With this practical book, build administrators, developers, testers, and other professionals will learn how the features in Jenkins 2 let you define pipelines as code, leverage integration with other key technologies, and create automated, reliable pipelines to simplify and accelerate your DevOps environments. Author Brent Laster shows you how Jenkins 2 is significantly different from the more traditional, web-only versions of this popular open source automation platform. If youre familiar with Jenkins and want to take advantage of the new technologies to transform your legacy pipelines or build new modern, automated continuous delivery environments, this is your book. Create continuous delivery pipelines as code with the Jenkins domain-specific language Get practical guidance on how to migrate existing jobs and pipelines Harness best practices and new methods for controlling access and security Explore the structure, implementation, and use of shared pipeline libraries Learn the differences between declarative syntax and scripted syntax Leverage new and existing project types in Jenkins Understand and use the new Blue Ocean graphical interface Take advantage of the capabilities of the underlying OS in your pipeline Integrate analysis tools, artifact management, and containers;;;;
Book;Vadapalli S;DevOps: Continuous Delivery, Integration, and Deployment with DevOps Dive into the Core DevOps Strategies;;2018;;;;;Packt Publishing;;;;;2018;9781789132991;;;;Explore the high-in demand core DevOps strategies with powerful DevOps tools such as Ansible, Jenkins, and ChefKey FeaturesGet acquainted with methodologies and tools of the DevOps frameworkPerform continuous integration, delivery, deployment, and monitoring using DevOps toolsExplore popular tools such as Git, Jenkins, Maven, Gerrit, Nexus, Selenium, and so on Embedded with assessments that will help you revise the concepts you have learned in this book Book Description DevOps is the most widely used software engineering culture and practice that aim sat software development and operation. Continuous integration is a cornerstone technique of DevOps that merges software code updates from developers into a shared central mainline. This book takes a practical approach and covers the tools and strategies of DevOps. It starts with familiarizing you with DevOps framework and then shows how toper form continuous delivery, integration, and deployment with DevOps. You will explore DevOps process maturity frameworks and progression models with checklist templates for each phase of DevOps. You will also be familiar with agile terminology, methodology, and the benefits accrued by an organization by adopting it. You will also get acquainted with popular tools such as Git, Jenkins, Maven, Gerrit, Nexus, Selenium, and so on. You will learn configuration, automation, and the implementation of infrastructure automation (Infrastructure as Code) with tools such as Chef and Ansible. This book is ideal for engineers, architects, and developers, who wish to learn the core strategies of DevOps. This book is embedded with useful assessments that will help you revise the concepts you have learned in this book. This book is repurposed for this specific learning experience from material from Packt's Hands-on DevOps by Sricharan Vadapalli. What you will learnGet familiar with life cycle models, maturity states, progression and best practices of DevOps frameworks Learn to set up Jenkins and integrate it with GitKnow how to build jobs and perform testing with Jenkins Implement infrastructure automation (Infrastructure as Code) with tools such as Chef and Ansible Understand continuous monitoring process with tools such as Splunk and Nagios Learn how Splunk improves the code quality Who This Book Is ForThis book is for engineers, architects, and developers, who wish to learn the core strategies of DevOps.;;;;
Conference Paper;Günalp O,Escoffier C,Lalanda P;Rondo: A Tool Suite for Continuous Deployment in Dynamic Environments;;2015;;;720–727;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE International Conference on Services Computing;;2015;9781467372817;;"https://doi-org.proxy.bnl.lu/10.1109/SCC.2015.102;http://dx.doi.org/10.1109/SCC.2015.102";10.1109/SCC.2015.102;Driven by the emergence of new computing environments, dynamically evolving software systems makes it impossible for developers to deploy software with human-centric processes. Instead, there is an increasing need for automation tools that continuously deploy software into execution, in order to push updates or adapt existing software regarding contextual and business changes. Existing solutions fall short on providing fault-tolerant, reproducible deployments that can scale on heterogeneous environments. In this paper we present Rondo, a tool suite that enables continuous deployment for dynamic, service-oriented applications. At the center of these tools, we propose a deterministic and idem potent deployment process. We provide with Rondo a deployment manager that implements this process and capable of conducting deployments and continuously adapting applications according to the changes in the current target platform. The tool suite also includes a domain-specific language for describing deployment requests. We validate our approach in multiple projects, for provisioning the platform as well as for installing applications and continuous reconfigurations.;Continuous Deployment, Service-Oriented Computing, Dynamism;;;SCC '15
Conference Paper;Çalikli G,Staron M,Meding W;Measure Early and Decide Fast: Transforming Quality Management and Measurement to Continuous Deployment;;2018;;;51–60;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2018 International Conference on Software and System Process;Gothenburg, Sweden;2018;9781450364591;;"https://doi-org.proxy.bnl.lu/10.1145/3202710.3203156;http://dx.doi.org/10.1145/3202710.3203156";10.1145/3202710.3203156;Continuous deployment has become software companies' inevitable response to the economic pressures of the market. At the same time, software quality is crucial in order to meet customers' expectations and hence succeed in the market. Therefore, current quality management processes require transformation in order to keep up with the fast pace of the market while at the same time meeting customers' expectations. In order to figure out how the current quality management process should be transformed to keep up with the fast pace of the market while ensuring both product quality and continuous deployment, we conducted a qualitative study at a large infrastructure provider company. During the interviews we conducted with the quality manager, developer and test architect, we used a metrics portfolio consisting of 59 candidate metrics that can be used in the transformed quality management process. Our findings show that, out of these candidate metrics, 9 metrics should be used in the internal quality measurement dashboard for quality check at the end of the software development life-cycle (SDLC) before the software is released to customer site, while 3 metrics should be used by quality manager to monitor earlier phases of SDLC and 5 metrics should also be delegated to earlier phases of SDLC but without the involvement of the quality manager. To summarize, our study support the claim that quality managers should not be only gatekeepers, but also proactive controllers of quality by monitoring earlier phases of the SDLC.;continuous deployment, software quality, metrics;;;ICSSP '18
Book;Farcic V;The DevOps 2.4 Toolkit: Continuous Deployment To Kubernetes Continuously Deploying Applications with Jenkins to a Kubernetes Cluster;;2018;;;;;Independently published;;;;;2018;9781718187542;;;;"Just like other books I wrote, this one did not have a fixed scope. I did not start with an index. I didn't write a summary of each chapter in an attempt to define the scope. I do not do such things. There was only a high-level goal to explore continuous delivery and deployment inside Kubernetes clusters. What I did do, though, was to set a few guidelines. The first guideline is that ""all the examples will be tested on all major Kubernetes platforms."" Well, that might be a bit far-fetched. I'm aware that any sentence that mentions ""all"" together with ""Kubernetes"" is bound to be incorrect. New platforms are popping out like mushrooms after rain. Still, what I can certainly do is to choose a few of the most commonly used ones. Minikube and Docker for Mac or Windows should undoubtedly be there for those who prefer to ""play"" with Docker locally. AWS is the biggest hosting provider so Kubernetes Operations (kops) must be included as well. Since it would be silly to cover only un-managed cloud, I had to include managed Kubernetes clusters as well. Google Kubernetes Engine (GKE) is the obvious choice. It is the most stable and features rich managed Kubernetes solution. Adding GKE to the mix means that Azure Container Service (AKS) and Amazon's Elastic Container Service (EKS) should be included as well so that we can have the ""big trio"" of the hosting vendors that offer managed Kubernetes. Unfortunately, at the time of this writing (May 2018), Elastic Container Service (EKS) is in the preview stage and Amazon is providing access only to a relatively small number of people. AKS, on the other hand, is available but, at this moment, it is too unstable. So, I'm forced to scale down from the trio to GKE as the only managed Kubernetes we'll explore. Finally, a possible on-prem solution should be included as well. Since OpenShift shines in that area, the choice was relatively easy. All in all, I decided to test everything in minikube and Docker for Mac locally, AWS with kops as the representative of a cluster in the cloud, GKE for managed Kubernetes clusters, and OpenShift (with minishift) as a potential on-prem solution. That, in itself, already constitutes a real challenge that might prove to be more than I can chew. Still, making sure that all the examples work with all those platforms and solutions should provide some useful insights. Some of you already chose the Kubernetes flavor you'll use. Others might still wonder whether to adopt one or the other. Even though the comparison of different Kubernetes platforms is not the primary scope of the book, I'll do my best to explain the differences as they come. To summarize the guidelines, the book has to explore continuous delivery and deployment in Kubernetes using Jenkins. All the examples have to be tested in minikube, Docker for Mac (or Windows), AWS with kops, GKE, and OpenShift with minishift, and EKS.";;;;
Book Chapter;Lourenço H,Tavares J,Eugénio R,Lourenço M,Simões T;LUV is Not the Answer: Continuous Delivery of a Model Driven Development Platform;;2020;;;;;Association for Computing Machinery;New York, NY, USA;Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings;;;2020;9781450381352;;https://doi-org.proxy.bnl.lu/10.1145/3417990.3419502;;The OutSystems Platform is a visual model-driven development and delivery platform that allows developers to create enterprise-grade cross platform web and mobile applications.The platform consists of several inter-dependent components, most notably Service Studio, the Platform Server, and LifeTime. Service Studio is an integrated development environment used to create applications that are then compiled by the Platform Server. LifeTime is used to stage applications between different environments (e.g., development, testing, production).Our meta-model is versioned using a version number that we call Last Upgrade Version (LUV). Service Studio, the Platform Server, and the models they create/process are associated with a particular LUV. As a general rule, a platform component is only able to process models with the same LUV as the component itself.This approach is not very flexible: a change to the meta-model requires releasing a new set of platform components that our customers then need to install. Although there's low resistance to installing new versions of Service Studio, the same is not true for the Platform Server. Thus, for all practical purposes LUV changes are tied to releases of major versions of the OutSystems Platform.In this paper we share the techniques that allowed us to transition to a Continuous Delivery process in which our meta-model can evolve freely with no impact on our installed base.;;;;
Conference Paper;Schermann G,Schöni D,Leitner P,Gall HC;Bifrost: Supporting Continuous Deployment with Automated Enactment of Multi-Phase Live Testing Strategies;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 17th International Middleware Conference;Trento, Italy;2016;9781450343008;;"https://doi-org.proxy.bnl.lu/10.1145/2988336.2988348;http://dx.doi.org/10.1145/2988336.2988348";10.1145/2988336.2988348;Live testing is used in the context of continuous delivery and deployment to test changes or new features in the production environment. This includes canary releases, dark launches, A/B tests, and gradual rollouts. Oftentimes, multiple of these live testing practices need to be combined (e.g., running an A/B test after a dark launch). Manually administering such multi-phase live testing strategies is a daunting task for developers or release engineers. In this paper, we introduce a formal model for multi-phase live testing, and present Bifrost as a Node.js based prototype implementation that allows developers to define and automatically enact complex live testing strategies. We extensively evaluate the runtime behavior of Bifrost in three rollout scenarios of a microservice-based case study application, and conclude that the performance overhead of our prototype is at or below 8 ms for most scenarios. Further, we show that more than 100 parallel strategies can be enacted even on cheap public cloud instances.;Canary Releases, Continuous Deployment, Microservices, A/B Testing, Release Engineering;;;Middleware '16
Book;Chandrasekara C;Beginning Build and Release Management with TFS 2017 and VSTS: Leveraging Continuous Delivery for Your Business;;2017;;;;1st;Apress;USA;;;;2017;9781484228104;;;;Master build and release management with Team Foundation Service and Visual Studio Team Services to facilitate the continuous delivery of software updates to your development team. You'll receive detailed, practical guidance on automating website deployments in Azure App Service, database deployments to Azure platform, Micro Services deployments in Azure Service Fabric, and more. Each deployment is structured with the aid of hands-on lessons in a given target environment designed to empower your teams to achieve successful DevOps. This book provides lessons on how to optimize build release management definitions using capabilities, such as task groups. With the help of practical scenarios, youll also learn how to diagnose and fix issues in automated builds and deployments. Youll see how to enhance the capability of build and release management, using team services/TFS Marketplace extensions and writing your own extensions for any missing functionality via hands-on lessons. What You Will Learn Automate deployment to Azure platform, including Web App Service, Azure SQL and Azure Service FabricTest automation integration with builds and deployments Perform Dynamic CRM deployment handling and package management with TFS/VSTS Examine requirement to production delivery traceability in practical terms Review cross platform build/deployment capabilities of TFS/VSTS. Who This Book Is For Build/Release Engineers, Configuration Managers, Software Developers, Test Automation Engineers, System Engineers, Software Architects and System/Production Support Engineers or anyone who handles and involves in the software delivery process.;;;;
Book;Vadapalli S;Hands-on DevOps: Explore the Concept of Continuous Delivery and Integrate It with Data Science Concepts;;2017;;;;;Packt Publishing;;;;;2017;9781788471183;;;;Transform yourself into a specialist in DevOps adoption for Big Data on cloudKey FeaturesLearn the concepts of Bigdata and Devops and Implement themGet Acquainted with DevOps Frameworks Methodologies and ToolsA practical approach to build and work efficiently with your big data clusterGet introduced to multiple flavors of tools and platforms from vendors on Hadoop, Cloud, Containers and IoT OfferingsIn-Depth Technology understanding on Data Sciences, Microservices, BigdataBook DescriptionDevOps strategies have really become an important factor for big data environments. This book initially provides an introduction to big data, DevOps, and Cloud computing along with the need for DevOps strategies in big data environments. We move on to explore the adoption of DevOps frameworks and business scenarios. We then build a big data cluster, deploy it on the cloud, and explore DevOps activities such as CI/CD and containerization. Next, we cover big data concepts such as ETL for data sources, Hadoop clusters, and their applications. Towards the end of the book, we explore ERP applications useful for migrating to DevOps frameworks and examine a few case studies for migrating big data and prediction models. By the end of this book, you will have mastered implementing DevOps tools and strategies for your big data clusters. What you will learnLearn about the DevOps culture, its frameworks, maturity, and design patternsGet acquainted with multiple niche technologies microservices, containers, kubernetes, IoT, and cloudBuild big data clusters, enterprise applications and data science modelsApply DevOps concepts for continuous integration, delivery, deployment and monitoringGet introduced to Open source tools, service offerings from multiple vendorsStart digital journey to apply DevOps concepts to migrate big data, cloud, microservices, IoT, security, ERP systemsWho This Book Is ForIf you are a Big Data Architects, solutions provider, or any stakeholder working in big data environment and wants to implement the strategy of DevOps, then this book is for you.;;;;
Book;Narayan S;Agile IT Organization Design: For Digital Transformation and Continuous Delivery;;2015;;;;1st;Addison-Wesley Professional;;;;;2015;9780133903355;;;;"To gain the full benefits of agility in any software organization, you need to extend it beyond developers to the organization as a whole. Aspiring digital businesses need overall agility, not just development team agility. Now, Sriram Narayan, IT management consultant at Thought Works, shows how to do just that. Drawing on 15+ years working with leaders in telecommunications, finance, energy, retail, and beyond, he introduces a comprehensive agile approach to ""Business-IT Effectiveness"" that is as practical as it is valuable. Sriram demonstrates how to integrate agility throughout sales, marketing, product development, engineering, and operations, helping each function deliver more value individually and through its linkages with the rest of the business. Addressing people, process, and technology, he guides you in improving both the dynamic and static aspects of organization design, addressing team structure, accountability structures, organizational norms and culture, metrics, and more. Using real examples, Sriram helps you evaluate and improve organization designs to enhance autonomy, mastery, and purpose. You'll learn how to eliminate the specific organizational silos that cause the most problems... improve communication in organizations that claim to be (but aren't really) non-hierarchical... optimize the way you build teams, design office space, and even choose tools. Simply put, Agile IT Organization Design will help you improve the performance of any software organization.";;;;
Conference Paper;Bellomo S,Ernst N,Nord R,Kazman R;Toward Design Decisions to Enable Deployability: Empirical Study of Three Projects Reaching for the Continuous Delivery Holy Grail;;2014;;;702–707;;IEEE Computer Society;USA;;Proceedings of the 2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks;;2014;9781479922338;;"https://doi-org.proxy.bnl.lu/10.1109/DSN.2014.104;http://dx.doi.org/10.1109/DSN.2014.104";10.1109/DSN.2014.104;There is growing interest in continuous delivery practices to enable rapid and reliable deployment. While practices are important, we suggest architectural design decisions are equally important for projects to achieve goals such continuous integration (CI) build, automated testing and reduced deployment-cycle time. Architectural design decisions that conflict with deploy ability goals can impede the team's ability to achieve the desired state of deployment and may result in substantial technical debt. To explore this assertion, we interviewed three project teams striving to practicing continuous delivery. In this paper, we summarize examples of the deploy ability goals for each project as well as the architectural decisions that they have made to enable deploy ability. We present the deploy ability goals, design decisions, and deploy ability tactics collected and summarize the design tactics derived from the interviews in the form of an initial draft version hierarchical deploy ability tactic tree.;deployability, continuous integration, continuous delivery, architecture tactic, test automation;;;DSN '14
Book;Lines M,Ambler SW;Introduction to Disciplined Agile Delivery: A Small Agile Team's Journey from Scrum to Continuous Delivery;;2015;;;;1st;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2015;9781497544383;;;;Introduction to Disciplined Agile Delivery provides a quick overview of how agile software development works from beginning-to-end. It describes the Disciplined Agile Delivery (DAD) process decision framework and then works through a case study describing a typical agile teams experiences adopting a disciplined agile approach. The book describes how the team develops the first release of a mission-critical application while working in a legacy enterprise environment. It describes their experiences from beginning-to-end, starting with their initial team initiation efforts through construction and finally to deploying the solution into production. It also describes how the team stays together for future releases, overviewing their process improvement efforts from their Scrum-based beginnings through to a lean continuous delivery approach that fits in with their organizations evolving DevOps strategy. The DAD framework is a hybrid of existing methods such as Scrum, Kanban, Agile Modeling, SAFe, Extreme Programming, Agile Data, Unified Process and many others. DAD provides the flexibility to use various approaches and plugs the gaps not addressed by mainstream agile methods. In a nutshell, DAD is pragmatic agile. DAD describes proven strategies to adapt and scale your agile initiatives to suit the unique realities of your enterprise without having to figure it all out by yourself. Heres an overview of what each chapter covers: * Chapter 1: Introduction. This chapter provides a quick overview of the book and a brief history of Disciplined Agile. * Chapter 2: Reality over Rhetoric. This chapter explores several common myths about DAD and more importantly disproves them. * Chapter 3: Disciplined Agile Delivery in a Nutshell. This chapter provides a brief yet comprehensive overview of the DAD framework. * Chapter 4: Introduction to the Case Study. This chapter introduces us to the team, describes the market opportunity that they hope to address, and describes the environment in which theyre working. * Chapter 5: Inception. The teams initiation effort includes initial requirements modeling and planning with their stakeholders in a streamlined manner, initial architecture modeling, setting up their physical work environment, setting up the start of their tooling infrastructure, initial risk identification, and finally securing stakeholder support and funding for the rest of the first release. * Chapters 6 through 10: Construction. These chapters each describe a single Construction iteration, sharing the teams experiences during each of those two-week timeboxes. * Chapter 11: Transition. The two-week transition phase focuses on final testing and fixing, training the support/help-desk staff, finishing a few short end-user how to videos, and deploying the solution into production. * Chapter 12: Future Releases. This chapter overviews the teams improvement efforts over the next few releases, describing how they evolve from the agile Scrum-based lifecycle to a leaner approach and eventually to continuous delivery. * Chapter 13: Closing Thoughts. This chapter overviews the disciplined agile resources that are available to you. * Appendix: The Disciplined Agile IT Department. This short appendix overviews our ongoing work on the Disciplined Agile framework to address the full scope of an IT department. At 102 pages, you should find this book to be a quick, informative read.;;;;
Book;Scheaffer J,Ravichandran A,Martins A;The Kitty Hawk Venture: A Novel About Continuous Testing in DevOps to Support Continuous Delivery and Business Success;;2018;;;;1st;Apress;USA;;;;2018;9781484236604;;;;An airline is supposed to make the experience of booking a flight easy, trouble free, and reliable. But when scheduling software breaks down and flights get canceled, customers will walk, and heads will roll. Thats what Leigh Freemark faces the day she and her team launch a software upgrade that fails spectacularly and hits the media immediately. As Senior Director of Quality Assurance, her job is to make sure that code is market ready. And shes the one who must face the music when it doesnt. Tasked by senior management to find and fix the source of the failure, Leigh discovers just how essential it has become to radically improve the process of software development by introducing a concept called continuous testing. She must quickly learn what it means, how it works, and how to build it into her companys legacy system. But she soon discovers that managing change is much more difficult than it first appears. The airline business is changing fast, yet old traditions and loyalties still dominate. As she fights to convince her team to change or perish, she discovers that obstructions and opportunities come in surprising forms.***In The Kitty Hawk Venture, the authors deliver a sound lesson in the importance of continuous testing while taking the reader inside the world of commercial aviation. Each chapter delivers distinct and vital learning opportunities wrapped inside a fast-moving narrative complete with interesting characters, intriguing situations, and even some humor. The book concludes with a Flight Plan for Continuous Testing that stands on its own as a valuable resource guide for digital leaders in their continuous testing journey. The story is immediately relatable to anyone who has worked in software development or for the companies that rely on it. Who This Book Is For C-level executives, VPs of apps and quality, VPs of DevOps, architecture and strategy managers, and SMB and enterprise professionals;;;;
Conference Paper;Ibrahim MM,Syed-Mohamad SM,Husin MH;Managing Quality Assurance Challenges of DevOps through Analytics;;2019;;;194–198;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2019 8th International Conference on Software and Computer Applications;Penang, Malaysia;2019;9781450365734;;"https://doi-org.proxy.bnl.lu/10.1145/3316615.3316670;http://dx.doi.org/10.1145/3316615.3316670";10.1145/3316615.3316670;DevOps is an intermarriage between developmental practices and operational modalities. The methodology employs the practices of continuous integration and delivery and places the deployment pipeline as the main requirement to automate, deliver and operate software in a robust way, without compromising on the quality in the software development process. Over time, many systems and tools have been developed to implement the deployment pipeline and support the continuous delivery process. A pipeline splits the process of software delivery into various stages. Each stage is designed to verify the quality of new features from a new perspective to attest to the functionality and prevent either small or big errors from impacting the end users. The pipeline must provide a response and feedback loop to the concerned team and provide a window into the flow of changes that takes place. However, there is no clear rule to define what goes into a pipeline. This paper reviews the challenges of quality assurance of DevOps and provides tentative recommendations to deal with quality issues. Our proposed pipeline with analytic features is expected to provide accurate metrics on a real-time basis.;continuous integration, quality assurance, deployment pipeline, DevOps, devops analytics, continuous deployment, continuous delivery;;;ICSCA '19
Book;Bass L,Weber I,Zhu L;DevOps: A Software Architect's Perspective;;2015;;;;1st;Addison-Wesley Professional;;;;;2015;9780134049847;;;;The First Complete Guide to DevOps for Software Architects DevOps promises to accelerate the release of new software features and improve monitoring of systems in production, but its crucial implications for software architects and architecture are often ignored. In DevOps: A Software Architects Perspective, three leading architects address these issues head-on. The authors review decisions software architects must make in order to achieve DevOps goals and clarify how other DevOps participants are likely to impact the architects work. They also provide the organizational, technical, and operational context needed to deploy DevOps more efficiently, and review DevOps impact on each development phase. The authors address cross-cutting concerns that link multiple functions, offering practical insights into compliance, performance, reliability, repeatability, and security. This guide demonstrates the authors ideas in action with three real-world case studies: datacenter replication for business continuity, management of a continuous deployment pipeline, and migration to a microservice architecture. Comprehensive coverage includes Why DevOps can require major changes in both system architecture and IT roles How virtualization and the cloud can enable DevOps practices Integrating operations and its service lifecycle into DevOps Designing new systems to work well with DevOps practices Integrating DevOps with agile methods and TDD Handling failure detection, upgrade planning, and other key issues Managing consistency issues arising from DevOps independent deployment models Integrating security controls, roles, and audits into DevOps Preparing a business plan for DevOps adoption, rollout, and measurement;;;;
Conference Paper;Laukkarinen T,Kuusinen K,Mikkonen T;DevOps in Regulated Software Development: Case Medical Devices;;2017;;;15–18;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 39th International Conference on Software Engineering: New Ideas and Emerging Results Track;;2017;9781538626757;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-NIER.2017.20;http://dx.doi.org/10.1109/ICSE-NIER.2017.20";10.1109/ICSE-NIER.2017.20;DevOps and continuous development are getting popular in the software industry. Adopting these modern approaches in regulatory environments, such as medical device software, is not straightforward because of the demand for regulatory compliance. While DevOps relies on continuous deployment and integration, regulated environments require strict audits and approvals before releases. Therefore, the use of modern development approaches in regulatory environments is rare, as is the research on the topic. However, as software is more and more predominant in medical devices, modern software development approaches become attractive. This paper discusses the fit of DevOps for regulated medical device software development. We examine two related standards, IEC 62304 and IEC 82304-1, for obstacles and benefits of using DevOps for medical device software development. We found these standards to set obstacles for continuous delivery and integration. Respectively, development tools can help fulfilling the requirements of traceability and documentation of these standards.;medical software development standards, DevOps, regulated software, agile development;;;ICSE-NIER '17
Book;Felsen N;Effective DevOps with AWS;;2017;;;;;Packt Publishing;;;;;2017;9781786466815;;;;Key Features Implement DevOps principles to take full advantage of the AWS stack and servicesTake expert look at solving problems faced by real developers and operation teams and learn to overcome themLearn from expert insights of the author who has worked with Silicon Valley's most high-profile companies Book Description The DevOps movement has transformed the way modern tech companies work. AWS which has been on the forefront of the Cloud computing revolution has also been a key contributor of this DevOps movement creating a huge range of managed services that help you implement the DevOps principles. In this book, you'll see how the most successful tech start-ups launch and scale their services on AWS and how you can too. Written by a lead member of Mediums DevOps team, this book explains how to treat infrastructure as code, meaning you can bring resources online and offline as necessary with the code as easily as you control your software. You will also build a continuous integration and continuous deployment pipeline to keep your app up to date. You'll find out how to scale your applications to offer maximum performance to users anywhere in the world, even when traffic spikes with the latest technologies, such as containers and serverless computing. You will also take a deep dive into monitoring and alerting to make sure your users have the best experience when using your service. Finally, you'll get to grips with ensuring the security of your platform and data. What you will learnFind out what it means to practice DevOps and what its principles areBuild repeatable infrastructures using templates and configuration managementDeploy;;;;
Book;Soni M;DevOps Bootcamp: The Fastest Way to Learn DevOps;;2017;;;;;Packt Publishing;;;;;2017;9781787285965;;;;Sharpen your DevOps knowledge with DevOps Bootcamp About This Book Improve your organization's performance to ensure smooth production of software and services. Learn how Continuous Integration and Continuous Delivery practices can be utilized to cultivate the DevOps culture. A fast-paced guide filled with illustrations and best practices to help you consistently ship quality software. Who This Book Is ForThe book is aimed at IT Developers and Operations administrators who want to quickly learn and implement the DevOps culture in their organization. What You Will Learn Static Code Analysis using SOnarqube Configure a Maven-based JEE Web Application Perform Continuous Integration using Jenkins and VSTS Install and configure Docker Converge a Chef node using a Chef workstation Accomplish Continuous Delivery in Microsoft Azure VM and Microsoft Azure App Services (Azure Web Apps) using Jenkins Perform Load Testing using Apache JMeterBuild and Release Automation using Visual Studio Team Services Monitor Cloud-based resourcesIn Detail DevOps Bootcamp delivers practical learning modules in manageable chunks. Each chunk is delivered in a day, and each day is a productive one. Each day builds your competency in DevOps. You will be able to take the task you learn every day and apply it to cultivate the DevOps culture. Each chapter presents core concepts and key takeaways about a topic in DevOps and provides a series of hands-on exercises. You will not only learn the importance of basic concepts or practices of DevOps but also how to use different tools to automate application lifecycle management. We will start off by building the foundation of the DevOps concepts. On day two, we will perform Continuous Integration using Jenkins and VSTS both by configuring Maven-based JEE Web Application. We will also integrate Jenkins and Sonar qube for Static Code Analysis. Further, on day three, we will focus on Docker containers where we will install and configure Docker and also create a Tomcat Container to deploy our Java based web application. On day four, we will create and configure the environment for application deployment in AWS and Microsoft Azure Cloud for which we will use Infrastructure as a Service and Open Source Configuration Management tool Chef. For day five, our focus would be on Continuous Delivery. We will automate application deployment in Docker container using Jenkins Plugin, AWS EC2 using Script, AWS Elastic Beanstalk using Jenkins Plugin, Microsoft Azure VM using script, and Microsoft Azure App Services Using Jenkins. We will also configure Continuous Delivery using VSTS. We will then learn the concept of Automated Testing on day six using Apache JMeter and URL-based tests in VSTS. Further, on day seven, we will explore various ways to automate application lifecycle management using orchestration. We will see how Pipeline can be created in Jenkins and VSTS, so the moment Continuous Integration is completed successfully, Continuous Delivery will start and application will be deployed. On the final day, our focus would be on Security access to Jenkins and Monitoring of CI resources, and cloud-based resources in AWS and Microsoft Azure Platform as a Service. Style and Approach This book is all about fast and intensive learning. This means we dont waste time in helping readers get started. The new content is basically about filling in with highly-effective examples to build new things, solving problems in newer and unseen ways, and solving real-world examples.;;;;
Book;Saito H,Lee HC,Wu CY;DevOps with Kubernetes: Accelerating Software Delivery with Container Orchestrators;;2017;;;;;Packt Publishing;;;;;2017;9781788396646;;;;Learn to implement DevOps using Docker & Kubernetes. About This Book Learning DevOps, container, and Kubernetes within one book. Leverage Kubernetes as a platform to deploy, scale, and run containers efficiently. A practical guide towards container management and orchestration Who This Book Is ForThis book is targeted for anyone, who wants to learn containerization and clustering in a practical way using Kubernetes. No prerequisite skills required, however, essential DevOps skill and public/private Cloud knowledge will accelerate the reading speed. If you're advanced readers, you can also get a deeper understanding of all the tools and technique described in the book. What You Will Learn Learn fundamental and advanced DevOps skills and tools Get a comprehensive understanding for container Learn how to move your application to container world Learn how to manipulate your application by KubernetesLearn how to work with Kubernetes in popular public cloud Improve time to market with Kubernetes and Continuous DeliveryLearn how to monitor, log, and troubleshoot your application with Kubernetes In Detail Containerization is said to be the best way to implement DevOps. Google developed Kubernetes, which orchestrates containers efficiently and is considered the frontrunner in container orchestration. Kubernetes is an orchestrator that creates and manages your containers on clusters of servers. This book will guide you from simply deploying a container to administrate a Kubernetes cluster, and then you will learn how to do monitoring, logging, and continuous deployment in DevOps. The initial stages of the book will introduce the fundamental DevOps and the concept of containers. It will move on to how to containerize applications and deploy them into. The book will then introduce networks in Kubernetes. We then move on to advanced DevOps skills such as monitoring, logging, and continuous deployment in Kubernetes. It will proceed to introduce permission control for Kubernetes resources via attribute-based access control and role-based access control. The final stage of the book will cover deploying and managing your container clusters on the popular public cloud Amazon Web Services and Google Cloud Platform. At the end of the book, other orchestration frameworks, such as Docker Swarm mode, Amazon ECS, and Apache Mesos will be discussed. Style and approach Readers will be taken through fundamental DevOps skills and Kubernetes concept and administration with detailed examples. It introduces comprehensive DevOps topics, including microservices, automation tools, containers, monitoring, logging, continuous delivery, and popular public cloud environments. At each step readers will learn how to leverage Kubernetes in their everyday lives and transform their original delivery pipeline for fast and efficient delivery.;;;;
Conference Paper;Steffens A,Lichter H,Döring JS;Designing a Next-Generation Continuous Software Delivery System: Concepts and Architecture;;2018;;;1–7;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 4th International Workshop on Rapid Continuous Software Engineering;Gothenburg, Sweden;2018;9781450357456;;"https://doi-org.proxy.bnl.lu/10.1145/3194760.3194768;http://dx.doi.org/10.1145/3194760.3194768";10.1145/3194760.3194768;Continuous Integration and Continuous Delivery are established practices in modern agile software development. The DevOps movement adapted theses practices and places the deployment pipeline at its heart as one of the main requirements to automate the software development process and to deliver and operate software in a more robust way with higher quality.Over the time a lot of systems and tools has been developed to implement the deployment pipeline and to support continuous delivery. But software development is complex, its process even more and due to the individual organization of software vendors no real all-in-one solution for CD exists. Literature identified a lot of challenges when adopting CD and DevOps in an organization.This paper presents a conceptual model and fundamental design decisions for a new generation of software delivery systems tackling some of these issues. Our approach focuses on two specific challenges for adopting CD. The first is the lack of flexibility and maintainability of software delivery systems. The second is the insufficient user support to model and manage delivery processes and pipelines. We introduce an automated mechanism to ease the effort for developers and other stakeholders.Based on these results this paper introduces an architectural proposal for a next-generation continuous software delivery system.;domain modelling, devops, microservices, continuous software engineering, continuous delivery, architecture, framework;;;RCoSE '18
Conference Paper;Chung S;Object-Oriented Programming with DevOps;;2017;;;65;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 18th Annual Conference on Information Technology Education;Rochester, New York, USA;2017;9781450351003;;"https://doi-org.proxy.bnl.lu/10.1145/3125659.3125670;http://dx.doi.org/10.1145/3125659.3125670";10.1145/3125659.3125670;DevOps is an emerging culture that emphasizes continuous collaboration between software developers and IT operators through continuous standard process with automated tools for continuous delivery. DevOps participants take diverse roles to support its values - continuous collaboration, continuous process, and continuous delivery. A development team needs to be familiar with user cases, Object-Oriented Analysis (OOA), Object-Oriented Design (OOD), Object-Oriented Programming (OOP), and software testing. A quality assurance team must know use cases, abuse cases, software testing, and penetration testing. An operation team requires understanding deployment of Application Programming Interface (API) documents and executable components, and monitoring them and sharing their monitoring outcomes with both development and quality assurance teams.;devops, oop, reengineering, ebp, oop with devops;;;SIGITE '17
Conference Paper;Zeller M;Towards Continuous Safety Assessment In Context of DevOps;;2021;;;145–157;;Springer-Verlag;Berlin, Heidelberg;;Computer Safety, Reliability, and Security. SAFECOMP 2021 Workshops: DECSoS, MAPSOD, DepDevOps, USDAI, and WAISE, York, UK, September 7, 2021, Proceedings;York, United Kingdom;2021;9783030839055;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-83906-2_11;http://dx.doi.org/10.1007/978-3-030-83906-2_11";10.1007/978-3-030-83906-2_11;Promoted by the internet companies, continuous delivery is more and more appealing to industries which develop systems with safety-critical functions. Since safety-critical systems must meet regulatory requirements and require specific safety assessment processes in addition to the normal development steps, enabling continuous delivery of software in safety-critical systems requires the automation of the safety assessment process in the delivery pipeline. In this paper, we outline a continuous delivery pipeline for realizing continuous safety assessment in software-intensive safety-critical systems based on model-based safety assessment methods.;Agile, Safety assessment, DevOps, Continuous delivery;;;
Conference Paper;Rouf Y,Mukherjee J,Litoiu M,Wigglesworth J,Mateescu R;A Framework for Developing DevOps Operation Automation in Clouds Using Components-off-the-Shelf;;2021;;;265–276;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the ACM/SPEC International Conference on Performance Engineering;Virtual Event, France;2021;9781450381949;;"https://doi-org.proxy.bnl.lu/10.1145/3427921.3450235;http://dx.doi.org/10.1145/3427921.3450235";10.1145/3427921.3450235;DevOps is an emerging paradigm that integrates the development and operations teams to enable fast and efficient continuous delivery of software. Applications and services deployed on cloud platforms can benefit from implementing the DevOps practice. This involves using different tools for enabling end-to-end automation to ensure continuous deployment and maintain good Quality-of-Service. Self-Adaptive systems can support the DevOps process by automating service deployment and maintenance without manual intervention by employing a MAPE-K (Monitoring, Analysis, Planning, Execution- Knowledge) framework. While industrial MAPE-K tools are robust and built for production environments, they lack the flexibility to adapt large applications on multi-cloud environments. Academic models are more flexible and can be used to perform sophisticated self-adaption, but can lack the robustness to be used in production environments. In this paper, we present a MAPE-K framework that is built with existing Components-off-the-Shelf (COTS) that interacts with each other to perform self-adaptive actions on multi-cloud environments. By integrating existing COTS, we are able to deploy a MAPE-K framework efficiently to support DevOps for applications running on a multi-cloud environment. We validate our framework with a prototype implementation and demonstrate its practical feasibility by a detailed case study done on a real industrial platform.;autonomous systems, hybrid cloud, DevOps, self-adaptive, components-off-the-shelf, cloud, multicloud;;;ICPE '21
Book;Vehent J;Securing DevOps: Security in the Cloud;;2018;;;;1st;Manning Publications Co.;USA;;;;2018;9781617294136;;;;Summary Securing DevOps explores how the techniques of DevOps and security should be applied together to make cloud services safer. This introductory book reviews the latest practices used in securing web applications and their infrastructure and teaches you techniques to integrate security directly into your product. You'll also learn the core concepts of DevOps, such as continuous integration, continuous delivery, and infrastructure as a service. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the Technology An application running in the cloud can benefit from incredible efficiencies, but they come with unique security threats too. A DevOps team's highest priority is understanding those risks and hardening the system against them. About the Book Securing DevOps teaches you the essential techniques to secure your cloud services. Using compelling case studies, it shows you how to build security into automated testing, continuous delivery, and other core DevOps processes. This experience-rich book is filled with mission-critical strategies to protect web applications against attacks, deter fraud attempts, and make your services safer when operating at scale. You'll also learn to identify, assess, and secure the unique vulnerabilities posed by cloud deployments and automation tools commonly used in modern infrastructures. What's inside An approach to continuous security Implementing test-driven security in DevOps Security techniques for cloud services Watching for fraud and responding to incidents Security testing and risk assessment About the Reader Readers should be comfortable with Linux and standard DevOps practices like CI, CD, and unit testing. About the Author Julien Vehent is a security architect and DevOps advocate. He leads the Firefox Operations Security team at Mozilla, and is responsible for the security of Firefox's high-traffic cloud services and public websites.;;;;
Conference Paper;Kerzazi N,Adams B;Who Needs Release and Devops Engineers, and Why?;;2016;;;77–83;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the International Workshop on Continuous Software Evolution and Delivery;Austin, Texas;2016;9781450341578;;"https://doi-org.proxy.bnl.lu/10.1145/2896941.2896957;http://dx.doi.org/10.1145/2896941.2896957";10.1145/2896941.2896957;The recent surge in interest in continuous delivery has opened up the job market for release and DevOps engineers. However, despite an increasing number of conferences and publications on continuous delivery, smaller companies and start-ups still have a hard time determining the core tasks their future release and DevOps engineers should be responsible for (and what the differences between those two roles are), while universities are not sure what essential techniques and skills they should teach to their students. This paper performs an empirical analysis of online job postings to determine and compare the main tasks of release and DevOps engineers, globally and across countries. Our qualitative analysis shows that automation is the most important activity across the three roles, as articulated in job posting description data, and that the release engineer role combines the top activities of the DevOps and more traditional build engineer roles. Finally, different countries have a moderate degree of similarity between their ads, although each country has its specific focus.;release engineer, empirical study, job description, devops;;;CSED '16
Book;Farcic V;The DevOps 2.2 Toolkit: Self-Sufficient Docker Clusters Building Self-Adaptive And Self-Healing Docker Clusters (Volume 3);;2017;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2017;9781979347198;;;;"It seems that with each new book the scope gets fuzzier and less precise. When I started writing Test-Driven Java Development the scope of the whole book was done in advance. I had a team working with me. We defined the index and a short description of each chapter. From there on we worked on a schedule as most technical authors do. Then I started writing the second book. The scope was more obscure. I wanted to write about DevOps practices and processes and had only a very broad idea what will be the outcome. I knew that Docker had to be there. I knew that configuration management is a must. Microservices, centralized logging, and a few other practices and tools that I used in my projects were part of the initial scope. For that book, I had no one behind me. There was no team but me, a lot of pizzas, an unknown number of cans of Red Bull, and many sleepless nights. The result is ""The DevOps 2.0 Toolkit: Automating the Continuous Deployment Pipeline with Containerized Microservices"". With the third book, the initial scope became even more obscure. I started writing without a plan. It was supposed to be about cluster management. After a couple of months of work, I attended DockerCon in Seattle where we were presented with the new Docker Swarm Mode. My immediate reaction was to throw everything I wrote to trash and start over. I did not know what will the book be about except that it must be something about Docker Swarm. I was impressed with the new design. Something about Swarm ended up being ""The DevOps 2.1 Toolkit: Docker Swarm: Building, testing, deploying, and monitoring services inside Docker Swarm clusters"". While working on it, I decided to make DevOps Toolkit Series. I thought that it would be great to record my experiences from different experiments, and from working with various companies and open source projects. So, naturally, I started thinking and planning the third installment in the series; ""The DevOps Toolkit 2.""2. The only problem is that, this time, I honestly did not have a clue what will it about. One idea was to do a deep comparison of different schedulers (e.g., Docker Swarm, Kubernetes, and Mesos/Maraton). The another was to explore serverless. Even though it is a terrible name (there are servers, we just don't manage them), it is a great subject. The ideas kept coming, but there was no clear winner. So, I decided not to define the scope. Instead, I defined some general objectives. The goals I set in front of were to build a self-adaptive and self-healing system based on Docker. When I started writing this book, I did not know how I will do that. There were different bits of practices and tools I've been using, but there was no visible light at the end of the tunnel. Instead of defining what the book will be, I defined what I want to accomplish. You can think of this book as my recording of the journey. I had to explore a lot. I had to adopt some new tools and write some code myself. Think of this book as ""Viktor's diary while trying to do stuff."" The objectives are to go beyond a simple setup of a cluster, services, continuous deployment, and all the other things you probably already know. If you don't, read my older books.";;;;
Journal Article;Leite L,Rocha C,Kon F,Milojicic D,Meirelles P;A Survey of DevOps Concepts and Challenges;ACM Comput. Surv.;2019;52;6;;;Association for Computing Machinery;New York, NY, USA;;;;2019-11;;0360-0300;"https://doi-org.proxy.bnl.lu/10.1145/3359981;http://dx.doi.org/10.1145/3359981";10.1145/3359981;DevOpsis a collaborative and multidisciplinary organizational effort to automate continuous delivery of new software updates while guaranteeing their correctness and reliability. The present survey investigates and discusses DevOps challenges from the perspective of engineers, managers, and researchers. We review the literature and develop a DevOps conceptual map, correlating the DevOps automation tools with these concepts. We then discuss their practical implications for engineers, managers, and researchers. Finally, we critically explore some of the most relevant DevOps challenges reported by the literature.;release process, and build process, configuration management, continuous (delivery, deployment, integration), versioning, DevOps;;;
Book Chapter;Ferino S,Fernandes M,Fernandes A,Kulesza U,Aranha E,Treude C;Analyzing DevOps Teaching Strategies: An Initial Study;;2021;;;180–185;;Association for Computing Machinery;New York, NY, USA;Brazilian Symposium on Software Engineering;;;2021;9781450390613;;https://doi-org.proxy.bnl.lu/10.1145/3474624.3477071;;DevOps refers to a set of practices that integrate software development and operations with the primary aim to enable the continuous delivery of high-quality software. DevOps has also promoted several challenges to software engineering teaching. In this paper, we present a preliminary study that analyzes existing teaching strategies reported in the literature. Our findings indicate a set of approaches highlighting the use of environments to support teaching. Our work also investigates how these environments can contribute to address existing challenges and recommendations of DevOps teaching.;;;;
Journal Article;Sjodin R,Barnes S;Teaching Agile Methodologies and DevOps/CI/CD in the Classroom: Concepts, Techniques, Modalities: Panel Discussion;J. Comput. Sci. Coll.;2016;32;2;90–91;;Consortium for Computing Sciences in Colleges;Evansville, IN, USA;;;;2016-12;;1937-4771;;;This panel will address various techniques for teaching agile and DevOps/Continuous Integration/Continuous Deployment methodologies in the classroom. Both online and in-class modalities are addressed.;;;;
Book;Riti P;Pro DevOps with Google Cloud Platform: With Docker, Jenkins, and Kubernetes;;2018;;;;1st;Apress;USA;;;;2018;9781484238967;;;;Use DevOps principles with Google Cloud Platform (GCP) to develop applications and services. This book builds chapter by chapter to a complete real-life scenario, explaining how to build, monitor, and maintain a complete application using DevOps in practice. Starting with core DevOps concepts, continuous integration, and continuous delivery, youll cover common tools including Jenkins, Docker, and Kubernetes in the context of a real microservices application to deploy in the cloud. You will also create a monitor for your cloud and see how to use its data to prevent errors and improve the stability of the system. By the end of Pro DevOps with Google Cloud Platform, you will be able to deploy, maintain, and monitor a real application with GCP. What You Will Learn Build and deploy applications and services using DevOps on Google Cloud Platform Maintain a complete continuous integration (CI) and continuous delivery (CD) pipeline Use containerization with Docker and Kubernetes Carry out CD with GCP and Jenkins Create microservices with Jenkins, Docker, and Kubernetes Monitor your newly deployed application and its deployment and performance Set up security and manage your network with GCP Who This Book Is For Developers and software architects who want to implement DevOps in practice. Some prior programming experience is recommended as well as a basic knowledge of a Linux command-line environment.;;;;
Journal Article;Khan AA,Shameem M;Multicriteria Decision‐Making Taxonomy for DevOps Challenging Factors Using Analytical Hierarchy Process;J. Softw. Evol. Process;2020;32;10;;;John Wiley & Sons, Inc.;USA;;;;2020-10;;2047-7473;"https://doi-org.proxy.bnl.lu/10.1002/smr.2263;http://dx.doi.org/10.1002/smr.2263";10.1002/smr.2263;Development and operations (DevOps) practices significantly accelerate and automate the continuous delivery and deployment of software systems. However, adopting DevOps concepts is not a straightforward job. Most organizations are not able to keep pace with the rhythm of continuous delivery and deployment, which are key DevOps attributes. Despite the significance of DevOps programs, it is still unknown why software development firms are demotivated or unable to adopt them. We tried to fill this gap by investigating, prioritizing, and developing the taxonomy of the key factors that could impact the adaptation and implementation of DevOps practices. We extracted a total of 16 factors from the available literature and empirically assessed them using the survey approach. The identified factors are further classified into three core categories of the software process improvement (SPI) manifesto. The analytical hierarchy process (AHP) approach was used to calculate the prioritization weight for each factor and present it as a taxonomy. The developed taxonomy provides a roadmap to tackle the key challenges to implementing DevOps and offers suggestions for streamlining DevOps practices.;Prioritization, DevOps, AHP, Challenging Factors, Taxonomy;;;
Book;Dive P,Gornalli N;DevOps for Salesforce: Build, Test, and Streamline Data Pipelines to Simplify Development in Salesforce;;2018;;;;;Packt Publishing;;;;;2018;9781788833349;;;;Implement DevOps for Salesforce and explore its features Key Features Learn DevOps principles and techniques for enterprise operations in Salesforce Implement Continuous Integration and Continuous Delivery using tools such as Jenkins and Ant script Use the Force.com Migration Tool and Git to achieve versioning in Salesforce Book Description Salesforce is one of the top CRM tools used these days, and with its immense functionalities and features, it eases the functioning of an enterprise in various areas of sales, marketing, and finance, among others. Deploying Salesforce applications is a tricky event, and it can get quite taxing for admins and consultants. This book addresses all the problems that you might encounter while trying to deploy your applications and shows you how to resort to DevOps to take these challenges head on. Beginning with an overview of the development and delivery process of a Salesforce app, DevOps for Salesforce covers various types of sandboxing and helps you understand when to choose which type. You will then see how different it is to deploy with Salesforce as compared to deploying with another app. You will learn how to leverage a migration tool and automate deployment using the latest and most popular tools in the ecosystem. This book explores topics such as version control and DevOps techniques such as Continuous Integration, Continuous Delivery, and testing. Finally, the book will conclude by showing you how to track bugs in your application changes using monitoring tools and how to quantify your productivity and ROI. By the end of the book, you will have acquired skills to create, test, and effectively deploy your applications by leveraging the features of DevOps. What you will learn Implement DevOps for Salesforce and understand the benefits it offers Abstract the features of Force.com MigrationTool to migrate and retrieve metadata Develop your own CI/CD Pipeline for Salesforce project Use Qualitia to perform scriptless automation for Continuous Testing Track application changes using Bugzilla Apply Salesforce best practices to implement DevOps Who this book is for If you are a Salesforce developer, consultant, or manager who wants to learn DevOps tools and set up pipelines for small as well as large Salesforce projects, this book is for you.;;;;
Conference Paper;Masombuka T,Mnkandla E;A DevOps Collaboration Culture Acceptance Model;;2018;;;279–285;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Annual Conference of the South African Institute of Computer Scientists and Information Technologists;Port Elizabeth, South Africa;2018;9781450366472;;"https://doi-org.proxy.bnl.lu/10.1145/3278681.3278714;http://dx.doi.org/10.1145/3278681.3278714";10.1145/3278681.3278714;Development and Operations (DevOps) is a buzzword in organisations developing software in which reacting to changing requirements and continuous delivery are inevitable. Resolving the issues of siloes between the development and operations departments in order to allow collaboration between them is the underlying philosophy of the DevOps movement. However, existing evidence indicates that the challenges surrounding the adoption of this collaboration culture by management and organisations may not necessarily translate to acceptance at implantation level by the teams. There is therefore a need for a model to guide the adoption.This study investigated human behavioural models and technology acceptance models that predict the behavioural intent to accept new technology. Based on the identified acceptance predictors, a model for successful acceptance of DevOps collaboration culture was proposed. This proposed model would be useful to software development organisations who have already adopted or are about to adopt DevOps.;communication, respect, collaboration, development and operations (DevOps), trust, culture, technology acceptance;;;SAICSIT '18
Book;Farcic V;The DevOps 2.1 Toolkit: Docker Swarm;;2017;;;;;Packt Publishing;;;;;2017;9781787289703;;;;Viktor Farcic's latest book, The DevOps 2.1 Toolkit: Docker Swarm, shows you how to successfully integrate Docker Swarm into your DevOps toolset. About This Book * Expand your DevOps Toolkit with the DevOps thought leader, Viktor Farcic * Build, test, deploy, and monitor services inside Docker Swarm clusters * Translate your understanding to different hosting providers like AWS, Azure, and DigitalOcean * Go beyond simple deployment to explore how to create a continuous deployment process * Extend the deep understanding you gained from Viktor's DevOps 2.0 Toolkit book Who This Book Is For This book is for professionals interested in the full microservices life cycle combined with continuous deployment and containers. Target audience could be architects who want to know how to design their systems around microservices. It could be DevOps wanting to know how to apply modern configuration management practices and continuously deploy applications packed in containers. It is for developers who would like to take the process back into their hands as well as for managers who would like to gain a better understanding of the process used to deliver software from the beginning to the end. This book is for everyone wanting to know more about the software development life cycle starting from requirements and design, through the development and testing all the way until deployment and post-deployment phases. We'll create the processes taking into account the best practices developed by and for some of the biggest companies. What You Will Learn * Learn all aspects of Docker Swarm from building, testing, deploying, and monitoring services inside Docker Swarm clusters, available since Docker 1.12. * Master the deeper logic of DevOps with Viktor, so that you can successfully apply that logic across any specific set of tools you're working with. * Translate a deep understanding to different hosting providers like AWS, Azure, DigitalOcean, among others. * You'll go beyond simple deployment: you will explore with Viktor how to create a continuous deployment process. Accomplish zero-downtime deployments, and what to do in case of a failover. * Know how to run services at scale, how to monitor the systems, and how to make it heal itself. In Detail Viktor Farcic's latest book, The DevOps 2.1 Toolkit: Docker Swarm, takes you deeper into one of the major subjects of his international best seller, The DevOps 2.0 Toolkit, and shows you how to successfully integrate Docker Swarm into your DevOps toolset. Viktor shares with you his expert knowledge in all aspects of building, testing, deploying, and monitoring services inside Docker Swarm clusters. You'll go through all the tools required for running a cluster. You'll travel through the whole process with clusters running locally on a laptop. Once you're confident with that outcome, Viktor shows you how to translate your experience to different hosting providers like AWS, Azure, and DigitalOcean. Viktor has updated his DevOps 2.0 framework in this book to use the latest and greatest features and techniques introduced in Docker. We'll go through many practices and even more tools. While there will be a lot of theory, this is a hands-on book. You won't be able to complete it by reading it on the metro on your way to work. You'll have to read this book while in front of the computer and get your hands dirty. Style and approach We'll go through many practices and even more tools. While there will be a lot of theory, this is a hands-on book. You'll have to read this book while in front of the computer and get your hands dirty. The goal is not to master one particular set of tools, but to learn the logic behind them so that you can apply it to your job in various contexts.;;;;
Conference Paper;Kontogiannis K,Cronin D,Giammaria A,Brealey C,Grigoriou M;DevOps Toolchains for Continuous Engineering and Improvement;;2017;;;326;;IBM Corp.;USA;;Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering;Markham, Ontario, Canada;2017;;;;;"The workshop participants focused-on, and primarily discussed, three main areas a) models to denote and reconcile software system related data, obtained from different and diverse DevOps sources such as version control systems, bug reporting systems, collaboration tools and testing frameworks; b) analytics on software artifacts stored or created by DevOps tools; these artifacts include not only source code but also deployment scripts, configuration files, build specifications, bug reports, version histories, developer's comments and notes and c) infrastructures to support continuous maintenance and deployment by providing insights on deploy or no-deploy decision making choices, and by considering and analyzing information that is collected from the overall application and its constituent components. The workshop topics are related to the IBM DevOps Analytics, IBM DevOps Insights, and IBM DevOps Continuous Delivery (Open Toolchain) frameworks.";;;;CASCON '17
Conference Paper;Gottesheim W;Challenges, Benefits and Best Practices of Performance Focused DevOps;;2015;;;3;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 4th International Workshop on Large-Scale Testing;Austin, Texas, USA;2015;9781450333375;;"https://doi-org.proxy.bnl.lu/10.1145/2693182.2693187;http://dx.doi.org/10.1145/2693182.2693187";10.1145/2693182.2693187;Did you know that just a handful of root causes are responsible for the majority of application issues like crashes, slow performance or incorrect application behavior? Non-optimized database access, deployment mistakes, memory leaks, or inefficient coding are just some examples. Companies that think Continuous Delivery and DevOps will solve all their problems typically fail as they just run into these problems faster. In this session we take a closer look at the most common problems, how to detect them and how to incorporate performance into your DevOps culture by automatically detecting these top problems.;performance, continuous delivery, devops, testing;;;LT '15
Conference Paper;Jennings RA,Gannod G;DevOps - Preparing Students for Professional Practice;;2019;;;1–5;;IEEE Press;Covington, KY, USA;;2019 IEEE Frontiers in Education Conference (FIE);;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/FIE43999.2019.9028598;http://dx.doi.org/10.1109/FIE43999.2019.9028598";10.1109/FIE43999.2019.9028598;This work in progress paper presents a course on DevOps which is a combination of software development skills and software operations skills. This new course is for sophomores and juniors in the computer science program who want to be prepared for professional software engineering careers. Introduction to DevOps Is a hands-on laboratory course that brings students through Git for source code management, Capybara for automated testing, AWS, Docker, and Ansible for automated virtual machine provisioning and configuration, and Jenkins for Continuous Integration. Unlike our current course offerings which primarily focus on the single developer context in a localized environment, this course prepares students for highly collaborative, team-based projects that use cloud resources to facilitate management of the software deployment pipeline. We developed this course based on feedback from our external advisory board and under consultation from a number of industrial partners. This is complementary to our current offerings in software engineering which focus on Agile software practices. In this paper we describe the core concepts, the design, learning experiences, technologies, and lessons learned through developing and conducting this course. In future work we hope to present student perceptions of learning and provide data collected through direct assessment of student outcomes.;;;;
Book;Bangera S;DevOps for Serverless Applications: Design, Deploy, and Monitor Your Serverless Applications Using DevOps Practices;;2018;;;;;Packt Publishing;;;;;2018;9781788623445;;;;Set up complete CI and CD pipelines for your serverless applications using DevOps principles Key Features Understand various services for designing serverless architecture Build CD pipelines using various cloud providers for your serverless applications Implement DevOps best practices when building serverless applications Book Description Serverless applications are becoming very popular among developers and are generating a buzz in the tech market. Many organizations struggle with the effective implementation of DevOps with serverless applications. DevOps for Serverless Applications takes you through different DevOps-related scenarios to give you a solid foundation in serverless deployment. You will start by understanding the concepts of serverless architecture and development, and why they are important. Then, you will get to grips with the DevOps ideology and gain an understanding of how it fits into the Serverless Framework. You'll cover deployment framework building and deployment with CI and CD pipelines for serverless applications. You will also explore log management and issue reporting in the serverless environment. In the concluding chapters, you will learn important security tips and best practices for secure pipeline management. By the end of this book, you will be in a position to effectively build a complete CI and CD delivery pipeline with log management for serverless applications. What you will learn Explore serverless fundamentals and effectively combine them with DevOps Set up CI and CD with AWS Lambda and other popular Serverless service providers with the help of the Serverless Framework Perform monitoring and logging with serverless applications Set up a dynamic dashboard for different service providers Discover best practices for applying DevOps to serverless architecture Understand use cases for different serverless architectures Who this book is for DevOps for Serverless Applications is for DevOps engineers, architects, or anyone interested in understanding the DevOps ideology in the serverless world. You will learn to use DevOps with serverless and apply continuous integration, continuous delivery, testing, logging, and monitoring with serverless.;;;;
Journal Article;Lwakatare LE,Kilamo T,Karvonen T,Sauvola T,Heikkilä V,Itkonen J,Kuvaja P,Mikkonen T,Oivo M,Lassenius C;DevOps in Practice: A Multiple Case Study of Five Companies;Inf. Softw. Technol.;2019;114;C;217–230;;Butterworth-Heinemann;USA;;;;2019-10;;0950-5849;"https://doi-org.proxy.bnl.lu/10.1016/j.infsof.2019.06.010;http://dx.doi.org/10.1016/j.infsof.2019.06.010";10.1016/j.infsof.2019.06.010;;Continuous deployment, Agile, DevOps, Development, Operations;;;
Book;Kort W;DevOps on the Microsoft Stack;;2016;;;;1st;Apress;USA;;;;2016;9781484214473;;;;This book tells you everything you need to know to help your organization implement DevOps on the Microsoft platform. You will learn how to use Visual Studio, Visual Studio Team Services, and Azure to implement a complete DevOps process in your company. You will learn about Agile Project Management, Continuous Integration, Continuous Delivery, Technical Debt Management, Automatic Testing and Monitoring, and see how all these areas fit together. DevOps is important for organizations that want to make the best use of their resources and avoid costly mistakes. Teams that embrace DevOps deploy code up to 30 times more frequently than their competition and less than 50% of their deployments fail according to Puppet Labs State of DevOps survey. DevOps on the Microsoft Stack shows you how to help your organization implement DevOps, covering the tooling they will need and how to make everything work together while following best practices. The focus is not only on technology but also on the cultural issues that teams will face when implementing DevOps. The authors goal is to not only show you which tooling there is but help you to successfully use everything together to implement DevOps in your projects and organization. In this book, you'll learn: What DevOps is and how it can help development teams How to use Visual Studio, Visual Studio Team Services, and Azure to setup a DevOps process How to introduce DevOps to your organization and how to overcome problems;;;;
Book;Ravichandran A,Taylor K,Waterhouse P;DevOps for Digital Leaders: Reignite Business with a Modern DevOps-Enabled Software Factory;;2016;;;;1st;Apress;USA;;;;2016;9781484218419;;;;This book provides digital leaders who are accountable for the rapid development of high-quality software applications a concise guide to designing, implementing, measuring, and improving DevOps programs that are tailored to their organizations. In DevOps for Digital Leaders, deep collective experience on both sides of the devops divide informs the global thought leadership and penetrating insights of the authors, all three of whom are cross-portfolio DevOps leaders at CA Technologies. Aruna Ravichandran, Kieran Taylor, and Peter Waterhouse analyze the organizational benefits, costs, freedoms, and constraints of DevOps. They chart the coordinated strategy of organizational change, metrics, lean thinking, and investment that an enterprise must undertake to realize the full potential of DevOps and reach the sweet spot where accelerating code deployments drive increasing customer satisfaction, revenue, and profitability. Digital leaders are charged to bridge the devops disconnect if their organizations are to survive and flourish in a business world increasingly differentiated by the degree to which dynamic application software development harmonizes with operational resilience and reliability. This short book applies the DevOps perspective to the competitive challenge, faced by every high-performance IT organization today, of integrating and automating open source, cloud, and enterprise tools, processes, and techniques across the software development life cycle from requirements to release. What Readers Will Learn Remove dependencies and constraints so that parallel practices can accelerate the development of defect-free software Automate continuous delivery across the software life cycle to eliminate release bottlenecks, manual labor waste, and technical debt accumulation Generate virtualized production-style testing of applications through real-time behavioral analytics Adopt agile practices so operations teams can support developer productivity with automated feedback, streamline infrastructure monitoring, spot and resolve operations issues before they impact production, and improve customer experience Identify the DevOps metrics appropriate to your organization and integrate DevOps with your existing best practices and investment Who This Book Is ForIT leaders in largecompanies and government agencies who have any level of responsibility for the rapid development of high-quality software applications. The secondary readership is members of development and operations teams, security professionals, and service managers.;;;;
Conference Paper;Rimba P,Zhu L,Bass L,Kuz I,Reeves S;Composing Patterns to Construct Secure Systems;;2015;;;213–224;;IEEE Computer Society;USA;;Proceedings of the 2015 11th European Dependable Computing Conference (EDCC);;2015;9781467392891;;"https://doi-org.proxy.bnl.lu/10.1109/EDCC.2015.12;http://dx.doi.org/10.1109/EDCC.2015.12";10.1109/EDCC.2015.12;Building secure applications requires significant expertise. Secure platforms and security patterns have been proposed to alleviate this problem. However, correctly applying patterns to use platform features is still highly expertise-dependent. Patterns are informal and there is a gap between them and platform features. We propose the concept of reusable verified design fragments, which package security patterns and platform features and are verified to provide assurance about their security properties. Design fragments can be composed through four primitive tactics. The verification of the composed design against desired security properties is presented in an assurance case. We demonstrate our approach by securing a Continuous Deployment pipeline and show that the tactics are sufficient to compose design fragments into a secure system. Finally, we formally define composition tactics, which are intended to support the development of systems that are secure by construction.;;;;EDCC '15
Conference Paper;Yang B,Sailer A,Mohindra A;Survey and Evaluation of Blue-Green Deployment Techniques in Cloud Native Environments;;2019;;;69–81;;Springer-Verlag;Berlin, Heidelberg;;Service-Oriented Computing – ICSOC 2019 Workshops: WESOACS, ASOCA, ISYCC, TBCE, and STRAPS, Toulouse, France, October 28–31, 2019, Revised Selected Papers;Toulouse, France;2019;9783030459888;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-45989-5_6;http://dx.doi.org/10.1007/978-3-030-45989-5_6";10.1007/978-3-030-45989-5_6;Today, the cloud computing customers assume that the services or applications consumed from the cloud are always on, highly available for uninterrupted utilization. The requirement then for the service providers becomes to minimize the planned maintenance windows duration in order to reduce their repercussions on the service availability for the consumers. We evaluate in this paper the continuous deployment methodology called Blue/Green deployment which aims to support zero maintenance windows, and consequently to avoid any interruption to the end users. Our experiments analyze the most common Blue/Green deployment techniques in the industry, measure and normalize their behavior, and aim to identify the approach with the best performing continuous delivery as compared to the available technologies.;High availability, Continuous delivery, Blue/Green deployment, Service discovery;;;
Journal Article;Hemon A,Lyonnet B,Rowe F,Fitzgerald B;From Agile to DevOps: Smart Skills and Collaborations;Information Systems Frontiers;2020;22;4;927–945;;Kluwer Academic Publishers;USA;;;;2020-08;;1387-3326;"https://doi-org.proxy.bnl.lu/10.1007/s10796-019-09905-1;http://dx.doi.org/10.1007/s10796-019-09905-1";10.1007/s10796-019-09905-1;Although agile software development approaches have become increasingly prevalent, many organizations, have found they were not able to achieve a more frequent release cadence, largely due to different departmental functions operating in silos. In an effort to remove these silos, companies have moved towards DevOps. As digitalization continues, companies increasingly implement DevOps. We suggest three different stages in the agile to DevOps transition: agile, continuous integration, and continuous delivery. Based on an in-depth case study in an organization with several years’ experience in DevOps, we identify a fundamental disruption in the soft skills that software teams are expected to possess, and in the patterns of collaboration among teams. Arguably, smartness may be characterized as being flexible, teaming up with people who have a different profile, belonging to a different function, and achieving a quicker delivery schedule. In light of this, we argue that DevOps leads to greater smartness for the Information Systems function.;Agile, Roles, Smartness, Skills, Collaboration, DevOps;;;
Conference Paper;Olszewska M,Waldén M;DevOps Meets Formal Modelling in High-Criticality Complex Systems;;2015;;;7–12;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1st International Workshop on Quality-Aware DevOps;Bergamo, Italy;2015;9781450338172;;"https://doi-org.proxy.bnl.lu/10.1145/2804371.2804373;http://dx.doi.org/10.1145/2804371.2804373";10.1145/2804371.2804373;Quality is the cornerstone of high criticality systems, since in case of failure not only major financial losses are at stake, but also human lives. Formal methods that support model based-development are one of the methodologies used to achieve correct-by-construction systems. However, these are often heavy-weight and need a dedicated development process. In our work we combine formal and agile software engineering approaches. In particular, we use Event-B and Scrum to assure the quality and more rapid and flexible development. Since we identified that there are more prerequisites for a successful IT project, we use DevOps to embrace the development, quality assurance and IT operations. In this paper we show how formal modelling can function within DevOps and thus promote various dimensions of quality and continuous delivery.;DevOps, Agile, formal modelling, Scrum, Event-B;;;QUDOS 2015
Conference Paper;Cukier D;DevOps Patterns to Scale Web Applications Using Cloud Services;;2013;;;143–152;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2013 Companion Publication for Conference on Systems, Programming, & Applications: Software for Humanity;Indianapolis, Indiana, USA;2013;9781450319959;;"https://doi-org.proxy.bnl.lu/10.1145/2508075.2508432;http://dx.doi.org/10.1145/2508075.2508432";10.1145/2508075.2508432;Scaling a web applications can be easy for simple CRUD software running when you use Platform as a Service Clouds (PaaS). But if you need to deploy a complex software, with many components and a lot users, you will need have a mix of cloud services in PaaS, SaaS and IaaS layers. You will also need knowledge in architecture patterns to make all these software components communicate accordingly. In this article, we share our experience of using cloud services to scale a web application. We show usage examples of load balancing, session sharing, e-mail delivery, asynchronous processing, logs processing, monitoring, continuous deployment, realtime user monitoring (RUM). These are a mixture of development and system operations (DevOps) that improved our application availability, scalability and performance.;tomcat, rest, email, cloud, AWS, paas, devops, SAAS, ELO7, APIs, scalability, cloud computing, ELB, scalable, web services, load balancing, S3, IAAS;;;SPLASH '13
Conference Paper;Brunnert A,Krcmar H;Detecting Performance Change in Enterprise Application Versions Using Resource Profiles;;2014;;;165–172;;ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering);Brussels, BEL;;Proceedings of the 8th International Conference on Performance Evaluation Methodologies and Tools;Bratislava, Slovakia;2014;9781631900570;;"https://doi-org.proxy.bnl.lu/10.4108/icst.valuetools.2014.258184;http://dx.doi.org/10.4108/icst.valuetools.2014.258184";10.4108/icst.valuetools.2014.258184;Performance characteristics (i.e., response time, throughput, resource utilization) of enterprise applications change for each version due to feature additions, bug fixes or configuration changes. Therefore, performance needs to be continuously evaluated to detect performance changes (i.e., improvements or regressions). This work proposes a performance change detection process by creating and versioning resource profiles for each application version that is being built. Resource profiles are models that describe the resource demand per transaction for each component of an enterprise application and their control flow. Combined with workload and hardware environment models, resource profiles can be used to predict performance. Performance changes can be identified by comparing the performance metrics resulting from predictions of different resource profile versions (e.g., by observing an increase or decrease of response time). The source of changes in the resulting performance metrics can be identified by comparing the profiles of different application versions. We propose and evaluate an integration of these capabilities into a deployment pipeline of a continuous delivery process.;palladio component model, performance change detection, Java, enterprise applications, performance evaluation;;;VALUETOOLS '14
Conference Paper;Lwakatare LE,Karvonen T,Sauvola T,Kuvaja P,Olsson HH,Bosch J,Oivo M;Towards DevOps in the Embedded Systems Domain: Why is It So Hard?;;2016;;;5437–5446;;IEEE Computer Society;USA;;Proceedings of the 2016 49th Hawaii International Conference on System Sciences (HICSS);;2016;9780769556703;;"https://doi-org.proxy.bnl.lu/10.1109/HICSS.2016.671;http://dx.doi.org/10.1109/HICSS.2016.671";10.1109/HICSS.2016.671;DevOps is a predominant phenomenon in the web domain. Its two core principles emphasize collaboration between software development and operations, and the use of agile principles to manage deployment environments and their configurations. DevOps techniques, such as collaboration and behaviour-driven monitoring, have been used by web companies to facilitate continuous deployment of new functionality to customers. The techniques may also offer opportunities for continuous product improvement when adopted in the embedded systems domain. However, certain characteristics of embedded software development present obstacles for DevOps adoption, and as yet, there is no empirical evidence of its adoption in the embedded systems domain. In this study, we present the challenges for DevOps adoption in embedded systems using a multiple-case study approach with four companies. The contribution of this paper is to introduce the concept of DevOps adoption in the embedded systems domain and then to identify key challenges for the DevOps adoption.;;;;HICSS '16
Book;Armstrong S;DevOps for Networking;;2016;;;;;Packt Publishing;;;;;2016;9781786464859;;;;Boost your organization's growth by incorporating networking in the DevOps culture About This Book Implement networking fundamentals to the DevOps culture with ease, improving your organization's stabilityLeverage various open source tools such as Puppet and Ansible in order to automate your network This step-by-step learning guide collaborating the functions of developers and network administrators Who This Book Is For The book is aimed for Network Engineers, Developers, IT operations and System admins who are planning to incorporate Networking in DevOps culture and have no knowledge about it. What You Will Learn Learn about public and private cloud networking using AWS and OpenStack as examples Explore strategies that can be used by engineers or managers to initiate the cultural changes required to enable the automation of network functions Learn about SDN and how an API-driven approach to networking can help solve common networking problemsGet the hang of configuration management tools, such as Ansible and Jenkins, that can be used to orchestrate and configure network devicesSetup continuous integration, delivery, and deployment pipelines for network functions Create test environments for network changes Understand how load balancing is becoming more software defined with the emergence of microservice applications In Detail Frustrated that your company's network changes are still a manual set of activities that slow developers down? It doesn't need to be that way any longer, as this book will help your company and network teams embrace DevOps and continuous delivery approaches, enabling them to automate all network functions. This book aims to show readers network automation processes they could implement in their organizations. It will teach you the fundamentals of DevOps in networking and how to improve DevOps processes and workflows by providing automation in your network. You will be exposed to various networking strategies that are stopping your organization from scaling new projects quickly. You will see how SDN and APIs are influencing DevOps transformations, which will in turn help you improve the scalability and efficiency of your organizations networks operations. You will also find out how to leverage various configuration management tools such as Ansible, to automate your network. The book will also look at containers and the impact they are having on networking as well as looking at how automation impacts network security in a software-defined network. Style and approach This will be a comprehensive, learning guide for teaching our readers how networking can be leveraged to improve the DevOps culture for any organization.;;;;
Journal Article;Rahman A,Williams L;Source Code Properties of Defective Infrastructure as Code Scripts;Inf. Softw. Technol.;2019;112;C;148–163;;Butterworth-Heinemann;USA;;;;2019-08;;0950-5849;"https://doi-org.proxy.bnl.lu/10.1016/j.infsof.2019.04.013;http://dx.doi.org/10.1016/j.infsof.2019.04.013";10.1016/j.infsof.2019.04.013;;Continuous deployment, Devops, Configuration as code, Puppet, Defect prediction, Empirical study, Infrastructure as code;;;
Book;Davis A;Mastering Salesforce DevOps: A Practical Guide to Building Trust While Delivering Innovation;;2019;;;;1st;Apress;USA;;;;2019;9781484254721;;;;This practical guide brings DevOps principles to Salesforce development. It fits together two major movements within the IT world: the movement to Software/Platform as a Service (SaaS/PaaS), and the DevOps movement. While SaaS and PaaS allow companies to invest in their core competencies rather than maintain their own infrastructure, the goal of DevOps is to optimize the process of delivering software innovation and value. The release of Salesforce DX in late 2017 unlocks the possibility of a true DevOps workflow on Salesforce. But DevOps is new to the Salesforce world and there is not a widespread understanding of its goals and methods, and so adoption of Salesforce DX is still in the early stages. Mastering Salesforce DevOps explains how to build a powerful and comprehensive DevOps workflow for Salesforce-allowing you to finally deploy the world's most innovative platform using the world's most effective and efficient techniques. It addresses the need for a comprehensive guide to DevOps for Salesforce, allowing teams to bring proven practices from the IT world to resolve the hardest problems facing Salesforce developers today. What You Will Learn Improve company performance and software delivery performance using Salesforce DX Translate DevOps concepts into the unique language and practices of Salesforce Understand why and how you can implement Salesforce DX to achieve greater productivity and innovation Enable continuous delivery on Salesforce Build packages and architect code so it can be deployed easily Allow admins to participate in what has traditionally been a developer workflow Know the techniques for reducing the stress and risk of deployment Apply the full range of automated tests that can be used on Salesforce Who This Book Is for Salesforce developers, release managers, and those managing Salesforce development teams who need a guide to DevOps, and DevOps specialists who need to apply familiar concepts to Salesforce;;;;
Book;Kantsev V;Implementing DevOps on AWS;;2017;;;;;Packt Publishing;;;;;2017;9781786460141;;;;Key FeaturesWork through practical examples and gain DevOps best practices to successfully deploy applications on AWSSuccessfully provision and operate distributed application systems and your AWS infrastructure using DevOps Perform Continuous Integration and deployment and fine-tune the way you deliver on AWS Book Description Knowing how to adopt DevOps in your organization is becoming an increasingly important skill for developers, whether you work for a start-up, an SMB, or an enterprise. This book will help you to drastically reduce the amount of time spent on development and increase the reliability of your software deployments on AWS using popular DevOps methods of automation. To start, you will get familiar with the concept of IaC and will learn to design, deploy, and maintain AWS infrastructure. Further on, youll see how to design and deploy a Continuous Integration platform on AWS using either open source or AWS provided tools/services. Following on from the delivery part of the process, you will learn how to deploy a newly created, tested, and verified artefact to the AWS infrastructure without manual intervention. You will then find out what to consider in order to make the implementation of Configuration Management easier and more effective. Toward the end of the book, you will learn some tricks and tips to optimize and secure your AWS environment. By the end of the book, you will have mastered the art of implementing DevOps practices onto AWS. What you will learn Design and deploy infrastructure as code within your AWS Virtual Private Cloud Implement Continuous Integration using AWS Services Configure EC2 instances using Salt Stack Implement Continuous Deployment using Jenkins and the AWS CLI Collect important metrics and log data to gain more insight into infrastructure and applications Troubleshooting popular issues with some less known techniques using the AWS platform About the Author Veselin Kantsev is a DevOps professional and a Linux enthusiast who lives in London, UK. His introduction to Linux was as a System Administrator back in 2006. His focus for the past few years has been mostly on cloud technologies and the transition of the community from an Ops to a DevOps culture. He has worked with companies in various sectors such as Design, Media, and Finance, specializing in the migration of infrastructure onto AWS and the promotion of DevOps principles and practices;;;;
Book;Fawzy A;A Beginner's Guide to DevOps & Cloud: Concept & Implementation;;2018;;;;;;;;;;2018;9781949814019;;;;Learn How to Design Cloud Solutions and implement DevOpsWhat if you can design cloud solutions to improve your business services? What if you can utilize the DevOps methods and best practices to improve both development and operation process? Ahmed Fawzy, present an approached to improve IT Operations using DevOps and Cloud. Based on 14 years of experience building services for various organizations of different sizes across all sectors, Ahmed answer the question: How Cloud and DevOps deliver value to the Business? In this book you will learn: Understand Business Requirements How to become a DevOps Team member Create a process thats actually works How to migrate applications to Cloud How to realize the business value How to translate Goals into projects How to build a team, change the organization and overcome resistance. How to create a Business Case How to Assess the running processes and determine the GapLearn the core concepts of cloud computing What is a cloud? Private cloud, Public cloud IAAS, SAAS, PAAS Cloud benefits Advantages and disadvantages of cloud computing Learn the core concepts of DevOps Continuous delivery and continuous integration Infrastructure as code Get an overview on Microservices Containers Serverless Computing Site Reliability Engineering Learn this and more, Buy this book NOW to learn How Cloud and DevOps deliver value to the Business. Pick up your copy by clicking buy now at the top of this page!;;;;
Book;Abdoulaye PA;The DevOps Revolution: Disrupting the Status Quo - From IT Modernization to Digital Competitiveness;;2018;;;;;Independently published;;;;;2018;9781731123022;;;;Forget about those DevOps, Cloud Computing, AI, Big Data scattered implementations that solution vendors urge you to proceed to. They remain poor investments as long as they don't guarantee that your company will survive and succeed in markets disrupted by Google, Amazon, Facebook, Apple (GAFA) as well as Walmart and all the innovative tech startups out there. In this very practical guide, fast, and easy to read, Philippe Abdoulaye, featured several times on Forbes, ZDNet, Inc, cited as a major contributor to the future of the CIO job in 2018, tells all about how to properly and rapidly transform your business including IT around these technologies. Building on the failure and success cases in the increasingly raging digital competition Weight Watchers, Fitbit, Toys R Us, Sears he reveals the secrets, techniques, and tips of the very few companies that have been succeeding. Youll learn: (1) Why Amazons irruption in the toy market, kicked Toys R Us out of business (2) How Weight watchers struggled to survive the disrupted diet market (3) How the GAFAs platform business model is expanding the network economy a standard and changing the way we do business (4) Whats the DevOps culture and how to implement it (5) How DevOps when implemented entirely unlocks platform models competitive advantage (6) Why DevOps features agile and lean practices, continuous delivery, Microservices and containers enable the business benefits of platforms (7) How augmenting DevOps with Design Thinking principles makes it a powerful digital service development platform (8) Actionable DevOps-based Platform Architecture businesses can reuse (9) How WellBeing, Inc., took advantage of the BlueBird platform to disrupt the diet market and put leading and historical firms in troubles. Your company or your career success in the digital economy is your dream, one that you want to share with your staff, clients, and stakeholders. The DevOps Revolution is the complete tool you need to make that dream a reality, ignoring it would be a terrible mistake.;;;;
Conference Paper;Sharif M,Janto S,Lueckemeyer G;COaaS: Continuous Integration and Delivery Framework for HPC Using Gitlab-Runner;;2020;;;54–58;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2020 the 4th International Conference on Big Data and Internet of Things;Singapore, Singapore;2020;9781450375504;;"https://doi-org.proxy.bnl.lu/10.1145/3421537.3421539;http://dx.doi.org/10.1145/3421537.3421539";10.1145/3421537.3421539;To quickly and securely deploy the latest version of hardware and software resources, DevOps communities use continuous delivery, continuous integration, and continuous deployment framework. This paper presents the methodology adopted by the m41ab team of the University of Applied Sciences to use the CI/CD framework in the development of workflows and shows the benefits that can be achieved using the CI/CD framework. Using High-Performance Computing (HPC) along with GitLab runners, we show that the use of Continuous Integration and Delivery framework can efficiently overcome software management challenges even without knowing much about HPC. We present our CI/CD infrastructure deployed for the transfer portal for m41ab, and explain how Gitlab-Runner allows end-user to adapt the environment to use HPC for computation diligently. The research, by use-case, shows the way forward to use the m41ab transfer portal for developing and maintaining the computing resources. Similarly traditional software, HPC software management is a complicated process that shares a number of objectives with enterprise-scale software development which obliges trustworthy updates and validation on a hard deadline.;M4LAB, continuous integration (CI), containers, software automation, continuous deployment (CD), High Performance Computing (HPC), simstadt, Message Passing Interface (MPI), software builds, continuous delivery (CD);;;BDIOT 2020
Conference Paper;Kontogiannis K,Brealey C,Giammaria A,Countryman B,Grigoriou M,Jimenez M,Fokaefs M,Kassam F,Bordeleau F;2nd Workshop on DevOps and Software Analytics for Continuous Engineering and Improvement;;2018;;;369–370;;IBM Corp.;USA;;Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering;Markham, Ontario, Canada;2018;;;;;"The workshop participants focused and discussed the following areas a) techniques, tools, and schemas to mine software repositories including DevOps environments as well as techniques for denoting information extracted from these repositories. Such information includes not only source code but also deployment scripts, configuration files, build specifications, bug reports, version histories, developers comments and other notes; b) techniques to reconcile software system related data, obtained from such different and diverse DevOps sources (e.g. version control systems, bug reporting systems, collaboration tools and testing frameworks); c) static and dynamic software analysis techniques in order to identify and model direct and indirect dependencies in complex systems, with emphasis on micro-services based systems; and d) software analytics techniques in order to assess deployment risks in order to support continuous maintenance and deployment by providing insights on deploy or no-deploy decision making choices. The workshop topics are related to the IBM DevOps Analytics, IBM DevOps Insights, and IBM DevOps Continuous Delivery (Open Toolchain) frameworks.";;;;CASCON '18
Conference Paper;Alperowitz L,Weintraud AM,Kofler SC,Bruegge B;Continuous Prototyping;;2017;;;36–42;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 3rd International Workshop on Rapid Continuous Software Engineering;;2017;9781538604281;;;;"Developing for devices like smartphones, tablets or smartwatches is more than just ""shipping code"". Especially in mobile development there is a strong focus on user interface design and user experience. In order to explore the design space, development teams and designers need early feedback from users testing the designs.Continuous Delivery (CD) is a well-established technique for the delivery of software. In this paper we describe Continuous Prototyping which extends CD to cover the delivery of early artifacts like user interface mockups that usually do not benefit from an automated delivery process. Continuous Prototyping enables stakeholders to receive all artifacts through a unified delivery pipeline in fast cycles, from the first mockup to the finished product.We developed Prototyper as a tool to demonstrate the technical feasibility of Continuous Prototyping. Prototyper allows developers and designers to deliver mockups, mobile applications as will as a mixture of both using the same deployment pipeline. In a experiment with 42 developers we found that applying Continuous Prototyping not only reduces the cycle time for delivering mockups and receiving feedback but also facilitates the frequent delivery of mockups in early project stages.";;;;RCoSE '17
Conference Paper;Alonso J,Stefanidis K,Orue-Echevarria L,Blasi L,Walker M,Escalante M,López MJ,Dutkowski S;DECIDE: An Extended DevOps Framework for Multi-Cloud Applications;;2019;;;43–48;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2019 3rd International Conference on Cloud and Big Data Computing;Oxford, United Kingdom;2019;9781450371650;;"https://doi-org.proxy.bnl.lu/10.1145/3358505.3358522;http://dx.doi.org/10.1145/3358505.3358522";10.1145/3358505.3358522;DevOps represents a model for application development that enables close collaboration between software developers and IT operations with the objective of implementing continuous integration, continuous delivery and continuous development of software applications. This paper proposes an approach for extending the DevOps philosophy with the objective of supporting the development and operation of multi-cloud native applications deployed over heterogeneous cloud resources. The authors present the extended DECIDE DevOps framework and the supporting tool suite developed in the context of the DECIDE H2020 action;DevOps, Cloud Computing, Continuous pre-deployment, continuous adaptation, Continuous Design, Multi-cloud, deployment optimization, continuous monitoring;;;ICCBDC 2019
Conference Paper;de S. Campos Junior H,de Paiva CA,Braga R,Araújo MA,David JM,Campos F;Regression Tests Provenance Data in the Continuous Software Engineering Context;;2017;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2nd Brazilian Symposium on Systematic and Automated Software Testing;Fortaleza, Brazil;2017;9781450353021;;"https://doi-org.proxy.bnl.lu/10.1145/3128473.3128483;http://dx.doi.org/10.1145/3128473.3128483";10.1145/3128473.3128483;Regression tests are executed after every change in software. In a software development environment that adopts Continuous Software Engineering practices such as Continuous Integration, Continuous Delivery and Continuous Deployment, software is changed, built and tested many times. Every regression test execution may include different situations and problems that are treated in isolated way. Data provenance is concerned with the origins and processes that some data has gone through, until it becomes information. Ontologies are formal models that contain axioms and relationships between classes and individuals from a specific context and can be used to infer implicit knowledge. Considering that Continuous Software Engineering activities are based on feedback cycles, in this paper, we propose an architecture based on the use of an ontology and provenance model to capture and provide regression tests data to support the continuous improvement of software testing processes. Moreover, using ontology and provenance to track execution performance and issues in this scenario, may increase the chances of those issues not happening again, since practitioners can address and solve them for future executions.;Continuous Testing, Data Provenance, Ontological Inferences, Process Improvement, Continuous Integration;;;SAST
Conference Paper;Mizutani I,Ramanathan G,Mayer S;Integrating Multi-Disciplinary Offline and Online Engineering in Industrial Cyber-Physical Systems through DevOps;;2021;;;40–47;;Association for Computing Machinery;New York, NY, USA;;11th International Conference on the Internet of Things;St.Gallen, Switzerland;2021;9781450385664;;"https://doi-org.proxy.bnl.lu/10.1145/3494322.3494328;http://dx.doi.org/10.1145/3494322.3494328";10.1145/3494322.3494328;Industry 4.0 is transforming industrial automation systems into increasingly complex cyber-physical systems (CPS). In particular, there is a need to integrate systems across horizontal and vertical layers across industrial and disciplinary domains. The development of industrial CPS requires not only high-level configuration and control at the execution system level, but also offline and online engineering (OOE) work, including mechanical and electrical engineering of the devices, their installation, networking, and documentation. Using DevOps, a collection of modern software lifecycle management tactics, we propose to build an integrated platform to manage the OOE tasks. Continuous Integration/Continuous Delivery (CI/CD) pipelines and Infrastructure as Code, which are key aspects of DevOps, coordinate the building, testing, and deployment of software services. To bring the corresponding benefits of pure software systems to industrial CPS, we integrate engineering tasks using distributed version control and the W3C Web of Things. As a proof of concept, we implemented the concept for a mock system that includes the OOE tasks in a process automation scenario. The DevOps platform provides a structured transfer and exchange of engineering knowledge among stakeholders involved in industrial CPS.;Web of Things, Cyber-Physical Systems, DevOps, Industrial Automation, CI/CD;;;IoT '21
Conference Paper;Williams L;Continuously Integrating Security;;2018;;;1–2;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1st International Workshop on Security Awareness from Design to Deployment;Gothenburg, Sweden;2018;9781450357272;;"https://doi-org.proxy.bnl.lu/10.1145/3194707.3194717;http://dx.doi.org/10.1145/3194707.3194717";10.1145/3194707.3194717;Continuous deployment is a software engineering process where incremental software changes are automatically tested and frequently deployed to production environments. With continuous deployment, the elapsed time for a change made by a developer to reach a customer can now be measured in days or even hours. To understand the emerging practices surrounding continuous deployment, three annual one-day Continuous Deployment Summits have been held at Facebook, Netflix, and Google in 2015--2017, where 17 companies have described how they used continuous deployment. This short paper will describe the practices and environment used by these companies as they strive to develop secure and privacy-preserving products while making ultra-fast changes.;devsecops, devops, continuous deployment, software security;;;SEAD '18
Conference Paper;Fitzgerald B,Stol KJ;Continuous Software Engineering and beyond: Trends and Challenges;;2014;;;1–9;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1st International Workshop on Rapid Continuous Software Engineering;Hyderabad, India;2014;9781450328562;;"https://doi-org.proxy.bnl.lu/10.1145/2593812.2593813;http://dx.doi.org/10.1145/2593812.2593813";10.1145/2593812.2593813;Throughout its short history, software development has been characterized by harmful disconnects between important activities e.g., planning, development and implementation. The problem is further exacerbated by the episodic and infrequent performance of activities such as planning, testing, integration and releases. Several emerging phenomena reflect attempts to address these problems. For example, the Enterprise Agile concept has emerged as a recognition that the benefits of agile software development will be sub- optimal if not complemented by an agile approach in related organizational function such as finance and HR. Continuous integration is a practice which has emerged to eliminate discontinuities between development and deployment. In a similar vein, the recent emphasis on DevOps recognizes that the integration between software development and its operational deployment needs to be a continuous one. We argue a similar continuity is required between business strategy and development, BizDev being the term we coin for this. These disconnects are even more problematic given the need for reliability and resilience in the complex and data-intensive systems being developed today. Drawing on the lean concept of flow, we identify a number of continuous activities which are important for software development in today’s context. These activities include continuous planning, continuous integration, continuous deployment, continuous delivery, continuous verification, continuous testing, continuous compliance,continuous security, continuous use, continuous trust, continuous run-time monitoring, continuous improvement (both process and product), all underpinned by continuous innovation. We use the umbrella term, ``Continuous *'' (continuous star) to identify this family of continuous activities.;BizDev, continuous software engineering, Continuous Star, DevOps;;;RCoSE 2014
Conference Paper;Debroy V,Miller S,Brimble L;Building Lean Continuous Integration and Delivery Pipelines by Applying DevOps Principles: A Case Study at Varidesk;;2018;;;851–856;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Lake Buena Vista, FL, USA;2018;9781450355735;;"https://doi-org.proxy.bnl.lu/10.1145/3236024.3275528;http://dx.doi.org/10.1145/3236024.3275528";10.1145/3236024.3275528;Continuous Integration (CI) and Continuous Delivery (CD) are widely considered to be best practices in software development. Studies have shown however, that adopting these practices can be challenging and there are many barriers that engineers may face, such as – overly long build times, lack of support for desired workflows, issues with configuration, etc. At Varidesk, we recently began shifting our primary web application (from a monolithic) to a micro-services-based architecture and also adapted our software development practices to aim for more effective CI/CD. In doing so, we also ran into some of the same afore-mentioned barriers. In this paper we focus on two specific challenges that we faced – long wait times for builds/releases to be queued and completed, and the lack of support for tooling, especially from a cross-cloud perspective. We then present the solutions that we came up with, which involved re-thinking DevOps as it applied to us, and re-building our own CI/CD pipelines based on DevOps-supporting approaches such as containerization, infrastructure-as-code, and orchestration. Our re-designed pipelines have led us to see speed increases, in terms of total build/release time, in the range of 330x-1110x and have enabled us to seamlessly move from a single-cloud to a multi- cloud environment, with no architectural changes to any apps.;Continuous Deployment, DevOps, Software Build, Software Release, Continuous Integration, Continuous Delivery;;;ESEC/FSE 2018
Conference Paper;McCarthy MA,Herger LM,Khan SM,Belgodere BM;Composable DevOps: Automated Ontology Based DevOps Maturity Analysis;;2015;;;600–607;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE International Conference on Services Computing;;2015;9781467372817;;"https://doi-org.proxy.bnl.lu/10.1109/SCC.2015.87;http://dx.doi.org/10.1109/SCC.2015.87";10.1109/SCC.2015.87;"In this era of the emerging digitized, mobilized, and cloudified enterprises, the concept of the ""compos able business"" is the most critical piece which ties everything together. The digital enterprise is here, and its prime characteristic is that is essentially detaches and segregates existing businesses and reassembles them according to market demands. Every industry, from transportation to eyewear is up for disruption, and developers are in the forefront of this movement. In turn, these developers are under intense pressure to accelerate time to market. The compos able enterprise approach requires a reconsideration of traditional models of the entire IT organization. These organization and their processes need to be broken up into components that follow certain key design principles such as The Minimal Functions with least Dependencies, portability, Shared Knowledge, Predictable Contracts and Maximized Human Value. The last three bullet points encapsulate the very definition of DevOps [3]. The concept of better integration between Development and Operations is a valuable objective. The goal is to foster measurable incremental cultural change to derive most overall value out of the union of people, process and technology. But the cultural issues, reward models, and risk allocation create obvious barriers in attaining those goals. The common industry belief is to use the compos able enterprise framework to build a platform using the right tools and you will have attained DevOps nirvana. In this paper we will explore valuable lessons learned from our mistakes in tool centric adoption of IT Infrastructure Library (ITIL) [8]. We will also show how we applied those lessons to develop a lightweight compos able/contextual DevOps framework that learns and measure itself to avoid those cultural pitfalls.";ontology, itil, devops, maturity, semantic, deontic;;;SCC '15
Book;Warnock D;DevOps: From Newbie to Professional. Fast and Simple Guide to DevOps;;2016;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2016;9781533114181;;;;"DevOps From newbie to professional. Fast and simple guide to DevOps This book discusses DevOps. It begins by guiding you on the measures which you can take so as to make a cultural change in DevOps teams. The process of deployment with Capistrano, Thin, and nginx is also been discussed in this book.. ElasticSearch, which is a search engine is examined in detail. You will learn how to analyze text for content enrichment in this search engine. Searchable documents are also covered in detail. After reading this book, you will know how to work with tc. The Docker compose and the Couchbase cluster are also been discussed in this book. You will learn how to create nodes and then add them to clusters by use of the Docker compose. The book will also guide you on how to work with multiple instances of Tomcat. The use of Mailgun API so as to simplify email in an app is examined in detail. The following topics are discussed in this book: Making a Cultural Change in DevOps Teams Deployment with Capistrano, Thin,and nginx ElasticSearch Analyzing Text for Content Enrichment Searchable Documents Working with tc Couchbase Cluster by use of Docker Compose Multiple Tomcat Instances Simplifying Email in a App using Mailgun API Download your copy of "" DevOps"" by scrolling up and clicking ""Buy Now With 1-Click"" button.";;;;
Journal Article;Ebert C,Gallardo G,Hernantes J,Serrano N;DevOps;IEEE Softw.;2016;33;3;94–100;;IEEE Computer Society Press;Washington, DC, USA;;;;2016-05;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2016.68;http://dx.doi.org/10.1109/MS.2016.68";10.1109/MS.2016.68;Building on lean and agile practices, DevOps means end-to-end automation in software development and delivery. Hardly anybody will be able to approach it with a cookbook-style approach, but most developers will benefit from better connecting the previously isolated silos of development and operations. Many DevOps tools exist that can help them do this.;;;;
Book;Fawzy A;IT Operation Optimization - A Beginners Guide To Service Improvement: A Simplified Approach To Agile, Lean, ITSM & DevOps;;2018;;;;;;;;;;2018;9781949814026;;;;Learn How to Optimize IT operations. What if small steps will dramatically increase your Business productivity in critical areas?ITIL Expert, Ahmed Fawzy, present a Simplified approached to improve services. Based on years of experience building services for various organizations of different sizes. In this book you will learn: How to transform IT to align with business objectives Design a process thats actually works Stop unscheduled business interruption. Eliminate unauthorized changes and stabilize IT environment Transform and optimize your operation to achieve better user satisfaction. Learn the core concepts of DevOps Continuous delivery and continuous integration Infrastructure as codePick up your copy by clicking buy now at the top of this page!;;;;
Journal Article;Arulkumar V,Lathamanju R;Start to Finish Automation Achieve on Cloud with Build Channel: By DevOps Method;Procedia Comput. Sci.;2019;165;C;399–405;;Elsevier Science Publishers B. V.;NLD;;;;2019-01;;1877-0509;"https://doi-org.proxy.bnl.lu/10.1016/j.procs.2020.01.032;http://dx.doi.org/10.1016/j.procs.2020.01.032";10.1016/j.procs.2020.01.032;;DevOps, Cloud, Automation;;;
Book;World T;DevOps Handbook: A Guide To Implementing DevOps In Your Workplace;;2017;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2017;9781547145881;;;;DevOps HandBook Are you ready to discover how to utilize devops in your workplace? DevOps is not just a buzzword. It is a mindset that can pull your companies problems by the root and change the traditional, core beliefs. Youre about to discover the ultimate ways to start implementing DevOps in order to decrease the deployment time and maximize the profit, this book will show you why some of the worlds largest companies have chosen to think DevOps. GET your copy today!;;;;
Book;Erder M,Pureur P;Continuous Architecture: Sustainable Architecture in an Agile and Cloud-Centric World;;2015;;;;1st;Morgan Kaufmann Publishers Inc.;San Francisco, CA, USA;;;;2015;9780128032848;;;;Continuous Architecture provides a broad architectural perspective for continuous delivery, and describes a new architectural approach that supports and enables it. As the pace of innovation and software releases increases, IT departments are tasked to deliver value quickly and inexpensively to their business partners. With a focus on getting software into end-users hands faster, the ultimate goal of daily software updates is in sight to allow teams to ensure that they can release every change to the system simply and efficiently. This book presents an architectural approach to support modern application delivery methods and provide a broader architectural perspective, taking architectural concerns into account when deploying agile or continuous delivery approaches. The authors explain how to solve the challenges of implementing continuous delivery at the project and enterprise level, and the impact on IT processes including application testing, software deployment and software architecture. Covering the application of enterprise and software architecture concepts to the Agile and Continuous Delivery models Explains how to create an architecture that can evolve with applications Incorporates techniques including refactoring, architectural analysis, testing, and feedback-driven development Provides insight into incorporating modern software development when structuring teams and organizations;;;;
Book;Erder M,Pureur P;Continuous Architecture: Sustainable Architecture in an Agile and Cloud-Centric World;;2015;;;;;Morgan Kaufmann Publishers Inc.;San Francisco, CA, USA;;;;2015;9780128032855;;;;Continuous Architecture provides a broad architectural perspective for continuous delivery, and describes a new architectural approach that supports and enables it. As the pace of innovation and software releases increases, IT departments are tasked to deliver value quickly and inexpensively to their business partners. With a focus on getting software into end-users hands faster, the ultimate goal of daily software updates is in sight to allow teams to ensure that they can release every change to the system simply and efficiently. This book presents an architectural approach to support modern application delivery methods and provide a broader architectural perspective, taking architectural concerns into account when deploying agile or continuous delivery approaches. The authors explain how to solve the challenges of implementing continuous delivery at the project and enterprise level, and the impact on IT processes including application testing, software deployment and software architecture. Covering the application of enterprise and software architecture concepts to the Agile and Continuous Delivery models Explains how to create an architecture that can evolve with applications Incorporates techniques including refactoring, architectural analysis, testing, and feedback-driven development Provides insight into incorporating modern software development when structuring teams and organizations Table of Contents A Brief Introduction to Continuous Architecture The Principles of Continuous Architecture (CA) Getting Started With the Continuous Architecture Process Evolving the Architecture Continuous Architecture and Continuous Delivery Validating the Architecture Continuous Architecture in Practice: A Case Study How Does Continuous Architecture Impact the Role of the Architect Continuous Architecture in the Enterprise What about Enterprise Services Conclusion;;;;
Conference Paper;Rafi S,Yu W,Akbar MA;RMDevOps: A Road Map for Improvement in DevOps Activities in Context of Software Organizations;;2020;;;413–418;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Evaluation and Assessment in Software Engineering;Trondheim, Norway;2020;9781450377317;;"https://doi-org.proxy.bnl.lu/10.1145/3383219.3383278;http://dx.doi.org/10.1145/3383219.3383278";10.1145/3383219.3383278;DevOps is a new software engineering paradigm adopted by various software organizations to develop an environment of continuous deployment and delivery within time. Numerous experts are offering their services to help organizations, how to implement DevOps activities in software organization. Though, still there are various issues for software organizations to adopt DevOps activities. To overcome such issues, there must be an approach that could assist software organizations towards better adoption of DevOps activities. The core objective of this research is to design a Readiness Model for DevOps (RMDevOps) to improve the adoption of DevOps activities in a software organization. Based on existing models in other fields of software engineering, we will develop this model. We have conducted a systematic literature review and empirical study on DevOps, for understanding the impact of the success factors of DevOps in the real world and literature. This study covers the first step of development of RMDevOps model, by identifying the success factors of DevOps and presenting the outcomes in the form of robust framework.;software organizations, systematic literature review, Readiness model, guidelines;;;EASE '20
Book;Uphill T,Arundel J,Khare N;DevOps: Puppet, Docker, and Kubernetes;;2017;;;;;Packt Publishing;;;;;2017;9781788297615;;;;Get hands-on recipes to automate and manage Linux containers with the Docker 1.6 environment and jump-start your Puppet development About This Book * Successfully deploy DevOps with proven solutions and recipes * Automate your infrastructure with Puppet and combine powerful DevOps methods * Deploy and manage highly scalable applications using Kubernetes * streamline the way you manage your applications Who This Book Is For This Learning Path is for developers, system administrators, and DevOps engineers who want to use Puppet, Docker, and Kubernetes in their development, QA, or production environments. This Learning Path assumes experience with Linux administration and requires some experience with command-line usage and basic text file editing. What You Will Learn * Discover how to build high availability Kubernetes clusters * Deal with inherent issues with container virtualization and container concepts * Create services with Docker to enable the swift development and deployment of applications * Make optimum use of Docker in a testing environment * Create efficient manifests to streamline your deployments * Automate Puppet master deployment using Git hooks, r10k, and PuppetDB In Detail With so many IT management and DevOps tools on the market, both open source and commercial, it's difficult to know where to start. DevOps is incredibly powerful when implemented correctly, and here's how to get it done. This Learning Path covers three broad areas: Puppet, Docker, and Kubernetes. This Learning Path is a large resource of recipes to ease your daily DevOps tasks. We begin with recipes that help you develop a complete and expert understanding of Puppet's latest and most advanced features. Then we provide recipes that help you efficiently work with the Docker environment. Finally, we show you how to better manage containers in different scenarios in production using Kubernetes. This course is based on these books: * Puppet Cookbook, Third Edition * Docker Cookbook * Kubernetes Cookbook Style and approach This easy-to-follow tutorial-style guide teaches you precisely how to configure complex systems in Puppet and manage your containers using Kubernetes.;;;;
Journal Article;Subramanian A,Krishnamachariar PK,Gupta M,Sharman R;Auditing an Agile Development Operations Ecosystem;Int. J. Risk Conting. Manag.;2018;7;4;90–110;;IGI Global;USA;;;;2018-10;;2160-9624;"https://doi-org.proxy.bnl.lu/10.4018/IJRCM.2018100105;http://dx.doi.org/10.4018/IJRCM.2018100105";10.4018/IJRCM.2018100105;"In an enterprise software development, DevOps is a practice of integrating development and operations to deliver cost-efficient, improved quality solutions to the customer by automating the existing processes to achieve ""continuous delivery."" In the current dynamic IT Ecosystem where there is a rising need to prove a competitive edge to maximize profitability, it is pivotal to drive business value with profound emphasis on quality. Agile enables us to take calculated risks during development whereas its affinity to adopting DevOps will promote continuous delivery with reduced friction to improve business efficiency. As this approach requires a change in people, process, technology, culture, usage of right tools and techniques, the early involvement of IT Auditors during the process of transformation could aid to build effective Risk Management strategies to handle organizational challenges. This article aims to present a risk-based audit approach to effectively use audit tools and techniques in an Agile-DevOps transformation environment to achieve maximum business value.";Risk Management, Project Management, DevOps, IT Audit, Software Development, Agile;;;
Conference Paper;Rosenberg CM,Moonen L;Improving Problem Identification via Automated Log Clustering Using Dimensionality Reduction;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Oulu, Finland;2018;9781450358231;;"https://doi-org.proxy.bnl.lu/10.1145/3239235.3239248;http://dx.doi.org/10.1145/3239235.3239248";10.1145/3239235.3239248;Background: Continuous engineering practices, such as continuous integration and continuous deployment, see increased adoption in modern software development. A frequently reported challenge for adopting these practices is the need to make sense of the large amounts of data that they generate.Goal: We consider the problem of automatically grouping logs of runs that failed for the same underlying reasons, so that they can be treated more effectively, and investigate the following questions: (1) Does an approach developed to identify problems in system logs generalize to identifying problems in continuous deployment logs? (2) How does dimensionality reduction affect the quality of automated log clustering? (3) How does the criterion used for merging clusters in the clustering algorithm affect clustering quality?Method: We replicate and extend earlier work on clustering system log files to assess its generalization to continuous deployment logs. We consider the optional inclusion of one of these dimensionality reduction techniques: Principal Component Analysis (PCA), Latent Semantic Indexing (LSI), and Non-negative Matrix Factorization (NMF). Moreover, we consider three alternative cluster merge criteria (Single Linkage, Average Linkage, and Weighted Linkage), in addition to the Complete Linkage criterion used in earlier work. We empirically evaluate the 16 resulting configurations on continuous deployment logs provided by our industrial collaborator.Results: Our study shows that (1) identifying problems in continuous deployment logs via clustering is feasible, (2) including NMF significantly improves overall accuracy and robustness, and (3) Complete Linkage performs best of all merge criteria analyzed.Conclusions: We conclude that problem identification via automated log clustering is improved by including dimensionality reduction, as it decreases the pipeline's sensitivity to parameter choice, thereby increasing its robustness for handling different inputs.;log analysis, failure diagnosis, log mining, continuous engineering;;;ESEM '18
Journal Article;Zhu L,Xu D,Tran AB,Xu X,Bass L,Weber I,Dwarakanathan S;Achieving Reliable High-Frequency Releases in Cloud Environments;IEEE Softw.;2015;32;2;73–80;;IEEE Computer Society Press;Washington, DC, USA;;;;2015-03;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2015.23;http://dx.doi.org/10.1109/MS.2015.23";10.1109/MS.2015.23;Continuous delivery and deployment are dramatically shortening release cycles from months to hours. Cloud applications with high-frequency releases often rely heavily on automated tools and cloud infrastructure APIs to deploy new software versions. The authors report on reliability issues and how these tools and APIs contribute to them. They also analyze the trade-offs between using heavily baked and lightly baked virtual-image approaches, on the basis of experiments with Amazon Web Service OpsWorks APIs and the Chef configuration management tool. Finally, they propose error-handling practices for continuous-delivery facilities.;;;;
Journal Article;Rehmann KT,Seo C,Hwang D,Truong BT,Boehm A,Lee DH;Performance Monitoring in SAP HANA's Continuous Integration Process;SIGMETRICS Perform. Eval. Rev.;2016;43;4;43–52;;Association for Computing Machinery;New York, NY, USA;;;;2016-02;;0163-5999;"https://doi-org.proxy.bnl.lu/10.1145/2897356.2897362;http://dx.doi.org/10.1145/2897356.2897362";10.1145/2897356.2897362;Development principles such as continuous integration and continuous delivery become increasingly popular in the software industry. They allow for the quick and automated build, test, and delivery of software, thereby significantly improving the overall quality assurance and release processes.In this paper, we show how to apply the ideas of continuous delivery to complex system software, as exemplified by the SAP HANA database platform. We discuss the integration of performance testing early in the delivery process and the construction of services to detect and report performance anomalies in a continuous integration process.;;;;
Book;Palermo J;..NET DevOps for Azure: A Developer's Guide to DevOps Architecture the Right Way;;2019;;;;1st;Apress;USA;;;;2019;9781484253427;;;;"Use this book as your one-stop shop for architecting a world-class DevOps environment with Microsoft technologies. .NET DevOps for Azure is a synthesis of practices, tools, and process that, together, can equip a software organization to move fast and deliver the highest quality software. The book begins by discussing the most common challenges faced by developers in DevOps today and offers options and proven solutions on how to implement DevOps for your team. Daily, millions of developers use .NET to build and operate mission-critical software systems for organizations around the world. While the marketplace has scores of information about the technology, it is completely up to you to put together all the blocks in the right way for your environment. This book provides you with a model to build on. The relevant principles are covered first along with how to implement that part of the environment. And while variances in tools, language, or requirements will change the needed implementation, the DevOps model is the architecture for the working environment for your team. You can modify parts of the model to customize it to your enterprise, but the architecture will enable all of your teams and applications to accelerate in performance. What You Will Learn Get your .NET applications into a DevOps environment in Azure Analyze and address the part of your DevOps process that causes delays or bottlenecks Track code using Azure Repos and conduct acceptance tests Apply the rules for segmenting applications into Git repositories Understand the different types of builds and when to use each Know how to think about code validation in your DevOps environment Provision and configure environments; deploy release candidates across the environments in Azure Monitor and support software that has been deployed to a production environment Who This Book Is For .NET Developers who are using or want to use DevOps in Azure but don't know where to begin";;;;
Journal Article;Yin Z,Liu J,Chen B,Chen C,Muscato G;A Delivery Robot Cloud Platform Based on Microservice;J. Robot.;2021;2021;;;;Hindawi Limited;London, GBR;;;;2021-01;;1687-9600;"https://doi-org.proxy.bnl.lu/10.1155/2021/6656912;http://dx.doi.org/10.1155/2021/6656912";10.1155/2021/6656912;Delivery robots face the problem of storage and computational stress when performing immediate tasks, exceeding the limits of on-board computing power. Based on cloud computing, robots can offload intensive tasks to the cloud and acquire massive data resources. With its distributed cluster architecture, the platform can help offload computing and improve the computing power of the control center, which can be considered the external “brain” of the robot. Although it expands the capabilities of the robot, cloud service deployment remains complex because most current cloud robot applications are based on monolithic architectures. Some scholars have proposed developing robot applications through the microservice development paradigm, but there is currently no unified microservice-based robot cloud platform. This paper proposes a delivery robot cloud platform based on microservice, providing dedicated services for autonomous driving of delivery robot. The microservice architecture is adopted to split the monomer robot application into multiple services and then implement automatic orchestration and deployment of services on the cloud platform based on components such as Kubernetes, Docker, and Jenkins. This enables containerized CI/CD (continuous integration, continuous deployment, and continuous delivery) for the cloud platform service, and the whole process can be visualized, repeatable, and traceable. The platform is prebuilt with development tools, and robot application developers can use these tools to develop in the cloud, without the need for any customization in the background, to achieve the rapid deployment and launch of robot cloud service. Through the cloud migration of traditional robot applications and the development of new APPs, the platform service capabilities are continuously improved. This paper verifies the feasibility of the platform architecture through the delivery scene experiment.;;;;
Conference Paper;Ur Rahman AA,Williams L;Security Practices in DevOps;;2016;;;109–111;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Symposium and Bootcamp on the Science of Security;Pittsburgh, Pennsylvania;2016;9781450342773;;"https://doi-org.proxy.bnl.lu/10.1145/2898375.2898383;http://dx.doi.org/10.1145/2898375.2898383";10.1145/2898375.2898383;DevOps focuses on collaboration between different teams in an organization to achieve rapid deployment of software and services to end-users by automating the software delivery infrastructure. According to Dyck et al. [1] DevOps is a software process that emphasizes collaboration within and between different teams involved in software development. According to a study from CA Technologies [5], 88% of 1425 organization executives stated that they have adopted DevOps, or are planning to adopt DevOps in the next five years. According to Puppet Labs' 2015 State of DevOps Report [2], organizations that have adopted DevOps experienced 60 times fewer failures and deploy 30 times more frequently than organizations that have not adopted DevOps. Despite the popularity, security aspects of DevOps remain a concern for organizations that want to adopt DevOps [5]. In organizations that use DevOps practices, developers can commit and deploy their software changes at a rapid rate using an automated pipeline. At such a rapid rate, if the security team operates in isolation without close collaboration with the development and operations teams, then the rapidly deployed software changes might not undergo the adequate security reviews, potentially leading to vulnerable software. Bringing security principles within the DevOps process can help the organization in achieving better quality of software by integrating security checks into the phases of development, testing, and deployment.;;;;HotSos '16
Book;Httermann M;DevOps for Developers;;2012;;;;1st;Apress;USA;;;;2012;9781430245698;;;;DevOps for Developers delivers a practical, thorough introduction to approaches, processes and tools to foster collaboration between software development and operations. Efforts of Agile software development often end at the transition phase from development to operations. This book covers the delivery of software, this means the last mile, with lean practices for shipping the software to production and making it available to the end users, together with the integration of operations with earlier project phases (elaboration, construction, transition). DevOps for Developers describes how to streamline the software delivery process and improve the cycle time (that is the time from inception to delivery). It will enable you to deliver software faster, in better quality and more aligned with individual requirements and basic conditions. And above all, work that is aligned with the DevOps approach makes even more fun! Provides patterns and toolchains to integrate software development and operations Delivers an one-stop shop for kick-starting with DevOps Provides guidance how to streamline the software delivery process What youll learn Know what DevOps is and how it can result in better and faster delivered software Apply patterns to improve collaboration between development and operations Introduce unified processes and incentives to support shared goals Start with or extend a tool infrastructure that spans projects roles and phases Address pain points in your individual environment with appropriate recipes Break down existing walls that make up an unnecessarily sluggish delivery process Who this book is for DevOps for Developers is for motivated software engineers, particularly programmers, testers, QA, system admins, database admins, both beginners and experts, who want to improve their software delivery process. Its the perfect choice for engineers who want to go the next step by integrating their approaches for development and delivery of software. This book is for engineers who want to shape their processes and decide on and integrate open source tools and seek for guidance how to integrate standard tools in advanced real world use cases. Table of Contents Beginning DevOps for Developers Introducing DevOps Building Blocks of DevOps Quality and Testing Introduce Shared Incentives Gain Fast Feedback Unified and Holistic Approach Automatic Releasing Infrastructure as Code Specification by Example;;;;
Book;;AST '19: Proceedings of the 14th International Workshop on Automation of Software Test;;2019;;;;;IEEE Press;Montreal, Quebec, Canada;;;;2019;;;;;"Welcome to the 14th edition of the IEEE/ACM Workshop on Automation of Software Test (AST). Effective and efficient testing with reduced costs and a high fault detection capability is the desirable goal in industry which can be achieved only through automation of all parts of the testing process. In the past decades, a great amount of research effort has been spent on automating all various parts of the testing process such as test case derivation, test selection, test oracle construction, test execution, and others. In addition, there has been a rapid growth in automated software testing tools which is stimulated in part through the shift towards agile development practices in industry that demands a high level of automation. Work on this topic has long been published as an important part of software engineering. In recent years, testing has been consistently among the top-most popular topics in submissions to software engineering conferences. The practice of software test automation (TA) has also moved forward significantly in the past few years. However, progress in TA is still required. Software systems have become more and more complicated through the integration of components developed by different vendors and using different techniques in different programming languages running on different platforms. The advent of cloud computing, mobile computing and the Internet of Things has imposed grave new challenges to TA. Those systems become increasingly reactive to changes in their environment, requiring equally adaptive TA approaches. Few software testing tools can currently handle the needed requirements to test such systems.This year's theme for AST is Testing and Continuous Deployment. Continuous deployment has become a major strategy in industry even for large software projects and continues to be a relevant topic in research. As one of the main strategies in modern DevOps environments, continuous deployment aims to increase code velocity---the time between making a code change and shipping the change to customers. At the same time, DevOps and continuous deployment impose heavy constraints onto testing: (a) testing must be completely automated and act as the last safeguard against customer incidents; (b) testing should be fast without slowing down code velocity; and (c) testing is happening within the engineering teams (DevOps) rather than dedicated testing teams. In other words, test automation may have become more wanted than ever before and we seek contributions to highlight solutions, challenges, and problem statements for test automation in a continuous deployment world. Choosing this special theme, our goal was to spark interest from industry partners to show and describe issues and solutions in this area and thus to foster the communication between researchers and industry and thus to reduce the gap between both worlds.";;;Proceedings;
Conference Paper;Sagenschneider D;OfficeFloor: Using Office Patterns to Improve Software Design;;2015;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 18th European Conference on Pattern Languages of Program;Irsee, Germany;2015;9781450334655;;"https://doi-org.proxy.bnl.lu/10.1145/2739011.2739013;http://dx.doi.org/10.1145/2739011.2739013";10.1145/2739011.2739013;OfficeFloor is a middleware framework that bases its design on the patterns occurring within an office. Re-using office patterns within software provides two improvements to software design. The first is improved performance tuning of applications operating within complex enterprise environments. Complex enterprise environments, such as Service-Oriented Architecture, require applications to interact with multiple downstream systems. Any one of these downstream systems may impact the application's performance. The improved performance tuning is a result of the office patterns enabling the use of multiple thread pools to isolate the performance impacts of each of these downstream systems. The second improvement is a middleware framework that enables early and continuous delivery of working code for Agile methodologies. The early and continuous delivery of working code is a result of the office patterns enabling inversion of control for methods. The inversion of control for methods enables building applications bottom-up. This bottom-up approach to building applications reduces the lead times involved with top-down software designs and also reduces the refactoring due to top-down software designs. The reduced lead times and reduced refactoring enables early and continuous delivery of working code for Agile methodologies.;task orchestration, inversion of control, responsible thread pool;;;EuroPLoP '13
Journal Article;John W,Marchetto G,Nemeth F,Skoldstrom P,Steinert R,Meirosu C,Papafili I,Pentikousis K;Service Provider DevOps;Comm. Mag.;2017;55;1;204–211;;IEEE Press;;;;;2017-01;;0163-6804;"https://doi-org.proxy.bnl.lu/10.1109/MCOM.2017.1500803CM;http://dx.doi.org/10.1109/MCOM.2017.1500803CM";10.1109/MCOM.2017.1500803CM;Although there is consensus that software defined networking and network functions virtualization overhaul service provisioning and deployment, the community still lacks a definite answer on how carrier-grade operations praxis needs to evolve. This article presents what lies beyond the first evolutionary steps in network management, identifies the challenges in service verification, observability, and troubleshooting, and explains how to address them using our Service Provider DevOps (SP-DevOps) framework. We compendiously cover the entire process from design goals to tool realization and employ an elastic version of an industry-standard use case to show how on-the-fly verification, software-defined monitoring, and automated troubleshooting of services reduce the cost of fault management actions. We assess SP-DevOps with respect to key attributes of software-defined telecommunication infrastructures both qualitatively and quantitatively, and demonstrate that SP-DevOps paves the way toward carrier-grade operations and management in the network virtualization era.;;;;
Book Chapter;Olsson HH,Bosch J;Towards Agile and beyond: An Empirical Account on the Challenges Involved When Advancing Software Development Practices;;2014;;;327–335;;Springer-Verlag;Berlin, Heidelberg;Agile Processes in Software Engineering and Extreme Programming;;;2014;9783642206771;;;;During the last decade, the vast majority of software companies have adopted agile development practices. Now companies are looking to move beyond agile and further advance their practices. In this paper, we report on the experiences of a company in the embedded systems domain that is adopting agile practices with the intention to move beyond agile and towards continuous deployment of software. Based on case study research involving group interviews and a web-based survey, we identify challenges in relation to (1) the adoption of agile practices, (2) testing practices, (3) continuous deployment, and (4) customer validation.;;;;
Book;Farooqui SM;Enterprise DevOps Framework: Transforming IT Operations;;2018;;;;1st;Apress;USA;;;;2018;9781484236116;;;;Transform your IT organization from one weighed down by set practices to one with a DevOps culture and a cloud-first strategy that is optimized by automation and other lean practices. In this engaging read, you will discover the opportunities, challenges, lessons, and rewards that CA Technologies encountered when making their agile and DevOps transformation. In Enterprise DevOps Framework author Shamayel Farooqui shows you how agile adoption will enable your organization to stay ahead in an ever-changing business environment and meet your customers needs. He includes detailed references to key concepts such as agile, hybrid and cloud technology, infrastructure management, and process automation. What Youll Learn Establish the focus areas for your IT organization Prepare for the challenges of transforming your enterprise to a DevOps, agile organization Know the key steps for executing an enterprise DevOps strategy Build a strong team of DevOps individuals focused on improving the efficiency of your organization through Agile methodologies, automation, cloud adoption, and infrastructure as code practices Who This Book Is For IT administrators, operational personnel, cloud professionals, DevOps professionals, human resources professionals, managers, and C-level staff;;;;
Journal Article;Karvonen T,Behutiye W,Oivo M,Kuvaja P;Systematic Literature Review on the Impacts of Agile Release Engineering Practices;Inf. Softw. Technol.;2017;86;C;87–100;;Butterworth-Heinemann;USA;;;;2017-06;;0950-5849;"https://doi-org.proxy.bnl.lu/10.1016/j.infsof.2017.01.009;http://dx.doi.org/10.1016/j.infsof.2017.01.009";10.1016/j.infsof.2017.01.009;"ContextAgile release engineering (ARE) practices are designed to deliver software faster and cheaper to end users; hence, claims of such impacts should be validated by rigorous and relevant empirical studies. ObjectiveThe study objective was to analyze both direct and indirect impacts of ARE practices as well as to determine how they have been empirically studied. MethodThe study applied the systematic literature review research method. ARE practices were identified in empirical studies by searching articles for rapid release, continuous integration, continuous delivery, and continuous deployment. We systematically analyzed 619 articles and selected 71 primary studies for deeper investigation. The impacts of ARE practices were analyzed from three viewpoints: impacts associated with adoption of the practice, prevalence of the practice, and success of software development. ResultsThe results indicated that ARE practices can create shorter lead times and better communication within and between development teams. However, challenges and drawbacks were also found in change management, software quality assurance, and stakeholder acceptance. The analysis revealed that 33 out of 71 primary studies were casual experience reports that had neither an explicit research method nor a data collection approach specified, and 23 out of 38 empirical studies applied qualitative methods, such as interviews, among practitioners. Additionally, 12 studies applied quantitative methods, such as mining of software repositories. Only three empirical studies combined these research approaches. ConclusionARE practices can contribute to improved efficiency of the development process. Moreover, release stakeholders can develop a better understanding of the software project's status. Future empirical studies should consider the comprehensive reporting of the context and how the practice is implemented instead of merely referring to usage of the practice. In addition, different stakeholder points of view, such as customer perceptions regarding ARE practices, still clearly require further research.";Rapid release, Release engineering, Continuous delivery, Continuous integration, Agile, Continuous deployment;;;
Conference Paper;Capizzi A,Distefano S,Mazzara M;From DevOps to DevDataOps: Data Management in DevOps Processes;;2019;;;52–62;;Springer-Verlag;Berlin, Heidelberg;;Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Château de Villebrumier, France, May 6–8, 2019, Revised Selected Papers;Villebrumier, France;2019;9783030393052;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-39306-9_4;http://dx.doi.org/10.1007/978-3-030-39306-9_4";10.1007/978-3-030-39306-9_4;DevOps is a quite effective approach for managing software development and operation, as confirmed by plenty of success stories in real applications and case studies. DevOps is now becoming the main-stream solution adopted by the software industry in development, able to reduce the time to market and costs while improving quality and ensuring evolvability and adaptability of the resulting software architecture. Among the aspects to take into account in a DevOps process, data is assuming strategic importance, since it allows to gain insights from the operation directly into the development, the main objective of a DevOps approach. Data can be therefore considered as the fuel of the DevOps process, requiring proper solutions for its management. Based on the amount of data generated, its variety, velocity, variability, value and other relevant features, DevOps data management can be mainly framed into the BigData category. This allows exploiting BigData solutions for the management of DevOps data generated throughout the process, including artefacts, code, documentation, logs and so on. This paper aims at investigating data management in DevOps processes, identifying related issues, challenges and potential solutions taken from the BigData world as well as from new trends adopting and adapting DevOps approaches in data management, i.e. DataOps.;;;;
Journal Article;Callanan M,Spillane A;DevOps: Making It Easy to Do the Right Thing;IEEE Softw.;2016;33;3;53–59;;IEEE Computer Society Press;Washington, DC, USA;;;;2016-05;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2016.66;http://dx.doi.org/10.1109/MS.2016.66";10.1109/MS.2016.66;"Wotif Group used DevOps principles to recover from the downward spiral of manual release activity that many IT departments face. Its approach involved the idea of ""making it easy to do the right thing."" By defining the right thing (deployment standards) for development and operations teams and making it easy to adopt, Wotif drastically improved the average release cycle time. This article is part of a theme issue on DevOps.";;;;
Book;Aiello B,Sachs L;Agile Application Lifecycle Management: Using DevOps to Drive Process Improvement;;2016;;;;1st;Addison-Wesley Professional;;;;;2016;9780321774101;;;;Integrate Agile ALM and DevOps to Build Better Software and Systems at Lower Cost Agile Application Lifecycle Management (ALM) is a comprehensive development lifecycle that encompasses essential Agile principles and guides all activities needed to deliver successful software or other customized IT products and services. Flexible and robust, Agile ALM offers just enough process to get the job done efficiently and utilizes the DevOps focus on communication and collaboration to enhance interactions among all participants. Agile Application Lifecycle Management offers practical advice and strategies for implementing Agile ALM in your complex environment. Leading experts Bob Aiello and Leslie Sachs show how to fully leverage Agile benefits without sacrificing structure, traceability, or repeatability. Youll find realistic guidance for managing source code, builds, environments, change control, releases, and more. The authors help you support Agile in organizations that maintain traditional practices, conventional ALM systems, or siloed, non-Agile teams. They also show how to scale Agile ALM across large or distributed teams and to environments ranging from cloud to mainframe. Coverage includes Understanding key concepts underlying modern application and system lifecycles Creating your best processes for developing your most complex software and systems Automating build engineering, continuous integration, and continuous delivery/deployment Enforcing Agile ALM controls without compromising productivity Creating effective IT operations that align with Agile ALM processes Gaining more value from testing and retrospectives Making ALM work in the cloud, and across the enterprise Preparing for the future of Agile ALM Today, you need maximum control, quality, and productivity, and this guide will help you achieve these capabilities by combining the best practices found in Agile ALM, Configuration Management (CM), and DevOps.;;;;
Conference Paper;Artač M,Borovšak T,Di Nitto E,Guerriero M,Tamburri DA;DevOps: Introducing Infrastructure-as-Code;;2017;;;497–498;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 39th International Conference on Software Engineering Companion;;2017;9781538615898;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-C.2017.162;http://dx.doi.org/10.1109/ICSE-C.2017.162";10.1109/ICSE-C.2017.162;"DevOps entails a series of software engineering tactics aimed at shortening the actionable operation of software design changes. One of these tactics is to harness infrastructure-as-code, that is, writing a blueprint that contains deployment specifications ready for orchestration in the cloud. This abstract briefly discusses all necessary elements and abstractions in writing and maintaining that blueprint, revolving around a key standard for its expression, namely, the OASIS ""Topology and Orchestration Specification for Cloud Applications"" (TOSCA) industrial standard adopted by as many as 60+ big industrial players worldwide.";TOSCA, infrastructure-as-code, DevOps;;;ICSE-C '17
Book;Rankin K;DevOps Troubleshooting: Linux Server Best Practices;;2012;;;;1st;Addison-Wesley Professional;;;;;2012;9780321832047;;;;If youre a developer trying to figure out why your application is not responding at 3 am, you need this book! This is now my go-to book when diagnosing production issues. It has saved me hours in troubleshooting complicated operations problems. Trotter Cashion, cofounder, Mashion DevOps can help developers, QAs, and admins work together to solve Linux server problems far more rapidly, significantly improving IT performance, availability, and efficiency. To gain these benefits, however, team members need common troubleshooting skills and practices. In DevOps Troubleshooting: Linux Server Best Practices , award-winning Linux expert Kyle Rankin brings together all the standardized, repeatable techniques your team needs to stop finger-pointing, collaborate effectively, and quickly solve virtually any Linux server problem. Rankin walks you through using DevOps techniques to troubleshoot everything from boot failures and corrupt disks to lost email and downed websites. Youll master indispensable skills for diagnosing high-load systems and network problems in production environments. Rankin shows how to Master DevOps approach to troubleshooting and proven Linux server problem-solving principles Diagnose slow servers and applications by identifying CPU, RAM, and Disk I/O bottlenecks Understand healthy boots, so you can identify failure points and fix them Solve full or corrupt disk issues that prevent disk writes Track down the sources of network problems Troubleshoot DNS, email, and other network services Isolate and diagnose Apache and Nginx Web server failures and slowdowns Solve problems with MySQL and Postgres database servers and queries Identify hardware failureseven notoriously elusive intermittent failures;;;;
Conference Paper;Desertot M,Cervantes H,Donsez D;FROGi: Fractal Components Deployment over OSGi;;2006;;;275–290;;Springer-Verlag;Berlin, Heidelberg;;Proceedings of the 5th International Conference on Software Composition;Vienna, Austria;2006;9783540376576;;"https://doi-org.proxy.bnl.lu/10.1007/11821946_18;http://dx.doi.org/10.1007/11821946_18";10.1007/11821946_18;This paper presents FROGi, a proposal to support continuous deployment activities inside Fractal, a hierarchical component model. FROGi is implemented on top of the OSGi platform. Motivation for this work is twofold. On one hand FROGi provides an extensible component model to OSGi developers and eases bundle providing. FROGi-based bundles are still compatible with “legacy” OSGi bundles that offer third party services. On the other hand, FROGi benefits from the deployment infrastructure provided by OSGi which simplifies conditioning and packaging of Fractal components. With FROGi, it is possible to automate the assembly of a Fractal component application. Partial or complete deployment is also supported as well as performing continuous deployment and update activities.;;;;SC'06
Conference Paper;Díaz J,Almaraz R,Pérez J,Garbajosa J;DevOps in Practice: An Exploratory Case Study;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th International Conference on Agile Software Development: Companion;Porto, Portugal;2018;9781450364225;;"https://doi-org.proxy.bnl.lu/10.1145/3234152.3234199;http://dx.doi.org/10.1145/3234152.3234199";10.1145/3234152.3234199;DevOps is a cultural movement and technical solution that plays a fundamental role for software-intensive organizations whose business greatly depends on how efficient development and operation are. DevOps is relatively recent, and thus little is known about best practices and the real value and barriers associated with DevOps in industry. To conduct an analysis on practicing DevOps in various software development companies in order to provide patterns of DevOps practices and identify their benefits and barriers. An exploratory case study based on the interviews to relevant stakeholders of 11 (multinational) software-intensive companies. The study is currently ongoing. This study aims to help practitioners and researchers to better understand some DevOps improvement practices as well as real DevOps projects and the contexts where the practices worked, and benefits and barriers appeared. This, hopefully, will contribute to strengthening the evidence regarding DevOps and supporting practitioners in making better informed decisions about the ROI of introducing DevOps.;DevOps, empirical software engineering, exploratory case study;;;XP '18
Conference Paper;Ibrahim A,Bozhinoski S,Pretschner A;Attack Graph Generation for Microservice Architecture;;2019;;;1235–1242;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing;Limassol, Cyprus;2019;9781450359337;;"https://doi-org.proxy.bnl.lu/10.1145/3297280.3297401;http://dx.doi.org/10.1145/3297280.3297401";10.1145/3297280.3297401;Microservices, which are typically technologically heterogenous and can be deployed automatically, are increasingly dominating service systems. However, with increased utilization of third-party components distributed as images, the potential vulnerabilities in microservice-based systems increase. Based on component dependency, such vulnerabilities can lead to exposing a system's critical assets. Similar problems have been addressed by the computer networks community. In this paper, we propose utilizing attack graphs in the continuous delivery infrastructure of microservices-based systems. To that end, we relate microservices to network nodes and automatically generate attack graphs that help practitioners identify, analyze, and prevent plausible attack paths in their microservice-based container networks. We present a complete solution that can be easily embedded in continuous delivery systems and demonstrate its efficiency and scalability based on real-world use cases.;microservices, attack graph generation, containers;;;SAC '19
Book;Roberts TA,Atwell J,Sigler E,van Doorn Y;DevOps for VMware Administrators;;2015;;;;1st;VMware Press;Palo Alto, CA, USA;;;;2015;9780133846478;;;;DevOps for VMware Administrators is the first book focused on using DevOps tools and practices with VMware technologies. The authors introduce high-value tools from third parties and VMware itself, and guide you through using them to improve the performance of all your virtualized systems and applications. Youll walk through automating and optimizing configuration management, provisioning, log management, continuous integration, and more. The authors also offer step-by-step coverage of deploying and managing applications at scale with Docker containers and Google Kubernetes. They conclude with an up-to-the-minute discussion of VMwares newest DevOps initiatives, including VMware vRealize Automation and VMware vRealize Code Stream. Coverage includes Understanding the challenges that DevOps tools and practices can help VMware administrators to solve Using Vagrant to quickly deploy Dev and Test environments that match production system specifications Writing Chef recipes that streamline server configuration and maintenance Simplifying Unix/Linux configuration management and orchestration with Ansible Implementing Docker containers for faster and easier application management Automating provisioning across the full lifecycle with Razor Integrating Microsoft PowerShell Desired State Configuration (DSC) and VMware PowerCLI to automate key Windows Server and vSphere VM admin tasks Using Puppet to automate infrastructure provisioning, configuration, orchestration, and reporting Supercharging log management with ELK (Elasticsearch, Logstash, Kibana) Supporting DevOps source code management with Git and continuous integration practices with Jenkins Achieving continuous integration, delivery, and deployment with VMwares vRealize Code Stream;;;;
Conference Paper;Vöst S,Wagner S;Keeping Continuous Deliveries Safe;;2017;;;259–261;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 39th International Conference on Software Engineering Companion;;2017;9781538615898;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-C.2017.135;http://dx.doi.org/10.1109/ICSE-C.2017.135";10.1109/ICSE-C.2017.135;Allowing swift release cycles, Continuous Delivery has become popular in application software development and is starting to be applied in safety-critical domains such as the automotive industry.These domains require thorough analysis regarding safety constraints, which can be achieved by the execution of safety tests resulting from a safety analysis on the product. With continuous delivery in place, such tests need to be executed with every build to ensure the latest software still fulfills all safety requirements. Even more though, the safety analysis has to be updated with every change to ensure the safety test suite is still up-to-date.We thus propose that a safety analysis should be treated no differently from other deliverables such as source-code and dependencies, propose guidelines to adopt this and formulate implications for the development process.;embedded software, software quality, software safety;;;ICSE-C '17
Journal Article;Wiedemann A,Forsgren N,Wiesche M,Gewald H,Krcmar H;The DevOps Phenomenon: An Executive Crash Course;Queue;2019;17;2;93–112;;Association for Computing Machinery;New York, NY, USA;;;;2019-04;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/3329781.3338532;http://dx.doi.org/10.1145/3329781.3338532";10.1145/3329781.3338532;Stressful emergency releases are a thing of the past for companies that subscribe to the DevOps method of software development and delivery. New releases are frequent. Bugs are fixed rapidly. New business opportunities are sought with gusto and confidence. New features are released, revised, and improved with rapid iterations. DevOps presents a strategic advantage for organizations when compared with traditional software-development methods. Leadership plays an important role during that transformation. DevOps is about providing guidelines for faster time to market of new software features and achieving a higher level of stability. Implementing cross-functional, product-oriented teams helps bridge the gaps between software development and operations. By ensuring their transformations include all of the principles outlined in CALMS, teams can achieve superior performance and deliver value to their organizations. DevOps is often challenging, but stories from across the industry show that many organizations have already overcome the early hurdles and plan to continue their progress, citing the value to their organizations and the benefits to their engineers.;;;;
Book;Fenton S;Exploring Octopus Deploy;;2015;;;;;Lulu.com;;;;;2015;9781326294441;;;;If you are interested in learning how to use Octopus Deploy, this book will take you through the whole process in just eight steps, with plenty of tips and screen-shots to aid learning. * Learn how to package your application and database * Find out how to publish packages to the library * Discover how to create an automated deployment process * Learn how to manage environments and machines * Move your software along a deployment pipeline * Add steps to obtain approval for deployments;;;;
Conference Paper;Ferry N,Chauvel F,Song H,Solberg A;Continous Deployment of Multi-Cloud Systems;;2015;;;27–28;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1st International Workshop on Quality-Aware DevOps;Bergamo, Italy;2015;9781450338172;;"https://doi-org.proxy.bnl.lu/10.1145/2804371.2804377;http://dx.doi.org/10.1145/2804371.2804377";10.1145/2804371.2804377;In this paper we present our mechanism and tooling for the continuous deployment and resource provisioning of multi-cloud applications. In order to facilitate collaboration between development and operation teams as promoted in the DevOps movement, our deployment and resource provisioning engine is based on the Models@Runtime principles. This enables applying the same concepts and language (i.e., CloudML) for deployment and resource provisioning at development-and operation-time.;Cloud computing, model-driven engineering, CloudML, deployment, Models@Runtime;;;QUDOS 2015
Conference Paper;Taibi D,Lenarduzzi V,Pahl C,Janes A;Microservices in Agile Software Development: A Workshop-Based Study into Issues, Advantages, and Disadvantages;;2017;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the XP2017 Scientific Workshops;Cologne, Germany;2017;9781450352642;;"https://doi-org.proxy.bnl.lu/10.1145/3120459.3120483;http://dx.doi.org/10.1145/3120459.3120483";10.1145/3120459.3120483;In the last years, cloud-native architectures have emerged as a target platform for the deployment of microservice architectures. The migration of existing monoliths into cloud-native applications is still in the early phase, and only few companies already started their migrations. Therefore, success and failure stories about different approaches are not available in the literature. This context connects also to the recently discussed DevOps context where development and continuous deployment are closely linked.;cloud software, microservices, SOA, software architecture;;;XP '17
Journal Article;Spinellis D;Being a DevOps Developer;IEEE Softw.;2016;33;3;4–5;;IEEE Computer Society Press;Washington, DC, USA;;;;2016-05;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2016.76;http://dx.doi.org/10.1109/MS.2016.76";10.1109/MS.2016.76;In many IT sectors, DevOps is here to stay, helping deliver higher-quality services more efficiently. Thinking like a DevOps developer is an essential trait of an enlightened software professional. This article is part of a theme issue on DevOps.;;;;
Journal Article;de Oliveira MA,Possamai O,Dalla Valentina LV,Flesch CA;Applying Bayesian Networks to Performance Forecast of Innovation Projects: A Case Study of Transformational Leadership Influence in Organizations Oriented by Projects;Expert Syst. Appl.;2012;39;5;5061–5070;;Pergamon Press, Inc.;USA;;;;2012-04;;0957-4174;"https://doi-org.proxy.bnl.lu/10.1016/j.eswa.2011.11.033;http://dx.doi.org/10.1016/j.eswa.2011.11.033";10.1016/j.eswa.2011.11.033;The focus of this work is the analysis of the influence of transformational leadership on organizational factors, and their impacts on the project performance. The factors considered are communication, flexibility, continuous delivery and continuous improvement, overlap of activities, and maturity of the team, in projects with a high degree of innovation. Bayesian networks were chosen as a simulation tool. Results showed that for a moderate level of overlap of activities, the maximum project performance is obtained when the leadership components individual consideration, inspirational motivation, idealized influence and intellectual stimulation, are either at moderate levels. This leads to high levels of team maturity, flexibility and continuous delivery, while continuous improvement and communication tend to be moderate. It is highlighted the characterization of the individual contribution of the variables to the project performance and the empirical application of Bayesian networks, as an alternative to statistical methods commonly employed in leadership and management studies.;Decision making, Uncertainty, Bayesian methods, Simulation, New products, Organizational behavior;;;
Journal Article;Forsgren N;DevOps Delivers;Commun. ACM;2018;61;4;32–33;;Association for Computing Machinery;New York, NY, USA;;;;2018-03;;0001-0782;"https://doi-org.proxy.bnl.lu/10.1145/3174799;http://dx.doi.org/10.1145/3174799";10.1145/3174799;;;;;
Journal Article;Forsgren N,Kersten M;DevOps Metrics;Commun. ACM;2018;61;4;44–48;;Association for Computing Machinery;New York, NY, USA;;;;2018-03;;0001-0782;"https://doi-org.proxy.bnl.lu/10.1145/3159169;http://dx.doi.org/10.1145/3159169";10.1145/3159169;Your biggest mistake might be collecting the wrong data.;;;;
Conference Paper;Kousa J,Ihantola P,Hellas A,Luukkainen M;Teaching Container-Based DevOps Practices;;2020;;;494–502;;Springer-Verlag;Berlin, Heidelberg;;Web Engineering: 20th International Conference, ICWE 2020, Helsinki, Finland, June 9–12, 2020, Proceedings;Helsinki, Finland;2020;9783030505776;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-50578-3_34;http://dx.doi.org/10.1007/978-3-030-50578-3_34";10.1007/978-3-030-50578-3_34;We present the design of a online course that focuses on container-based virtualization as part of the DevOps toolchain. In addition, we outline the professional background of participants taking the course, and describe how this affects perceived previous knowledge of DevOps. We found out that the self-evaluated conceptual understanding of DevOps topics is nearly equal regardless of the participants professional identity (e.g., student or developer). However, there are significant differences in how much participants have used tools like Docker before. We conclude that there is a clear need for lifelong learning among software engineering professionals as (future) developers often struggle in operations related skills such as command line or networking.;DevOps, Education, Lifelong learning;;;
Book Chapter;Pang C,Hindle A,Barbosa D;Understanding DevOps Education with Grounded Theory;;2020;;;260–261;;Association for Computing Machinery;New York, NY, USA;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings;;;2020;9781450371223;;https://doi-org.proxy.bnl.lu/10.1145/3377812.3390808;;DevOps stands for Development-Operations. It arises from the IT industry as a movement aligning development and operations teams. DevOps is broadly recognized as an IT standard, and there is high demand for DevOps practitioners in industry. Therefore, we studied whether undergraduates acquired adequate DevOps skills to fulfill the demand for DevOps practitioners in industry. We employed Grounded Theory (GT), a social science qualitative research methodology, to study DevOps education from academic and industrial perspectives. In academia, academics were not motivated to learn or adopt DevOps, and we did not find strong evidence of academics teaching DevOps. Academics need incentives to adopt DevOps, in order to stimulate interest in teaching DevOps. In industry, DevOps practitioners lack clearly defined roles and responsibilities, for the DevOps topic is diverse and growing too fast. Therefore, practitioners can only learn DevOps through hands-on working experience. As a result, academic institutions should provide fundamental DevOps education (in culture, procedure, and technology) to prepare students for their future DevOps advancement in industry. Based on our findings, we proposed five groups of future studies to advance DevOps education in academia.;;;;
Book;Lines M,Ambler SW;Introduction to Disciplined Agile Delivery 2nd Edition: A Small Agile Team's Journey from Scrum to Disciplined DevOps;;2018;;;;2nd;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2018;9781983891304;;;;Introduction to Disciplined Agile Delivery 2nd Edition provides a quick overview of how agile software development works from beginning-to-end. It describes Disciplined Agile Delivery (DAD), the first of four levels of the Disciplined Agile (DA) process decision framework, and works through a case study describing a typical agile teams experiences adopting a DA approach. The book describes how the team develops the first release of a mission-critical application while working in a legacy enterprise environment. It describes their experiences from beginning-to-end, starting with their initial team initiation efforts through construction and finally to deploying the solution into production. It also describes how the team stays together for future releases, overviewing their process improvement efforts from their Scrum-based beginnings through to a lean continuous delivery approach that fits in with their organizations evolving DevOps strategy. The DAD framework is a hybrid of existing methods such as Scrum, Kanban, Agile Modeling, SAFe, Extreme Programming, Agile Data, Unified Process and many others. DAD provides the flexibility to use various approaches and plugs the gaps not addressed by mainstream agile methods. In a nutshell, DAD is pragmatic agile. DAD describes proven strategies to adapt and scale your agile initiatives to suit the unique realities of your enterprise without having to figure it all out by yourself. Heres an overview of what each chapter covers: Chapter 1: Introduction. This chapter provides a quick overview of the book and a brief history of Disciplined Agile. Chapter 2: Reality over Rhetoric. This chapter explores several common myths about DAD and more importantly disproves them. Chapter 3: Disciplined Agile Delivery in a Nutshell. This chapter provides a brief yet comprehensive overview of DAD. Chapter 4: Introduction to the Case Study. This chapter introduces us to the team, describes the market opportunity that they hope to address, and describes the environment in which theyre working. Chapter 5: Inception. The teams initiation effort includes initial requirements modeling and planning with their stakeholders in a streamlined manner, initial architecture modeling, setting up their physical work environment, setting up the start of their tooling infrastructure, initial risk identification, and finally securing stakeholder support and funding for the rest of the first release. Chapters 6 through 10: Construction. These chapters each describe a single Construction iteration, sharing the teams experiences during each of those two-week timeboxes. Chapter 11: Transition. The two-week transition phase focuses on final testing and fixing, training the support/help-desk staff, finishing a few short end-user how to videos, and deploying the solution into production. Chapter 12: The Road to Disciplined DevOps. This chapter overviews the teams improvement efforts over the next few releases, describing how they evolve from the agile Scrum-based lifecycle to a leaner approach and eventually to continuous delivery. All of this dovetails into their organizations efforts to implement a Disciplined DevOps strategy. Chapter 13: Closing Thoughts. This chapter overviews the disciplined agile resources that are available to you. Appendix: The Disciplined Agile Framework. This short appendix overviews our ongoing work on the Disciplined Agile framework to address the full scope of an agile business. At 111 pages, you should find this book to be a quick, informative read. Whats Different in This Edition: Chapter 3 was completely rewritten to reflect the changes to DAD. Chapter 12 was rewritten to describe how the team evolved into a Disciplined DevOps strategy. Appendix A was rewritten to reflect the latest release of the DA framework. General updates were made throughout the book.;;;;
Book;Farcic V;The DevOps 2.2 Toolkit;;2018;;;;;Packt Publishing;;;;;2018;9781788991278;;;;Learn from an expert on how use self-adapting and self-healing systems within Docker. Key Features Viktor Farcic shows you all aspects in the creation of self-adapting and self-healing systems in both a practical and hands-on approach. Learn how to choose a successful solution for metrics storage and query, including InfluxDB, Nagios and Sensu, Prometheus and Graphite. Discover how to integrate Docker Flow Monitor with Docker Flow Proxy. How to apply Docker self-healing and self-adaptive to both services and infrastructure. Book Description Building on The DevOps 2.0 Toolkit and The DevOps 2.1 Toolkit: Docker Swarm, Viktor Farcic brings his latest exploration of the Docker technology as he records his journey to explore two new programs, self-adaptive and self-healing systems within Docker. The DevOps 2.2 Toolkit: Self-Sufficient Docker Clusters is the latest book in Viktor Farcic's series that helps you build a full DevOps Toolkit. This book in the series looks at Docker, the tool designed to make it easier in the creation and running of applications using containers. In this latest entry, Viktor combines theory with a hands-on approach to guide you through the process of creating self-adaptive and self-healing systems. Within this book, Viktor will cover a wide-range of emerging topics, including what exactly self-adaptive and self-healing systems are, how to choose a solution for metrics storage and query, the creation of cluster-wide alerts and what a successful self-sufficient system blueprint looks like. Work with Viktor and dive into the creation of self-adaptive and self-healing systems within Docker. What you will learn Let Viktor Farcic show you all aspects in the creation of self-adapting and self-healing systems in both a practical and hands-on approach. Learn how to choose a successful solution for metrics storage and query, including InfluxDB, Nagios and Sensu, Prometheus and Graphite. Understand how to integrate Docker Flow Monitor with Docker Flow Proxy. The creation of cluster-wide alerts by creating alerts based on metrics. How to apply self-healing and self-adaptive to both services and infrastructure. Who this book is forThis book is for professionals experienced with Docker looking to create both self-adapting and self-healing systems using the software.;;;;
Conference Paper;Sebby B;Devops is Improv: How Improv Made Me a Better Sysadmin;;2015;;;49;;USENIX Association;USA;;Proceedings of the 29th Usenix Conference on Large Installation System Administration;Washington, D.C.;2015;9781931971270;;;;With the rise of DevOps as a prevailing software development model, organizations are finding that teamwork and communication are tools that are vital to the overall success of their mission. Three years ago, I took my first improv class, and in addition to helping me be more comfortable with public speaking, I have found that many of the techniques that help an improv team succeed on stage are directly applicable to helping a DevOps team succeed.;;;;LISA'15
Conference Paper;Jabbari R,bin Ali N,Petersen K,Tanveer B;What is DevOps? A Systematic Mapping Study on Definitions and Practices;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Scientific Workshop Proceedings of XP2016;Edinburgh, Scotland, UK;2016;9781450341349;;"https://doi-org.proxy.bnl.lu/10.1145/2962695.2962707;http://dx.doi.org/10.1145/2962695.2962707";10.1145/2962695.2962707;Context: DevOps, the combination of Development and Operations, is a new way of thinking in the software engineering domain that recently received much attention. Given that DevOps is a new term and novel concept recently introduced, no common understanding of what it entails has been achieved yet. Consequently, definitions of DevOps often only represent a part that is relevant to the concept.Objective:This study aims to characterize DevOps by exploring central components of DevOps definitions reported in the literature, specifying practices explicitly proposed for DevOps and investigating the similarities and differences between DevOps and other existing methods in software engineering.Method: A systematic mapping study was conducted that used six electronic databases: IEEE, ACM, Inspec, Scopus, Wiley Online Library and Web of Science.Result: 44 studies have been selected that report a definition of DevOps, 15 studies explicitly stating DevOps practices, and 15 studies stating how DevOps is related to other existing methods. Papers in some cases stated a combination of a definition, practices, and relations to other methods, the total number of primary studies was 49.Conclusion: We proposed a definition for DevOps which may overcome inconsistencies over the various existing definitions of individual research studies. In addition, the practices explicitly proposed for DevOps have been presented as well as the relation to other software development methods.;DevOps practice, Software development method, DevOps definition;;;XP '16 Workshops
Conference Paper;Mattila AL,Lehtonen T,Terho H,Mikkonen T,Systä K;Mashing Up Software Issue Management, Development, and Usage Data;;2015;;;26–29;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 2nd International Workshop on Rapid Continuous Software Engineering;;2015;9781467370677;;"https://doi-org.proxy.bnl.lu/10.1109/RCoSE.2015.12;http://dx.doi.org/10.1109/RCoSE.2015.12";10.1109/RCoSE.2015.12;Modern software development approaches rely extensively on tools. Motivated by practices such as continuous integration, deployment and delivery, these tools are used in a fashion where data are automatically accumulated in different databases as a side-effect of everyday development activities. In this paper we introduce an approach for software engineering data visualization as a mash up that combines data from issue management, software development and production use. The visualization can show to all stake holders how well continuous delivery is realized in the project. The visualization clearly shows the time spent to specify and develop the features as well the length of the delivery cycle. Further more the visualization shows how much work is unfinished and waiting for delivery. This can help the development team to decrease the amount of unfinished work and by that help them to keep up in continuous delivery mind set. In addition to development data usage of the features is also visualized.;Software Analytics, Continuous Delivery, Information Visualization;;;RCOSE '15
Conference Paper;Vergori G,Tamburri DA,Perez-Palacin D,Mirandola R;DevOps Performance Engineering: A Quasi-Ethnographical Study;;2017;;;127–132;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3053600.3053628;http://dx.doi.org/10.1145/3053600.3053628";10.1145/3053600.3053628;DevOps is a software engineering strategy to reduce soft- ware changes' rollout times by adopting any set of tactics that reduce friction in software lifecycles and their organisational variables, for example: coordination, communication, product evolution, deployment, operation, continuous architecting, continuous integration and more. Going DevOps is increasingly demanding that software engineering disciplines which were typically product-oriented such as software performance engineering to rethink their typical comfort zone, enlarging their scope from product, to process or even further to ecosystem and organisational levels of abstraction. This article makes an attempt at understanding what are the dimensions in DevOps organisational scenarios that can be addressed with a performance engineering lens. To do this, we performed a quasi-ethnographical study featuring a real-life industrial DevOps scenario. Discussing our results we conclude that many synergies exist between DevOps and performance engineering each with peculiarities, limitations and challenges - more research is needed to offer a full-spectrum performance-engineering support for DevOps practitioners.;devops performance engineering, ethnography, the phoenix project;;;ICPE '17 Companion
Conference Paper;Mattila AL,Lehtonen T,Terho H,Mikkonen T,Systä K;Mashing up Software Issue Management, Development, and Usage Data;;2015;;;26–29;;IEEE Press;Florence, Italy;;Proceedings of the Second International Workshop on Rapid Continuous Software Engineering;;2015;;;;;Modern software development approaches rely extensively on tools. Motivated by practices such as continuous integration, deployment and delivery, these tools are used in a fashion where data are automatically accumulated in different databases as a side-effect of everyday development activities. In this paper we introduce an approach for software engineering data visualization as a mashup that combines data from issue management, software development and production use.The visualization can show to all stake holders how well continuous delivery is realized in the project. The visualization clearly shows the time spent to specify and develop the features as well the length of the delivery cycle. Further more the visualization shows how much work is unfinished and waiting for delivery. This can help the development team to decrease the amount of unfinished work and by that help them to keep up in continuous delivery mind set. In addition to development data usage of the features is also visualized.;continuous delivery, software analytics, information visualization;;;RCoSE '15
Book Chapter;Bordeleau F,Bruel JM,Cabot J,Dingel J,Mosser S;1st Workshop on DevOps@MODELS;;2019;;;587–588;;IEEE Press;;Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems;;;2019;9781728151250;;https://doi-org.proxy.bnl.lu/10.1109/MODELS-C.2019.00089;;The first edition of the International Workshop DevOps@MODELS, specifically devoted to DevOps and Model Driven Engineering, was held on September 17, 2019 in Munich, Germany, as part of the satellite events of the ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems (MODELS 2019). The motivation, objectives, organization, and program of the workshop are summarized.;;;;
Book;Tak R,Modi J;Mobile DevOps: Deliver Continuous Integration and Deployment within Your Mobile Applications;;2018;;;;;Packt Publishing;;;;;2018;9781788296243;;;;This step-by-step guide will teach you to continuously improve your mobile application development process Key Features Efficiently deliver continuous integration and deployment within all the stages of your application's lifecycle Learn to implement mobile DevOps with Xamarin and Visual Studio Deliver high quality and performing mobile applications Book Description Today's world is all about perfection, and there are hundreds of applications that are released each day out of which only a few succeed. Making sure that the app looks, performs, and behaves as expected is one of the biggest challenge developers face today. The main goal of this book is to teach developers to implement DevOps to build, test, and deliver. This book will teach you to implement Mobile DevOps at every stage of your application's lifecycle with Visual Studio and Xamarin Mobile Lifecycle solutions. Later, it will also show you how to leverage Mobile Center's continuous integration and automated testing to develop a high-quality applications. Next, you'll see how to mobilize your on-premises data to the cloud and increase your productivity with code reuse. Finally, you'll discover how to find and fix bugs beforehand, improving the efficiency of your application while it is being developed. By the end of this book, you will be well-versed with Mobile DevOps techniques, delivering high quality and high performance mobile apps. What you will learnBecome fluent with the basic components of Mobile DevopsFind out how to use code repositories and install Git on an EC2 server and manage users and groups Set up an Android device for development and install Visual Studio and Xamarin on Windows Create an Android project and UI for applications Add permissions to Android Manifest Write tests with Xamarin. UI and test using test cloud to check it on multiple devices Monitor and optimize the application using the Android monitoring tool Debug the mobile application and improve its efficiency Who This Book Is ForIf you are a programmer and developer who wants to increase the efficiency and scalability of your mobile application with the implementation of DevOps, then this book is for you. You need basic experience of the application process development.;;;;
Book;Zadka M;DevOps in Python: Infrastructure as Python;;2019;;;;1st;Apress;USA;;;;2019;9781484244326;;;;Explore and apply best practices for efficient application deployment. This book draws upon author Moshe Zadka's years of Dev Ops experience and focuses on the parts of Python, and the Python ecosystem, that are relevant for DevOps engineers. You'll start by writing command-line scripts and automating simple DevOps-style tasks. You'll then move on to more advanced cases, like using Jupyter as an auditable remote-control panel, and writing Ansible and Salt extensions. This work also covers how to use the AWS API to manage cloud infrastructure, and how to manage Python programs and environments on remote machines. Python was invented as a systems management language for distributed operating systems, which makes it an ideal tool for DevOps. u200bAssuming a basic understanding of Python concepts, this book is perfect for engineers who want to move from operations/system administration into coding. What You'll Learn Use third party packages and create new packages Create operating system management and automation code in Python Write testable code, and testing best practices Work with REST APIs for web clients Who This Book Is For Junior or intermediate sysadmin who has picked up some bash and Python basics.;;;;
Book;Rangel D;DevOps: Learn One of the Most Powerful Software Development Methodologies FAST AND EASY!;;2016;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2016;9781532738043;;;;"DevOps Learn One of the Most Powerful Software Development Methodologies FAST AND EASY! This book is an exploration of DevOps (Developer Operations). It begins by explaining what DevOps is, how it is used, and why it was introduced. The next step is a guide on how one can set up TomEE from Puppet. The Puppet and Packer immutable servers are also explored, and thus you will know how to work with them after reading this book. The book will guide you on how to set up a modern web stack in Ubuntu, which is a distribution of the Linux operating system. With the advancement in technology, users now liketo use databases which are more advanced for their applications. Note that each of the web applications developed has a database. With DynamoDB, the administration overhead is greatly reduced. This book will guide you on how to shift your database from MongoDB to DynamoDB. The process of performing operations on tree structures in MongoDB is also discussed in detail, enabling you to operate on different types of tree structures. You will also learn how to configure your Apache for multiple domains. Reverse cache proxy, which is a very nice feature in Nginx is presented in detail, instructing you on how to work with it. The process of using Nginx in a web application is further explored. Here is a preview of what you'll learn: Definition Installation of TomEE from Puppet Puppet and Packer Immutable Servers How to set up a modern web stack in Ubuntu Migration of MongoDB to DynamoDB MongoDB and Tree Structures Configuration of Apache for Multiple Domains Reverse Cache Proxy in Nginx Setting Up LAMP on Ubuntu hosted on AWS Using Nginx with a Web Application Download your copy of "" DevOps "" by scrolling up and clicking ""Buy Now With 1-Click"" button.";;;;
Conference Paper;Pang C,Hindle A,Barbosa D;Understanding Devops Education with Grounded Theory;;2020;;;107–118;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training;Seoul, South Korea;2020;9781450371247;;"https://doi-org.proxy.bnl.lu/10.1145/3377814.3381711;http://dx.doi.org/10.1145/3377814.3381711";10.1145/3377814.3381711;"DevOps stands for Development-Operations. It arises from the IT industry as a movement aligning development and operations teams. DevOps is broadly recognized as an IT standard, and there is high demand for DevOps practitioners in industry. Since ACM & IEEE suggest that undergraduate computer science curricula ""must adequately prepare [students] for the workforce"", we studied whether undergraduates acquired adequate DevOps skills to fulfill the demand for DevOps practitioners in industry. We employed Grounded Theory (GT), a social science qualitative research methodology, to study DevOps education from academic and industrial perspectives. In academia, academics were not motivated to learn or adopt DevOps, and we did not find strong evidence of academics teaching DevOps. Academics need incentives to adopt DevOps, in order to stimulate interest in teaching DevOps. In industry, DevOps practitioners lack clearly defined roles and responsibilities, for the DevOps topic is diverse and growing too fast. Therefore, practitioners can only learn DevOps through hands-on working experience. As a result, academic institutions should provide fundamental DevOps education (in culture, procedure, and technology) to prepare students for their future DevOps advancement in industry. Based on our findings, we proposed five groups of future studies to advance DevOps education in academia.";devops, continuous delivery, continuous integration, software engineering, education, grounded theory;;;ICSE-SEET '20
Journal Article;Chand S,Om H;Storage Space Estimation for Videos Using Fading Channels;Digit. Signal Process.;2009;19;2;287–296;;Academic Press, Inc.;USA;;;;2009-03;;1051-2004;"https://doi-org.proxy.bnl.lu/10.1016/j.dsp.2008.01.006;http://dx.doi.org/10.1016/j.dsp.2008.01.006";10.1016/j.dsp.2008.01.006;In this paper, we propose a model for estimating the buffer storage for providing continuous delivery of the video data to users. The model incorporates the jitter delay, which is a switching delay between two consecutive video segments being transmitted through a logical channel. The jitter delay is assumed to be Rayleigh distributed as it characterizes the channel fading.;Video channelization, Jitter delay, Rayleigh distribution;;;
Conference Paper;Rivera LF,Villegas NM,Tamura G,Jiménez M,Müller HA;UML-Driven Automated Software Deployment;;2018;;;257–268;;IBM Corp.;USA;;Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering;Markham, Ontario, Canada;2018;;;;;Software companies face the challenge of ensuring customer satisfaction through the continuous delivery of functionalities and rapid response to quality issues. However, achieving frequent software delivery is not a trivial task. It requires agile---and continuous---design, development and deployment of existing and new software features. Over time, managing these systems becomes increasingly complex. This complexity stems, in part, from the deployment pipelines and the myriad possible configurations of the software components. Furthermore, software deployment is a time-consuming and error-prone process, which, even when automated, can lead to configuration errors and cost overruns. In this paper, we address deployment challenges that developers face during continuous delivery and DevOps. Our proposal consists of Urano, a mechanism for automating the deployment process, which uses UML, an interoperable and de facto modeling standard, as a means of specifying a software architecture and its associated deployment. Our approach is based on the model-driven architecture principles to generate executable deployment specifications from user-defined UML deployment diagrams. We extend this kind of diagrams by defining and applying a UML profile that captures the semantics and requirements of the installation, configuration, and update of software components. Thus, enabling more expressive deployment specifications and their automatic realization. To evaluate Urano, we conducted three case studies that demonstrate its potential to effectively automate software deployment processes in industry.;DevOps, continuous delivery, UML, model-driven architecture, deployment, model-driven engineering;;;CASCON '18
Conference Paper;Leppänen M,Kilamo T,Mikkonen T;Towards Post-Agile Development Practices through Productized Development Infrastructure;;2015;;;34–40;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 2nd International Workshop on Rapid Continuous Software Engineering;;2015;9781467370677;;"https://doi-org.proxy.bnl.lu/10.1109/RCoSE.2015.14;http://dx.doi.org/10.1109/RCoSE.2015.14";10.1109/RCoSE.2015.14;Modern software is developed to meet evolving customer needs in a timely fashion. The need for a rapid time-to-market together with changing requirements has led software intensive companies to utilize agile development, where each iteration aims at producing end-user value and change is embraced. In today's post-agile software development world, there is a need for processes and tools that deliver new software to the end-user as fast as possible. The level of adoption of these continuous software engineering practices depends on the product, customers, and the business domain. In this paper, we investigate the benefits gained from implementing a completely continuous delivery workflow using a domain specific productized development infrastructure through a descriptive single case study. Embracing the continuous delivery mindset throughout the development pipeline allows the case customer company to gain fast insight on new business directions and lends the services to live experimentation which in turn adds to end-user value. Up-to-date feedback cycles between all stakeholders all the way from concept design to end-users are offered.;continuous delivery, Continuous software engineering, development infrastructure;;;RCOSE '15
Conference Paper;Leppänen M,Kilamo T,Mikkonen T;Towards Post-Agile Development Practices through Productized Development Infrastructure;;2015;;;34–40;;IEEE Press;Florence, Italy;;Proceedings of the Second International Workshop on Rapid Continuous Software Engineering;;2015;;;;;Modern software is developed to meet evolving customer needs in a timely fashion. The need for a rapid time-to-market together with changing requirements has led software intensive companies to utilize agile development, where each iteration aims at producing end-user value and change is embraced. In today's post-agile software development world, there is a need for processes and tools that deliver new software to the end-user as fast as possible. The level of adoption of these continuous software engineering practices depends on the product, customers, and the business domain. In this paper, we investigate the benefits gained from implementing a completely continuous delivery workflow using a domain specific productized development infrastructure through a descriptive single case study. Embracing the continuous delivery mindset throughout the development pipeline allows the case customer company to gain fast insight on new business directions and lends the services to live experimentation which in turn adds to end-user value. Up-to-date feedback cycles between all stakeholders all the way from concept design to end-users are offered.;continuous delivery, continuous software engineering, development infrastructure;;;RCoSE '15
Book;Davis J,Daniels R;Effective DevOps: Building a Culture of Collaboration, Affinity, and Tooling at Scale;;2016;;;;1st;O'Reilly Media, Inc.;;;;;2016;9781491926307;;;;Some companies think that adopting devops means bringing in specialists or a host of new tools. With this practical guide, youll learn why devops is a professional and cultural movement that calls for change from inside your organization. Authors Katherine Daniels and Jennifer Davis provide several approaches for improving collaboration within teams, creating affinity among teams, promoting efficient tool usage in your company, and scaling up what works throughout your organizations inflection points. Devops stresses iterative efforts to break down information silos, monitor relationships, and repair misunderstandings that arise between and within teams in your organization. By applying the actionable strategies in this book, you can make sustainable changes in your environment regardless of your level within your organization. Explore the foundations of devops and learn the four pillars of effective devopsEncourage collaboration to help individuals work together and build durable and long-lasting relationships Create affinity among teams while balancing differing goals or metrics Accelerate cultural direction by selecting tools and workflows that complement your organization Troubleshoot common problems and misunderstandings that can arise throughout the organizational lifecycleLearn from case studies from organizations and individuals to help inform your own devops journey;;;;
Book;Nahavandipoor V;IOS 11 Swift Programming Cookbook: Solutions and Examples for IOS Apps;;2017;;;;1st;O'Reilly Media, Inc.;;;;;2017;9781491992470;;;;iOS 11, Swift 4, and Xcode 9 provide many new APIs for iOS developers. With this cookbook, youll learn more than 170 proven solutions for tackling the latest features in iOS 11 and watchOS 4, including new ways to use Swift and Xcode to make your day-to-day app development life easier. This collection of code-rich recipes also gets you up to speed on continuous delivery and continuous integration systems. Ideal for intermediate and advanced iOS developers looking to work with the newest version of iOS, these recipes include reusable code on GitHub, so you can put them to work in your project right away. Among the topics covered in this book: New features in Swift 4 and Xcode 9Tools for continuous delivery and continuous integration Snapshot testing and test automation Creating document-based applications Updated Map view and Core Location featuresiOS 11s Security and Password Autofill Data storage with Apples Core DataCreating lively user interfaces with UI Dynamics Building iMessage applications and sticker packages Integrating Siri into your apps with Siri KitCreating fascinating apps for Apple Watch;;;;
Book;Staveley-Curator E;Learning Path: DevOps with Docker;;2016;;;;;Packt Publishing;;;;;2016;9781786463937;;;;DevOps might feel like it?'s still an emerging trend, but Docker is definitely here to stay. This rapid Learning Path will show you how to get up to speed with real-world containerization so that you can build and ship like an engineering professional.;;;;
Conference Paper;Pagrut DS;Testing of Changing Requirement in an Agile Environment - A Case Study of Telecom Project;;2007;;;136;;IEEE Computer Society;USA;;Proceedings of the Testing: Academic and Industrial Conference Practice and Research Techniques - MUTATION;;2007;9780769529844;;;;This paper is focused on before and after changes of agile implementation and describing the successful testing goals of agile implementation in Flow Product Project (Telecom Project). After implementation of agile methodology in Tech Mahindra, team would really gain a drastic change in testing activity, continuous delivery, customer satisfaction and also help to meet challenges of changing requirements and new functionalities.;;;;TAICPART-MUTATION '07
Conference Paper;Badshah S,Khan AA,Khan B;Towards Process Improvement in DevOps: A Systematic Literature Review;;2020;;;427–433;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Evaluation and Assessment in Software Engineering;Trondheim, Norway;2020;9781450377317;;"https://doi-org.proxy.bnl.lu/10.1145/3383219.3383280;http://dx.doi.org/10.1145/3383219.3383280";10.1145/3383219.3383280;In recent years, the software release cost has been reduced dramatically due to the alteration from traditional shrink-wrapped software to software as a service. Organizations that can deliver their services continuously and with a high frequency have a higher ability to compete in the market. As a response to this, a substantial number of software companies acquired DevOps to establish a culture of effective communication and collaboration between development and operation teams and in order to enhance the production release frequency as well as to maintain the product quality. However, the DevOps environment requires a platform that aid in evaluating the performance of existing processes and provide improvement recommendations. On top of that, organizations can only achieve the perceived benefits of DevOps if their processes are mature and continuously measured. The objective of this research is to investigate the process improvement contributions made by researchers in the DevOps field. For this purpose, we performed a systematic literature review that resulted in several maturity models and best practices. Our ultimate aim is to develop a DevOps maturity model that can appraise and improve the processes in the DevOps environment.;Continuous software engineering, DevOps, maturity models, process improvement, systematic review;;;EASE '20
Conference Paper;Bezemer CP,Eismann S,Ferme V,Grohmann J,Heinrich R,Jamshidi P,Shang W,van Hoorn A,Villavicencio M,Walter J,Willnecker F;How is Performance Addressed in DevOps?;;2019;;;45–50;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering;Mumbai, India;2019;9781450362399;;"https://doi-org.proxy.bnl.lu/10.1145/3297663.3309672;http://dx.doi.org/10.1145/3297663.3309672";10.1145/3297663.3309672;DevOps is a modern software engineering paradigm that is gaining widespread adoption in industry. The goal of DevOps is to bring software changes into production with a high frequency and fast feedback cycles. This conflicts with software quality assurance activities, particularly with respect to performance. For instance, performance evaluation activities --- such as load testing --- require a considerable amount of time to get statistically significant results.We conducted an industrial survey to get insights into how performance is addressed in industrial DevOps settings. In particular, we were interested in the frequency of executing performance evaluations, the tools being used, the granularity of the obtained performance data, and the use of model-based techniques. The survey responses, which come from a wide variety of participants from different industry sectors, indicate that the complexity of performance engineering approaches and tools is a barrier for wide-spread adoption of performance analysis in DevOps. The implication of our results is that performance analysis tools need to have a short learning curve, and should be easy to integrate into the DevOps pipeline in order to be adopted by practitioners.;continuous integration, devops, software performance, industrial practices;;;ICPE '19
Conference Paper;Boyer F,de Palma N,Tao X,Etchevers X;A Declarative Approach for Updating Distributed Microservices;;2018;;;392–393;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings;Gothenburg, Sweden;2018;9781450356633;;"https://doi-org.proxy.bnl.lu/10.1145/3183440.3195023;http://dx.doi.org/10.1145/3183440.3195023";10.1145/3183440.3195023;One of the greatest benefits of microservices is to sensitively ease changing applications by splitting these into independently deployable units [5]. Combined with Continuous Delivery (CD) -that aims at delivering quickly and safely every software releases- and Platform as a Service (PaaS) automating application management in a on-demand virtualized environment, the microservice paradigm has become essential to implement agile processes.;;;;ICSE '18
Journal Article;Chen S,Wang H,Zhang X,Shen B,Wee S;Segment-Based Proxy Caching for Internet Streaming Media Delivery;IEEE MultiMedia;2005;12;3;59–67;;IEEE Computer Society Press;Washington, DC, USA;;;;2005-07;;1070-986X;"https://doi-org.proxy.bnl.lu/10.1109/MMUL.2005.56;http://dx.doi.org/10.1109/MMUL.2005.56";10.1109/MMUL.2005.56;The proliferation of multimedia content on the Internet poses challenges to existing content delivery networks. While proxy caching can successfully deliver traditional text-basedstatic objects, it faces difficulty delivering streaming media objects because of the objectsý sizes aswell as clients' rigorous continuous delivery demands.We present two techniques supporting segmentbased proxy caching of streaming media. We evaluated these techniques in simulations and realsystems.;simulations, segment-based, Streaming media, internet, real systems;;;
Book;Kim G,Debois P,Willis J,Humble J;The DevOps Handbook: How to Create World-Class Agility, Reliability, and Security in Technology Organizations;;2016;;;;;IT Revolution Press;;;;;2016;9781942788003;;;;Increase profitability, elevate work culture, and exceed productivity goals through DevOps practices. More than ever, the effective management of technology is critical for business competitiveness. For decades, technology leaders have struggled to balance agility, reliability, and security. The consequences of failure have never been greaterwhether it's the healthcare.gov debacle, cardholder data breaches, or missing the boat with Big Data in the cloud. And yet, high performers using DevOps principles, such as Google, Amazon, Facebook, Etsy, and Netflix, are routinely and reliably deploying code into production hundreds, or even thousands, of times per day. Following in the footsteps of The Phoenix Project, The DevOps Handbook shows leaders how to replicate these incredible outcomes, by showing how to integrate Product Management, Development, QA, IT Operations, and Information Security to elevate your company and win in the marketplace. Take the DORA DevOps X-ray Assessment and see where you stand! Visit devops-survey.com with your access code to take the DevOps X-ray Assessment.;;;;
Journal Article;Balalaie A,Heydarnoori A,Jamshidi P;Microservices Architecture Enables DevOps: Migration to a Cloud-Native Architecture;IEEE Softw.;2016;33;3;42–52;;IEEE Computer Society Press;Washington, DC, USA;;;;2016-05;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2016.64;http://dx.doi.org/10.1109/MS.2016.64";10.1109/MS.2016.64;When DevOps started gaining momentum in the software industry, one of the first service-based architectural styles to be introduced, be applied in practice, and become popular was microservices. Migrating monolithic architectures to cloud-native architectures such as microservices reaps many benefits, such as adaptability to technological changes and independent resource management for different system components. This article reports on experiences and lessons learned during incremental migration and architectural refactoring of a commercial MBaaS (mobile back end as a service) to microservices. It explains how adopting DevOps facilitated a smooth migration. Furthermore, the researchers transformed their experiences in different projects into reusable migration practices, resulting in microservices migration patterns. This article is part of a theme issue on DevOps. The Web extra at https://youtu.be/MF3-dKTCQ88 is an audio recording of Brian Brannon speaking with author Pooyan Jamshidi and James Lewis, principal engineer at ThoughtWorks, about DevOps and microservices architecture.;;;;
Conference Paper;Umar M,Colomo-Palacios R;DevOps Job Roles: A Multivocal Literature Review;;2021;;;247–256;;Springer-Verlag;Berlin, Heidelberg;;Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part IX;Cagliari, Italy;2021;9783030870126;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-87013-3_19;http://dx.doi.org/10.1007/978-3-030-87013-3_19";10.1007/978-3-030-87013-3_19;DevOps bridges the gap between software development and operations to provide rapid deliveries and integrated collaboration. However, DevOps entails lots of factors and challenges involved in its implementation including technical, organizational and personnel aspects. Focusing on the last set of aspects, this paper identifies current DevOps job roles, an aspect that is crucial to implement and to support DevOps practices in organizations. It also highlights collaboration between different actors under different automation levels in DevOps to deliver software at high speed.;DevOps, Software development, Multivocal literature review, Job roles;;;
Book;Familiar B;Microservices, IoT, and Azure: Leveraging DevOps and Microservice Architecture to Deliver SaaS Solutions;;2015;;;;1st;Apress;USA;;;;2015;9781484212769;;;;This book provides practical guidance for adopting a high velocity, continuous delivery process to create reliable, scalable, Software-as-a-Service (SaaS) solutions that are designed and built using a microservice architecture, deployed to the Azure cloud, and managed through automation. Microservices, IoT, and Azure offers software developers, architects, and operations engineers step-by-step directions for building SaaS applicationsapplications that are available 24x7, work on any device, scale elastically, and are resilient to change--through code, script, exercises, and a working reference implementation. The book provides a working definition of microservices and contrasts this approach with traditional monolithic Layered Architecture. A fictitious, homebiomedical startup is used to demonstrate microservice architecture and automation capabilities for cross-cutting and business services as well as connected device scenarios for Internet of Things (IoT). Several Azure PaaS services are detailed including Storage, SQL Database, DocumentDb, Redis Cache, Cloud Services, Web API's, API Management, IoT Hub, IoT Suite, Event Hub, and Stream Analytics. Finally the book looks to the future and examines Service Fabric to see how microservices are becoming the de facto approach to building reliable software in the cloud. What youll learn What microservices are and why are theyre a compelling architecture pattern for SaaS applications How to design, develop, and deploy microservices using Visual Studio, Power Shell, and Azure Microservice patterns for cross-cutting concerns and business capabilities Microservice patterns for Internet of Things and big data analytics solutions using IoT Hub, Event Hub, and Stream AnalyticsTechniques for automating microservice provisioning, building, and deployment What Service Fabric is and how its the future direction for microservices on Microsoft Azure Who this book is for Software Application Architects, .NET Developers, Database Admins and DevOps engineers. The code samples will primarily be in C# but will also include Node.JS samples.;;;;
Book;Cuppett MS;DevOps, DBAs, and DBaaS: Managing Data Platforms to Support Continuous Integration;;2016;;;;1st;Apress;USA;;;;2016;9781484222072;;;;Learn how DBAs in a DevOps environment manage data platforms and change requests to support and optimize continuous integration, delivery, testing, and deployment in the application development life cycle. On the Dev side, DBAs evaluate change requests to ensure compliance with organizational best practices and guard against degradation of database performance and the validity of dependent objects. On the Ops side, DBAs perform release and troubleshooting activities in support of the application, manage the data platforms access and security, and monitor and maintain performance of the databases that they have designed and provisioned. DevOps, DBAs, and DBaaS investigates the complex intersection between DBA functions and DevOps processes. DevOps teams traditionally viewed DBAs as process outliers who disrupt and retard SDLC timelines. At each touch point, veteran DBA Mike Cuppett shows how DBAs can most effectively contribute to decreasing release cycle times and improving product resiliency by applying automation, orchestration, and DBaaS solutions to database administration in ways that dovetail with DevOps requirements and metrics. At a high level, Cuppett demonstrates the importance of leveling silo walls in the IT supply chain and of measuring application performance holistically by reference to satisfaction of customer requirements and end-user experience. At a technical level, he drills into topics and case studies on diagnosing and resolving problems commonly encountered by DBAs and DevOps teams when meshing database management with application delivery. What You Will Learn:Understand techniques and best practices at all points of collaboration between DBAs and DevOps teams in product developmentUse tools for measuring DBA inputs to DevOps processes by holistic criteria of end-user experience and business requirementIntegrate open source database technologies with DevOpsKnow when to decouple application and database layers and move to DBaaS modelsOvercome language and mindset barriers between DBAs and DevOps teamsWho This Book Is For:DBAs who are leaning toward or already involved with DevOps and DevOps engineers, team leaders, developers and product managers who are already working with DBAs or planning to integrate DBAs in DevOps teams. The secondary readership is executives and managers in companies that practice DevOps.;;;;
Conference Paper;Sokolowski D,Weisenburger P,Salvaneschi G;Automating Serverless Deployments for DevOps Organizations;;2021;;;57–69;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Athens, Greece;2021;9781450385626;;"https://doi-org.proxy.bnl.lu/10.1145/3468264.3468575;http://dx.doi.org/10.1145/3468264.3468575";10.1145/3468264.3468575;DevOps unifies software development and operations in cross-functional teams to improve software delivery and operations (SDO) performance. Ideally, cross-functional DevOps teams independently deploy their services, but the correct operation of a service often demands other services, requiring coordination to ensure the correct deployment order. This issue is currently solved either with a central deployment or manual out-of-band communication across teams, e.g., via phone, chat, or email. Unfortunately, both contradict the independence of teams, hindering SDO performance—the reason why DevOps is adopted in the first place. In this work, we conduct a study on 73 IT professionals, showing that, in practice, they resort to manual coordination for correct deployments even if they expect better SDO performance with fully automated approaches. To address this issue, we propose µs ([mju:z] “muse”), a novel IaC system automating deployment coordination in a fully decentralized fashion, still retaining compatibility with DevOps practice—in contrast to today’s solutions. We implement µs, demonstrate that it effectively enables automated coordination, introduces negligible definition overhead, has no performance overhead, and is broadly applicable, as shown by the migration of 64 third-party IaC projects.;DevOps, Cloud, Serverless Computing, Infrastructure as Code;;;ESEC/FSE 2021
Book;Machiraju S,Gaurav S;DevOps for Azure Applications: Deploy Web Applications on Azure;;2018;;;;1st;Apress;USA;;;;2018;9781484236420;;;;Deploy web applications on Azure using DevOps tools. This book gives solutions to real-world Cloud deployment scenarios which will enable you to become adept in DevOps work for Azure. You'll start by seeing an overview of DevOps for Azure deployments where you will also survey the available tools, including Octopus Deploy and TeamCity. Here, you will learn how to use TeamCity as a CI tool and Octopus Deploy as release-management and CD software to get your package deployed on Azure Web Application. Next, the authors demonstrate using the Microsoft Visual Studio Team Services (VSTS) integrated developer platform. Finally, you will go through some real-world scenarios using DevOps tools to deploy web applications on Azure. To do this, you will create resources in Azure and integrate with an open source buildout. After reading this book, you will be ready to use various tools in a DevOps environment to support an Azure deployment. What You Will Learn Carry out a survey of DevOps tools Build a DevOps solution using standalone DevOps tools Team City and Octopus Deploy Use an integrated DevOps platform VSTS Build out an Azure deployment using open source code and VSTS Who This Book Is For Developers and release engineers. Also, project managers will find it useful to understand the workflow in DevOps.;;;;
Book;Picozzi S,Hepburn M,O'Connor N;DevOps with OpenShift: Cloud Deployments Made Easy;;2017;;;;1st;O'Reilly Media, Inc.;;;;;2017;9781491975961;;;;For many organizations, a big part of DevOps appeal is software automation using infrastructure-as-code techniques. This book presents developers, architects, and infra-ops engineers with a more practical option. Youll learn how a container-centric approach from OpenShift, Red Hats cloud-based PaaS, can help your team deliver quality software through a self-service view of IT infrastructure. Three OpenShift experts at Red Hat explain how to configure Docker application containers and the Kubernetes cluster manager with OpenShifts developer- and operational-centric tools. Discover how this infrastructure-agnostic container management platform can help companies navigate the murky area where infrastructure-as-code ends and application automation begins. Get an application-centric view of automationand understand why its importantLearn patterns and practical examples for managing continuous deployments such as rolling, A/B, blue-green, and canaryImplement continuous integration pipelines with OpenShifts Jenkins capabilityExplore mechanisms for separating and managing configuration from static runtime softwareLearn how to use and customize OpenShifts source-to-image capabilityDelve into management and operational considerations when working with OpenShift-based application workloadsInstall a self-contained local version of the OpenShift environment on your computer;;;;
Journal Article;;Emerging Themes in Agile Software Development;Inf. Softw. Technol.;2016;77;C;56–60;;Butterworth-Heinemann;USA;;;;2016-09;;0950-5849;"https://doi-org.proxy.bnl.lu/10.1016/j.infsof.2016.04.018;http://dx.doi.org/10.1016/j.infsof.2016.04.018";10.1016/j.infsof.2016.04.018;The relationship between customers and suppliers remains a challenge in agile software development. Two trends seek to improve this relationship, the increased focus on value and the move towards continuous deployment. In this special section on continuous value delivery, we describe these emerging research themes and show the increasing interest in these topics over time. Further, we discuss implications for future research.;;;;
Conference Paper;Hussain W,Clear T,MacDonell S;Emerging Trends for Global DevOps: A New Zealand Perspective;;2017;;;21–30;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 12th International Conference on Global Software Engineering;;2017;9781538615874;;"https://doi-org.proxy.bnl.lu/10.1109/ICGSE.2017.16;http://dx.doi.org/10.1109/ICGSE.2017.16";10.1109/ICGSE.2017.16;The DevOps phenomenon is gaining popularity through its ability to support continuous value delivery and ready accommodation of change. However, given the relative immaturity and general confusion about DevOps, a common view of expectations from a DevOps role is lacking. Through investigation of online job advertisements, combined with interviews, we identified key Knowledge Areas, Skills and Capabilities for a DevOps role and their relative importance in New Zealand's job market. Our analysis also revealed the global dimensions and the emerging nature of the DevOps role in GSE projects. This research adds a small advanced economy (New Zealand) perspective to the literature on DevOps job advertisements and should be of value to employers, job seekers, researchers as well educators and policy makers.;online job postings analysis, analysis, continuous deployment, DevOps, empirical, GSE, content analysis' cloud, AWS, GSD, education, continuous integration;;;ICGSE '17
Conference Paper;Ur Rahman AA,Williams L;Software Security in DevOps: Synthesizing Practitioners' Perceptions and Practices;;2016;;;70–76;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the International Workshop on Continuous Software Evolution and Delivery;Austin, Texas;2016;9781450341578;;"https://doi-org.proxy.bnl.lu/10.1145/2896941.2896946;http://dx.doi.org/10.1145/2896941.2896946";10.1145/2896941.2896946;In organizations that use DevOps practices, software changes can be deployed as fast as 500 times or more per day. Without adequate involvement of the security team, rapidly deployed software changes are more likely to contain vulnerabilities due to lack of adequate reviews. The goal of this paper is to aid software practitioners in integrating security and DevOps by summarizing experiences in utilizing security practices in a DevOps environment. We analyzed a selected set of Internet artifacts and surveyed representatives of nine organizations that are using DevOps to systematically explore experiences in utilizing security practices. We observe that the majority of the software practitioners have expressed the potential of common DevOps activities, such as automated monitoring, to improve the security of a system. Furthermore, organizations that integrate DevOps and security utilize additional security activities, such as security requirements analysis and performing security configurations. Additionally, these teams also have established collaboration between the security team and the development and operations teams.;DevOps, software practices, security, survey;;;CSED '16
Conference Paper;Moore J,Kortuem G,Smith A,Chowdhury N,Cavero J,Gooch D;DevOps for the Urban IoT;;2016;;;78–81;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Second International Conference on IoT in Urban Space;Tokyo, Japan;2016;9781450342049;;"https://doi-org.proxy.bnl.lu/10.1145/2962735.2962747;http://dx.doi.org/10.1145/2962735.2962747";10.1145/2962735.2962747;Choosing the right technologies to build an urban-scale IoT system can be challenging. There is often a focus on low-level architectural details such as the scalability of message handling. In our experience building an IoT information system requires a high-level holistic approach that mixes traditional data collection from vendor-specific cloud backends, together with data collected directly from embedded hardware and mobile devices. Supporting this heterogeneous environment can prove challenging and lead to complex systems that are difficult to develop and deploy in a timely fashion. In this paper we describe how we address these challenges by proposing a three-tiered DevOps model which we used to build an information system that is capable of providing real-time analytics of Electric Vehicle (EV) mobility usage and management within a smart city project.;Smart City, Solar Energy, EV Mobility, DevOps, Urban IoT;;;Urb-IoT '16
Conference Paper;Senapathi M,Buchan J,Osman H;DevOps Capabilities, Practices, and Challenges: Insights from a Case Study;;2018;;;57–67;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018;Christchurch, New Zealand;2018;9781450364034;;"https://doi-org.proxy.bnl.lu/10.1145/3210459.3210465;http://dx.doi.org/10.1145/3210459.3210465";10.1145/3210459.3210465;DevOps is a set of principles and practices to improve collaboration between development and IT Operations. Against the backdrop of the growing adoption of DevOps in a variety of software development domains, this paper describes empirical research into factors influencing its implementation. It presents findings of an in-depth exploratory case study that explored DevOps implementation in a New Zealand product development organisation. The study involved interviewing six experienced software engineers who continuously monitored and reflected on the gradual implementation of DevOps principles and practices. For this case study the use of DevOps practices led to significant benefits, including increase in deployment frequency from about 30 releases a month to an average of 120 releases per month, as well as improved natural communication and collaboration between IT development and operations personnel. We found that the support of a number of technological enablers, such as implementing an automation pipeline and cross functional organisational structures, were critical to delivering the expected benefits of DevOps.;DevOps benefits and challenges, DevOps enablers and practices;;;EASE'18
Conference Paper;Avritzer A;Automated Scalability Assessment in DevOps Environments;;2020;;;10;;Association for Computing Machinery;New York, NY, USA;;Companion of the ACM/SPEC International Conference on Performance Engineering;Edmonton AB, Canada;2020;9781450371094;;"https://doi-org.proxy.bnl.lu/10.1145/3375555.3384936;http://dx.doi.org/10.1145/3375555.3384936";10.1145/3375555.3384936;In this extended abstract, we provide an outline of the presentation planned for WOSP-C 2020. The goal of the presentation is to provide an overview of the challenges and approaches for automated scalability assessment in the context of DevOps and microservices. The focus of this presentation is on approaches that employ automated identification of performance problems because these approaches can leverage performance anti-pattern[5] detection technology. In addition, we envision extending the approach to recommend component refactoring. In our previous work[1,2] we have designed a methodology and associated tool support for the automated scalability assessment of micro-service architectures, which included the automation of all the steps required for scalability assessment. The presentation starts with an introduction to dependability, operational Profile Data, and DevOps. Specifically, we provide an overview of the state of the art in continuous performance monitoring technologies[4] that are used for obtaining operational profile data using APM tools. We then present an overview of selected approaches for production and performance testing based on the application monitoring tool (PPTAM) as introduced in [1,2]. The presentation concludes by outlining a vision for automated performance anti-pattern[5] detection. Specifically, we present the approach introduced for automated anti-pattern detection based on load testing results and profiling introduced in[6] and provide recommendations for future research.;;;;ICPE '20
Conference Paper;Fernandes M,Ferino S,Kulesza U,Aranha E;Challenges and Recommendations in DevOps Education: A Systematic Literature Review;;2020;;;648–657;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 34th Brazilian Symposium on Software Engineering;Natal, Brazil;2020;9781450387538;;"https://doi-org.proxy.bnl.lu/10.1145/3422392.3422496;http://dx.doi.org/10.1145/3422392.3422496";10.1145/3422392.3422496;Over the last years, DevOps has gained more importance and attention from the software industry, given its role in enabling continuous software delivery. As a new area, DevOps has brought significant challenges for the academy, both in terms of research topics and teaching strategies. In this paper, we present a systematic literature review that aims to identify challenges and recommendations for teaching DevOps. Our findings show a total of 73 challenges and 85 recommendations organized into different seven categories from a total of 18 papers selected. We also discuss how existing recommendations address the challenges found in the study, thus contributing to the preparation and execution of DevOps courses. Finally, we investigate if challenges and recommendations are specific for teaching DevOps.;courses, DevOps, education, challenges, recommendations;;;SBES '20
Book;Vemula R;Integrating Serverless Architecture: Using Azure Functions, Cosmos DB, and SignalR Service;;2019;;;;1st;Apress;USA;;;;2019;9781484244883;;;;Design, develop, build, and deploy an end-to-end serverless architecture by leveraging Azure services, frameworks, and tools. This book offers a holistic approach, guiding you through the design and development of a Twitter Bot application, while leveraging Azure Functions. Integrating Serverless Architecture begins with an overview of serverless computing and getting started with Azure Functions. Here, you will create a Twitter bot function which scans Twitter for the latest tweets and makes use of dependency injection. Further, you will learn about Azure Cosmos DB where you will cover its change feed mechanism and the repository pattern. You will create a Cosmos DB trigger-based tweet notifier function, which will broadcast the latest tweets to connected clients. You will explore the basics of Azure Service Bus and create a tweet scheduler function, which will prioritize different keywords for the Twitter bot function. Along the way, you will debug, deploy, and test the functions in the Azure environment. This book shows you how to secure your Azure Function secrets with the help of Azure Key Vault. To further your understanding of the technology, you will learn logging and exception handling in Azure Functions. Later in the book, you will build a Twitter bot web application by using ASP.NET Core and Materialize CSS, which will interact with several HTTP-based Azure Functions. The Twitter bot web application allows users to log in through the Twitter Identity Provider, subscribe to different keywords/hashtags, and browse the latest tweets based on subscriptions. You will get started with SignalR Service and integrate it with Azure Functions and web applications. Towards the end you will go through app service authentication on Azure Functions and discover how to configure continuous integration and deployment to Azure Functions. After reading this book, you will be able to understand the steps involved in design, development, and deployment of a workflow using Azure Functions. What You Will Learn Design and develop a Twitter bot application using Azure Functions with Azure Web App Service as the front end Leverage Azure Cosmos DB as data storage and trigger notifications using its change feed mechanism Store and retrieve secrets from Azure Key Vault Integrate Azure Functions with Azure SignalR Service to broadcast real-time messages Secure Azure Functions by enabling Twitter identity authentication using built-in App Service authentication Build a continuous integration and continuous deployment pipeline for Azure Functions using Visual Studio Team Services (VSTS) Who This Book Is For Developers, software engineers, and architects who design and manage infrastructures and build applications by leveraging Microsoft cloud services.;;;;
Conference Paper;Di Marco A;DevOps and WSN App: A Bio-Inspired Paradigm;;2017;;;157–158;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3053600.3053625;http://dx.doi.org/10.1145/3053600.3053625";10.1145/3053600.3053625;Wireless Sensor Networks (WSN) are nowadays applied to a wide set of domains (e.g., security, health). WSN are networks of spatially distributed, radio-communicating, battery-powered, autonomous sensor nodes. WSN are characterized by scarcity of resources, hence an application running on them should carefully manage its resources. Applications running on WSN (namely, WSN App) and using sensors, must be adaptable to modify their behavior at run-time to respond to changes in the environment they run, to changes of the users' requirements or to changes occurring in the system itself.This talk will present a bio-inspired paradigm that mimics the cell lifecycle and uses the concept of membrane to define the border of a system adaptation. The adaptation is specifies by PROTEUS a language for reconfiguration plans. The talk will show the application of such a paradigm to WSN domain through the MAIA framework (FraMework for Adaptaptive wIreless sensor network Applications). MAIA provides components i) to model and analysis quality attributes (e.g., timing, performance and energy consumption) of AGILLA agents, ii) to generate AGILLA code from the provided models and to dynamically delivery the generated code on WSN. MAIA supports DevOps process for WSN App.;quality attribute, wireless sensor network, adaptation, devops;;;ICPE '17 Companion
Conference Paper;Hupy C;DevOps: The Sky's the Limit in Higher Education;;2021;;;43;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 22st Annual Conference on Information Technology Education;SnowBird, UT, USA;2021;9781450383554;;"https://doi-org.proxy.bnl.lu/10.1145/3450329.3476842;http://dx.doi.org/10.1145/3450329.3476842";10.1145/3450329.3476842;;workforce development, innovation, git, devops, continuous integration, continuous development,;;;SIGITE '21
Conference Paper;Sokolowski D;Deployment Coordination for Cross-Functional DevOps Teams;;2021;;;1630–1634;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Athens, Greece;2021;9781450385626;;"https://doi-org.proxy.bnl.lu/10.1145/3468264.3473101;http://dx.doi.org/10.1145/3468264.3473101";10.1145/3468264.3473101;Software stability and reliability are the core concerns of DevOps. They are improved by tightening the collaboration between developers and operators in cross-functional teams on the one hand and by automating operations through continuous integration (CI) and infrastructure as code (IaC) on the other hand. Ideally, teams in DevOps are fully independent. Still, their applications often depend on each other in practice, requiring them to coordinate their deployment through centralization or manual coordination. With this work, we propose and implement the novel IaC solution µs ([mju:z] ”muse”), which automates deployment coordination in a decentralized fashion. µs is the first approach that is compatible with the DevOps goals as it enables truly independent operations of the DevOps teams. We define our research problem through a questionnaire survey with IT professionals and evaluate the solution by comparing it to other modern IaC approaches, assessing its performance, and applying it to existing IaC programs.;Resource Orchestration, Cloud, Infrastructure as Code, DevOps;;;ESEC/FSE 2021
Book;Medina O,Schumann E;DevOps for SharePoint: With Packer, Terraform, Ansible, and Vagrant;;2018;;;;1st;Apress;USA;;;;2018;9781484236871;;;;Deploy a SharePoint farm in a repeatable, predictable, and reliable fashion using Infrastructure as Code (IaC) techniques to automate provisioning. Savvy IT pros will learn how to use DevOps practices and open source tools to greatly reduce costs, and streamline management operations for SharePoint farms deployed via Amazon Web Services (AWS), Azure, or on premise. DevOps for SharePointwill help you navigate the complex challenges of deploying and managing SharePoint Server farms. You will learn how to reduce time-consuming tasks and errors when generating development, testing, or production environments. And you will benefit from learning proven methods to apply Microsoft updates with minimal downtime and productivity loss. Whether you are a SharePoint architect, IT pro, or developer helping customers with the SharePoint platform, this book will teach you the most useful DevOps practices to tackle those issues and broaden your skill set. What Youll Learn Understand the basics of the most popular open source tools Vagrant, Packer, Terraform, and Ansibleand how to use them in the context of deploying and scaling a SharePoint farm Use Vagrant to build SharePoint development environments in less than an hour, and add automated testing Use Packer to create a golden image with preconfigured settings, and then use it as the base image in your Terraform configuration for both AWS and Azure farms Use Terraform to scale your SharePoint farm topology Use Red Hats Ansible Playbooks to perform configuration management on your farm Use Terraform to deploy immutable infrastructure environments using IaC (Infrastructure as Code) Use InSpec 2.0 to stay in compliance by testing your cloud infrastructure Use Ansible to apply Microsoft updates and patches Who This Book Is ForIT pros and developers who are looking to expand their knowledge and take a modern approach by using open source technologies to work with Microsoft products. Experience installing SharePoint, and a basic understanding of either Azure or AWS, is helpful.;;;;
Journal Article;Adams B,Bellomo S,Bird C,Marshall-Keim T,Khomh F,Moir K;The Practice and Future of Release Engineering: A Roundtable with Three Release Engineers;IEEE Softw.;2015;32;2;42–49;;IEEE Computer Society Press;Washington, DC, USA;;;;2015-03;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2015.52;http://dx.doi.org/10.1109/MS.2015.52";10.1109/MS.2015.52;Three release engineers share their perspectives on quality metrics for releases and on continuous delivery's benefits and limitations. They also discuss release-engineering job skills, the required mind-set, the role of education, and cultural change, and they recommend future research areas. The Web extra at http://youtu.be/O3cJQTZXAI8 is an audio recording of Davide Falessi speaking with Guest Editors Bram Adams and Foutse Khomh about release engineering and its value to the software industry.;;;;
Conference Paper;Heinrich R,van Hoorn A,Knoche H,Li F,Lwakatare LE,Pahl C,Schulte S,Wettinger J;Performance Engineering for Microservices: Research Challenges and Directions;;2017;;;223–226;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3053600.3053653;http://dx.doi.org/10.1145/3053600.3053653";10.1145/3053600.3053653;Microservices complement approaches like DevOps and continuous delivery in terms of software architecture. Along with this architectural style, several important deployment technologies, such as container-based virtualization and container orchestration solutions, have emerged. These technologies allow to efficiently exploit cloud platforms, providing a high degree of scalability, availability, and portability for microservices.Despite the obvious importance of a sufficient level of performance, there is still a lack of performance engineering approaches explicitly taking into account the particularities of microservices. In this paper, we argue why new solutions to performance engineering for microservices are needed. Furthermore, we identify open issues and outline possible research directions with regard to performance-aware testing, monitoring, and modeling of microservices.;microservices, software performance engineering, continuous delivery;;;ICPE '17 Companion
Book;Hsu T;Hands-On Security in DevOps: Ensure Continuous Security, Deployment, and Delivery with DevSecOps;;2018;;;;;Packt Publishing;;;;;2018;9781788995504;;;;Protect your organization's security at all levels by introducing the latest strategies for securing DevOps Key Features Integrate security at each layer of the DevOps pipeline Discover security practices to protect your cloud services by detecting fraud and intrusion Explore solutions to infrastructure security using DevOps principles Book Description DevOps has provided speed and quality benefits with continuous development and deployment methods, but it does not guarantee the security of an entire organization. Hands-On Security in DevOps shows you how to adopt DevOps techniques to continuously improve your organizations security at every level, rather than just focusing on protecting your infrastructure. This guide combines DevOps and security to help you to protect cloud services, and teaches you how to use techniques to integrate security directly in your product. You will learn how to implement security at every layer, such as for the web application, cloud infrastructure, communication, and the delivery pipeline layers. With the help of practical examples, youll explore the core security aspects, such as blocking attacks, fraud detection, cloud forensics, and incident response. In the concluding chapters, you will cover topics on extending DevOps security, such as risk assessment, threat modeling, and continuous security. By the end of this book, you will be well-versed in implementing security in all layers of your organization and be confident in monitoring and blocking attacks throughout your cloud services. What you will learn Understand DevSecOps culture and organization Learn security requirements, management, and metrics Secure your architecture design by looking at threat modeling, coding tools and practices Handle most common security issues and explore black and white-box testing tools and practices Work with security monitoring toolkits and online fraud detection rules Explore GDPR and PII handling case studies to understand the DevSecOps lifecycle Who this book is for Hands-On Security in DevOps is for system administrators, security consultants, and DevOps engineers who want to secure their entire organization. Basic understanding of Cloud computing, automation frameworks, and programming is necessary.;;;;
Conference Paper;de França BB,Jeronimo H,Travassos GH;Characterizing DevOps by Hearing Multiple Voices;;2016;;;53–62;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 30th Brazilian Symposium on Software Engineering;Maringá, Brazil;2016;9781450342018;;"https://doi-org.proxy.bnl.lu/10.1145/2973839.2973845;http://dx.doi.org/10.1145/2973839.2973845";10.1145/2973839.2973845;Recently, DevOps has emerged as an alternative for software organizations inserted into a dynamic market to handle daily software demands. As claimed, it intends to make the software development and operations teams to work collaboratively. However, it is hard to observe a shared understanding of DevOps, what potentially hinders the discussions in the literature and can confound observations when conducting empirical studies. Therefore, we performed a Multivocal Literature Review aiming at characterizing DevOps in multiple perspectives, including data sources from technical and gray literature. Grounded Theory procedures were used to rigorous analyze the collected data. It allowed us to achieve a grounded definition for DevOps, as well as to identify its recurrent principles, practices, required skills, potential benefits, challenges and what motivates the organizations to adopt it. Finally, we understand the DevOps movement has identified relevant issues in the state-of-the-practice. However, we advocate for the scientific investigations concerning the potential benefits and drawbacks as a consequence of adopting the suggested principles and practices.;Multivocal Literature Review, Grounded Theory, DevOps, Software Development and Operations;;;SBES '16
Conference Paper;Hobeck R,Weber I,Bass L,Yasar H;Teaching DevOps: A Tale of Two Universities;;2021;;;26–31;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2021 ACM SIGPLAN International Symposium on SPLASH-E;Chicago, IL, USA;2021;9781450390897;;"https://doi-org.proxy.bnl.lu/10.1145/3484272.3484962;http://dx.doi.org/10.1145/3484272.3484962";10.1145/3484272.3484962;DevOps is a set of practices in software engineering that is in high demand by industry. It is a dynamic field which constantly adds new methods and tools. Teaching DevOps prepares today’s computer science students for best-practices in a working environment but challenges university lecturers to provide central concepts while staying up-to-date with current trends. In this paper we report and reflect on our experiences teaching DevOps at two universities (in the USA and Germany) in an inverted classroom format. We describe how we set-up the courses, provide a brief analysis of data we collected, and share our lessons learned.;DevOps, inverted classroom, software engineering;;;SPLASH-E 2021
Book Chapter;Pereira I,Carneiro T,Figueiredo E;Main Differences of DevOps on IoT Systems;;2021;;;315–319;;Association for Computing Machinery;New York, NY, USA;Brazilian Symposium on Software Engineering;;;2021;9781450390613;;https://doi-org.proxy.bnl.lu/10.1145/3474624.3474630;;IoT systems have barriers related to the different areas that involve their development. Hence, the scientific literature and industry practices investigate approaches that enable continuous interaction of these areas. Through semi-structured interviews with thirty-one professionals working in industry, this study investigated how DevOps is applied to make the development of IoT projects continuous and meet the demands of the industry. Through group discussions, we categorized the results of this study. As a preliminary contribution to this work, we investigate the contrasts between using DevOps in IoT system projects and using rigid, plan-oriented processes to develop embedded systems.;;;;
Conference Paper;Perez-Palacin D,Ridene Y,Merseguer J;Quality Assessment in DevOps: Automated Analysis of a Tax Fraud Detection System;;2017;;;133–138;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3053600.3053632;http://dx.doi.org/10.1145/3053600.3053632";10.1145/3053600.3053632;The paper presents an industrial application of a DevOps process for a Tax fraud detection system. In particular, we report the influence of the quality assessment during development iterations, with special focus on the fulfillment of performance requirements. We investigated how to guarantee quality requirements in a process iteration while new functionalities are added. The experience has been carried out by practitioners and academics in the context of a project for improving quality of data intensive applications.;model-based quality of service, devops, data intensive applications, tax fraud detection, unified modeling language;;;ICPE '17 Companion
Conference Paper;Lima GL,Ferreira GA,Saotome O,Cunha AM,Dias LA;Hardware Development: Agile and Co-Design;;2015;;;784–787;;IEEE Computer Society;USA;;Proceedings of the 2015 12th International Conference on Information Technology - New Generations;;2015;9781479988280;;"https://doi-org.proxy.bnl.lu/10.1109/ITNG.2015.142;http://dx.doi.org/10.1109/ITNG.2015.142";10.1109/ITNG.2015.142;The development of devices that combine hardware and software has created new challenges. The new built devices have a short life cycle and frequently require upgrading. The software industry attends to these requests with agile methods, such as Scrum. Agile methods apply quick iterations and continuous preplanning based on feedback and past iterations, enabling a quick and continuous delivery for those requests. This scenario is being analyzed when applied to hardware or software development and used along with agile methodologies.;Co-Desing, Hardware Agile, Agile Methods, Scrum, Hardware and Software Agile;;;ITNG '15
Conference Paper;Jones S,Noppen J,Lettice F;Management Challenges for DevOps Adoption within UK SMEs;;2016;;;7–11;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2nd International Workshop on Quality-Aware DevOps;Saarbrücken, Germany;2016;9781450344111;;"https://doi-org.proxy.bnl.lu/10.1145/2945408.2945410;http://dx.doi.org/10.1145/2945408.2945410";10.1145/2945408.2945410;The DevOps phenomenon is gathering pace as more UK organisations seek to leverage the benefits it can potentially bring to software engineering functions. However substantial organisational change is inherent to adopting DevOps, especially where there are prior and established methods. As part of a wider piece of doctoral research investigating the management challenges of DevOps adoption, we present early findings of a six month qualitative diary study following the adoption of DevOps within a UK based SME with over 200 employees. We find that within our case study organisation, the DevOps approach is being adopted for the development of a new system used both internally and by customers. DevOps, conceptually, appears to be generally well regarded, but in reality is proving difficult to fully adopt. This difficulty is down to a combination of necessity in maintaining a legacy system, lack of senior management buy-in, managerial structure and resistance. Additionally, we are finding evidence of job crafting, especially with the software developers. Taken together, we put forward the argument that DevOps is an interdisciplinary topic which would greatly benefit from further management and potentially psychology oriented research attention.;United Kingdom, SME, DevOps, Management Challenges, Case Study;;;QUDOS 2016
Conference Paper;Hobeck R,Weber I,Bass L,Yasar H;Teaching DevOps: A Tale of Two Universities;;2021;;;26–31;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2021 ACM SIGPLAN International Symposium on SPLASH-E;Chicago, IL, USA;2021;9781450390897;;"https://doi-org.proxy.bnl.lu/10.1145/3484272.3484962;http://dx.doi.org/10.1145/3484272.3484962";10.1145/3484272.3484962;DevOps is a set of practices in software engineering that is in high demand by industry. It is a dynamic field which constantly adds new methods and tools. Teaching DevOps prepares today’s computer science students for best-practices in a working environment but challenges university lecturers to provide central concepts while staying up-to-date with current trends. In this paper we report and reflect on our experiences teaching DevOps at two universities (in the USA and Germany) in an inverted classroom format. We describe how we set-up the courses, provide a brief analysis of data we collected, and share our lessons learned.;DevOps, inverted classroom, software engineering;;;SPLASH-E 2021
Conference Paper;Maroukian K,R. Gulliver S;Synthesis of a Leadership Model for DevOps Adoption;;2021;;;58–66;;Association for Computing Machinery;New York, NY, USA;;2021 2nd European Symposium on Software Engineering;Larissa, Greece;2021;9781450385060;;"https://doi-org.proxy.bnl.lu/10.1145/3501774.3501783;http://dx.doi.org/10.1145/3501774.3501783";10.1145/3501774.3501783;"The first decade of DevOps-orientation in software-intensive organizational environments is often characterized with an emerging set of skills that support DevOps practice adoption, targeting a cross-functional collaborative culture; with an aim of achieving a shift in mindset, skillset, and toolset. We investigate DevOps adoption constructs to facilitate development of a formative measurement model to support leadership throughout the DevOps transitional journey. The model and its constructs are designed and validated with a multi-method approach. Initially an exploratory study of a survey is conducted with 250 respondents 76% of whom possess leadership roles, 93% work in Europe and Middle East, and two-thirds are practicing as DevOps practitioners. Pertinent model indicators are produced and grouped under constructs based on survey results and validated using PLS-SEM. The formative structural model is presented and validated in three separate focus group sessions, comprising of respectively seven (7), five (5), and seven (7) participants all of whom had held leadership positions; from countries including USA, UK, The Netherlands, UAE, Greece, Georgia, Switzerland. Seventeen (17) focus group participants provided additional responses through a focus group in-session survey, which allowed feedback on specific model constructs. Results indicate that a set of practices, a set of skills, a set of metrics, DevOps adoption planning and the existence of the DevOps adoption leader roles, should be part of organizational aspirations in the definition of leadership in a DevOps transition path.";PLS-SEM, Focus group, Leadership model, Survey, DevOps;;;ESSE 2021
Conference Paper;Sumbaly R,Kreps J,Gao L,Feinberg A,Soman C,Shah S;Serving Large-Scale Batch Computed Data with Project Voldemort;;2012;;;18;;USENIX Association;USA;;Proceedings of the 10th USENIX Conference on File and Storage Technologies;San Jose, CA;2012;;;;;Current serving systems lack the ability to bulk load massive immutable data sets without affecting serving performance. The performance degradation is largely due to index creation and modification as CPU and memory resources are shared with request serving. We have extended Project Voldemort, a general-purpose distributed storage and serving system inspired by Amazon's Dynamo, to support bulk loading terabytes of read-only data. This extension constructs the index offline, by leveraging the fault tolerance and parallelism of Hadoop. Compared to MySQL, our compact storage format and data deployment pipeline scales to twice the request throughput while maintaining sub 5 ms median latency. At LinkedIn, the largest professional social network, this system has been running in production for more than 2 years and serves many of the data-intensive social features on the site.;;;;FAST'12
Conference Paper;Yasar H;Implementing Secure DevOps Assessment for Highly Regulated Environments;;2017;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 12th International Conference on Availability, Reliability and Security;Reggio Calabria, Italy;2017;9781450352574;;"https://doi-org.proxy.bnl.lu/10.1145/3098954.3105819;http://dx.doi.org/10.1145/3098954.3105819";10.1145/3098954.3105819;Secure DevOps has become a standard option for entities seeking to streamline and increase comprehensive participation by all stakeholders in their secure Security Development Lifecycle (SDLC)[1]. In most case in industry, academia, and government, applying DevOps is a straight forward process. There is a subset of entities in these three sectors where applying Secure DevOps is challenging. These are entities that are highly regulated (HRE) as mandated by policies for various reasons, the most often being general security and protection of intellectual property. Even if an entity is highly regulated, its secure SDLC can still benefit from implementing DevOps as long as the implementation does not break any policy[2].;DevOps, AppSec, Security Engineering, Highly Regulated Environment, Secure DevOps assessment, DevSecOps, Secure DevOps;;;ARES '17
Conference Paper;Dyck A,Penners R,Lichter H;Towards Definitions for Release Engineering and DevOps;;2015;;;3;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 3rd International Workshop on Release Engineering;;2015;9781467370707;;"https://doi-org.proxy.bnl.lu/10.1109/RELENG.2015.10;http://dx.doi.org/10.1109/RELENG.2015.10";10.1109/RELENG.2015.10;Delivering software fast, reliable, and predictable is essential for software development organizations. Yet, they often struggle to implement proper approaches and practices like release engineering and DevOps. One reason is the lack of consistent definitions for both of these terms, making it difficult to grasp the meaning and adding further confusion. To the best of our knowledge, there are no uniform definitions for both terms, and thus, many inadequate or even wrong interpretations exist. Consequently, these terms are often confused, misinterpreted, or used as synonyms. In this paper, we propose definitions for release engineering and DevOps to tell both apart.;definition, devops, release engineering;;;RELENG '15
Conference Paper;Dyck A,Penners R,Lichter H;Towards Definitions for Release Engineering and DevOps;;2015;;;3;;IEEE Press;Florence, Italy;;Proceedings of the Third International Workshop on Release Engineering;;2015;;;;;Delivering software fast, reliable, and predictable is essential for software development organizations. Yet, they often struggle to implement proper approaches and practices like release engineering and DevOps. One reason is the lack of consistent definitions for both of these terms, making it difficult to grasp the meaning and adding further confusion.To the best of our knowledge, there are no uniform definitions for both terms, and thus, many inadequate or even wrong interpretations exist. Consequently, these terms are often confused, misinterpreted, or used as synonyms. In this paper, we propose definitions for release engineering and DevOps to tell both apart.;;;;RELENG '15
Conference Paper;Di Nitto E,Jamshidi P,Guerriero M,Spais I,Tamburri DA;A Software Architecture Framework for Quality-Aware DevOps;;2016;;;12–17;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2nd International Workshop on Quality-Aware DevOps;Saarbrücken, Germany;2016;9781450344111;;"https://doi-org.proxy.bnl.lu/10.1145/2945408.2945411;http://dx.doi.org/10.1145/2945408.2945411";10.1145/2945408.2945411;DevOps is an emerging software engineering strategy entailing the joined efforts of development and operations people, their concerns and best practices with the purpose of realising a coherent working group for increased software development and operations speed. To allow software architecture practitioners to enrich and properly elaborate their architecture specifications in a manner which is consistent with DevOps, we surveyed a number of DevOps stakeholders. We studied concerns and challenges to be tackled with respect to preparing a software architecture which is DevOps-ready, i.e., described in all details needed to enact DevOps scenarios. Subsequently, we introduce SQUID, that stands for Specification Quality In DevOps. SQUID is a software architecture framework that supports the model-based documentation of software architectures and their quality properties in DevOps scenarios with the goal of providing DevOps-ready software architecture descriptions. We illustrate our framework in a case-study in the Big Data domain.;QoD, Model-Driven Design, QoS, Architecture Frameworks;;;QUDOS 2016
Journal Article;Erich FM,Amrit C,Daneva M;A Qualitative Study of DevOps Usage in Practice;J. Softw. Evol. Process;2017;29;6;;;John Wiley & Sons, Inc.;USA;;;;2017-06;;2047-7473;"https://doi-org.proxy.bnl.lu/10.1002/smr.1885;http://dx.doi.org/10.1002/smr.1885";10.1002/smr.1885;Organizations are introducing agile and lean software development techniques in operations to increase the pace of their software development process and to improve the quality of their software. They use the term DevOps, a portmanteau of development and operations, as an umbrella term to describe their efforts. In this paper, we describe the ways in which organizations implement DevOps and the outcomes they experience. We first summarize the results of a systematic literature review that we performed to discover what researchers have written about DevOps. We then describe the results of an exploratory interview-based study involving 6 organizations of various sizes that are active in various industries. As part of our findings, we observed that all organizations were positive about their experiences and only minor problems were encountered while adopting DevOps.;qualitative interviews, DevOps, empirical study, systematic literature review, agile software development, software development life cycle;;;
Conference Paper;Chen B;Improving the Software Logging Practices in DevOps;;2019;;;194–197;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-Companion.2019.00080;http://dx.doi.org/10.1109/ICSE-Companion.2019.00080";10.1109/ICSE-Companion.2019.00080;DevOps refers to a set of practices dedicated to accelerating modern software engineering process. It breaks the barriers between software development and IT operations and aims to produce and maintain high quality software systems. Software logging is widely used in DevOps. However, there are few guidelines and tool support for composing high quality logging code and current application context of log analysis is very limited with respect to feedback for developers and correlations among other telemetry data. This thesis proposes automated approaches to improving software logging practices in DevOps by leveraging various types of software repositories (e.g., historical, communication, bug, and runtime repositories). We aim to support the software development side by providing guidelines and tools on developing and maintaining high quality logging code. We aim to support the IT operation side by enriching the log analysis context through systematic estimating code coverage via executing logs and in-depth problem diagnosis by correlating logs with other telemetry data (e.g., traces and APM data). Case studies show that our approaches can provide useful software logging suggestions to both developers and operators in open source and commercial systems.;;;;ICSE '19
Journal Article;Bennett BT,Barrett ML;Incorporating Devops into Undergraduate Software Engineering Courses: A Suggested Framework;J. Comput. Sci. Coll.;2018;34;2;180–187;;Consortium for Computing Sciences in Colleges;Evansville, IN, USA;;;;2018-12;;1937-4771;;;DevOps is a current trend for application development and delivery in the industry. Teaching about DevOps in an undergraduate software engineering course is difficult because the number of new concepts involved is high, and most students lack experience with them. This paper presents our initial experience integrating DevOps into undergraduate software engineering coursework. It discusses DevOps itself and introduces a basic framework for introducing DevOps into a software engineering sequence. Finally, we discuss how we currently approach DevOps instruction and where we need to go to fit within the suggested framework.;;;;
Book;Lenz M;Python Continuous Integration and Delivery: A Concise Guide with Examples;;2018;;;;1st;Apress;USA;;;;2018;9781484242803;;;;Gain the techniques and tools that enable a smooth and efficient software development process in this quick and practical guide on Python continuous integration (CI) and continuous delivery (CD). Based on example applications, this book introduces various kinds of testing and shows you how to set up automated systems that run these tests, and install applications in different environments in controlled ways. Python Continuous Integration and Delivery tackles the technical problems related to software development that are typically glossed over in pure programming texts. After reading this book, youll see that in today's fast-moving world, no software project can afford to go through development, then an integration phase of unpredictable length and complexity, and finally be shipped to the customer -- just to find out that the resulting application didn't quite fill their need. Instead, youll discover that practicing continuous integration and continuous delivery reduces the risks by keeping changes small and automating other wise painful processes. What You Will Learn Carry out various kinds of testing, including unit testing and continuous integration testing, of your Python code using Jenkins Build packages and manage repositories Incorporate Ansible and Go for automated packaging and other deployments Manage more complex and robust deployments Who This Book Is ForPython programmers and operating staff that work with Python applications.;;;;
Conference Paper;Murphy GC,Kersten M;Towards Bridging the Value Gap in DevOps;;2019;;;181–190;;Springer-Verlag;Berlin, Heidelberg;;Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Château de Villebrumier, France, May 6–8, 2019, Revised Selected Papers;Villebrumier, France;2019;9783030393052;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-39306-9_13;http://dx.doi.org/10.1007/978-3-030-39306-9_13";10.1007/978-3-030-39306-9_13;The DevOps movement, which combines software development with information technology operations, enables the more frequent delivery of changes to a software system. Adopting DevOps practices is seen as enabling the ability to deliver more. But is the more that is getting done actually of value to the end user or to the producing organization? In this paper, we describe how the ideas of value streams are being applied to software development and how more systematic handling of features is key to enabling an increased focus on the delivery of value.;Software development productivity, Software requirements, Value stream maps;;;
Journal Article;Yasar H,Kontostathis K;Where to Integrate Security Practices on DevOps Platform;Int. J. Secur. Softw. Eng.;2016;7;4;39–50;;IGI Global;USA;;;;2016-10;;1947-3036;"https://doi-org.proxy.bnl.lu/10.4018/IJSSE.2016100103;http://dx.doi.org/10.4018/IJSSE.2016100103";10.4018/IJSSE.2016100103;"""Software security"" often evokes negative feelings amongst software developers because this term is associated with additional programming effort, uncertainty and road blocker activity on rapid development and release cycles. The Secure DevOps movement attempts to combat the toxic environment surrounding software security by shifting the paradigm from following rules and guidelines to creatively determining solutions for tough security problems Taschner, 2015. Secure software should be focused on a proactive approach that limits the attack surface and produces reliable software. Secure DevOps developers want their software to bend but not break, which means the software absorbs attacks and continues to function. The burgeoning concepts of DevOps include a number of concepts that can be applied to increase the security of developed applications. Applying these and other DevOps principles can have a big impact on creating an environment that is resilient and secure. Specifically, this paper clearly explains how to address security concerns in the early stages of the development lifecycle and leverage that knowledge throughout the SDLC.";Software Security, Secure Software Development Life Cycle, Software Development Life Cycle, Secure DevOps;;;
Conference Paper;Morales JA,Yasar H,Volkman A;Implementing DevOps Practices in Highly Regulated Environments;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th International Conference on Agile Software Development: Companion;Porto, Portugal;2018;9781450364225;;"https://doi-org.proxy.bnl.lu/10.1145/3234152.3234188;http://dx.doi.org/10.1145/3234152.3234188";10.1145/3234152.3234188;In this paper, we discuss implementing DevOps practices in highly regulated environments (HREs). DevOps has become a standard option for entities seeking to streamline and increase participation by all stakeholders in their Software Development Lifecycle (SDLC). For a large portion of industry, academia, and government, applying DevOps is a straight forward process. There is, however, a subset of entities in these three sectors where applying DevOps can be very challenging. These are entities mandated by policies to conduct all or a portion of their SDLC activities in HREs. Often, the reason for an HRE is general security and protection of intellectual property. Even if an entity is functioning in a highly regulated environment, its SDLC can still benefit from implementing DevOps as long as the implementation conforms to all imposed policies. In this paper, we discuss the process of performing a DevOps assessment and implementation in an HRE which we refer to as HRE-DevOps.;highly regulated environment, DevOps, DevOps assessment, SDLC, secure DevOps;;;XP '18
Conference Paper;Capizzi A,Distefano S,Araújo LJ,Mazzara M,Ahmad M,Bobrov E;Anomaly Detection in DevOps Toolchain;;2019;;;37–51;;Springer-Verlag;Berlin, Heidelberg;;Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Château de Villebrumier, France, May 6–8, 2019, Revised Selected Papers;Villebrumier, France;2019;9783030393052;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-39306-9_3;http://dx.doi.org/10.1007/978-3-030-39306-9_3";10.1007/978-3-030-39306-9_3;The tools employed in the DevOps Toolchain generates a large quantity of data that is typically ignored or inspected only on particular occasions, at most. However, the analysis of such data could enable the extraction of useful information about the status and evolution of the project. For example, metrics like the “lines of code added since the last release” or “failures detected in the staging environment” are good indicators for predicting potential risks in the incoming release. In order to prevent problems appearing in later stages of production, an anomaly detection system can operate in the staging environment to compare the current incoming release with previous ones according to predefined metrics. The analysis is conducted before going into production to identify anomalies which should be addressed by human operators that address false-positive and negatives that can appear. In this paper, we describe a prototypical implementation of the aforementioned idea in the form of a “proof of concept”. The current study effectively demonstrates the feasibility of the approach for a set of implemented functionalities.;;;;
Journal Article;Schlossnagle T;Monitoring in a DevOps World: Perfect Should Never Be the Enemy of Better;Queue;2017;15;6;35–45;;Association for Computing Machinery;New York, NY, USA;;;;2017-12;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/3178368.3178371;http://dx.doi.org/10.1145/3178368.3178371";10.1145/3178368.3178371;"Monitoring can seem quite overwhelming. The most important thing to remember is that perfect should never be the enemy of better. DevOps enables highly iterative improvement within organizations. If you have no monitoring, get something; get anything. Something is better than nothing, and if you’ve embraced DevOps, you’ve already signed up for making it better over time.";;;;
Conference Paper;Anisetti M,Ardagna CA,Gaudenzi F,Damiani E;A Continuous Certification Methodology for DevOps;;2019;;;205–212;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 11th International Conference on Management of Digital EcoSystems;Limassol, Cyprus;2019;9781450362382;;"https://doi-org.proxy.bnl.lu/10.1145/3297662.3365827;http://dx.doi.org/10.1145/3297662.3365827";10.1145/3297662.3365827;The cloud paradigm has revolutionized the way in which software systems are designed, managed, and maintained. With the advent of the microservice architecture, this trend was brought to the extreme, pushing the whole software development process towards unification of software development (Dev) and software operation (Ops). This rapid evolution has not immediately found counterparts in assurance techniques, where the evaluation of the non-functional behavior of a software system and of the software development process are completely decoupled. In this paper, we put forward the idea that next-generation assurance techniques, and more specifically certification techniques, must evaluate a software system throughout the whole development process. To this aim, we define a continuous certification scheme for DevOps that evaluates the software artifacts produced at each stage of the development process. We then present the assurance framework managing our certification scheme and experimentally evaluate the continuous certification scheme in a real DevOps scenario.;Assurance, DevOps, Certification;;;MEDES '19
Journal Article;Rafi S,Yu W,Akbar MA,Mahmood S,Alsanad A,Gumaei A;Readiness Model for DevOps Implementation in Software Organizations;J. Softw. Evol. Process;2021;33;4;;;John Wiley & Sons, Inc.;USA;;;;2021-04;;2047-7473;"https://doi-org.proxy.bnl.lu/10.1002/smr.2323;http://dx.doi.org/10.1002/smr.2323";10.1002/smr.2323;DevOps is a new software engineering paradigm adopted by various software organizations to develop the quality software within time and budget. The implementation of DevOps practices is critical, and there are no guidelines to assess and improve the DevOps activities in software organizations. Hence, there is a need to develop a readiness model for DevOps (RMDevOps) with an aim to assist the practitioners for implementation of DevOps practices in software firms. To achieve the study objective, we conducted a systematic literature review (SLR) study to identify the critical challenges and associated best practices of DevOps. A total of 18 challenges and 73 best practices were identified from the 69 primary studies. The identified challenges and best practices were further evaluated by conducting a survey with industry practitioners. The RMDevOps was developed based on other well‐established models in software engineering domain, for example, software process improvement readiness model (SPIRM) and software outsourcing vendor readiness model (SOVRM). Finally, case studies were conducted with three different organizations with an aim to validate the developed model. The results show that the RMDevOps is effective to assess and improve the DevOps practices in software organizations.;case study, readiness model, best practices, guidelines;;;
Book;Saito H,Lee HC,Hsu KJ;Kubernetes Cookbook: Practical Solutions to Container Orchestration, 2nd Edition;;2018;;;;2nd;Packt Publishing;;;;;2018;9781788837606;;;;Learn how to automate and manage your containers and reduce the overall operation burden on your system. Key Features Use containers to manage, scale and orchestrate apps in your organization Transform the latest concept of Kubernetes 1.10 into examples Expert techniques for orchestrating containers effectively Book Description Kubernetes is an open source orchestration platform to manage containers in a cluster environment. With Kubernetes, you can configure and deploy containerized applications easily. This book gives you a quick brush up on how Kubernetes works with containers, and an overview of main Kubernetes concepts, such as Pods, Deployments, Services and etc. This book explains how to create Kubernetes clusters and run applications with proper authentication and authorization configurations. With real-world recipes, you'll learn how to create high availability Kubernetes clusters on AWS, GCP and in on-premise datacenters with proper logging and monitoring setup. You'll also learn some useful tips about how to build a continuous delivery pipeline for your application. Upon completion of this book, you will be able to use Kubernetes in production and will have a better understanding of how to manage containers using Kubernetes. What you will learn Build your own container cluster Deploy and manage highly scalable, containerized applications with Kubernetes Build high-availability Kubernetes clusters Build a continuous delivery pipeline for your application Track metrics and logs for every container running in your cluster Streamline the way you deploy and manage your applications with large-scale container orchestration Who This Book Is For This book is for system administrators, developers, DevOps engineers, or any stakeholder who wants to understand how Kubernetes works using a recipe-based approach. Basic knowledge of Kubernetes and Containers is required.;;;;
Conference Paper;Olagunju AO;Revamping the IT Curriculum with Agile and DevOps Methodology;;2018;;;86;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th Annual SIG Conference on Information Technology Education;Fort Lauderdale, Florida, USA;2018;9781450359542;;"https://doi-org.proxy.bnl.lu/10.1145/3241815.3241818;http://dx.doi.org/10.1145/3241815.3241818";10.1145/3241815.3241818;Information technology students need to learn the concepts and tools for Agile and DevOps methodology. What are the principles of Agile and DevOps? How is Agile different from DevOps? What set of Agile and DevOps skills should student learn and how? What kinds of case-based projects should be designed to promote learning of Agile and DevOps skills? This enlightening talk discusses these and other questions. The presentation provides scripts for automating the setup of DevOps tools.;devops, it curriculum, agile;;;SIGITE '18
Conference Paper;Lie MF,Sánchez-Gordón M,Colomo-Palacios R;DevOps in an ISO 13485 Regulated Environment: A Multivocal Literature Review;;2020;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Bari, Italy;2020;9781450375801;;"https://doi-org.proxy.bnl.lu/10.1145/3382494.3410679;http://dx.doi.org/10.1145/3382494.3410679";10.1145/3382494.3410679;"Background: Medical device development projects must follow proper directives and regulations to be able to market and sell the end-product in their respective territories. The regulations describe requirements that seem to be opposite to efficient software development and short time-to-market. As agile approaches, like DevOps, are becoming more and more popular in software industry, a discrepancy between these modern methods and traditional regulated development has been reported. Although examples of successful adoption in this context exist, the research is sparse. Aims: The objective of this study is twofold: to review the current state of DevOps adoption in regulated medical device environment; and to propose a checklist based on that review for introducing DevOps in that context. Method: A multivocal literature review is performed and evidence is synthesized from sources published between 2015 to March of 2020 to capture the opinions of experts and community in this field. Results: Our findings reveal that adoption of DevOps in a regulated medical device environment such as ISO 13485 has its challenges, but potential benefits may outweigh those in areas such as regulatory, compliance, security, organizational and technical. Conclusion: DevOps for regulated medical device environments is a highly appealing approach as compared to traditional methods and could be particularly suited for regulated medical development. However, an organization must properly anchor a transition to DevOps in top-level management and be supportive in the initial phase utilizing professional coaching and space for iterative learning; as such an initiative is a complex organizational and technical task.";Medical device software development, Multivocal Literature Review, DevOps, ISO 13485;;;ESEM '20
Book;Rossberg J;Agile Project Management with Azure DevOps: Concepts, Templates, and Metrics;;2019;;;;1st;APress;;;;;2019;9781484244821;;;;Roll up your sleeves and jump into Agile project management to use and customize Microsoft Azure DevOps. Organizations adopt Agile practices because they are a key enabler to run better projects, get more successful end results, and achieve an overall higher quality output. To benefit the most from Agile, you need an Application Life Cycle Management (ALM) or DevOps toolset that supports your style and work environment. Agile Project Management with Azure DevOps teaches you how to use Azure DevOps to implement many Agile practices such as SAFe, Scrum, and Kanban, and it shows you how they fit into a well-planned Agile implementation. Agile product owners will learn how to work with Azure DevOps to set up a project from scratch, and to continue using Azure DevOps throughout. Keeping track of progress is important in any project. Author Joachim Rossberg teaches you about the tools in Azure DevOps that can help you track progress and key metrics, including those that are available right out of the box. You will learn how to create and refine the backlog, work with Kanban and Scrum task boards, and get exposed to valuable key concepts along the way. Finally, you will dive into Azure DevOps extensibility to learn about the many ways you can customize reporting to best meet your needs What You'll Learn Understand Agile product management concepts and processes for working with Azure DevOps Discover how Azure DevOps supports agile processes end-to-end Implement Agile processes in Azure DevOps Customize Azure DevOps to better support your processes Complete step-by-step setup of an Agile project from scratch and manage it through its life cycle Who This Book Is For Software product owners, Agile leaders, Scrum masters, and software engineers who use Microsoft Azure DevOps. A basic understanding of Agile is helpful.;;;;
Journal Article;Trubiani C,Jamshidi P,Cito J,Shang W,Jiang ZM,Borg M;Performance Issues? Hey DevOps, Mind the Uncertainty;IEEE Softw.;2019;36;2;110–117;;IEEE Computer Society Press;Washington, DC, USA;;;;2019-03;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2018.2875989;http://dx.doi.org/10.1109/MS.2018.2875989";10.1109/MS.2018.2875989;DevOps is a novel trend that aims to bridge the gap between software development and operation teams. This article presents an experience report that better identifies performance uncertainties through a case study and provides a step-by-step guide to practitioners for controlling system uncertainties.;;;;
Book;Vemula R;Real-Time Web Application Development: With ASP.NET Core, SignalR, Docker, and Azure;;2017;;;;1st;Apress;USA;;;;2017;9781484232699;;;;"Design, develop, and deploy a real-world web application by leveraging modern open source technologies. This book shows you how to use ASP.NET Core to build cross-platform web applications along with SignalR to enrich the application by enabling real-time communication between server and clients. You will use Docker to containerize your application, integrate with GitHub to package the application, and provide continuous deployment to Azures IaaS platform. Along the way, Real-Time Web Application Development covers topics including designing a Materialize CSS theme, using a test-driven development approach with xUnit.net, and securing your application with the OAuth 2.0 protocol. To further your understanding of the technology, you will learn logging and exception handling; navigation using view components; and how to work with forms and validations. The rich code samples from this book can be used to retrofit or upgrade existing ASP.NET Core applications. What You Will Learn Design and develop a real-world web application Implement security and data storage with OAuth2 and Azure Table Storage Orchestrate real-time notifications through SignalR Use GitHub and Travis CI for continuous integration of code Master Docker containerization and continuous deployment with Docker Cloud to Azure Linux virtual machines Who This Book Is ForDevelopers and software engineers interested in learning an end-to-end approach to application development using Microsoft technologies.";;;;
Conference Paper;Rafi S,Yu W,Akbar MA;Towards a Hypothetical Framework to Secure DevOps Adoption: Grounded Theory Approach;;2020;;;457–462;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Evaluation and Assessment in Software Engineering;Trondheim, Norway;2020;9781450377317;;"https://doi-org.proxy.bnl.lu/10.1145/3383219.3383285;http://dx.doi.org/10.1145/3383219.3383285";10.1145/3383219.3383285;Security in DevOps is a challenging feature because traditional existing methods of security are not fulfilling the exact requirements of DevOps. To make DevOps activities successful for organizations this study will help to identify concerns about DevOps security in real world by interviewing the practitioners having DevOps working experience. The Classical grounded theory approach has been used to build our theory. We interviewed 13 practitioners working across five companies from different regions. We contributed to identify security concerns in DevOps and try to present a theoretical model to improve understanding and guidance of DevOps adoption. The security concerns were marked as functional and nonfunctional based upon the interviews concepts to help practitioners having understanding about particular concerns. Therefore, this theory will highlight security concerns that are hindering the adoption of DevOps successfully.;hypothetical framework, Classical grounded theory, Security concerns;;;EASE '20
Conference Paper;Rong G,Zhang H,Shao D;CMMI Guided Process Improvement for DevOps Projects: An Exploratory Case Study;;2016;;;76–85;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the International Conference on Software and Systems Process;Austin, Texas;2016;9781450341882;;"https://doi-org.proxy.bnl.lu/10.1145/2904354.2904372;http://dx.doi.org/10.1145/2904354.2904372";10.1145/2904354.2904372;Very recently, an increasing number of software companies adopted DevOps to adapt themselves to the ever-changing business environment. While it is important to mature adoption of the DevOps for these companies, no dedicated maturity models for DevOps exist. Meanwhile, maturity models such as CMMI models have demonstrated their effects in the traditional paradigm of software industry, however, it is not clear whether the CMMI models could guide the improvements with the context of DevOps. This paper reports a case study aiming at evaluating the feasibility to apply the CMMI models to guide process improvement for DevOps projects and identifying possible gaps. Using a structured method(i.e., SCAMPI C), we conducted a case study by interviewing four employees from one DevOps project. Based on evidence we collected in the case study, we managed to characterize the maturity/capability of the DevOps project, which implies the possibility to use the CMMI models to appraise the current processes in this DevOps project and guide future improvements. Meanwhile, several gaps also are identified between the CMMI models and the DevOps mode. In this sense, the CMMI models could be taken as a good foundation to design suitable maturity models so as to guide process improvement for projects adopting the DevOps.;DevOps, software process improvement, CMMI;;;ICSSP '16
Conference Paper;Gonnin T,Dechavanne F,Rocher G,Lavirotte S,Tigli JY,Capocchi L,Santucci JF;Actuation Conflict Management Enabler for DevOps in IoT;;2020;;;;;Association for Computing Machinery;New York, NY, USA;;10th International Conference on the Internet of Things Companion;Malmö, Sweden;2020;9781450388207;;"https://doi-org.proxy.bnl.lu/10.1145/3423423.3423474;http://dx.doi.org/10.1145/3423423.3423474";10.1145/3423423.3423474;DevOps methodology is well known in the field of classical software development to improve the software quality and the frequency of the deliveries. However, DevOps has not yet been popularized in the field of IoT. The reasons of that are new challenges that require new enablers in the DevOps tools ecosystem. The European ENACT project supported under the H2020 programme aims to respond to these challenges by providing new enablers to apply DevOps methodology for IoT application[2]. We present, here, one of these enablers called Action Conflict Management Enabler (ACM enabler) which aims at anticipating and resolving at Devs Time all conflicts[1] and dysfunctions that might result from mismanagement of the IoT system actuators.;Actuation Conflict, Internet of things, DevOps;;;IoT '20 Companion
Conference Paper;Selgert F;Cynefin Framework, DevOps and Secure IoT: Understanding the Nature of IoT Systems and Exploring Where in the DevOps Cycle Easy Gains Can Be Made to Increase Their Security;;2020;;;255–265;;Springer-Verlag;Berlin, Heidelberg;;Computer Safety, Reliability, and Security. SAFECOMP 2020 Workshops: DECSoS 2020, DepDevOps 2020, USDAI 2020, and WAISE 2020, Lisbon, Portugal, September 15, 2020, Proceedings;Lisbon, Portugal;2020;9783030555825;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-55583-2_19;http://dx.doi.org/10.1007/978-3-030-55583-2_19";10.1007/978-3-030-55583-2_19;In the relatively new domain of the Internet of Things (IoT), startups and small companies thrive in and stride in bringing new products to the market. Many of them experience problems and fail to profit from their IoT innovation. A lot of those problems are security related. In IoT development, security issues are often overlooked or underestimated.This article explores, from a holistic viewpoint, how security in IoT systems can be prevented or mitigated with a minimal effort. Concepts examined are: The Cynefin framework, Business DevOps, and the role of constraints and requirements in the design phase.;Security, SCRATCh, DevOps, IoT, Cynefin;;;
Journal Article;Oliveira F,Eilam T,Nagpurkar P,Isci C,Kalantar M,Segmuller W,Snible E;Delivering Software with Agility and Quality in a Cloud Environment;IBM J. Res. Dev.;2016;60;2–3;10:1–10:11;;IBM Corp.;USA;;;;2016-03;;0018-8646;"https://doi-org.proxy.bnl.lu/10.1147/JRD.2016.2517498;http://dx.doi.org/10.1147/JRD.2016.2517498";10.1147/JRD.2016.2517498;"Cloud computing and the DevOps movement are two pillars that facilitate software delivery with extreme agility. ""Born on the cloud"" companies, such as Netflix®, have demonstrated rapid growth to their business and continuous improvement to the service they provide, by reportedly applying DevOps principles. In this paper, we claim that to fulfill the vision of fast software delivery, without compromising the quality of the provided services, we need a new approach to detecting problems, including problems that may have occurred during the continuous deployment cycle. A native DevOps-centric approach to problem resolution puts the focus on a wider range of possible error sources (including code commits), makes use of DevOps metadata to clearly define the source of the problem, and leads to a quick problem resolution. We propose such a continuous quality assurance approach, and we demonstrate it by preliminary experiments in our public Container Cloud environment and in a private OpenStack® cloud environment.";;;;
Conference Paper;Pietrantuono R,Bertolino A,De Angelis G,Miranda B,Russo S;Towards Continuous Software Reliability Testing in DevOps;;2019;;;21–27;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 14th International Workshop on Automation of Software Test;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/AST.2019.00009;http://dx.doi.org/10.1109/AST.2019.00009";10.1109/AST.2019.00009;We introduce the DevOpRET approach for continuous reliability testing in DevOps. It leverages information monitored in operation to guide operational-profile based testing, which is conceived as part of the acceptance testing stage before each next release to production. We overview the envisaged test and monitoring pipeline, describe the approach and present a case-study evaluating how reliability assessment evolves over subsequent releases.;acceptance test, DevOps, software reliability testing, operational profile, quality gate;;;AST '19
Conference Paper;Gray J,Sprinkle J,Tolvanen JP,Rossi M;Workshop Preview of the 15th Workshop on Domain Specific Modeling (DSM 2015);;2015;;;101–102;;Association for Computing Machinery;New York, NY, USA;;Companion Proceedings of the 2015 ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity;Pittsburgh, PA, USA;2015;9781450337229;;"https://doi-org.proxy.bnl.lu/10.1145/2814189.2833204;http://dx.doi.org/10.1145/2814189.2833204";10.1145/2814189.2833204;Domain-specific languages provide a viable and time-tested solution for continuing to raise the level of abstraction, and thus productivity, beyond coding, making systems development faster and easier. When accompanied with suitable automated modeling tools and generators it delivers to the promises of continuous delivery and devops. In domain-specific modeling (DSM) the models are constructed using concepts that represent things in the application domain, not concepts of a given programming language. The modeling language follows the domain abstractions and semantics, allowing developers to perceive themselves as working directly with domain concepts. Together with frameworks and platforms, DSM can automate a large portion of software production. This paper introduces Domain-Specific Modeling and describes the SPLASH 2015 workshop, to be held on 27th of October in Pittsburgh, PA, which is the 15th anniversary of the event.;Domain-Specific Languages, Code Generation, Modeling Languages, Metamodeling;;;SPLASH Companion 2015
Book Chapter;Kontogiannis K,Grigoriou M,Brealey C,Giammaria A;Compliance by Design: Software Analytics and AIOps;;2021;;;294–295;;IBM Corp.;USA;Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering;;;2021;;;;;Large software systems encompass complex interactions among their components and are subjected to frequent maintenance activities applied in order to fix bugs, add new functionality, port to new platforms, or interoperate with other systems. An important aspect to consider, is how such maintenance activities can be achieved in a way that first minimizes the risk of failures, and second how these maintenance activities can be integrated in a continuous deployment (CD) / continuous integration (CI) DevOps process. One major aspect on achieving this objective is to identify and remediate early on, possible vulnerabilities which are manifested as violations of known published controls and policies. The workshop brought together researchers and practitioners to discuss technological advances in the areas of requirements modeling, systems modeling, logging, event processing, and system verification.;;;;
Book;Kaiser AK;Reinventing ITIL in the Age of DevOps: Innovative Techniques to Make Processes Agile and Relevant;;2018;;;;1st;Apress;USA;;;;2018;9781484239759;;;;Delve into the principles of ITIL and DevOps and examine the similarities and differences. This book re-engineers the ITIL framework to work in DevOps projects without changing its meaning and its original objectives, making it fit for purpose for use in DevOps projects. Reinventing ITILin the Age of DevOpsshows you the relevance of ITIL since the emergence of DevOps and puts a unique spin on the ITIL service management framework. Along the way you will see that ITIL is a mature service management framework and years of maturity will be lost if its made invalid. The ideas, recommendations, and solutions provided in Reinventing ITIL in the Age of DevOps can be leveraged in order to readily develop solutions or create proposals for clients. The ideas in this book can be further expanded to deliver seamless services to DevOps projects. What You Will Learn Discover the basics of ITIL and DevOps Compare ITIL and DevOps Understand the structure of a DevOps organization and adapt the ITIL roles to this structure Re-engineer ITIL for DevOps projects Implement major processes such as incident management, configuration management, and change management processes in DevOps projects Automate activities within processes Who This Book Is For Consultants, business analysts, administrators, and project managers who are looking for more information about Dynamics 365.;;;;
Conference Paper;De Sanctis M,Bucchiarone A,Trubiani C;A DevOps Perspective for QoS-Aware Adaptive Applications;;2019;;;95–111;;Springer-Verlag;Berlin, Heidelberg;;Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Château de Villebrumier, France, May 6–8, 2019, Revised Selected Papers;Villebrumier, France;2019;9783030393052;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-39306-9_7;http://dx.doi.org/10.1007/978-3-030-39306-9_7";10.1007/978-3-030-39306-9_7;"This paper presents a vision on how to apply the DevOps paradigm in the context of QoS-aware adaptive applications. The goal is to raise awareness on the lack of quantitative approaches that support software designers in understanding the impact of design alternatives at the development and operational stages. To this end, in this paper we: (i) verify the compliance of a design for adaptation approach with the DevOps life-cycle; (ii) perform the runtime monitoring of dynamic IoT systems, through Quality-of-Service (QoS) evaluation of system parameters, to guide a QoS-based adaptation with the goal of fulfilling QoS-based requirements over time.";;;;
Conference Paper;Van Rossem S,Cai X,Cerratoz I,Danielsson P,Németh F,Pechenot B,Pelle I,Risso F,Sharma S,Sköldström P,John W;NFV Service Dynamicity with a DevOps Approach;;2017;;;865–866;;IEEE Press;Lisbon, Portugal;;2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM);;2017;;;"https://doi-org.proxy.bnl.lu/10.23919/INM.2017.7987386;http://dx.doi.org/10.23919/INM.2017.7987386";10.23919/INM.2017.7987386;Next generation network services will be realized by NFV-based microservices to enable greater dynamics in deployment and operations. Here, we present a demonstrator that realizes this concept using the NFV platform built in the EU FP7 project UNIFY. Using the example of an Elastic Router service, we show automated deployment and configuration of service components as well as corresponding monitoring components facilitating automated scaling of the entire service. We also demonstrate automatic execution of troubleshooting and debugging actions. Operations of the service are inspired by DevOps principles, enabling quick detection of operational conditions and fast corrective actions. This demo conveys essential insights on how the life-cycle of an NFV-based network service may be realized in future NFV platforms.;;;;
Book;Hering M;DevOps For The Modern Enterprise: Winning Practices to Transform Legacy IT Organizations;;2018;;;;1st;IT Revolution Press;;;;;2018;9781942788195;;;;"Many organizations are facing the uphill battle of modernizing their legacy IT infrastructure. Most have evolved over the years by taking lessons from traditional or legacy manufacturing: creating a production process that puts the emphasis on the process instead of the people performing the tasks, allowing the organization to treat people like resources to try to achieve high-quality outcomes. But those practices and ideas are failing modern IT, where collaboration and creativeness are required to achieve high-performing, high-quality success. Mirco Hering, a thought leader in managing IT within legacy organizations, lays out a roadmap to success for IT managers, showing them how to create the right ecosystem, how to empower people to bring their best to work every day, and how to put the right technology in the driver's seat to propel their organization to success. But just having the right methods and tools will not magically transform an organization; the cultural change that is the hardest is also the most impactful. Using principles from Agile, Lean, and DevOps as well as first-hand examples from the enterprise world, Hering addresses the different challenges that legacy organizations face as they transform into modern IT departments.";;;;
Conference Paper;Guerriero M,Ciavotta M,Gibilisco GP,Ardagna D;SPACE4Cloud: A DevOps Environment for Multi-Cloud Applications;;2015;;;29–30;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1st International Workshop on Quality-Aware DevOps;Bergamo, Italy;2015;9781450338172;;"https://doi-org.proxy.bnl.lu/10.1145/2804371.2804378;http://dx.doi.org/10.1145/2804371.2804378";10.1145/2804371.2804378;Cloud computing has been a game changer in the design, development and management of modern applications, which have grown in scope and size becoming distributed and service oriented. New methodologies have emerged to deal with this paradigm shift in software engineering. Consequently, new tools, devoted to ease the convergence between developers and other IT professional, are required. Here, we present SPACE4Cloud, a DevOps integrated environment for model-driven design-time QoS assessment and optimization, and runtime capacity allocation for Cloud applications.;DevOps, Model-Driven, runtime, QoS, Cloud, design-time;;;QUDOS 2015
Journal Article;Forsgren N,Kersten M;DevOps Metrics: Your Biggest Mistake Might Be Collecting the Wrong Data;Queue;2017;15;6;19–34;;Association for Computing Machinery;New York, NY, USA;;;;2017-12;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/3178368.3182626;http://dx.doi.org/10.1145/3178368.3182626";10.1145/3178368.3182626;Delivering value to the business through software requires processes and coordination that often span multiple teams across complex systems, and involves developing and delivering software with both quality and resiliency. As practitioners and professionals, we know that software development and delivery is an increasingly difficult art and practice, and that managing and improving any process or system requires insights into that system. Therefore, measurement is paramount to creating an effective software value stream. Yet accurate measurement is no easy feat.;;;;
Journal Article;Laukkanen E,Paasivaara M,Itkonen J,Lassenius C;Comparison of Release Engineering Practices in a Large Mature Company and a Startup;Empirical Softw. Engg.;2018;23;6;3535–3577;;Kluwer Academic Publishers;USA;;;;2018-12;;1382-3256;"https://doi-org.proxy.bnl.lu/10.1007/s10664-018-9616-7;http://dx.doi.org/10.1007/s10664-018-9616-7";10.1007/s10664-018-9616-7;Modern release engineering practices provide multiple benefits for software companies, but organizations have struggled when trying to adopt the most advanced practices, such as continuous delivery. It is not known in which contexts the most advanced practices are applicable and what can be achieved by adopting them. In this study, we discuss the effect of the organizational context on adopted release engineering practices and what outcomes are achieved with the practices. We study two organizational contexts: the startup and the large mature company context. The effect of the product context is mitigated by studying two case organizations with similar products, a rare research opportunity. We performed 18 interviews with various roles in the case organizations. The number of production environments, the number of customers, the control over the production environment, the available resources, the organization size and the distribution of the organization affected the release engineering practices and the ability to release frequently. Having less internal verification and more customer verification enabled fast feedback and customer experimentation in the startup context, but increased the number of production defects. However, having more internal verification in the large mature company context surprisingly did not prevent production defects. The organizational context had a large effect on how achievable modern release engineering practices, such as continuous delivery, were. In the startup context, the lack of resources was the main factor hindering the improvement of release engineering practices, while in the large mature company context, the number of stakeholders and products were the main factors.;Startup, Continuous integration, Case study, Release engineering, Continuous delivery;;;
Ph.D. Thesis;Heine KM,Amir Etemadi,P Blackford J;Predicting DevOps Effectiveness in Information Technology (IT) Projects;;2022;;;;;The George Washington University;;;;;2022;;;;;In the dozen years since DevOps was introduced, the pace of the IT world has increased along with the demand for higher quality products and services with steadily decreasing turnaround rates. The principles and practices of DevOps alone cannot keep companies competitive in this evolving workplace, and many practitioners have adopted a hybrid, highly customized approach to the methods and practices they employ to achieve their specific project goals. For many, navigating the myriad of best practices, emerging tools and technologies, cultural changes, and personal skillsets necessary to take on DevOps can be daunting. This research introduces multivariate regression models that can predict the effectiveness of DevOps implementation in conjunction with other software development frameworks, methods, and practices. This research aims to provide IT managers with quantifiable data that can help make decisions regarding the implementation of DevOps, the adoption of other methodologies that complement DevOps, and the benefits of frequently used practices for effective project management.;;AAI28865497;Ph.D. Thesis;
Book;Farcic V;The Devops 2.3 Toolkit;;2018;;;;;Packt Publishing;;;;;2018;9781789135503;;;;;;;;
Conference Paper;Rana R,Staron M;First International Workshop on Emerging Trends in DevOps and Infrastructure;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Scientific Workshop Proceedings of XP2016;Edinburgh, Scotland, UK;2016;9781450341349;;"https://doi-org.proxy.bnl.lu/10.1145/2962695.2962706;http://dx.doi.org/10.1145/2962695.2962706";10.1145/2962695.2962706;In this paper, we describe the proceedings of first international Workshop on Emerging Trends in DevOps and Infrastructure held at XP-2016. The workshop was conceived and administered to provide a platform for researchers and industrial practitioners researching or working within DevOps environments to come together and discuss issues around the idea of DevOps.The workshop proceeded with research presentations and discussion on the basics of DevOps such as how to define them to more detailed technical challenges and opportunities of working with DevOps practices within an organizational setting.;Continuous Delivery, Emerging trends, Continuous software development, Continuous Experimentation, Decision Support, Operations, Development, DevOps;;;XP '16 Workshops
Book;Pylayeva D;Introduction to DevOps with Chocolate, LEGO and Scrum Game;;2017;;;;1st;Apress;USA;;;;2017;9781484225646;;;;"Discover a role-based simulation game, designed to introduce DevOps in a very unusual way. Working with LEGO and chocolate, using avatars, personas, and role cards, you will gain an understanding of the Dev and Ops roles as well as their interdependencies. Throughout the game, players go through a range of emotions and learn to expand the boundaries of individual roles, acquire T-shaped skills, and grow the Scrum-team circle to include Operations. The game combines ideas from ""The Phoenix Project"" with the experience gained from real-life challenges, encountered by development and operations teams in many organizations. Security vulnerabilities, environments patching, deployment code freeze, development and operations silos - the game helps simulate an end-to-end product delivery process and visualize the bottlenecks in the value delivery flow. Introduction to DevOps with Chocolate, LEGO and Scrum Gameengages all five senses to maximize learning effectiveness and in three sprints takes players through a gamified DevOps transformation journey. What You Will LearnPlay the Chocolate, LEGO and Scrum role-simulation game Gain knowledge of DevOps and how to apply the game to itSee how this game illustrates the DevOps cycle as a case studyWho This Book Is ForProgrammers or system admins/project managers who are new to DevOps. DevOps trainers and Agile Coaches who are interested in offering a collaborative and engaging learning experience to their teams.";;;;
Conference Paper;Chen HM,Kazman R,Haziyev S;Agile Big Data Analytics Development: An Architecture-Centric Approach;;2016;;;5378–5387;;IEEE Computer Society;USA;;Proceedings of the 2016 49th Hawaii International Conference on System Sciences (HICSS);;2016;9780769556703;;"https://doi-org.proxy.bnl.lu/10.1109/HICSS.2016.665;http://dx.doi.org/10.1109/HICSS.2016.665";10.1109/HICSS.2016.665;Agile development for big data analytics has become the new normal. However, research questions remain: 1) how should a big data system be designed and developed to effectively support advanced analytics__ __ and 2) how should the agile process be adapted for big data analytics development__ __ This article contributes an Architecture-centric Agile Big data Analytics (AABA) development methodology evolved and validated in 10 case studies through Collaborative Practice Research. Our studies showed that architecture agility is the key for successful agile big data analytics development. Employing an architecture-centric approach, the AABA methodology integrates the Big Data system Design (BDD) method and Architecture-centric Agile Analytics with architecture-supported DevOps (AAA) model for effective value discovery and rapid continuous delivery of value. The uses of a design concepts catalog and architectural spikes are advancements to architecture design methods that have proven to be critical to agile big data analytics development.;;;;HICSS '16
Journal Article;Payton R;DevOps Troubleshooting by Kyle Rankin;SIGSOFT Softw. Eng. Notes;2013;38;6;42;;Association for Computing Machinery;New York, NY, USA;;;;2013-11;;0163-5948;"https://doi-org.proxy.bnl.lu/10.1145/2532780.2532793;http://dx.doi.org/10.1145/2532780.2532793";10.1145/2532780.2532793;;;;;
Conference Paper;Wettinger J,Breitenbücher U,Leymann F;Standards-Based DevOps Automation and Integration Using TOSCA;;2014;;;59–68;;IEEE Computer Society;USA;;Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing;;2014;9781479978816;;"https://doi-org.proxy.bnl.lu/10.1109/UCC.2014.14;http://dx.doi.org/10.1109/UCC.2014.14";10.1109/UCC.2014.14;DevOps is an emerging paradigm to tightly integrate developers with operations personnel. This is required to enable fast and frequent releases in the sense of continuously delivering software. Users and customers of today's Web applications and mobile apps running in the Cloud expect fast feedback to problems and feature requests. Thus, it is a critical competitive advantage to be able to respond quickly. Beside cultural and organizational changes that are necessary to implement DevOps in practice, tooling is required to implement end-to-end automation of deployment processes. Automation is the key to efficient collaboration and tight integration between development and operations. The DevOps community is constantly pushing new approaches, tools, and open-source artifacts to implement such automated processes. However, as all these proprietary and heterogeneous DevOps automation approaches differ from each other, it is hard to integrate and combine them to deploy applications in the Cloud. In this paper we present a systematic classification of DevOps artifacts and show how different kinds of artifacts can be transformed toward TOSCA, an emerging standard in this field. This enables the seamless and interoperable orchestration of arbitrary artifacts to model and deploy application topologies. We validate the presented approach by a prototype implementation, show its practical feasibility by a detailed case study, and evaluate its performance.;Cloud Computing, Transformation, TOSCA, Chef, Deployment Automation, Juju, Cloud Standards, DevOps;;;UCC '14
Book Chapter;Benni B,Blay-Fornarino M,Mosser S,Précioso F,Jungbluth G;When DevOps Meets Meta-Learning: A Portfolio to Rule Them All;;2019;;;605–612;;IEEE Press;;Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems;;;2019;9781728151250;;https://doi-org.proxy.bnl.lu/10.1109/MODELS-C.2019.00092;;The Machine Learning (ML) world is in constant evolution, as the amount of different algorithms in this context is evolving quickly. Until now, it is the responsibility of data scientists to create ad-hoc ML pipelines for each situation they encounter, gaining knowledge about the adequacy between their context and the chosen pipeline. Considering that it is not possible at a human scale to analyze the exponential number of potential pipelines, picking the right pipeline that combines the proper preprocessing and algorithms is a hard task that requires knowledge and experience. In front of the complexity of building a right ML pipeline, algorithm portfolios aim to drive algorithm selection, learning from the past in a continuous process. However, building a portfolio requires that (i) data scientists develop and test pipelines and (ii) portfolio maintainers ensure the quality of the portfolio and enrich it. The firsts are the developers, while the seconds are the operators. In this paper, we present a set of criteria to be respected, and propose a pipeline-based meta-model, to support a DevOps approach in the context of Machine Learning Pipelines. The exploitation of this meta-model, both as a graph and as a logical expression, serves to ensure continuity between Dev and Ops. We depict our proposition through the simplified study of two primary use cases, one with developer's point-of-view, the other with ops'.;;;;
Conference Paper;Fokaefs M,Barna C,Veleda R,Litoiu M,Wigglesworth J,Mateescu R;Enabling Devops for Containerized Data-Intensive Applications: An Exploratory Study;;2016;;;138–148;;IBM Corp.;USA;;Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering;Toronto, Ontario, Canada;2016;;;;;In an ever-changing landscape of software technology, new development paradigms, novel infrastructure technologies and emerging application domains reveal exciting opportunities, but also unprecedented challenges for developers, practitioners and software engineers. Amongst this innovation, containers as infrastructure support, data-intensive application as a domain and DevOps as a development paradigm have gained significant popularity recently. In this work, we focus on these concepts and present an exploratory study on how to develop such applications, deploy and deliver them in Docker containers and eventually manage them by enabling autoscaling on the container level. In the paper, we detail our experimental process pointing out the problems we encountered along with the solutions we used. Eventually, we present a set of stable experiments to demonstrate the autoscaling capabilities we achieved.;cloud computing, devops, containers, big data, data analytics, autoscaling, adaptive systems;;;CASCON '16
Conference Paper;Capozucca A,Guelfi N;Analysing the SWECOM Standard for Designing a DevOps Education Programme;;2019;;;133–150;;Springer-Verlag;Berlin, Heidelberg;;Frontiers in Software Engineering Education: First International Workshop, FISEE 2019, Villebrumier, France, November 11–13, 2019, Invited Papers;Villebrumier, France;2019;9783030576622;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-57663-9_10;http://dx.doi.org/10.1007/978-3-030-57663-9_10";10.1007/978-3-030-57663-9_10;Developing academic education programmes for software engineers is a difficult task mainly due to three main factors: (1) ever-changing information and communication technologies produced by the industry and meant for citizens living in digital disruptions age, (2) lack of official or de-facto standards for the software engineering domain, (3) slow pace of the standardisation bodies and of the academia for deploying standard competence frameworks or education programmes. This applies more especially to DevOps which regroups a set of skills being the most demanded today by the job market. This paper is a first attempt to introduce a standard based development process to derive a DevOps education programme for graduate education. It is introduced as a generic process mainly based on the SWECOM standard. This process is applied to generate a proposal for a significant DevOps graduate academic programme definition in a comprehensive and, most importantly, in a skill oriented manner.;;;;
Journal Article;Ali N,Daneth H,Hong J;A Hybrid DevOps Process Supporting Software Reuse: A Pilot Project;J. Softw. Evol. Process;2020;32;7;;;John Wiley & Sons, Inc.;USA;;;;2020-07;;2047-7473;"https://doi-org.proxy.bnl.lu/10.1002/smr.2248;http://dx.doi.org/10.1002/smr.2248";10.1002/smr.2248;Large software development organizations manage reusable software components through a reusable software repository in order to reduce development time and cost and to improve software quality and productivity. This paper presents a hybrid DevOps process with a systematic reuse‐based software development and management process to reduce the effort and cost required for the rework and to increase productivity. The proposed approach promotes the systematic reuse of software components based on both information retrieval and ontology‐based retrieval techniques. The reusable assets are presented in different styles to ease and support the reuse process with fine‐grained reusable artifacts. To evaluate our proposed process, a pilot project, aiming to monitor the health of a patient, was developed and monitored the reuse activities throughout the whole experiment. The results revealed that our proposed process got an average gain of 35.2% in terms of developed function points by reusing 30.63% of reusable artifacts available in the reuse repository.We proposed a hybrid DevOps process with a systematic reuse‐based software development and management process to reduce the effort and cost required for the rework and to increase productivity. DevOps encourage tool support during the software delivery process for quick delivery. Therefore, we have developed a reuse repository to support rapid delivery by reusing artifacts during the development process. A pilot project—a health‐monitoring and management application—was developed to evaluate our proposed hybrid DevOps process. image;software development process, DevOps, reuse repository, software reuse;;;
Book;Baier J;Getting Started with Kubernetes;;2015;;;;;Packt Publishing;;;;;2015;9781784394035;;;;Orchestrate and manage large-scale Docker deployments with Kubernetes to unlock greater control over your infrastructure and extend your containerization strategyAbout This BookLearn the fundamentals of Kubernetes how it works, and how it fits into the growing containerization trendIntegrate Kubernetes into your workflow alongside continuous delivery tools to address today's operational challengesGet to grips with a wide range of tools to help you monitor and secure your deploymentsWho This Book Is ForIf you have some experience with Docker and want to get more from containerization, this book is the perfect place to start. Focused on helping you take control of your deployments in a simple way, you'll soon find out how to transform your operations for greater organizational and technical agility.What You Will LearnDownload, install, and configure the latest version of KubernetesPerform smooth updates and patches with minimal downtimeStreamline the way you deploy and manage your applications with large-scale container orchestrationFind out how Kubernetes can simplify the way you configure your clusters and networksLearn why the Open Container initiative is so important for the way you manage your infrastructureDiscover third-party tools that can enhance your production operationsExplore and use the most persistent storage options for your clusterterIntegrate Kubernetes with continuous delivery tools such as Gulp and JenkinsIn DetailKubernetes is the tool that's pushing the containerization revolution largely driven by Docker to another level. If Docker has paved the way for greater agility and control in the way we organize and manage our infrastructure, Kubernetes goes further, by helping you to orchestrate and automate container deployments on a massive scale. Kubernetes really does think big and it's time you did too!This book will show you how to start doing exactly that, showing you how to extend the opportunities that containerization innovations have brought about in new and even more effective ways. Get started with the basics - explore the fundamental elements of Kubernetes and find out how to install it on your system, before digging a little deeper into Kubernetes core constructs. Find out how to use Kubernetes pods, services, replication controllers, and labels to manage your clusters effectively and learn how to handle networking with Kubernetes.Once you've got to grips with these core components, you'll begin to see how Kubernetes fits into your workflow. From basic updates to integrating Kubernetes with continuous delivery tools such as Jenkins and Gulp, the book demonstrates exactly how Kubernetes will transform the way you work. With further insights on how to install monitoring and security tools, this book provides you with a direct route through Kubernetes so you can take advantage of it, fast!Style and approachThis straightforward guide will help you understand how to move your container applications into production through best practices and step by step walkthroughs tied to real-world operational strategies.;;;;
Journal Article;Bennett BT;Shifting Traditional Undergraduate Software Engineering Instruction to a DevOps Focus;J. Comput. Sci. Coll.;2021;36;5;129–138;;Consortium for Computing Sciences in Colleges;Evansville, IN, USA;;;;2021-01;;1937-4771;;;Classical Software Engineering education often includes traditional methodologies that do not adequately describe today's industry practice. DevOps is a culture that promotes fast delivery, continuous feedback, and an environment of learning. Its non-linear path requires a shift in software engineering pedagogy. This case study describes the redevelopment of a second-semester course in software engineering to focus on DevOps principles. The study evaluates student performance using formative and summative assessment through a team project tracked throughout the semester and final exam results. Results indicated that students developed DevOps skills during the course, but may have needed more reinforcement of some traditional Software Engineering topics.;;;;
Conference Paper;Perez JF,Wang W,Casale G;Towards a DevOps Approach for Software Quality Engineering;;2015;;;5–10;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2015 Workshop on Challenges in Performance Methods for Software Development;Austin, Texas, USA;2015;9781450333405;;"https://doi-org.proxy.bnl.lu/10.1145/2693561.2693564;http://dx.doi.org/10.1145/2693561.2693564";10.1145/2693561.2693564;DevOps is a novel trend in software engineering that aims at bridging the gap between development and operations, putting in particular the developer in greater control of deployment and application runtime. Here we consider the problem of designing a tool capable of providing feedback to the developer on the performance, reliability, and in general quality characteristics of the application at runtime. This raises a number of questions related to what measurement information should be carried back from runtime to design-time and what degrees of freedom should be provided to the developer in the evaluation of performance data. To answer these questions, we describe the design of a filling-the-gap (FG) tool, a software system capable of automatically analyzing performance data either directly or through statistical inference. A natural application of the FG tool is the continuous training of stochastic performance models, such as layered queueing networks, that can inform developers on how to refactor the software architecture.;design-time application models, quality of service, software performance engineering, monitoring;;;WOSP '15
Journal Article;Fregosi F;Flexing DevOps Talent in a Startup;XRDS;2017;23;4;11;;Association for Computing Machinery;New York, NY, USA;;;;2017-06;;1528-4972;"https://doi-org.proxy.bnl.lu/10.1145/3103612;http://dx.doi.org/10.1145/3103612";10.1145/3103612;The perfect place for a budding engineer.;;;;
Journal Article;Roche J;Adopting DevOps Practices in Quality Assurance;Commun. ACM;2013;56;11;38–43;;Association for Computing Machinery;New York, NY, USA;;;;2013-11;;0001-0782;"https://doi-org.proxy.bnl.lu/10.1145/2524713.2524721;http://dx.doi.org/10.1145/2524713.2524721";10.1145/2524713.2524721;Merging the art and science of software development.;;;;
Journal Article;Chen J,Xu X,Osterweil LJ,Zhu L,Brun Y,Bass L,Xiao J,Li M,Wang Q;Using Simulation to Evaluate Error Detection Strategies;J. Syst. Softw.;2015;110;C;205–221;;Elsevier Science Inc.;USA;;;;2015-12;;0164-1212;"https://doi-org.proxy.bnl.lu/10.1016/j.jss.2015.08.043;http://dx.doi.org/10.1016/j.jss.2015.08.043";10.1016/j.jss.2015.08.043;Created a framework to support modeling of erroneous behavior.Demonstrated the use of this framework in cloud-based system deployment processes.Enhanced process simulation engine to incorporate error-prone behavior model.Used discrete event simulation to support decision about error detection strategy. The processes for deploying systems in cloud environments can be the basis for studying strategies for detecting and correcting errors committed during complex process execution. These cloud-based processes encompass diverse activities, and entail complex interactions between cloud infrastructure, application software, tools, and humans. Many of these processes, such as those for making release decisions during continuous deployment and troubleshooting in system upgrades, are highly error-prone. Unlike the typically well-tested deployed software systems, these deployment processes are usually neither well understood nor well tested. Errors that occur during such processes may require time-consuming troubleshooting, undoing and redoing steps, and problem fixing. Consequently, these processes should ideally be guided by strategies for detecting errors that consider trade-offs between efficiency and reliability. This paper presents a framework for systematically exploring such trade-offs. To evaluate the framework and illustrate our approach, we use two representative cloud deployment processes: a continuous deployment process and a rolling upgrade process. We augment an existing process modeling language to represent these processes and model errors that may occur during process execution. We use a process-aware discrete-event simulator to evaluate strategies and empirically validate simulation results by comparing them to experiences in a production environment. Our evaluation demonstrates that our approach supports the study of how error-handling strategies affect how much time is taken for task-completion and error-fixing.;Process modeling, Deployment process, Simulation;;;
Conference Paper;Henkel J,Bird C,Lahiri SK,Reps T;Learning from, Understanding, and Supporting DevOps Artifacts for Docker;;2020;;;38–49;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering;Seoul, South Korea;2020;9781450371216;;"https://doi-org.proxy.bnl.lu/10.1145/3377811.3380406;http://dx.doi.org/10.1145/3377811.3380406";10.1145/3377811.3380406;With the growing use of DevOps tools and frameworks, there is an increased need for tools and techniques that support more than code. The current state-of-the-art in static developer assistance for tools like Docker is limited to shallow syntactic validation. We identify three core challenges in the realm of learning from, understanding, and supporting developers writing DevOps artifacts: (i) nested languages in DevOps artifacts, (ii) rule mining, and (iii) the lack of semantic rule-based analysis. To address these challenges we introduce a toolset, binnacle, that enabled us to ingest 900,000 GitHub repositories.Focusing on Docker, we extracted approximately 178,000 unique Dockerfiles, and also identified a Gold Set of Dockerfiles written by Docker experts. We addressed challenge (i) by reducing the number of effectively uninterpretable nodes in our ASTs by over 80% via a technique we call phased parsing. To address challenge (ii), we introduced a novel rule-mining technique capable of recovering two-thirds of the rules in a benchmark we curated. Through this automated mining, we were able to recover 16 new rules that were not found during manual rule collection. To address challenge (iii), we manually collected a set of rules for Dockerfiles from commits to the files in the Gold Set. These rules encapsulate best practices, avoid docker build failures, and improve image size and build latency. We created an analyzer that used these rules, and found that, on average, Dockerfiles on GitHub violated the rules five times more frequently than the Dockerfiles in our Gold Set. We also found that industrial Dockerfiles fared no better than those sourced from GitHub.The learned rules and analyzer in binnacle can be used to aid developers in the IDE when creating Dockerfiles, and in a post-hoc fashion to identify issues in, and to improve, existing Dockerfiles.;static checking, DevOps, docker, mining;;;ICSE '20
Conference Paper;Chen HM,Kazman R,Haziyev S,Kropov V,Chtchourov D;Architectural Support for DevOps in a Neo-Metropolis BDaaS Platform;;2015;;;25–30;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE 34th Symposium on Reliable Distributed Systems Workshop (SRDSW);;2015;9781509000920;;"https://doi-org.proxy.bnl.lu/10.1109/SRDSW.2015.14;http://dx.doi.org/10.1109/SRDSW.2015.14";10.1109/SRDSW.2015.14;Big data as a Service (BDaaS) provides a viable strategy for organizations to implement scalable, tailorable big data infrastructure and applications built on this infrastructure. New trends in the BDaaS market are moving toward an open world model -- what we call the Neo-Metropolis model -- for developing BDaaS platforms. The key to the success of such large-scale technology-agnostic platforms, we posit, is an architectural strategy revolving around microservices and DevOps. This article presents the results of an action research with a Neo-Metropolis BDaaS vendor and illustrates how architectural support for DevOps is critical in achieving desired system qualities and enabling platform success. This research contributes to illuminate best practices of DevOps, and to validate and augment a set of DevOps tactics previously developed, while adding and recategorizing new instances of well-established architectural tactics.;;;;SRDSW '15
Conference Paper;Moyón F,Soares R,Pinto-Albuquerque M,Mendez D,Beckers K;Integration of Security Standards in DevOps Pipelines: An Industry Case Study;;2020;;;434–452;;Springer-Verlag;Berlin, Heidelberg;;Product-Focused Software Process Improvement: 21st International Conference, PROFES 2020, Turin, Italy, November 25–27, 2020, Proceedings;Turin, Italy;2020;9783030641474;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-64148-1_27;http://dx.doi.org/10.1007/978-3-030-64148-1_27";10.1007/978-3-030-64148-1_27;In the last decade, companies adopted DevOps as a fast path to deliver software products according to customer expectations, with well aligned teams and in continuous cycles. As a basic practice, DevOps relies on pipelines that simulate factory swim-lanes. The more automation in the pipeline, the shorter a lead time is supposed to be. However, applying DevOps is challenging, particularly for industrial control systems (ICS) that support critical infrastructures and that must obey to rigorous requirements from security regulations and standards. Current research on security compliant DevOps presents open gaps for this particular domain and in general for systematic application of security standards. In this paper, we present a systematic approach to integrate standard-based security activities into DevOps pipelines and highlight their automation potential. Our intention is to share our experiences and help practitioners to overcome the trade-off between adding security activities into the development process and keeping a short lead time. We conducted an evaluation of our approach at a large industrial company considering the IEC 62443-4-1 security standard that regulates ICS. The results strengthen our confidence in the usefulness of our approach and artefacts, and in that they can support practitioners to achieve security compliance while preserving agility including short lead times.;Industrial control systems, Agile software engineering, DevSecOps, Security standards, Secure software engineering, DevOps pipeline;;;
Conference Paper;Shahin M,Babar MA;On the Role of Software Architecture in DevOps Transformation: An Industrial Case Study;;2020;;;175–184;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the International Conference on Software and System Processes;Seoul, Republic of Korea;2020;9781450375122;;"https://doi-org.proxy.bnl.lu/10.1145/3379177.3388891;http://dx.doi.org/10.1145/3379177.3388891";10.1145/3379177.3388891;Development and Operations (DevOps), a particular type of Continuous Software Engineering, has become a popular Software System Engineering paradigm. Software architecture is critical in succeeding with DevOps. However, there is little evidence-based knowledge of how software systems are architected in the industry to enable and support DevOps. Since architectural decisions, along with their rationales and implications, are very important in the architecting process, we performed an industrial case study that has empirically identified and synthesized the key architectural decisions considered essential to DevOps transformation by two software development teams. Our study also reveals that apart from the chosen architecture style, DevOps works best with modular architectures. In addition, we found that the performance of the studied teams can improve in DevOps if operations specialists are added to the teams to perform the operations tasks that require advanced expertise. Finally, investment in testing is inevitable for the teams if they want to release software changes faster.;Software Architecture, Case Study, DevOps, Continuous Delivery;;;ICSSP '20
Book;Gilchrist A;A Concise Guide to SSL/TLS for DevOps: 2nd Edition;;2017;;;;;Independently published;;;;;2017;9781521278628;;;;This book, 'A Concise Guide to SSL/TLS for DevOps' is an introduction to SSL & TLS in application and operational environments and as such is a more technical in depth study than is typically the case in the Executive and Management series. This book aims to cover the theory and practice of SSL in working operational situations. Consequently, although no prior knowledge of authentication and encryption methods is required, a good deal of this text will involve certificate and encryption theory, OpenSSL installation and configuration, SSL vulnerabilities and best practices in SSL certificate management.;;;;
Conference Paper;Maroukian K,Gulliver SR;The Link Between Transformational and Servant Leadership in DevOps-Oriented Organizations;;2020;;;21–29;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2020 European Symposium on Software Engineering;Rome, Italy;2020;9781450377621;;"https://doi-org.proxy.bnl.lu/10.1145/3393822.3432340;http://dx.doi.org/10.1145/3393822.3432340";10.1145/3393822.3432340;DevOps is a set of agile and lean practices and principles in the context of software product development aiming to decrease mean time-to-market and mean time-to-recover-from-failure through a shift in organizational mindset-skillset-toolset. There is literature to suggest that adopting DevOps has been challenging in practice and that a particular leadership style is necessary to lead DevOps adoption. There are studies to suggest that DevOps leadership is mainly related to transformational leadership characteristics. In this research, a mixed methods approach is used. Initially, semi-structured interviews are conducted with 30 EMEA (Europe, Middle-East and Africa) agile and lean practitioners holding more than 10 years of practitioner experience (81%) from the private and public sectors. The contribution also includes an analysis and evaluation of a survey completed by 250 participants of which 93% works in Europe and Middle East and 76% has held previous leadership positions. By looking to recent literature we identified agile, lean and DevOps practices and principles. In addition, we identify benefits and inhibiting factors to DevOps adoption and its leadership. Our results suggest that deep rooted organizational culture and lack of DevOps definition clarity are usually considered impediments to DevOps adoption followed by poor communication and collaboration. Our results also show that certain DevOps adoption leadership characteristics are relevant to transformational leadership and servant leadership. The research results also indicate that the DevOps adoption leadership role is linked to certain metrics.;DevOps adoption, principles, metrics, practices, leadership;;;ESSE 2020
Conference Paper;Toivakka H,Granlund T,Poranen T,Zhang Z;Towards RegOps: A DevOps Pipeline for Medical Device Software;;2021;;;290–306;;Springer-Verlag;Berlin, Heidelberg;;Product-Focused Software Process Improvement: 22nd International Conference, PROFES 2021, Turin, Italy, November 26, 2021, Proceedings;Turin, Italy;2021;9783030914516;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-91452-3_20;http://dx.doi.org/10.1007/978-3-030-91452-3_20";10.1007/978-3-030-91452-3_20;The manufacture of medical devices is a strictly regulated domain in the European Union. Traditionally, medical software compliance activities have been considered manual, document-centric, and burdensome. At the same time, over the last decade, software companies have maintained competitiveness and improved by relying on essential practices of DevOps, such as process automation and delivery pipelines. However, applying the same principles in medical software can be challenging due to regulatory requirements. In this paper, we utilize a systematic approach to align the essential medical device software regulatory requirements from the standards IEC 62304 and IEC 82304-1 and integrate them into the software delivery pipeline, which is the main contribution of our work. The outcome supports practitioners to establish more efficient software delivery models while maintaining compliance with the medical device standards.;Medical device standards, RegOps, Regulatory compliance, Medical device software, DevOps;;;
Conference Paper;Kong G,Duan X,Li J;An Efficient Local Bandwidth Management System for Supporting Video Streaming;;2008;;;214–218;;IEEE Computer Society;USA;;Proceedings of the 2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application - Volume 02;;2008;9780769534909;;"https://doi-org.proxy.bnl.lu/10.1109/PACIIA.2008.264;http://dx.doi.org/10.1109/PACIIA.2008.264";10.1109/PACIIA.2008.264;In order to guarantee continuous delivery of video streaming over Best-Effort (BE) forwarding network, some Quality-of-Service (QoS) strategies such as RSVP and DiffServ must be used to improve the transmission performance. However, these methods are too difficult to be employed in practical applications since their technical complexity. In this paper, we design and implement an efficient local bandwidth management system to tackle this problem in IPv6 environment. The system monitors local access network and provides Assured Forwarding (AF) service through controlling the video streaming requests based on available network bandwidth. To assess the benefit of this system, we perform tests to compare its performance with that of conventional BE service. Our test results indicate convincingly that AF offers substantially better performance than BE.;;;;PACIIA '08
Conference Paper;Jaatun MG;Software Security Activities That Support Incident Management in Secure DevOps;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 13th International Conference on Availability, Reliability and Security;Hamburg, Germany;2018;9781450364485;;"https://doi-org.proxy.bnl.lu/10.1145/3230833.3233275;http://dx.doi.org/10.1145/3230833.3233275";10.1145/3230833.3233275;Many software services are currently created using DevOps, where developers and operations personnel are more tightly integrated. The DevOps paradigm enables shorter development cycles, but increased speed has raised concerns over whether security issues may be overlooked. However, perfect security is never achievable, and in addition to the proactive software security efforts, we also need a reactive effort to handle flaws and bugs that are not discovered before they are used in an attack. In this paper we explore how focus on incident management and collaboration with developers can contribute to improved software security.;Incident Management, Software Security, DevOps;;;ARES 2018
Journal Article;Meng FJ,Wegman MN,Xu JM,Zhang X,Chen P,Chafle G;IT Troubleshooting with Drift Analysis in the DevOps Era;IBM J. Res. Dev.;2017;61;1;6:62–6:73;;IBM Corp.;USA;;;;2017-01;;0018-8646;"https://doi-org.proxy.bnl.lu/10.1147/JRD.2016.2630478;http://dx.doi.org/10.1147/JRD.2016.2630478";10.1147/JRD.2016.2630478;"Over the past few years, DevOps practices have led to many changes in the software industry. The need for agility has resulted in continuous development and deployment of frequent small updates in IT production systems. However, the ever-changing applications and their IT operations environments challenge existing IT troubleshooting approaches, which generally depend on prebuilt domain knowledge and ignore the frequent changes in the DevOps era. Moreover, the complexity and diversity of application architectures exacerbate the challenges. In this paper, we propose an unsupervised learning based drift analysis tool named CHASER to detect and analyze abnormal changes (referred to as ""drifts,"" which include configuration errors, processes hanging, etc.), with learned change models and patterns in real time as well as in the root cause analysis. First, we categorize the changes into two distinct groups (static and dynamic state changes) and periodically collect the finer grained changes. Then, we extract the time-series and structural features from these changes and apply statistical and machine learning algorithms to learn models and patterns from historical data. Furthermore, we apply these models and patterns to detect drifts in real time and infer possible root causes of reported errors based on a multidimensional correlation approach to improve the precision. Through experiments and case studies, we demonstrate the capability of CHASER.";;;;
Journal Article;Díaz J,López-Fernández D,Pérez J,González-Prieto Á;Why Are Many Businesses Instilling a DevOps Culture into Their Organization?;Empirical Softw. Engg.;2021;26;2;;;Kluwer Academic Publishers;USA;;;;2021-03;;1382-3256;"https://doi-org.proxy.bnl.lu/10.1007/s10664-020-09919-3;http://dx.doi.org/10.1007/s10664-020-09919-3";10.1007/s10664-020-09919-3;;DevOps, Exploratory case study, Empirical software engineering;;;
Journal Article;Karl H,Dräxler S,Peuster M,Galis A,Bredel M,Ramos A,Martrat J,Siddiqui MS,vanźRossem S,Tavernier W,Xilouris G;DevOps for Network Function Virtualisation: An Architectural Approach;Trans. Emerg. Telecommun. Technol.;2016;27;9;1206–1215;;John Wiley & Sons, Inc.;USA;;;;2016-09;;2161-3915;"https://doi-org.proxy.bnl.lu/10.1002/ett.3084;http://dx.doi.org/10.1002/ett.3084";10.1002/ett.3084;The Service Programming and Orchestration for Virtualised Software Networks SONATA project targets both the flexible programmability of software networks and the optimisation of their deployments by means of integrating Development and Operations in order to accelerate industry adoption of software networks and reduce time-to-market for networked services. SONATA supports network function chaining and orchestration, making service platforms modular and easier to customise to the needs of different service providers, and introduces a specialised Development and Operations model for supporting developers. © 2016 The Authors. Transactions on Emerging Telecommunications Technologies Published by John Wiley & Sons, Ltd.;;;;
Conference Paper;Lazuardi M,Raharjo T,Hardian B,Simanungkalit T;Perceived Benefits of DevOps Implementation in Organization: A Systematic Literature Review;;2021;;;10–16;;Association for Computing Machinery;New York, NY, USA;;2021 10th International Conference on Software and Information Engineering (ICSIE);Cairo, Egypt;2021;9781450384315;;"https://doi-org.proxy.bnl.lu/10.1145/3512716.3512718;http://dx.doi.org/10.1145/3512716.3512718";10.1145/3512716.3512718;Nowadays, organizations are competing to accelerate the process of transforming business needs or business ideas into software applications. DevOps emerges to enable the development and operation team to work collaboratively and has gained much attention from various organizations to improve their software delivery process. Therefore, this study aims to gain further knowledge from various case studies on the perceived benefits of implementing the DevOps approach in organizations. A systematic literature review was conducted to summarizes the benefits that organizations perceived in implementing DevOps into benefit category mapping. From 446 potential related papers, 10 papers were selected by full-text review. This research found that there are nine benefit categories. The most benefit that organizations have perceived is frequent software deployment improvement, then followed by team productivity improvement and software quality improvement. With this DevOps benefit categories, it is hoped that researchers and practitioners can have an easy-to-understand understanding of the benefits that will be obtained if their organization wants to implement DevOps as their software development method.;DevOps benefits, DevOps, DevOps implementation in organization;;;ICSIE 2021
Conference Paper;Guerriero M,Ciavotta M,Gibilisco GP,Ardagna D;A Model-Driven DevOps Framework for QoS-Aware Cloud Applications;;2015;;;345–351;;IEEE Computer Society;USA;;Proceedings of the 2015 17th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC);;2015;9781509004614;;"https://doi-org.proxy.bnl.lu/10.1109/SYNASC.2015.60;http://dx.doi.org/10.1109/SYNASC.2015.60";10.1109/SYNASC.2015.60;Recently we witnessed a deep transformation in the the design, development and management of modern applications, which have grown in scope and size becoming distributed and service-oriented. A big part in this metamorphosis is played by the Cloud with the availability of almost-infinite resources, high availability and outsourced maintenance. This has led to the emergence of new software development methodologies to effectively deal with this paradigm shift in the field of software engineering. DevOps is one of them, it advocates for a greater level of collaboration and convergence between developers and other IT professionals. Consequently, new tools, purposely designed to ease this process, are required. In this scenario, we present SPACE4Cloud, a DevOps integrated environment for model-driven design-time quality of service assessment and optimization, and runtime capacity allocation of Cloud applications.;;;;SYNASC '15
Conference Paper;Bordeleau F,Cabot J,Dingel J,Rabil BS,Renaud P;Towards Modeling Framework for DevOps: Requirements Derived from Industry Use Case;;2019;;;139–151;;Springer-Verlag;Berlin, Heidelberg;;Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Château de Villebrumier, France, May 6–8, 2019, Revised Selected Papers;Villebrumier, France;2019;9783030393052;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-39306-9_10;http://dx.doi.org/10.1007/978-3-030-39306-9_10";10.1007/978-3-030-39306-9_10;To succeed with the development, deployment, and operation of the new generation of complex systems, organizations need the agility to adapt to constantly evolving environments. In this context, DevOps has emerged as an evolution of the agile approaches. It focuses on optimizing the flow of activities involved in the creation of end-user value, from idea to deployed functionality and operating systems. However, in spite of its popularity, DevOps still lacks proper engineering frameworks to support continuous improvement. One of our key objectives is to contribute to the development of a DevOps engineering framework composed of process, methods, and tools. A core part of this framework relates to the modeling of the different aspects of the DevOps system. To better understand the requirements of modeling in a DevOps context, we focus on a Product Build use case provided by an industry partner.;DevOps, Process, Modeling;;;
Book Chapter;de Aguiar Monteiro L;A Proposal to Systematize Introducing DevOps into the Software Development Process;;2021;;;269–271;;IEEE Press;;Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings;;;2021;;;https://doi-org.proxy.bnl.lu/10.1109/ICSE-Companion52605.2021.00124;;The software development industry has been evolving with new development standards and service delivery models. Agile methodologies have reached their completion with DevOps, thereby increasing the quality of the software and creating greater speed in delivery. However, a gap regarding the formalization of its adoption and implementation doubts became relevant. My hypothesis is that, by systematizing the introduction of DevOps into the software development process and defining the function of the members of the DevOps team members, may well make it quicker to implement this process, thus reducing conflicts between the teams. As part of the investigation of this hypothesis, the result of the research will be applied in practical development environments i.e. in a Technology Agency of the State of the Brazilian Government and also at the Brazilian Company Neurotech in order to evaluate its effectiveness from metrics appropriate for DevOps environments.;;;;
Conference Paper;Meissner R,Junghanns K;Using DevOps Principles to Continuously Monitor RDF Data Quality;;2016;;;189–192;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 12th International Conference on Semantic Systems;Leipzig, Germany;2016;9781450347525;;"https://doi-org.proxy.bnl.lu/10.1145/2993318.2993351;http://dx.doi.org/10.1145/2993318.2993351";10.1145/2993318.2993351;One approach to continuously achieve a certain data quality level is to use an integration pipeline that continuously checks and monitors the quality of a data set according to defined metrics. This approach is inspired by Continuous Integration pipelines, that have been introduced in the area of software development and DevOps to perform continuous source code checks. By investigating in possible tools to use and discussing the specific requirements for RDF data sets, an integration pipeline is derived that joins current approaches of the areas of software-development and semantic-web as well as reuses existing tools. As these tools have not been built explicitly for CI usage, we evaluate their usability and propose possible workarounds and improvements. Furthermore, a real-world usage scenario is discussed, outlining the benefit of the usage of such a pipeline.;DevOps, Instant Feedback, Continuous Integration, Data Quality, Data Integration, RDF, Quality Monitoring;;;SEMANTiCS 2016
Conference Paper;Smowton C,Lorch JR,Molnar D,Saroiu S,Wolman A;Zero-Effort Payments: Design, Deployment, and Lessons;;2014;;;763–774;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing;Seattle, Washington;2014;9781450329682;;"https://doi-org.proxy.bnl.lu/10.1145/2632048.2632067;http://dx.doi.org/10.1145/2632048.2632067";10.1145/2632048.2632067;This paper presents Zero-Effort Payments (ZEP), a seamless mobile computing system designed to accept payments with no effort on the customer's part beyond a one-time opt-in. With ZEP, customers need not present cards nor operate smartphones to convey their identities. ZEP uses three complementary identification technologies: face recognition, proximate device detection, and human assistance. We demonstrate that the combination of these technologies enables ZEP to scale to the level needed by our deployments.We designed and built ZEP, and demonstrated its usefulness across two real-world deployments lasting five months of continuous deployment, and serving 274 customers. The different nature of our deployments stressed different aspects of our system. These challenges led to several system design changes to improve scalability and fault-tolerance.;face recognition, bluetooth, scalability, indoor localization, latency, fault tolerance, biometrics, BLE, mobile payments;;;UbiComp '14
Conference Paper;Berson S,Golubchik L,Muntz RR;Fault Tolerant Design of Multimedia Servers;;1995;;;364–375;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data;San Jose, California, USA;1995;9780897917315;;"https://doi-org.proxy.bnl.lu/10.1145/223784.223852;http://dx.doi.org/10.1145/223784.223852";10.1145/223784.223852;Recent technological advances have made multimedia on-demand servers feasible. Two challenging tasks in such systems are: a) satisfying the real-time requirement for continuous delivery of objects at specified bandwidths and b) efficiently servicing multiple clients simultaneously. To accomplish these tasks and realize economies of scale associated with servicing a large user population, the multimedia server can require a large disk subsystem. Although a single disk is fairly reliable, a large disk farm can have an unacceptably high probability of disk failure. Further, due to the real-time constraint, the reliability and availability requirements of multimedia systems are very stringent. In this paper we investigate techniques for providing a high degree of reliability and availability, at low disk storage, bandwidth, and memory costs for on-demand multimedia servers.;;;;SIGMOD '95
Conference Paper;Meinicke J,Wong CP,Vasilescu B,Kästner C;Exploring Differences and Commonalities between Feature Flags and Configuration Options;;2020;;;233–242;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice;Seoul, South Korea;2020;9781450371230;;"https://doi-org.proxy.bnl.lu/10.1145/3377813.3381366;http://dx.doi.org/10.1145/3377813.3381366";10.1145/3377813.3381366;Feature flags for continuous deployment and configuration options for customizing software share many similarities, both conceptually and technically. However, neither academic nor practitioner publications seem to clearly compare these two concepts. We argue that a distinction is valuable, as applications, goals, and challenges differ fundamentally between feature flags and configuration options. In this work, we explore the differences and commonalities of both concepts to help understand practices and challenges, and to help transfer existing solutions (e.g., for testing). To better understand feature flags and how they relate to configuration options, we performed nine semi-structured interviews with feature-flag experts. We discovered several distinguishing characteristics but also opportunities for knowledge and technology transfer across both communities. Overall, we think that both communities can learn from each other.;feature toggle, configuration option, continuous delivery, feature flag;;;ICSE-SEIP '20
Book Chapter;Rajapakse RN,Zahedi M,Babar MA;An Empirical Analysis of Practitioners' Perspectives on Security Tool Integration into DevOps;;2021;;;;;Association for Computing Machinery;New York, NY, USA;Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);;;2021;9781450386654;;https://doi-org.proxy.bnl.lu/10.1145/3475716.3475776;;Background: Security tools play a vital role in enabling developers to build secure software. However, it can be quite challenging to introduce and fully leverage security tools without affecting the speed or frequency of deployments in the DevOps paradigm. Aims: We aim to empirically investigate the key challenges practitioners face when integrating security tools into a DevOps workflow in order to provide recommendations for overcoming the challenges. Method: We conducted a study involving 31 systematically selected webinars on integrating security tools in DevOps. We used a qualitative data analysis method, i.e., thematic analysis, to identify the challenges and emerging solutions related to integrating security tools in rapid deployment environments. Results: We find that whilst traditional security tools are unable to cater for the needs of DevOps, the industry is moving towards new generations of security tools that have started focusing on the needs of DevOps. We have developed a DevOps workflow that integrates security tools and a set of guidelines by synthesizing practitioners' recommendations in the analyzed webinars. Conclusion: Whilst the latest security tools are addressing some of the requirements of DevOps, there are many tool-related drawbacks yet to be adequately addressed.;;;;
Conference Paper;Guerriero M,Tamburri DA,Ridene Y,Marconi F,Bersani MM,Artac M;Towards DevOps for Privacy-by-Design in Data-Intensive Applications: A Research Roadmap;;2017;;;139–144;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3053600.3053631;http://dx.doi.org/10.1145/3053600.3053631";10.1145/3053600.3053631;With the onset of Big Data and Data-Intensive Applications (DIAs) exploiting such big data, the problem of offering privacy guarantees to data owners becomes crucial, even more so with the emergence of DevOps development strategies where speed is paramount. This paper outlines this complex scenario and the challenges therein. On one hand, we outline a tool prototype that addresses the key challenge we found in industry, more specifically, assisting the process of continuous DIA architecting for the purpose of offering privacy-by-design guarantees. On the other hand we define a research roadmap in pursuit of a more correct and complete solution for ensured privacy-by-design in the context of Big Data DevOps.;devops, privacy-by-design, trace-checking, big data;;;ICPE '17 Companion
Conference Paper;Wettinger J,Breitenbücher U,Leymann F;Dyn Tail - Dynamically Tailored Deployment Engines for Cloud Applications;;2015;;;421–428;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE 8th International Conference on Cloud Computing;;2015;9781467372879;;"https://doi-org.proxy.bnl.lu/10.1109/CLOUD.2015.63;http://dx.doi.org/10.1109/CLOUD.2015.63";10.1109/CLOUD.2015.63;Shortening software release cycles increasingly becomes a critical competitive advantage, not exclusively for software vendors in the field of Web applications, mobile apps, and the Internet of Things. Today's users, customers, and other stakeholders expect quick responses to occurring issues and feature requests. DevOps and Cloud computing are two key paradigms to enable rapid, continuous deployment and delivery of applications utilizing automated software delivery pipelines. However, it is a highly complex and sophisticated challenge to implement such pipelines by installing, configuring, and integrating corresponding general-purpose deployment automation tooling. Therefore, we present a method in conjunction with a framework and implementation to dynamically generate tailored deployment engines for specific application stacks to deploy corresponding applications. Generated deployment engines are packaged in a portable manner to run them on various platforms and infrastructures. The core of our work is based on generating APIs for arbitrary deployment executables such as scripts and plans that perform different tasks in the automated deployment process. As a result, deployment tasks can be triggered through generated API endpoints, abstracting from lower-level, technical details of different deployment automation tooling.;APIfication, Deployment Engine, Deployment, Cloud Computing, Application Topology, Provisioning, DevOps;;;CLOUD '15
Journal Article;Jabbari R,bin Ali N,Petersen K,Tanveer B;Towards a Benefits Dependency Network for DevOps Based on a Systematic Literature Review;J. Softw. Evol. Process;2018;30;11;;;John Wiley & Sons, Inc.;USA;;;;2018-11;;2047-7473;"https://doi-org.proxy.bnl.lu/10.1002/smr.1957;http://dx.doi.org/10.1002/smr.1957";10.1002/smr.1957;DevOps as a new way of thinking for software development and operations has received much attention in the industry, while it has not been thoroughly investigated in academia yet. The objective of this study is to characterize DevOps by exploring its central components in terms of principles, practices and their relations to the principles, challenges of DevOps adoption, and benefits reported in the peer‐reviewed literature. As a key objective, we also aim to realize the relations between DevOps practices and benefits in a systematic manner. A systematic literature review was conducted. Also, we used the concept of benefits dependency network to synthesize the findings, in particular, to specify dependencies between DevOps practices and link the practices to benefits. We found that in many cases, DevOps characteristics, ie, principles, practices, benefits, and challenges, were not sufficiently defined in detail in the peer‐reviewed literature. In addition, only a few empirical studies are available, which can be attributed to the nascency of DevOps research. Also, an initial version of the DevOps benefits dependency network has been derived. The definition of DevOps principles and practices should be emphasized given the novelty of the concept. Further empirical studies are needed to improve the benefits dependency network presented in this study.In this paper, we aim to realize the relations between DevOps practices and benefits in a systematic manner. We used the concept of benefits dependency network to synthesize the findings of the literature, in particular, to specify dependencies between DevOps practices and link the practices to benefits. Only a few empirical studies are available that can be attributed to the nascency of DevOps research. An initial version of the DevOps benefits dependency network has been derived. image;systematic literature review, challenges, development and operations, principles and practices, benefits and values, DevOps;;;
Conference Paper;Song H,Dautov R,Ferry N,Solberg A,Fleurey F;Model-Based Fleet Deployment of Edge Computing Applications;;2020;;;132–142;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems;Virtual Event, Canada;2020;9781450370196;;"https://doi-org.proxy.bnl.lu/10.1145/3365438.3410951;http://dx.doi.org/10.1145/3365438.3410951";10.1145/3365438.3410951;Edge computing brings software in close proximity to end users and IoT devices. Given the increasing number of distributed Edge devices with various contexts, as well as the widely adopted continuous delivery practices, software developers need to maintain multiple application versions and frequently (re-)deploy them to a fleet of many devices with respect to their contexts. Doing this correctly and efficiently goes beyond manual capabilities and requires employing an intelligent and reliable automated approach. Accordingly this paper describes a joint research with a Smart Healthcare application provider on a model-based approach to automatically assigning multiple software deployments to hundreds of Edge gateways. From a Platform-Specific Model obtained from the existing Edge computing platform, we extract a Platform-Independent Model that describes a list of target devices and a pool of available deployments. Next, we use constraint solving to automatically assign deployments to devices at once, given their specific contexts. The resulting solution is transformed back to the PSM as to proceed with software deployment accordingly. We validate the approach with a Fleet Deployment prototype integrated into the DevOps toolchain currently used by the application provider. Initial experiments demonstrate the viability of the approach and its usefulness in supporting DevOps in Edge computing applications.;IoT, model-based software engineering, DevOps, device fleet, software deployment;;;MODELS '20
Journal Article;da Silva CE,Justino YL,Adachi E;SPReaD: Service-Oriented Process for Reengineering and DevOps: Developing Microservices for a Brazilian State Department of Taxation;Serv. Oriented Comput. Appl.;2022;16;1;1–16;;Springer-Verlag;Berlin, Heidelberg;;;;2022-03;;1863-2386;"https://doi-org.proxy.bnl.lu/10.1007/s11761-021-00329-x;http://dx.doi.org/10.1007/s11761-021-00329-x";10.1007/s11761-021-00329-x;The reengineering of systems into a microservice-based architecture can be seen as an implementation of a service-oriented architecture (SOA). However, the deployment of SOA into an enterprise is a challenging task, as it may involve the modernization of mission-critical systems with high technical debt and high maintenance costs. To this end, a process is required to provide an appropriate set of steps and techniques that minimize risks and at the same time ensure the quality of the systems during the migration process. Thus, this work presents the Service-oriented Process for Reengineering and DevOps—SPReaD, an instantiation of the mainstream SOA methodology focusing on the reengineering of legacy systems integrating DevOps aspects for developing microservices systems. This process has been defined during a real software reengineering project of legacy systems from a Brazilian State Department of Taxation. The results obtained include a substantial improvement in the quality of the main taxation system used by the state, including not only code-related metrics but also performance improvements of the services offered, and a change in the methodology adopted by the software development team.;SOA, Microservices, DevOps, Software Reengineering;;;
Journal Article;Hosono S;A DevOps Framework to Shorten Delivery Time for Cloud Applications;Int. J. Comput. Sci. Eng.;2012;7;4;329–344;;Inderscience Publishers;Geneva 15, CHE;;;;2012-10;;1742-7185;"https://doi-org.proxy.bnl.lu/10.1504/IJCSE.2012.049753;http://dx.doi.org/10.1504/IJCSE.2012.049753";10.1504/IJCSE.2012.049753;This paper proposes DevOps platforms for cloud applications, integrating both the development and operation environment seamlessly. It consists of the client-side integrated development environment (IDE), and the server-side service portfolio and cloud controller. The IDE has requirement definition, architecture design and application prototyping tools, and it can simulate execution of large-scale applications in developers' PCs. The service portfolio incorporates data from these tools and enables automatic data sharing between them, thereby avoiding setback and redundancy. To deploy the applications in the cloud, the cloud controller utilises the resource structures designed in the IDE and generates virtual machines (VMs) from templates, in which a verified OS and middleware for large-scale data processing are packaged. The behaviour of applications and VMs will be automatically monitored and catalogued as feedbacks for the developers. With these comprehensive approaches, the system integration methods can be streamlined and the acceleration of development can be easily demonstrated.;;;;
Conference Paper;Adi Prakoso B,Kuswardono Budiardjo E;The Usage of Agile Adoption Framework to Assess Scrum Process and Recommend Improvements;;2021;;;28–32;;Association for Computing Machinery;New York, NY, USA;;2021 The 4th International Conference on Software Engineering and Information Management;Yokohama, Japan;2021;9781450388955;;"https://doi-org.proxy.bnl.lu/10.1145/3451471.3451476;http://dx.doi.org/10.1145/3451471.3451476";10.1145/3451471.3451476;The Scrum framework is based on the values, principles, and practices that form the foundation for organizations to work. This case study examines an Indonesia-based technology on implementing software development using Scrum. The goal is to assess the process and recommend improvements so XYZ Company can achieve better results at delivering products and services using Scrum. Agile Adoption Framework is used as the assessment framework, evaluating 3 teams represented by its Manager, Product Owner, and Developers. Indicator assessment is done by using data collection methods such as questionnaires or observations. The assessment result shows that XYZ Company achieves Level 2, and the teams achieve Level 2, 4, and 5 respectively. Furthermore, 7 agile practices need improvements, such as evolutionary requirements, continuous delivery, risk-driven iterations, low process ceremony, agile project estimation, pair programming, and test-driven development.;software development, Agile Adoption Framework, software, software process improvement;;;ICSIM 2021
Journal Article;Sanchez-Reillo R;Signature Analysis in the Context of Mobile Devices;Image Vision Comput.;2016;55;P1;34–37;;Butterworth-Heinemann;USA;;;;2016-11;;0262-8856;"https://doi-org.proxy.bnl.lu/10.1016/j.imavis.2016.03.011;http://dx.doi.org/10.1016/j.imavis.2016.03.011";10.1016/j.imavis.2016.03.011;Handwritten signature is one of the oldest means of the human being to both authenticate him/herself and state that a certain document has been understood and accepted. In the modern world, this biometric modality was translated to the use of peripheral pads that allow the signature to be performed by the user. However, in the recent years, the proliferation of mobile devices with touch screens has paved the path to deploy this biometric modality beyond the limits of a desktop. Bringing this biometric modality to mobile devices open several challenges, being some of them already covered, but some others needing further study. This paper provides an overview of these challenges and point to future research works that can help to the continuous deployment of this biometric modality.;Static signature recognition, Dynamic signature recognition, Biometrics, Handwritten signature, User confidence, Forgeries;;;
Journal Article;Royce W,Cantor M;Economic Governance of Software Delivery;IEEE Softw.;2014;31;1;54–61;;IEEE Computer Society Press;Washington, DC, USA;;;;2014-01;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2013.102;http://dx.doi.org/10.1109/MS.2013.102";10.1109/MS.2013.102;Agility without objective governance cannot scale, and governance without agility cannot compete. Agile methods are mainstream, and software enterprises are adopting these practices in diverse delivery contexts and at enterprise scale. IBM's broad industry experience with agile transformations and deep internal know-how point to two key principles to deliver sustained improvements in software business outcomes with higher confidence: measure and streamline change costs, and steer with economic governance and Bayesian analytics. Applying these two principles in context is the crux of measured improvement in continuous delivery of smarter software-intensive systems. This article describes more meaningful measurement and prediction foundations for economic governance. The Web extra at http://youtu.be/ghAM8ifyeVI is a video in which Walker Royce, author, IEEE Software editorial board member, and IBM Chief Software Economist, describes how to reason about software delivery governance with lean principles.;measuring agility, Bayes methods, steering leadership, economic governance, Bayesian analytics, Cognition, Software quality, Economics, Uncertainty, Measurement uncertainty;;;
Journal Article;Golubchik L;On Issues and Tradeoffs in Design of Fault Tolerant VOD Servers;SIGMETRICS Perform. Eval. Rev.;1997;25;2;21–28;;Association for Computing Machinery;New York, NY, USA;;;;1997-09;;0163-5999;"https://doi-org.proxy.bnl.lu/10.1145/262391.262397;http://dx.doi.org/10.1145/262391.262397";10.1145/262391.262397;Recent technological advances in digital signal processing, data compression techniques, and high speed communication networks have made Video-on-Demand (VOD) servers feasible. A challenging task in such systems is servicing multiple clients simultaneously while satisfying real-time requirements of continuous delivery of objects at specified rates. To accomplish these tasks and realize economies of scale associated with servicing a large user population, a VOD server requires a large disk subsystem. Although a single disk is fairly reliable, a large disk farm can have an unacceptably high probability of disk failure. Furthermore, due to real-time constraints, the reliability and availability requirements of VOD systems are even more stringent than those of traditional information systems. In this paper we discuss some of the main issues and tradeoffs associated with providing fault tolerance in multidisk VOD systems.;;;;
Journal Article;Nam SM,Cho TH;Context-Aware Architecture for Probabilistic Voting-Based Filtering Scheme in Sensor Networks;IEEE Transactions on Mobile Computing;2017;16;10;2751–2763;;IEEE Educational Activities Department;USA;;;;2017-10;;1536-1233;"https://doi-org.proxy.bnl.lu/10.1109/TMC.2016.2641219;http://dx.doi.org/10.1109/TMC.2016.2641219";10.1109/TMC.2016.2641219;"Wireless sensor networks are widely deployed and implicitly characterized by stringent energy and computation constraints. Sensor nodes are vulnerable to false positive and false negative attacks that inject false data through compromised nodes. Such attacks cause false alarms with energy drain and information loss. Although several en-route filtering schemes have been designed to detect the attacks, they focus on saving energy through early filtering or continuous delivery of data in accordance with verification records; they cannot exclude compromised nodes. In this paper, we propose a scheme that effectively identifies the compromised nodes and copes with new attacks using a context-aware architecture. In addition, the proposed scheme improves the security strength and energy efficiency of the network. Simulation results validate that the proposed scheme provides energy savings of up to 45 percent and allows fewer attack successes than the existing scheme.";;;;
Conference Paper;Li F,Gelbke L;Microservice Architecture in Industrial Software Delivery on Edge Devices;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th International Conference on Agile Software Development: Companion;Porto, Portugal;2018;9781450364225;;"https://doi-org.proxy.bnl.lu/10.1145/3234152.3234196;http://dx.doi.org/10.1145/3234152.3234196";10.1145/3234152.3234196;Production in Industry 4.0 calls for flexible configurations, customizable features, frequent changes, and above all, short time to market, which poses significant challenges to the practices of industrial software development and delivery. However, under strict regulations and non-negotiable requirements on safety, reliability and compliance, industrial software is still dominated by monolithic architecture that usually requires planned downtime and manual installation for each update. The result is a typical release cycle of 12-18 months with several patches during the release cycle.This paper reports our experiences in applying microservice architecture, and delivery pipeline to achieve continuous deployment for industrial control software on edge devices. They are characterized by their physical proximity to industrial equipment, limited computational resources, high avail-ability, and highly heterogeneous software environments in order to accommodate various industrial protocols and processes.;industrial software, edge computing, microservice;;;XP '18
Book Chapter;Tripathi R,Monroe WS,Hanby M,Robinson JP;Building a Scalable Infrastructure: To Grow Computational Research and Enhance Collaboration across the Research Enterprise;;2020;;;530–533;;Association for Computing Machinery;New York, NY, USA;Practice and Experience in Advanced Research Computing;;;2020;9781450366892;;https://doi-org.proxy.bnl.lu/10.1145/3311790.3399620;;This paper documents our experience in building a scalable cyberinfrastructure to grow computational research and enhance collaboration across the research enterprise. It describes a modernized research computing system built on the principles of Software Defined Infrastructure (SDI) and DevOps. This approach helps develop, test and deploy enhancements to our High Performance Computing (HPC) platform. By separating development from production, the approach offers opportunities to train developers new to distributed systems and HPC platforms, safely gaining advanced skills in demand but not common in today’s job market. Providing a deployment pipeline empowers teams with varying skill levels to effectively contribute enhancements to HPC platforms extending the capacity of operations professionals. The paper highlights our experience in setting up a web frontend for HPC resources in the form of Open OnDemand. The Open OnDemand web interface new users transition from their dedicated workstations to the HPC ecosystem. Most recently this model has been extended to manifest a DataOps team focused on analyzing operational cluster data sets. Their analysis uses XDMOD and Jupyter notebooks, available on the cluster through Open OnDemand, to review wait times and utilization providing direct feedback on scheduling policy. This review helps validate user experiences and ensures we define our infrastructure in a way that is most useful for our researchers. This knowledge has contributed to optimize workflows for research teams on campus. An open-source SDI and DevOps principles enable broader collaboratations with with research teams on and off campus, delivering rapid improvements across teams that can share processes. This discussion further highlights the importance to collaboration of open-source tooling and sites like GitHub.com and self-hosted community edition of GitLab.;;;;
Conference Paper;Lim ZY,Chua JM,Yang K,Tan WS,Chai Y;Web Accessibility Testing for Singapore Government E-Services;;2020;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 17th International Web for All Conference;Taipei, Taiwan;2020;9781450370561;;"https://doi-org.proxy.bnl.lu/10.1145/3371300.3383353;http://dx.doi.org/10.1145/3371300.3383353";10.1145/3371300.3383353;The paper proposes a customized automated accessibility testing tool built on existing open source tools that makes upholding web accessibility standards less daunting and overwhelming for developers working on Singapore government e-services.We incorporate findings from contextual inquiry (N = 8) on government e-service use by persons with disabilities (PWDs) in Singapore to help software development teams identify and prioritise accessibility test findings within the agile development cycle. Our tool incorporates a customised accessibility audit tool with rule set prioritised from the contextual inquiry, and built as part of a software package that can be rapidly deployed on continuous integration / continuous delivery (CI/CD) platforms to scale up the adoption and accessibility testing.The goal of our tool is to deliver a usable output for developers and product managers that is streamlined, targeted, and integrated into existing workflows.;accessibility evaluation, automated testing, accessibility standards, web accessibility;;;W4A '20
Conference Paper;Alperowitz L,Dzvonyar D,Bruegge B;Metrics in Agile Project Courses;;2016;;;323–326;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 38th International Conference on Software Engineering Companion;Austin, Texas;2016;9781450342056;;"https://doi-org.proxy.bnl.lu/10.1145/2889160.2889183;http://dx.doi.org/10.1145/2889160.2889183";10.1145/2889160.2889183;We believe that software engineering should be taught in a hands-on way such as through a project-based capstone course where students apply the learned concepts in a real setting. However, such a teaching format can be challenging and time-consuming for instructors.In this paper we explain how we selected and introduced a set of metrics to improve the manageability of our large multi-project capstone course. We regularly run such a course with over 100 students developing applications in 10-12 parallel projects over the course of one semester.Our approach focuses on measuring the success of three key workflows, namely Merge Management, Continuous Integration and Continuous Delivery. We show how these metrics help the instructors to keep track of the progress of multiple projects running at the same time, enabling them to identify and react to problems early.;continuous integration, project management, agile software engineering, metrics, continuous delivery, capstone course;;;ICSE '16
Journal Article;Leppanen M,Makinen S,Lahtinen S,Sievi-Korte O,Tuovinen AP,Mannisto T;Refactoring-a Shot in the Dark?;IEEE Softw.;2015;32;6;62–70;;IEEE Computer Society Press;Washington, DC, USA;;;;2015-11;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2015.132;http://dx.doi.org/10.1109/MS.2015.132";10.1109/MS.2015.132;A study performed semistructured interviews of 12 seasoned software architects and developers at nine Finnish companies. Its main goals were to find out how the practitioners viewed the role and importance of refactoring, and how and when they refactored. Another goal was to see whether shortened cycle times and, especially, continuous-deployment practices affected how and when refactoring was done. The results paint a multifaceted picture with some common patterns. The respondents considered refactoring to be valuable but had difficulty explaining and justifying it to management and customers. Refactoring often occurred in conjunction with the development of new features because it seemed to require a clear business need. The respondents didn't use measurements to quantify the need for or impact of refactoring. This article is part of a special issue on Refactoring.;;;;
Conference Paper;Manteiga SM,Otero AG,Cunha AM,Dias LA;Financial Measuring of Incremental Deliveries in Software Projects -- Finding a Model That Can Answer: How Much is Worth to Split a Project into Iterations?;;2015;;;33–37;;IEEE Computer Society;USA;;Proceedings of the 2015 12th International Conference on Information Technology - New Generations;;2015;9781479988280;;"https://doi-org.proxy.bnl.lu/10.1109/ITNG.2015.11;http://dx.doi.org/10.1109/ITNG.2015.11";10.1109/ITNG.2015.11;In this article, it is presented a mathematical model for the additional financial value generated in software projects, as a function of the number of incremental deliveries during the project. Based on this model, it was presented the theoretical asymptotic limit, for infinite deliveries during the project. This practice is called Continuous Deployment (CD), already used by many companies such as Google and Facebook. As financial evaluation measuring, it was used the Net Present Value (NPV). It was also measured how the use of incremental deliveries can create additional NPV for software projects which have short duration (maximum of six months), median duration (one year) and long duration (two years). At the end, it is argued that this additional value can be strategic for maintaining a sustainable portfolio of innovation projects.;project portfolio, net present value (NPV), incremental delivery, continuous delivery;;;ITNG '15
Book;Rangel D;DevOps: Learn One of the Most Powerful Software Development Methodologies FAST AND EASY!;;2016;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2016;9781532738043;;;;"DevOps Learn One of the Most Powerful Software Development Methodologies FAST AND EASY! This book is an exploration of DevOps (Developer Operations). It begins by explaining what DevOps is, how it is used, and why it was introduced. The next step is a guide on how one can set up TomEE from Puppet. The Puppet and Packer immutable servers are also explored, and thus you will know how to work with them after reading this book. The book will guide you on how to set up a modern web stack in Ubuntu, which is a distribution of the Linux operating system. With the advancement in technology, users now liketo use databases which are more advanced for their applications. Note that each of the web applications developed has a database. With DynamoDB, the administration overhead is greatly reduced. This book will guide you on how to shift your database from MongoDB to DynamoDB. The process of performing operations on tree structures in MongoDB is also discussed in detail, enabling you to operate on different types of tree structures. You will also learn how to configure your Apache for multiple domains. Reverse cache proxy, which is a very nice feature in Nginx is presented in detail, instructing you on how to work with it. The process of using Nginx in a web application is further explored. Here is a preview of what you'll learn: Definition Installation of TomEE from Puppet Puppet and Packer Immutable Servers How to set up a modern web stack in Ubuntu Migration of MongoDB to DynamoDB MongoDB and Tree Structures Configuration of Apache for Multiple Domains Reverse Cache Proxy in Nginx Setting Up LAMP on Ubuntu hosted on AWS Using Nginx with a Web Application Download your copy of "" DevOps "" by scrolling up and clicking ""Buy Now With 1-Click"" button.";;;;
Conference Paper;Rahman A;Characteristics of Defective Infrastructure as Code Scripts in DevOps;;2018;;;476–479;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings;Gothenburg, Sweden;2018;9781450356633;;"https://doi-org.proxy.bnl.lu/10.1145/3183440.3183452;http://dx.doi.org/10.1145/3183440.3183452";10.1145/3183440.3183452;"Defects in infrastructure as code (IaC) scripts can have serious consequences for organizations who adopt DevOps. By identifying which characteristics of IaC scripts correlate with defects, we can identify anti-patterns, and help software practitioners make informed decisions on better development and maintenance of IaC scripts, and increase quality of IaC scripts. The goal of this paper is to help practitioners increase the quality of IaC scripts by identifying characteristics of IaC scripts and IaC development process that correlate with defects, and violate security and privacy objectives. We focus on characteristics of IaC scripts and IaC development that (i) correlate with IaC defects, and (ii) violate security and privacy-related objectives namely, confidentiality, availability, and integrity. For our initial studies, we mined open source version control systems from three organizations: Mozilla, Openstack, and Wikimedia, to identify the defect-related characteristics and conduct our case studies. From our empirical analysis, we identify (i) 14 IaC code and four churn characteristics that correlate with defects; and (ii) 12 process characteristics such as, frequency of changes, and ownership of IaC scripts that correlate with defects. We propose the following studies: (i) identify structural characteristics that correlate with defects; (ii) with respect to prediction performance, compare which characteristics of IaC scripts are more correlated with defects; and (iii) identify characteristics that violate security and privacy objectives.";infrastructure as code, defects, metrics, devops;;;ICSE '18
Journal Article;Limoncelli TA;SQL is No Excuse to Avoid DevOps;Commun. ACM;2018;62;1;46–49;;Association for Computing Machinery;New York, NY, USA;;;;2018-12;;0001-0782;"https://doi-org.proxy.bnl.lu/10.1145/3287299;http://dx.doi.org/10.1145/3287299";10.1145/3287299;Automation and a little discipline allow better testing, shorter release cycles, and reduced business risk.;;;;
Conference Paper;Durak U,Öztürk A,Katircioglu M;Simulation Deployment Blockset for MATLAB/Simulink;;2016;;;;;Society for Computer Simulation International;San Diego, CA, USA;;Proceedings of the Symposium on Theory of Modeling & Simulation;Pasadena, California;2016;9781510823211;;;;Model-based approaches are being employed more and more in simulation development. Graphical modeling languages and code generation technologies are enabling agile model development workflows, so that simulation modelers can update their models more easily. However, the process from changing the model to releasing a new simulation version is overlooked. Simulation deployment can be defined as a collection of activities, including model checking, Model-in-the-Loop testing, code generation, build, Software-in-the-Loop testing, deployment, when applicable Processor-in-the-Loop and Hardware-in-the-Loop testing and release. When it is conducted manually and ad hoc, it is repetitive, labor intensive, time-consuming and error prone. The automation of deployment pipeline, on the other hand, requires extensive scripting, unfortunately, in way in which simulation modelers are usually not accustomed. Causal Block Diagrams propose a graphical modeling language that is extensively used in simulation of technical systems. MATLAB/Simulink supports them as the basic modeling language. Exploiting the competence of MATLAB/Simulink users on Causal Block Diagrams, this paper presents a model-based approach for automating the simulation deployment activities. Thus, rather than scripting, the deployment automation functions are made available and accessible to the simulation modelers within the graphical modeling environment that they are using.;simulation deployment, continuous delivery, model-based simulation systems engineering;;;TMS-DEVS '16
Conference Paper;Wettinger J,Breitenbücher U,Leymann F;Dyn Tail - Dynamically Tailored Deployment Engines for Cloud Applications;;2015;;;421–428;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE 8th International Conference on Cloud Computing;;2015;9781467372879;;"https://doi-org.proxy.bnl.lu/10.1109/CLOUD.2015.63;http://dx.doi.org/10.1109/CLOUD.2015.63";10.1109/CLOUD.2015.63;Shortening software release cycles increasingly becomes a critical competitive advantage, not exclusively for software vendors in the field of Web applications, mobile apps, and the Internet of Things. Today's users, customers, and other stakeholders expect quick responses to occurring issues and feature requests. DevOps and Cloud computing are two key paradigms to enable rapid, continuous deployment and delivery of applications utilizing automated software delivery pipelines. However, it is a highly complex and sophisticated challenge to implement such pipelines by installing, configuring, and integrating corresponding general-purpose deployment automation tooling. Therefore, we present a method in conjunction with a framework and implementation to dynamically generate tailored deployment engines for specific application stacks to deploy corresponding applications. Generated deployment engines are packaged in a portable manner to run them on various platforms and infrastructures. The core of our work is based on generating APIs for arbitrary deployment executables such as scripts and plans that perform different tasks in the automated deployment process. As a result, deployment tasks can be triggered through generated API endpoints, abstracting from lower-level, technical details of different deployment automation tooling.;Application Topology, Deployment Engine, Deployment, Provisioning, DevOps, Cloud Computing, APIfication;;;CLOUD '15
Conference Paper;Jaatun MG,Cruzes DS,Luna J;DevOps for Better Software Security in the Cloud Invited Paper;;2017;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 12th International Conference on Availability, Reliability and Security;Reggio Calabria, Italy;2017;9781450352574;;"https://doi-org.proxy.bnl.lu/10.1145/3098954.3103172;http://dx.doi.org/10.1145/3098954.3103172";10.1145/3098954.3103172;The DevOps paradigm means that development and operations for an organisation blend together. For security, this implies that information on detected attacks can be fed back to the development, enabling faster eradication of vulnerabilities in software. This is particularly important in cloud installations, where release cycles can be less than a day. This paper argues that DevOps can be employed for overall improved software security.;Security Metrics, Software Security, Cloud Security, DevOps;;;ARES '17
Conference Paper;Guerriero M,Tamburri DA,Ridene Y,Marconi F,Bersani MM,Artac M;Towards DevOps for Privacy-by-Design in Data-Intensive Applications: A Research Roadmap;;2017;;;139–144;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3053600.3053631;http://dx.doi.org/10.1145/3053600.3053631";10.1145/3053600.3053631;With the onset of Big Data and Data-Intensive Applications (DIAs) exploiting such big data, the problem of offering privacy guarantees to data owners becomes crucial, even more so with the emergence of DevOps development strategies where speed is paramount. This paper outlines this complex scenario and the challenges therein. On one hand, we outline a tool prototype that addresses the key challenge we found in industry, more specifically, assisting the process of continuous DIA architecting for the purpose of offering privacy-by-design guarantees. On the other hand we define a research roadmap in pursuit of a more correct and complete solution for ensured privacy-by-design in the context of Big Data DevOps.;privacy-by-design, trace-checking, big data, devops;;;ICPE '17 Companion
Journal Article;Jabbari R,bin Ali N,Petersen K,Tanveer B;Towards a Benefits Dependency Network for DevOps Based on a Systematic Literature Review;J. Softw. Evol. Process;2018;30;11;;;John Wiley & Sons, Inc.;USA;;;;2018-11;;2047-7473;"https://doi-org.proxy.bnl.lu/10.1002/smr.1957;http://dx.doi.org/10.1002/smr.1957";10.1002/smr.1957;DevOps as a new way of thinking for software development and operations has received much attention in the industry, while it has not been thoroughly investigated in academia yet. The objective of this study is to characterize DevOps by exploring its central components in terms of principles, practices and their relations to the principles, challenges of DevOps adoption, and benefits reported in the peer‐reviewed literature. As a key objective, we also aim to realize the relations between DevOps practices and benefits in a systematic manner. A systematic literature review was conducted. Also, we used the concept of benefits dependency network to synthesize the findings, in particular, to specify dependencies between DevOps practices and link the practices to benefits. We found that in many cases, DevOps characteristics, ie, principles, practices, benefits, and challenges, were not sufficiently defined in detail in the peer‐reviewed literature. In addition, only a few empirical studies are available, which can be attributed to the nascency of DevOps research. Also, an initial version of the DevOps benefits dependency network has been derived. The definition of DevOps principles and practices should be emphasized given the novelty of the concept. Further empirical studies are needed to improve the benefits dependency network presented in this study.In this paper, we aim to realize the relations between DevOps practices and benefits in a systematic manner. We used the concept of benefits dependency network to synthesize the findings of the literature, in particular, to specify dependencies between DevOps practices and link the practices to benefits. Only a few empirical studies are available that can be attributed to the nascency of DevOps research. An initial version of the DevOps benefits dependency network has been derived. image;principles and practices, development and operations, benefits and values, challenges, DevOps, systematic literature review;;;
Conference Paper;Song H,Dautov R,Ferry N,Solberg A,Fleurey F;Model-Based Fleet Deployment of Edge Computing Applications;;2020;;;132–142;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems;Virtual Event, Canada;2020;9781450370196;;"https://doi-org.proxy.bnl.lu/10.1145/3365438.3410951;http://dx.doi.org/10.1145/3365438.3410951";10.1145/3365438.3410951;Edge computing brings software in close proximity to end users and IoT devices. Given the increasing number of distributed Edge devices with various contexts, as well as the widely adopted continuous delivery practices, software developers need to maintain multiple application versions and frequently (re-)deploy them to a fleet of many devices with respect to their contexts. Doing this correctly and efficiently goes beyond manual capabilities and requires employing an intelligent and reliable automated approach. Accordingly this paper describes a joint research with a Smart Healthcare application provider on a model-based approach to automatically assigning multiple software deployments to hundreds of Edge gateways. From a Platform-Specific Model obtained from the existing Edge computing platform, we extract a Platform-Independent Model that describes a list of target devices and a pool of available deployments. Next, we use constraint solving to automatically assign deployments to devices at once, given their specific contexts. The resulting solution is transformed back to the PSM as to proceed with software deployment accordingly. We validate the approach with a Fleet Deployment prototype integrated into the DevOps toolchain currently used by the application provider. Initial experiments demonstrate the viability of the approach and its usefulness in supporting DevOps in Edge computing applications.;software deployment, IoT, model-based software engineering, DevOps, device fleet;;;MODELS '20
Book Chapter;Liu L,Xie D,Cheng Y,Li G;Architecture Scheme of DevOps for Cross Network and Multiple Environment Collaboration;;2021;;;;;Association for Computing Machinery;New York, NY, USA;The 5th International Conference on Computer Science and Application Engineering;;;2021;9781450389853;;https://doi-org.proxy.bnl.lu/10.1145/3487075.3487116;;In the process of traditional enterprises exploring the middle platform architecture, DevOps is the cornerstone of its digital platform's long-term iterative construction and sustainable operation and maintenance. Aiming at the problems of physical isolation of multiple environments and cross regional collaboration of R&D teams faced by high security applications, based on the systematic analysis of DevOps concept, support tools and adoption situation, and based on the DevOps standard, this paper designs a DevOps architecture scheme for internal and external collaboration within cross-network multiple environments.;;;;
Conference Paper;Adi Prakoso B,Kuswardono Budiardjo E;The Usage of Agile Adoption Framework to Assess Scrum Process and Recommend Improvements;;2021;;;28–32;;Association for Computing Machinery;New York, NY, USA;;2021 The 4th International Conference on Software Engineering and Information Management;Yokohama, Japan;2021;9781450388955;;"https://doi-org.proxy.bnl.lu/10.1145/3451471.3451476;http://dx.doi.org/10.1145/3451471.3451476";10.1145/3451471.3451476;The Scrum framework is based on the values, principles, and practices that form the foundation for organizations to work. This case study examines an Indonesia-based technology on implementing software development using Scrum. The goal is to assess the process and recommend improvements so XYZ Company can achieve better results at delivering products and services using Scrum. Agile Adoption Framework is used as the assessment framework, evaluating 3 teams represented by its Manager, Product Owner, and Developers. Indicator assessment is done by using data collection methods such as questionnaires or observations. The assessment result shows that XYZ Company achieves Level 2, and the teams achieve Level 2, 4, and 5 respectively. Furthermore, 7 agile practices need improvements, such as evolutionary requirements, continuous delivery, risk-driven iterations, low process ceremony, agile project estimation, pair programming, and test-driven development.;software process improvement, software, software development, Agile Adoption Framework;;;ICSIM 2021
Journal Article;da Silva CE,Justino YL,Adachi E;SPReaD: Service-Oriented Process for Reengineering and DevOps: Developing Microservices for a Brazilian State Department of Taxation;Serv. Oriented Comput. Appl.;2022;16;1;1–16;;Springer-Verlag;Berlin, Heidelberg;;;;2022-03;;1863-2386;"https://doi-org.proxy.bnl.lu/10.1007/s11761-021-00329-x;http://dx.doi.org/10.1007/s11761-021-00329-x";10.1007/s11761-021-00329-x;The reengineering of systems into a microservice-based architecture can be seen as an implementation of a service-oriented architecture (SOA). However, the deployment of SOA into an enterprise is a challenging task, as it may involve the modernization of mission-critical systems with high technical debt and high maintenance costs. To this end, a process is required to provide an appropriate set of steps and techniques that minimize risks and at the same time ensure the quality of the systems during the migration process. Thus, this work presents the Service-oriented Process for Reengineering and DevOps—SPReaD, an instantiation of the mainstream SOA methodology focusing on the reengineering of legacy systems integrating DevOps aspects for developing microservices systems. This process has been defined during a real software reengineering project of legacy systems from a Brazilian State Department of Taxation. The results obtained include a substantial improvement in the quality of the main taxation system used by the state, including not only code-related metrics but also performance improvements of the services offered, and a change in the methodology adopted by the software development team.;DevOps, SOA, Software Reengineering, Microservices;;;
Journal Article;Sanchez-Reillo R;Signature Analysis in the Context of Mobile Devices;Image Vision Comput.;2016;55;P1;34–37;;Butterworth-Heinemann;USA;;;;2016-11;;0262-8856;"https://doi-org.proxy.bnl.lu/10.1016/j.imavis.2016.03.011;http://dx.doi.org/10.1016/j.imavis.2016.03.011";10.1016/j.imavis.2016.03.011;Handwritten signature is one of the oldest means of the human being to both authenticate him/herself and state that a certain document has been understood and accepted. In the modern world, this biometric modality was translated to the use of peripheral pads that allow the signature to be performed by the user. However, in the recent years, the proliferation of mobile devices with touch screens has paved the path to deploy this biometric modality beyond the limits of a desktop. Bringing this biometric modality to mobile devices open several challenges, being some of them already covered, but some others needing further study. This paper provides an overview of these challenges and point to future research works that can help to the continuous deployment of this biometric modality.;Handwritten signature, User confidence, Forgeries, Static signature recognition, Dynamic signature recognition, Biometrics;;;
Journal Article;Royce W,Cantor M;Economic Governance of Software Delivery;IEEE Softw.;2014;31;1;54–61;;IEEE Computer Society Press;Washington, DC, USA;;;;2014-01;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2013.102;http://dx.doi.org/10.1109/MS.2013.102";10.1109/MS.2013.102;Agility without objective governance cannot scale, and governance without agility cannot compete. Agile methods are mainstream, and software enterprises are adopting these practices in diverse delivery contexts and at enterprise scale. IBM's broad industry experience with agile transformations and deep internal know-how point to two key principles to deliver sustained improvements in software business outcomes with higher confidence: measure and streamline change costs, and steer with economic governance and Bayesian analytics. Applying these two principles in context is the crux of measured improvement in continuous delivery of smarter software-intensive systems. This article describes more meaningful measurement and prediction foundations for economic governance. The Web extra at http://youtu.be/ghAM8ifyeVI is a video in which Walker Royce, author, IEEE Software editorial board member, and IBM Chief Software Economist, describes how to reason about software delivery governance with lean principles.;Cognition, Economics, Measurement uncertainty, measuring agility, Software quality, steering leadership, Uncertainty, economic governance, Bayes methods, Bayesian analytics;;;
Journal Article;Golubchik L;On Issues and Tradeoffs in Design of Fault Tolerant VOD Servers;SIGMETRICS Perform. Eval. Rev.;1997;25;2;21–28;;Association for Computing Machinery;New York, NY, USA;;;;1997-09;;0163-5999;"https://doi-org.proxy.bnl.lu/10.1145/262391.262397;http://dx.doi.org/10.1145/262391.262397";10.1145/262391.262397;Recent technological advances in digital signal processing, data compression techniques, and high speed communication networks have made Video-on-Demand (VOD) servers feasible. A challenging task in such systems is servicing multiple clients simultaneously while satisfying real-time requirements of continuous delivery of objects at specified rates. To accomplish these tasks and realize economies of scale associated with servicing a large user population, a VOD server requires a large disk subsystem. Although a single disk is fairly reliable, a large disk farm can have an unacceptably high probability of disk failure. Furthermore, due to real-time constraints, the reliability and availability requirements of VOD systems are even more stringent than those of traditional information systems. In this paper we discuss some of the main issues and tradeoffs associated with providing fault tolerance in multidisk VOD systems.;;;;
Journal Article;Nam SM,Cho TH;Context-Aware Architecture for Probabilistic Voting-Based Filtering Scheme in Sensor Networks;IEEE Transactions on Mobile Computing;2017;16;10;2751–2763;;IEEE Educational Activities Department;USA;;;;2017-10;;1536-1233;"https://doi-org.proxy.bnl.lu/10.1109/TMC.2016.2641219;http://dx.doi.org/10.1109/TMC.2016.2641219";10.1109/TMC.2016.2641219;"Wireless sensor networks are widely deployed and implicitly characterized by stringent energy and computation constraints. Sensor nodes are vulnerable to false positive and false negative attacks that inject false data through compromised nodes. Such attacks cause false alarms with energy drain and information loss. Although several en-route filtering schemes have been designed to detect the attacks, they focus on saving energy through early filtering or continuous delivery of data in accordance with verification records; they cannot exclude compromised nodes. In this paper, we propose a scheme that effectively identifies the compromised nodes and copes with new attacks using a context-aware architecture. In addition, the proposed scheme improves the security strength and energy efficiency of the network. Simulation results validate that the proposed scheme provides energy savings of up to 45 percent and allows fewer attack successes than the existing scheme.";;;;
Journal Article;Hosono S;A DevOps Framework to Shorten Delivery Time for Cloud Applications;Int. J. Comput. Sci. Eng.;2012;7;4;329–344;;Inderscience Publishers;Geneva 15, CHE;;;;2012-10;;1742-7185;"https://doi-org.proxy.bnl.lu/10.1504/IJCSE.2012.049753;http://dx.doi.org/10.1504/IJCSE.2012.049753";10.1504/IJCSE.2012.049753;This paper proposes DevOps platforms for cloud applications, integrating both the development and operation environment seamlessly. It consists of the client-side integrated development environment (IDE), and the server-side service portfolio and cloud controller. The IDE has requirement definition, architecture design and application prototyping tools, and it can simulate execution of large-scale applications in developers' PCs. The service portfolio incorporates data from these tools and enables automatic data sharing between them, thereby avoiding setback and redundancy. To deploy the applications in the cloud, the cloud controller utilises the resource structures designed in the IDE and generates virtual machines (VMs) from templates, in which a verified OS and middleware for large-scale data processing are packaged. The behaviour of applications and VMs will be automatically monitored and catalogued as feedbacks for the developers. With these comprehensive approaches, the system integration methods can be streamlined and the acceleration of development can be easily demonstrated.;;;;
Conference Paper;Li F,Gelbke L;Microservice Architecture in Industrial Software Delivery on Edge Devices;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th International Conference on Agile Software Development: Companion;Porto, Portugal;2018;9781450364225;;"https://doi-org.proxy.bnl.lu/10.1145/3234152.3234196;http://dx.doi.org/10.1145/3234152.3234196";10.1145/3234152.3234196;Production in Industry 4.0 calls for flexible configurations, customizable features, frequent changes, and above all, short time to market, which poses significant challenges to the practices of industrial software development and delivery. However, under strict regulations and non-negotiable requirements on safety, reliability and compliance, industrial software is still dominated by monolithic architecture that usually requires planned downtime and manual installation for each update. The result is a typical release cycle of 12-18 months with several patches during the release cycle.This paper reports our experiences in applying microservice architecture, and delivery pipeline to achieve continuous deployment for industrial control software on edge devices. They are characterized by their physical proximity to industrial equipment, limited computational resources, high avail-ability, and highly heterogeneous software environments in order to accommodate various industrial protocols and processes.;edge computing, industrial software, microservice;;;XP '18
Book Chapter;Tripathi R,Monroe WS,Hanby M,Robinson JP;Building a Scalable Infrastructure: To Grow Computational Research and Enhance Collaboration across the Research Enterprise;;2020;;;530–533;;Association for Computing Machinery;New York, NY, USA;Practice and Experience in Advanced Research Computing;;;2020;9781450366892;;https://doi-org.proxy.bnl.lu/10.1145/3311790.3399620;;This paper documents our experience in building a scalable cyberinfrastructure to grow computational research and enhance collaboration across the research enterprise. It describes a modernized research computing system built on the principles of Software Defined Infrastructure (SDI) and DevOps. This approach helps develop, test and deploy enhancements to our High Performance Computing (HPC) platform. By separating development from production, the approach offers opportunities to train developers new to distributed systems and HPC platforms, safely gaining advanced skills in demand but not common in today’s job market. Providing a deployment pipeline empowers teams with varying skill levels to effectively contribute enhancements to HPC platforms extending the capacity of operations professionals. The paper highlights our experience in setting up a web frontend for HPC resources in the form of Open OnDemand. The Open OnDemand web interface new users transition from their dedicated workstations to the HPC ecosystem. Most recently this model has been extended to manifest a DataOps team focused on analyzing operational cluster data sets. Their analysis uses XDMOD and Jupyter notebooks, available on the cluster through Open OnDemand, to review wait times and utilization providing direct feedback on scheduling policy. This review helps validate user experiences and ensures we define our infrastructure in a way that is most useful for our researchers. This knowledge has contributed to optimize workflows for research teams on campus. An open-source SDI and DevOps principles enable broader collaboratations with with research teams on and off campus, delivering rapid improvements across teams that can share processes. This discussion further highlights the importance to collaboration of open-source tooling and sites like GitHub.com and self-hosted community edition of GitLab.;;;;
Conference Paper;Lim ZY,Chua JM,Yang K,Tan WS,Chai Y;Web Accessibility Testing for Singapore Government E-Services;;2020;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 17th International Web for All Conference;Taipei, Taiwan;2020;9781450370561;;"https://doi-org.proxy.bnl.lu/10.1145/3371300.3383353;http://dx.doi.org/10.1145/3371300.3383353";10.1145/3371300.3383353;The paper proposes a customized automated accessibility testing tool built on existing open source tools that makes upholding web accessibility standards less daunting and overwhelming for developers working on Singapore government e-services.We incorporate findings from contextual inquiry (N = 8) on government e-service use by persons with disabilities (PWDs) in Singapore to help software development teams identify and prioritise accessibility test findings within the agile development cycle. Our tool incorporates a customised accessibility audit tool with rule set prioritised from the contextual inquiry, and built as part of a software package that can be rapidly deployed on continuous integration / continuous delivery (CI/CD) platforms to scale up the adoption and accessibility testing.The goal of our tool is to deliver a usable output for developers and product managers that is streamlined, targeted, and integrated into existing workflows.;accessibility evaluation, automated testing, accessibility standards, web accessibility;;;W4A '20
Conference Paper;Alperowitz L,Dzvonyar D,Bruegge B;Metrics in Agile Project Courses;;2016;;;323–326;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 38th International Conference on Software Engineering Companion;Austin, Texas;2016;9781450342056;;"https://doi-org.proxy.bnl.lu/10.1145/2889160.2889183;http://dx.doi.org/10.1145/2889160.2889183";10.1145/2889160.2889183;We believe that software engineering should be taught in a hands-on way such as through a project-based capstone course where students apply the learned concepts in a real setting. However, such a teaching format can be challenging and time-consuming for instructors.In this paper we explain how we selected and introduced a set of metrics to improve the manageability of our large multi-project capstone course. We regularly run such a course with over 100 students developing applications in 10-12 parallel projects over the course of one semester.Our approach focuses on measuring the success of three key workflows, namely Merge Management, Continuous Integration and Continuous Delivery. We show how these metrics help the instructors to keep track of the progress of multiple projects running at the same time, enabling them to identify and react to problems early.;metrics, project management, continuous delivery, capstone course, agile software engineering, continuous integration;;;ICSE '16
Journal Article;Leppanen M,Makinen S,Lahtinen S,Sievi-Korte O,Tuovinen AP,Mannisto T;Refactoring-a Shot in the Dark?;IEEE Softw.;2015;32;6;62–70;;IEEE Computer Society Press;Washington, DC, USA;;;;2015-11;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2015.132;http://dx.doi.org/10.1109/MS.2015.132";10.1109/MS.2015.132;A study performed semistructured interviews of 12 seasoned software architects and developers at nine Finnish companies. Its main goals were to find out how the practitioners viewed the role and importance of refactoring, and how and when they refactored. Another goal was to see whether shortened cycle times and, especially, continuous-deployment practices affected how and when refactoring was done. The results paint a multifaceted picture with some common patterns. The respondents considered refactoring to be valuable but had difficulty explaining and justifying it to management and customers. Refactoring often occurred in conjunction with the development of new features because it seemed to require a clear business need. The respondents didn't use measurements to quantify the need for or impact of refactoring. This article is part of a special issue on Refactoring.;;;;
Conference Paper;Manteiga SM,Otero AG,Cunha AM,Dias LA;Financial Measuring of Incremental Deliveries in Software Projects -- Finding a Model That Can Answer: How Much is Worth to Split a Project into Iterations?;;2015;;;33–37;;IEEE Computer Society;USA;;Proceedings of the 2015 12th International Conference on Information Technology - New Generations;;2015;9781479988280;;"https://doi-org.proxy.bnl.lu/10.1109/ITNG.2015.11;http://dx.doi.org/10.1109/ITNG.2015.11";10.1109/ITNG.2015.11;In this article, it is presented a mathematical model for the additional financial value generated in software projects, as a function of the number of incremental deliveries during the project. Based on this model, it was presented the theoretical asymptotic limit, for infinite deliveries during the project. This practice is called Continuous Deployment (CD), already used by many companies such as Google and Facebook. As financial evaluation measuring, it was used the Net Present Value (NPV). It was also measured how the use of incremental deliveries can create additional NPV for software projects which have short duration (maximum of six months), median duration (one year) and long duration (two years). At the end, it is argued that this additional value can be strategic for maintaining a sustainable portfolio of innovation projects.;net present value (NPV), project portfolio, incremental delivery, continuous delivery;;;ITNG '15
Journal Article;Wettinger J,Breitenbücher U,Kopp O,Leymann F;Streamlining DevOps Automation for Cloud Applications Using TOSCA as Standardized Metamodel;Future Gener. Comput. Syst.;2016;56;C;317–332;;Elsevier Science Publishers B. V.;NLD;;;;2016-03;;0167-739X;"https://doi-org.proxy.bnl.lu/10.1016/j.future.2015.07.017;http://dx.doi.org/10.1016/j.future.2015.07.017";10.1016/j.future.2015.07.017;DevOps as an emerging paradigm aims to tightly integrate developers with operations personnel. This enables fast and frequent releases in the sense of continuously delivering new iterations of a particular application. Users and customers of today's Web applications and mobile apps running in the Cloud expect fast feedback to problems and feature requests. Thus, it is a critical competitive advantage to be able to respond quickly. Besides cultural and organizational changes that are necessary to apply DevOps in practice, tooling is required to implement end-to-end automation of deployment processes. Automation is the key to efficient collaboration and tight integration between development and operations. The DevOps community is constantly pushing new approaches, tools, and open-source artifacts to implement such automated processes. However, as all these proprietary and heterogeneous DevOps automation approaches differ from each other, it is hard to integrate and combine them to deploy applications in the Cloud using an automated deployment process. In this paper we present a systematic classification of DevOps artifacts and show how different kinds of artifacts can be discovered and transformed toward TOSCA, which is an emerging standard. We present an integrated modeling and runtime framework to enable the seamless and interoperable integration of different approaches to model and deploy application topologies. The framework is implemented by an open-source, end-to-end toolchain. Moreover, we validate and evaluate the presented approach to show its practical feasibility based on a detailed case study, in particular considering the performance of the transformation toward TOSCA. Classification of DevOps artifacts and their usage.Integrated, standards-driven modeling & runtime framework based on TOSCA.Discovery, transformation, and APIfication of DevOps artifacts.Enrichment and deployment of application topologies.Evaluation of artifact transformation and comprehensive case study.;Cloud standards, TOSCA, Deployment automation, Transformation, DevOps, Cloud computing;;;
Conference Paper;Rahman A;Characteristics of Defective Infrastructure as Code Scripts in DevOps;;2018;;;476–479;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings;Gothenburg, Sweden;2018;9781450356633;;"https://doi-org.proxy.bnl.lu/10.1145/3183440.3183452;http://dx.doi.org/10.1145/3183440.3183452";10.1145/3183440.3183452;"Defects in infrastructure as code (IaC) scripts can have serious consequences for organizations who adopt DevOps. By identifying which characteristics of IaC scripts correlate with defects, we can identify anti-patterns, and help software practitioners make informed decisions on better development and maintenance of IaC scripts, and increase quality of IaC scripts. The goal of this paper is to help practitioners increase the quality of IaC scripts by identifying characteristics of IaC scripts and IaC development process that correlate with defects, and violate security and privacy objectives. We focus on characteristics of IaC scripts and IaC development that (i) correlate with IaC defects, and (ii) violate security and privacy-related objectives namely, confidentiality, availability, and integrity. For our initial studies, we mined open source version control systems from three organizations: Mozilla, Openstack, and Wikimedia, to identify the defect-related characteristics and conduct our case studies. From our empirical analysis, we identify (i) 14 IaC code and four churn characteristics that correlate with defects; and (ii) 12 process characteristics such as, frequency of changes, and ownership of IaC scripts that correlate with defects. We propose the following studies: (i) identify structural characteristics that correlate with defects; (ii) with respect to prediction performance, compare which characteristics of IaC scripts are more correlated with defects; and (iii) identify characteristics that violate security and privacy objectives.";metrics, infrastructure as code, defects, devops;;;ICSE '18
Conference Paper;Durak U,Öztürk A,Katircioglu M;Simulation Deployment Blockset for MATLAB/Simulink;;2016;;;;;Society for Computer Simulation International;San Diego, CA, USA;;Proceedings of the Symposium on Theory of Modeling & Simulation;Pasadena, California;2016;9781510823211;;;;Model-based approaches are being employed more and more in simulation development. Graphical modeling languages and code generation technologies are enabling agile model development workflows, so that simulation modelers can update their models more easily. However, the process from changing the model to releasing a new simulation version is overlooked. Simulation deployment can be defined as a collection of activities, including model checking, Model-in-the-Loop testing, code generation, build, Software-in-the-Loop testing, deployment, when applicable Processor-in-the-Loop and Hardware-in-the-Loop testing and release. When it is conducted manually and ad hoc, it is repetitive, labor intensive, time-consuming and error prone. The automation of deployment pipeline, on the other hand, requires extensive scripting, unfortunately, in way in which simulation modelers are usually not accustomed. Causal Block Diagrams propose a graphical modeling language that is extensively used in simulation of technical systems. MATLAB/Simulink supports them as the basic modeling language. Exploiting the competence of MATLAB/Simulink users on Causal Block Diagrams, this paper presents a model-based approach for automating the simulation deployment activities. Thus, rather than scripting, the deployment automation functions are made available and accessible to the simulation modelers within the graphical modeling environment that they are using.;model-based simulation systems engineering, continuous delivery, simulation deployment;;;TMS-DEVS '16
Journal Article;Limoncelli TA;SQL is No Excuse to Avoid DevOps;Commun. ACM;2018;62;1;46–49;;Association for Computing Machinery;New York, NY, USA;;;;2018-12;;0001-0782;"https://doi-org.proxy.bnl.lu/10.1145/3287299;http://dx.doi.org/10.1145/3287299";10.1145/3287299;Automation and a little discipline allow better testing, shorter release cycles, and reduced business risk.;;;;
Conference Paper;Caprarelli A,Di Nitto E,Tamburri DA;Fallacies and Pitfalls on the Road to DevOps: A Longitudinal Industrial Study;;2019;;;200–210;;Springer-Verlag;Berlin, Heidelberg;;Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Château de Villebrumier, France, May 6–8, 2019, Revised Selected Papers;Villebrumier, France;2019;9783030393052;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-39306-9_15;http://dx.doi.org/10.1007/978-3-030-39306-9_15";10.1007/978-3-030-39306-9_15;DevOps has come into play to help companies in improving their product delivery. This paper offers an overview of the fallacies and pitfalls faced in this context by engineers and operators in an industrial case-study. We reveal a total of 8 key fallacies and pitfalls that span the organisational structure, technical structures, as well as software process and delivery mechanisms in the target case-study. Practitioners can use these challenges as references for diagnosing their own scenario while planning their own potential DevOps process migration strategy.;DevOps quality, Organizational and technical aspects, Process migration;;;
Conference Paper;Betz C,Olagunju AO,Paulson P;The Impacts of Digital Transformation, Agile, and DevOps on Future IT Curricula;;2016;;;106;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 17th Annual Conference on Information Technology Education;Boston, Massachusetts, USA;2016;9781450344524;;"https://doi-org.proxy.bnl.lu/10.1145/2978192.2978205;http://dx.doi.org/10.1145/2978192.2978205";10.1145/2978192.2978205;Prior practices such as waterfall software development, project management, and IT process frameworks are being questioned, and workforce requirements changing in response. IT education must keep current with these digital trends. Present programs and curricula do not adequately meet the rapidly emerging demand for digitally-skilled professionals. To address this urgent need, the lightening talk discusses needs for digital transformation, Agile and DevOps skills. This lightening talk presents the first version of an IT curriculum reference guide recently developed for use in the Minnesota State Colleges and Universities system. The audience will be able to use this guide to embed digital and DevOps skills into new IT curriculum, modify existing IT curriculum, or develop new courses/programs for IT.;agile, it curriculum, devops, digital technology;;;SIGITE '16
Conference Paper;Kazerouni AM;Toward Continuous Assessment of the Programming Process;;2019;;;335–336;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2019 ACM Conference on International Computing Education Research;Toronto ON, Canada;2019;9781450361859;;"https://doi-org.proxy.bnl.lu/10.1145/3291279.3339429;http://dx.doi.org/10.1145/3291279.3339429";10.1145/3291279.3339429;Assessment of software tends to focus on postmortem evaluation of metrics like correctness, mergeability, and code coverage. This is evidenced in the current practices of continuous integration and deployment that focus on software's ability to pass unit tests before it can be merged into a deployment pipeline. However, little attention or tooling is given to the assessment of the software development process itself. Good process becomes both more challenging and more critical as software complexity increases. Real-time evaluation and feedback about a student's software development skills, such as incremental development, testing, and time management, could greatly increase productivity and improve the ability to write tested and correct code. In my research, I develop models to quantify a student's programming process in terms of these metrics. By measuring the programming process, I can empirically evaluate its adherence to known best practices in software engineering. With the ability to characterize this, I can build tools to provide them with intelligent and timely feedback when they are in danger of straying from those practices. In the long term, I hope to contribute to the standardization and adoption of continuous software assessment techniques that include not only the final product, but also the process undertaken to produce it.;incremental development, software testing, procrastination;;;ICER '19
Conference Paper;Kazerouni AM;Toward Continuous Assessment of the Programming Process: (Abstract Only);;2018;;;272;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 49th ACM Technical Symposium on Computer Science Education;Baltimore, Maryland, USA;2018;9781450351034;;"https://doi-org.proxy.bnl.lu/10.1145/3159450.3162337;http://dx.doi.org/10.1145/3159450.3162337";10.1145/3159450.3162337;Assessment of software tends to focus on postmortem evaluation of metrics like correctness, mergeability, and code coverage. This is evidenced in the current practices of continuous integration and deployment that focus on software's ability to pass unit tests before it can be merged into a deployment pipeline. However, little attention or tooling is given to the assessment of the software development process itself. Good process becomes both more challenging and more critical as software complexity increases. Real-time evaluation and feedback about a software developer's skills, such as incremental development, testing, and time management, could greatly increase productivity and improve the ability to write tested andcorrect code. My work focuses on the collection and analysis of fine-grained programming process data to help quantitatively model the programming process in terms of these metrics. I report on my research problem, presenting past work involving the collection and analysis of IDE event data from junior level students working on large and complex projects. The goal is to quantify the programming process in terms of incremental development and procrastination. I also present a long-term vision for my research and present work planned in the short term as a step toward that vision.;programming process, educational data mining, testing behavior, repository mining;;;SIGCSE '18
Conference Paper;Border C;Development of a Configuration Management Course for Operations Students;;2019;;;41;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 20th Annual SIG Conference on Information Technology Education;Tacoma, WA, USA;2019;9781450369213;;"https://doi-org.proxy.bnl.lu/10.1145/3349266.3351360;http://dx.doi.org/10.1145/3349266.3351360";10.1145/3349266.3351360;"In the recent past only a few of the ""Unicorn"" companies such as Facebook, Amazon, and Google were concerned about being able to deploy software into production on distributed computing architectures multiple times per day. To facilitate their ability to do this they developed a series of practices such as Continuous Integration/Continuous Deployment (CI/CD), Test Driven Development, Agile Development and DevOps. The goal of these techniques was to be able to get the work of their thousands of developers into production as quickly, safely, reliably and consistently as possible. Most other large-scale companies have since adopted as least some of these practices and they are considered standard procedure for most large organizations.The Operations side of deploying a modern computing application necessarily involves multiple groups working in concert to develop and test the application and the server side configuration that will support that application. This lightning talk reports on initial efforts to develop a course that encourages students to dig into issues related to configuration management, security policy development, application auditing, business control issues, and most importantly, team work. While the course is entitled ""Configuration Management"" it is much more about students creating a process for secure iterative application deployment that borrows extensively from the DevOps movement.";security, operations, devops, configuration management;;;SIGITE '19
Conference Paper;Bosch J;Architecting to Ensure Requirement Relevance: Keynote Twinpeaks Workshop;;2015;;;1–2;;IEEE Press;Florence, Italy;;Proceedings of the Fifth International Workshop on Twin Peaks of Requirements and Architecture;;2015;;;;;Research has shown that up to two thirds of features in software systems are hardly ever used or not even used at all. This represents a colossal waste of R&D resources and occurs across the industry. On the other hand, product management and many others work hard at interacting with customers, building business cases and prioritizing requirements. A fundamentally different approach to deciding what to build is required: requirements should be treated as hypothesis throughout the development process and constant feedback from users and systems in the field should be collected to dynamically reprioritize and change requirements. This requires architectural support beyond the current state of practice as continuous deployment, split testing and data collection need to be an integral part of the architecture. In this paper, we present a brief overview of our research and industry collaboration to address this challenge.;software architecture, requirements engineering, data-driven development;;;TwinPeaks '15
Journal Article;Xu Y,Koren I,Krishna CM;AdaFT: A Framework for Adaptive Fault Tolerance for Cyber-Physical Systems;ACM Trans. Embed. Comput. Syst.;2017;16;3;;;Association for Computing Machinery;New York, NY, USA;;;;2017-03;;1539-9087;"https://doi-org.proxy.bnl.lu/10.1145/2980763;http://dx.doi.org/10.1145/2980763";10.1145/2980763;Cyber-physical systems (CPS) frequently have to use massive redundancy to meet application requirements for high reliability. While such redundancy is required, it can be activated adaptively, based on the current state of the controlled plant. Most of the time, the plant is in a state that allows for a lower level of fault tolerance. Avoiding the continuous deployment of massive fault tolerance will greatly reduce the workload of the CPS, and lower the operating temperature of the cyber sub-system, thus increasing its reliability. In this article, we extend our prior research by demonstrating a software simulation framework Adaptive Fault Tolerance (AdaFT) that can automatically generate the sub-spaces within which our adaptive fault tolerance can be applied. We also show the theoretical benefits of AdaFT and its actual implementation in several real-world CPSs.;cyber-physical system, Fault tolerance, processor thermal reliability;;;
Conference Paper;Bosch J;Architecting to Ensure Requirement Relevance: Keynote TwinPeaks Workshop;;2015;;;1–2;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 5th International Workshop on the Twin Peaks of Requirements and Architecture;;2015;9781467371001;;"https://doi-org.proxy.bnl.lu/10.1109/TwinPeaks.2015.8;http://dx.doi.org/10.1109/TwinPeaks.2015.8";10.1109/TwinPeaks.2015.8;Research has shown that up to two thirds of features in software systems are hardly ever used or not even used at all. This represents a colossal waste of R&D resources and occurs across the industry. On the other hand, product management and many others work hard at interacting with customers, building business cases and prioritizing requirements. A fundamentally different approach to deciding what to build is required: requirements should be treated as hypothesis throughout the development process and constant feedback from users and systems in the field should be collected to dynamically reprioritize and change requirements. This requires architectural support beyond the current state of practice as continuous deployment, split testing and data collection need to be an integral part of the architecture. In this paper, we present a brief overview of our research and industry collaboration to address this challenge.;software architecture, data-driven development, requirements engineering;;;TWINPEAKS '15
Journal Article;Kalantar MH,Rosenberg F,Doran J,Eilam T,Elder MD,Oliveira F,Snible EC,Roth T;Weaver: Language and Runtime for Software Defined Environments;IBM J. Res. Dev.;2014;58;2–3;10;;IBM Corp.;USA;;;;2014-03;;0018-8646;"https://doi-org.proxy.bnl.lu/10.1147/JRD.2014.2304865;http://dx.doi.org/10.1147/JRD.2014.2304865";10.1147/JRD.2014.2304865;Continuous delivery of software and related infrastructure environments is a challenging proposition. Typical enterprise environments, comprising distributed software and its supporting infrastructure, exhibit non-obvious, often implicit dependencies and requirements. Further increasing this challenge is that knowledge about configuration is fragmented and informally recorded. Given this situation, we propose Weaver, a domain-specific language designed to formally specify blueprints, desired state descriptions of environments. An associated runtime executes blueprints to create or modify environments through a set of target-specific platform providers that supply cloud-specific implementations. New and existing automation to implement and maintain the desired state can be associated with a blueprint specified in Weaver. Furthermore, Weaver supports the definition of conditions to validate a blueprint at design time and deployment time, as well as to continuously validate a deployed environment. We demonstrate the use of Weaver to deploy IBM Connections, an enterprise social software platform.;;;;
Conference Paper;Bartusevics A,Novickis L;Model-Based Approach for Implementation of Software Configuration Management Process;;2015;;;177–184;;SCITEPRESS - Science and Technology Publications, Lda;Setubal, PRT;;Proceedings of the 3rd International Conference on Model-Driven Engineering and Software Development;ESEO, Angers, Loire Valley, France;2015;9789897580833;;"https://doi-org.proxy.bnl.lu/10.5220/0005228701770184;http://dx.doi.org/10.5220/0005228701770184";10.5220/0005228701770184;Software configuration management is a discipline that controls software evolution process. Nowadays this process is not only challenge to choose the best version control system o branching strategy for particular project. Together with source code management the following tasks should be solved: continuous integration, continuous delivery, release management, build management etc. Usually software development companies already have a set of tools to support mentioned processes. The main challenge is to adopt this solutions to new projects as soon as possible with minimum efforts of manual steps. The article provides new model-driven approach to increase reuse of existing solutions in configuration management area. In order to illustrate the approach, there were developed new meta-models that are purposed for development of different configuration management models in context of a model-driven approach. This article provides a simplified example to illustrate models and defines further researches.;Model-Driven Approach, Software Configuration Management, Models;;;MODELSWARD 2015
Book;Farcic V;The DevOps 2.3 Toolkit: Kubernetes Deploying and Managing Highly-Available and Fault-Tolerant Applications at Scale;;2018;;;;;Independently published;;;;;2018;9781980690139;;;;"The goal of this book is not to convince you to adopt Kubernetes but to provide a detailed overview of its features. I want you to become confident in your Kubernetes knowledge and only then choose whether to embrace it. That is, unless you already made up your mind and stumbled upon this book in search of Kubernetes guidance. The plan is to cover all aspect behind Kubernetes, from basic to advanced features. We'll go not only through the tools behind the official project but also third-party add-ons. I hope that, by the time you finish reading this book, you will be able to call yourself ""Kubernetes ninja"". I cannot say that you will know everything there is to know about the Kubernetes ecosystem. That would be impossible to accomplish since its growing faster than any single person could follow. What I can say is that you will be very confident in running a Kubernetes cluster of any scale in production. Like all my other books, this one is very hands-on. There will be just enough theory for you to understand the principles behind each topic. The book is packed with examples, so I need to give you a heads up. Do not buy this book if you're planning to read it on a bus or in bed before going to sleep. You will need to be in front of your computer. A terminal will be your best friend. `kubectl` will be your lover. The book assumes that you feel comfortable with containers, especially Docker. We won't go into details how to build an image, what is container registry, and how to write Dockerfile. I hope you already know all that. If that's not the case, you might want to postpone reading this and learn at least basic container operations. This book is about things that happen after you built your images and stored them in a registry. This book is about running containers at scale and not panicking when problems arise. It is about the present and the future of software deployment and monitoring. It's about embracing the challenges and staying ahead of the curve.";;;;
Conference Paper;Bosch J,Olsson HH;Data-Driven Continuous Evolution of Smart Systems;;2016;;;28–34;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 11th International Symposium on Software Engineering for Adaptive and Self-Managing Systems;Austin, Texas;2016;9781450341875;;"https://doi-org.proxy.bnl.lu/10.1145/2897053.2897066;http://dx.doi.org/10.1145/2897053.2897066";10.1145/2897053.2897066;As Marc Andreessen said in his Wall Street Journal OpEd, software is eating the world. The systems that we are building today and in the near future will exhibit levels of autonomy that will put new demands on the engineering of such systems. Although promising examples of autonomous systems exist, there is no established methodology for systematically building autonomous systems that employ modern software engineering technology such as continuous deployment and data-driven engineering. The contribution of this paper is twofold. First, it identifies and presents the challenge of continuous evolution of autonomous systems as a well-defined problem that needs to be addressed by software engineering research. Second, it presents a conceptual solution to this problem that integrates the development of new software for autonomous systems by R&D teams with systematic experimentation by autonomous systems.;split testing, data-driven development, continuous deployment, autonomous systems;;;SEAMS '16
Journal Article;Angara J,Prasad S,Sridevi G;DevOps Project Management Tools for Sprint Planning, Estimation and Execution Maturity;Cybern. Inf. Technol.;2020;20;2;79–92;;Walter de Gruyter GmbH;Berlin, DEU;;;;2020-06;;1314-4081;"https://doi-org.proxy.bnl.lu/10.2478/cait-2020-0018;http://dx.doi.org/10.2478/cait-2020-0018";10.2478/cait-2020-0018;The goal of DevOps is to cut down the project timelines, increase the productivity, and manage rapid development-deployment cycles without impacting business and quality. It requires efficient sprint management. The objective of this paper is to develop different sprint level project management tools for quick project level Go/No-Go decision making (using real-time projects data and machine learning), sprint estimation technique (gamified-consensus based), statistical understanding of overall project management maturity, project sentiment & perception. An attempt is made to device a model to calibrate the perception or the tone of a project culture using sentiment analysis.;planning poker, DevOps, sentimental analysis, Machine Learning (ML), effort estimation;;;
Journal Article;Limoncelli TA;SQL is No Excuse to Avoid DevOps: Automation and a Little Discipline Allow Better Testing, Shorter Release Cycles, and Reduced Business Risk;Queue;2018;16;5;12–23;;Association for Computing Machinery;New York, NY, USA;;;;2018-10;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/3291276.3300018;http://dx.doi.org/10.1145/3291276.3300018";10.1145/3291276.3300018;Using SQL databases is not an impediment to doing DevOps. Automating schema management and a little developer discipline enables more vigorous and repeatable testing, shorter release cycles, and reduced business risk. When you can confidently deploy new releases, you do it more frequently. New features that previously sat unreleased for weeks or months now reach users sooner. Bugs are fixed faster. Security holes are closed sooner. It enables the company to provide better value to customers.;;;;
Conference Paper;Ugarte Querejeta M,Etxeberria L,Sagardui G;Towards a DevOps Approach in Cyber Physical Production Systems Using Digital Twins;;2020;;;205–216;;Springer-Verlag;Berlin, Heidelberg;;Computer Safety, Reliability, and Security. SAFECOMP 2020 Workshops: DECSoS 2020, DepDevOps 2020, USDAI 2020, and WAISE 2020, Lisbon, Portugal, September 15, 2020, Proceedings;Lisbon, Portugal;2020;9783030555825;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-55583-2_15;http://dx.doi.org/10.1007/978-3-030-55583-2_15";10.1007/978-3-030-55583-2_15;Nowadays product manufacturing must respond to mass customisation of products in order to meet the global market needs. This requires an agile and dynamic production process to be competitive in the market. Consequently, the need of factory digitalisation arises with the introduction of Industry 4.0. One example of the digitalisation is the digital twin. Digital twin enhances flexibility due to its adaptability and seamless interaction between the physical system and its virtual model. Furthermore, it bridges the gap between development and operations through the whole product life cycle. Therefore, digital twin can be an enabler for the DevOps application in cyber physical production systems as DevOps aims at merging Development and Operations to provide a continuous and an agile process. This paper analyses the use of the digital twin to enable a DevOps approach of cyber physical production systems (CPPS) in order to create a fully integrated and automated production process, enabling continuous improvement.;DevOps, Cyber physical production system, Digital twin, Life cycle;;;
Conference Paper;Rana R,Durisic D,Jan-Stol K,Staron M;Session Details: Emerging Trends in DevOps and Infrastructure;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Scientific Workshop Proceedings of XP2016;Edinburgh, Scotland, UK;2016;9781450341349;;"https://doi-org.proxy.bnl.lu/10.1145/3248743;http://dx.doi.org/10.1145/3248743";10.1145/3248743;;;;;XP '16 Workshops
Journal Article;Zdun U,Wittern E,Leitner P;Emerging Trends, Challenges, and Experiences in DevOps and Microservice APIs;IEEE Softw.;2020;37;1;87–91;;IEEE Computer Society Press;Washington, DC, USA;;;;2020-01;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2019.2947982;http://dx.doi.org/10.1109/MS.2019.2947982";10.1109/MS.2019.2947982;"In August 2019, we organized the second Vienna Software Seminar (VSS) with the topic ""DevOps and Microservice APIs.""1 Embracing the positive reception of its first iteration in 2017,2 VSS is an opportunity for attendees to discuss recent software technologies, practices, and related research. The seminar's 34 participants included a mix of practitioners and academics, who were invited based on their roles and experiences. The explicit intention of the seminar was to provide ample opportunities for exchange and communication: six themed sessions consisted of one invited keynote and two lightning talks, giving different perspectives on the session?s topic and (ideally) sparking ideas for follow-up discussions. After the talks, all participants decided on subtopics for two to three breakout sessions (i.e., informal, self-organized discussions among interested participants). Breakout session topics included microservice security, tooling for application programming interface (API) evolution, serverless programming models, and identification of microservices using domaindriven design. The sessions provided opportunities for detailed discussions and identifying challenges to address in future collaborations. Toward the end of each session, all participants gathered once more to summarize the breakout discussions. Additional opportunities for communication were provided during shared lunch breaks and social events in the evenings.";;;;
Journal Article;Ben Mesmia W,Escheikh M,Barkaoui K;DevOps Workflow Verification and Duration Prediction Using Non‐Markovian Stochastic Petri Nets;J. Softw. Evol. Process;2021;33;3;;;John Wiley & Sons, Inc.;USA;;;;2021-03;;2047-7473;"https://doi-org.proxy.bnl.lu/10.1002/smr.2329;http://dx.doi.org/10.1002/smr.2329";10.1002/smr.2329;In this paper, we provide a non‐Markovian Stochastic Petri Net (SPN) model for DevOps workflow specification, and we determine how business processes are carried out. After describing our model semantics, we show how general properties related to liveness and safety can be checked. After that, we provide several extensions on SPNs (SPN) the notation and expressivity to check some specific properties related to actors' (Developers and Operators) availability, interactions between the actors, and execution failures detection linked to the DevOps steps. Next, we validate the proposed model relevance with MATLAB simulation through a specific DevOps case study. Finally, we propose a truncated density function to anticipate the delays related to the DevOps business process overall steps.;NM‐WSPN, DevOps, workflow, verification, specification, prediction;;;
Conference Paper;Barros DD,Horita F,Fantinato DG;Data Mining Tool to Discover DevOps Trends from Public Repositories: Predicting Release Candidates with Gthbmining.Rc;;2020;;;658–663;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 34th Brazilian Symposium on Software Engineering;Natal, Brazil;2020;9781450387538;;"https://doi-org.proxy.bnl.lu/10.1145/3422392.3422501;http://dx.doi.org/10.1145/3422392.3422501";10.1145/3422392.3422501;Public repositories have been performing an essential role in bringing software and services to technical communities and general users. Most of the cases, public repositories have a DevOps tool, with a live and historical database behind it, to support delivering and all steps this software or service should adopt before going to production. This paper introduces gthbmining, a data mining set of tools to discover DevOps trends from public repositories, and presents the module gthbmining.rc. Considering the premise of a GitHub public repository, the main contribution here is predicting release candidates, an important label a software release has. The methodology, architecture, components and interfaces are explained, as well as potential users. The results show a reliable and flexible tool, as classifiers metrics and graphics are provided, along with the possibility to add new data mining algorithms in the open source module presented. Related works are also supplied, and a conclusion shows the outcomes gthbmining.rc can provide.;DevOps, GitHub Mining Tool, Release Candidate, Data Mining;;;SBES '20
Journal Article;Pawlish MJ,Varde AS;The DevOps Paradigm with Cloud Data Analytics for Green Business Applications;SIGKDD Explor. Newsl.;2018;20;1;51–59;;Association for Computing Machinery;New York, NY, USA;;;;2018-05;;1931-0145;"https://doi-org.proxy.bnl.lu/10.1145/3229329.3229334;http://dx.doi.org/10.1145/3229329.3229334";10.1145/3229329.3229334;This paper reviews the emergence of the DevOps (development and operations) paradigm in the industry and the influence it has along with cloud based data management and analytics in the greening of business applications. It considers the geoscience domain as an example discussing usefulness in a GIS (geographic information system). Similar claims can be applied to other domains. Investigating the emergence of DevOps technologies and examining the dramatic shift in IT towards cloud and hybrid models for data analytics, the paper paints a picture of systems that have the ability to green their impact on society. It also addresses concerns from a privacy and security perspective and concludes with open issues for further research.;Security, DevOps, Hybrid Models, Privacy, Geoscience, Cloud Computing, Green Energy;;;
Conference Paper;Murphy GC;Is Continuous Adoption in Software Engineering Achievable and Desirable?;;2016;;;8;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 38th International Conference on Software Engineering Companion;Austin, Texas;2016;9781450342056;;"https://doi-org.proxy.bnl.lu/10.1145/2889160.2893462;http://dx.doi.org/10.1145/2889160.2893462";10.1145/2889160.2893462;Continuity in software development is all about shortening cycle times. For example, continuous integration shortens the time to integrating changes from multiple developers and continuous delivery shortens the time to get those integrated changes into the hands of users. Although it is now possible to get multiple new versions of complex software systems released per day, it still often takes years, if ever, to get software engineering research results into use by software development teams. What would software engineering research and software engineering development look like if we could shorten the cycle time from taking a research result into practice? What can we learn from how continuity in development is performed to make it possible to achieve continuous adoption of research results? Do we even want to achieve continuous adoption? In this talk, I will explore these questions, drawing from experiences I have gained in helping to take a research idea to market and from insights learned from interviewing industry leaders.;;;;ICSE '16
Conference Paper;Sánchez-Gordón M,Colomo-Palacios R;A Multivocal Literature Review on the Use of DevOps for E-Learning Systems;;2018;;;883–888;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Sixth International Conference on Technological Ecosystems for Enhancing Multiculturality;Salamanca, Spain;2018;9781450365185;;"https://doi-org.proxy.bnl.lu/10.1145/3284179.3284328;http://dx.doi.org/10.1145/3284179.3284328";10.1145/3284179.3284328;DevOps is an approach to reduce software development times by integrating a set of tools in order to get a better and automated transition towards production. DevOps is highly connected to tools and to Cloud Computing. On the other hand, e-Learning tools are also evolving towards the cloud. In this scenario, the connection of this two research fields seems to be promising. However, to the best of authors' knowledge the interaction of both has not been studied in deep. To bridge this gap, in this paper, a multivocal literature review is presented. By means of this systematic approach, authors analyze scientific and professional literature on the topic. Results reveal a nascent but still modest interest in DevOps in e-Learning solutions. Authors believe that the increasing adoption of cloud e-Learning solutions and the increasing pressure to deploy new versions of software with boost the interest in this research field.;DevOps, multivocal literature review, learning management systems, E-Learning systems;;;TEEM'18
Book;Garverick J;Migrating to Azure: Transforming Legacy Applications into Scalable Cloud-First Solutions;;2018;;;;1st;Apress;USA;;;;2018;9781484235843;;;;Design an enterprise solution from scratch that allows the migration of a legacy application. Begin with the planning and design phase and be guided through all the stages of selecting the architecture framework that fits your enterprise. Join Microsoft MVP Josh Garverick as he addresses all major areas of design and implementation application, infrastructure, data, security, and deployment while leveraging the power and tools of Visual Studio Team Services (VSTS) to bring DevOps to the forefront. With an emphasis on principles and best practices of enterprise design, you will discover how to recognize existing patterns within the legacy platform and to identify potential risks, bottlenecks, and candidates for automation. What Youll Learn Accurately and completely capture baseline information about a legacy system Leverage enterprise patterns for constructing next-generation platforms in the cloud Design, plan, and implement deployment pipelines to enable continuous delivery Identify and implement cloud-based platform components to reduce total cost of ownership Understand testing and validation: iterative component authoring, monitoring, deployment, and performance Price and perform capacity planning for cloud-based infrastructure and workloads Who This Book Is For Enterprise architects and IT professionals who are required to keep legacy applications relevant in todays cloud-first world;;;;
Conference Paper;John W,Meirosu C,Pechenot B,Sköldström P,Kreuger P,Steinert R;Scalable Software Defined Monitoring for Service Provider DevOps;;2015;;;61–66;;IEEE Computer Society;USA;;Proceedings of the 2015 Fourth European Workshop on Software Defined Networks;;2015;9781509001804;;"https://doi-org.proxy.bnl.lu/10.1109/EWSDN.2015.62;http://dx.doi.org/10.1109/EWSDN.2015.62";10.1109/EWSDN.2015.62;Technology trends such as Cloud, SDN, and NFV are transforming the telecommunications business, promising higher service flexibility and faster deployment times. They also allow for increased programmability of the infrastructure layers. We propose to split selected monitoring control functionality onto node-local control planes, thereby taking advantage of processing capabilities on programmable nodes. Our software defined monitoring approach provides telecom operators with a way to handle the trade off between high-granular monitoring information versus network and computation loads at central control and management layers. To illustrate the concept, a link rate monitoring function is implemented using node-local control plane components. Furthermore, we introduce a messaging bus for simple and flexible communication between monitoring function components as well as control and management systems. We investigate scalability gains with a numerical analysis, demonstrating that our approach would generate thousand fold less monitoring traffic while providing similar information granularity as a naive SNMP implementation or an Open Flow approach.;management, scalability, NFV, monitoring, SDN;;;EWSDN '15
Conference Paper;Cheng Y,Li X,Li Z,Jiang S,Li Y,Jia J,Jiang X;AirCloud: A Cloud-Based Air-Quality Monitoring System for Everyone;;2014;;;251–265;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 12th ACM Conference on Embedded Network Sensor Systems;Memphis, Tennessee;2014;9781450331432;;"https://doi-org.proxy.bnl.lu/10.1145/2668332.2668346;http://dx.doi.org/10.1145/2668332.2668346";10.1145/2668332.2668346;We present the design, implementation, and evaluation of AirCloud -- a novel client-cloud system for pervasive and personal air-quality monitoring at low cost. At the frontend, we create two types of Internet-connected particulate matter (PM2:5) monitors -- AQM and miniAQM, with carefully designed mechanical structures for optimal air-flow. On the cloud-side, we create an air-quality analytics engine that learn and create models of air-quality based on a fusion of sensor data. This engine is used to calibrate AQMs and mini-AQMs in real-time, and infer PM2:5 concentrations. We evaluate AirCloud using 5 months of data and 2 month of continuous deployment, and show that AirCloud is able to achieve good accuracies at much lower cost than previous solutions. We also show three real applications built on top of AirCloud by 3rd party developers to further demonstrate the value of our system.;client-cloud calibration system, air quality, PM2.5;;;SenSys '14
Journal Article;Perez-Palacin D,Merseguer J,Requeno JI,Guerriero M,Di Nitto E,Tamburri DA;A UML Profile for the Design, Quality Assessment and Deployment of Data-Intensive Applications;Softw. Syst. Model.;2019;18;6;3577–3614;;Springer-Verlag;Berlin, Heidelberg;;;;2019-12;;1619-1366;"https://doi-org.proxy.bnl.lu/10.1007/s10270-019-00730-3;http://dx.doi.org/10.1007/s10270-019-00730-3";10.1007/s10270-019-00730-3;Big Data or Data-Intensive applications (DIAs) seek to mine, manipulate, extract or otherwise exploit the potential intelligence hidden behind Big Data. However, several practitioner surveys remark that DIAs potential is still untapped because of very difficult and costly design, quality assessment and continuous refinement. To address the above shortcoming, we propose the use of a UML domain-specific modeling language or profile specifically tailored to support the design, assessment and continuous deployment of DIAs. This article illustrates our DIA-specific profile and outlines its usage in the context of DIA performance engineering and deployment. For DIA performance engineering, we rely on the Apache Hadoop technology, while for DIA deployment, we leverage the TOSCA language. We conclude that the proposed profile offers a powerful language for data-intensive software and systems modeling, quality evaluation and automated deployment of DIAs on private or public clouds.;Apache Hadoop, Big Data, Profile, TOSCA language, Performance assessment, Data-intensive applications, Model-driven deployment, Software design, UML;;;
Book Chapter;Júnior E,Farias K,Silva B;A Survey on the Use of UML in the Brazilian Industry;;2021;;;275–284;;Association for Computing Machinery;New York, NY, USA;Brazilian Symposium on Software Engineering;;;2021;9781450390613;;https://doi-org.proxy.bnl.lu/10.1145/3474624.3474632;;Although UML modeling has been used in the Brazilian industry in the last decade, little is known about the factors, perceptions of professionals and practices that end up affecting the UML use in real-world projects. This paper, therefore, reports on an exploratory survey focused on investigating how UML is used in practice in the Brazilian software industry. In total, 314 practitioners from 180 information technology companies answered an online questionnaire about the usage-affecting factors, difficulty and frequency of use, perceived benefits, and adoption-preventi ng contextual factors of UML models. Moreover, 20 practitioners participated in a semi-structured interview. The results show that the participants recognize the usefulness of the UML models, e.g., allowing an improved understanding of the integration among enterprise applications. However, 74.8% of the participants did not use UML models due to some factors such as continuous delivery practices, time constraints, lack of knowledge about modeling, company culture, and the ever-present difficulty of keeping the models updated and synchronized.;;;;
Conference Paper;Křikava F,Rouvoy R,Seinturier L;Infrastructure as Runtime Models: Towards Model-Driven Resource Management;;2015;;;100–105;;IEEE Press;Ottawa, Ontario, Canada;;Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems;;2015;9781467369084;;;;The importance of continuous delivery and the emergence of tools allowing to treat infrastructure configurations programmatically have revolutionized the way computing resources and software systems are managed. However, these tools keep lacking an explicit model representation of underlying resources making it difficult to introspect, verify or reconfigure the system in response to external events.In this paper, we outline a novel approach that treats system infrastructure as explicit runtime models. A key benefit of using such models@run.time representation is that it provides a uniform semantic foundation for resources monitoring and reconfiguration. Adopting models at runtime allows one to integrate different aspects of system management, such as resource monitoring and subsequent verification into an unified view which would otherwise have to be done manually and require to use different tools. It also simplifies the development of various self-adaptation strategies without requiring the engineers and researchers to cope with low-level system complexities.;;;;MODELS '15
Conference Paper;Dan A,Sitaram D;An Online Video Placement Policy Based on Bandwidth to Space Ratio (BSR);;1995;;;376–385;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data;San Jose, California, USA;1995;9780897917315;;"https://doi-org.proxy.bnl.lu/10.1145/223784.223853;http://dx.doi.org/10.1145/223784.223853";10.1145/223784.223853;In a video-on-demand server, resource reservation is required to guarantee continuous delivery. Hence any given storage device (or a striping group treated as a single logical device) can serve only up to a fixed number of client access streams. Each storage device is also limited by the number of video files it can store. For the reasons of availability, incremental growth, and heterogeneity, there may be multiple storage devices in a video server environment. Hence, one or more copies of a particular video may be placed on different storage devices. Since the access rates to different videos are not uniform, there may be load imbalance among the devices. In this paper, we propose a dynamic placement policy (called the Bandwidth to Space Ratio (BSR) Policy) that creates and/or deletes replica of a video, and mixes hot and cold videos so as to make the best use of bandwidth and space of a storage device. The proposed policy is evaluated using a simulation study.;;;;SIGMOD '95
Book;Acetozi J;Pro Java Clustering and Scalability: Building Real-Time Apps with Spring, Cassandra, Redis, WebSocket and RabbitMQ;;2017;;;;1st;Apress;USA;;;;2017;9781484229842;;;;Build clustered and scalable Java-based, real-time applications using Spring Framework, Boot, WebSocket, Cassandra, Redis and RabbitMQ. In this book, you'll tie all this together with a dive-in case study, a real-time scalable chat application under differing scenarios. Pro Java Clustering and Scalability also discusses how to horizontally scale the WebSocket chat application using a full STOMP broker such as RabbitMQ. Although this is a programming book, it also discusses many interesting infrastructure topics and tips about continuous delivery, Docker, NoSQL (Cassandra and Redis) and other related technologies. What You Will Learn Handle clustering and scalability using various open source Java, microservices, and web services tools and technologies Use Spring Framework, Boot, and other Spring technologies Integrate with Redis, RabbitMQ, Cassandra, NoSQL, and much more Test the case study code under various scenarios and stresses Who This Book Is For Experienced Java developers with at least some prior experience with Java, especially Spring Framework, Boot and other tools, and some web services.;;;;
Conference Paper;Krusche S,Bruegge B;CSEPM: A Continuous Software Engineering Process Metamodel;;2017;;;2–8;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 3rd International Workshop on Rapid Continuous Software Engineering;;2017;9781538604281;;;;Software engineers have to cope with uncertainties and changing requirements. Agile methods provide flexibility towards changes and the emergence of continuous delivery has made regular feedback loops possible. The abilities to maintain high code quality through reviews, to regularly release software, and to collect and prioritize user feedback, are necessary for continuous software engineering (CSE). However, there exists no software process metamodel that handles the continuous character of software engineering.In this paper, we describe an empirical process metamodel for continuous software engineering called CSEPM, which treats development activities as parallel running workflows and allows tailoring and customization. CSEPM includes static aspects that describe the relations between specific CSE concepts including reviews, releases, and feedback. It also describes the dynamic aspect of CSE, how development workflows are activated through change events. We show how CSEPM allows to instantiate linear, iterative, agile and continuous process models and how it enables tailoring and customization.;process model, change, review, release, event, feedback, workflow, agile methods;;;RCoSE '17
Conference Paper;Van Landuyt D,Walraven S,Joosen W;Variability Middleware for Multi-Tenant SaaS Applications: A Research Roadmap for Service Lines;;2015;;;211–215;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th International Conference on Software Product Line;Nashville, Tennessee;2015;9781450336130;;"https://doi-org.proxy.bnl.lu/10.1145/2791060.2791080;http://dx.doi.org/10.1145/2791060.2791080";10.1145/2791060.2791080;Software product line engineering (SPLE) and variability enforcement techniques have been applied to run-time adaptive systems for quite some years, also in the context of multi-tenant Software-as-a-Service (SaaS) applications. The focus has been mainly on (1) the pre-deployment phases of the development life cycle and (2) fine-grained (tenant-level), run-time activation of specific variants. However, with upcoming trends such as DevOps and continuous delivery and deployment, operational aspects become increasingly important.In this paper, we present our integrated vision on the positive interplay between SPLE and adaptive middleware for multi-tenant SaaS applications, focusing on the operational aspects of running and maintaining a successful SaaS offering. This vision, called Service Lines, is based on and motivated by our experience and frequent interactions with a number of Belgian SaaS providers.We concretely highlight and motivate a number of operational use cases that require advanced variability support in middleware and have promising added value for the economic feasibility of SaaS offerings. In addition, we provide a gap analysis of what is currently lacking from the perspectives of variability modeling and management techniques and middleware support, and as such sketch a concrete roadmap for continued research in this area.;models at run time, multi-tenant SaaS, operational support, run-time variability, variability middleware, service lines;;;SPLC '15
Book;Dalcher D;Rethinking Software Development: The Case for a Dynamic Life Cycle Model;;2012;;;;;LAP Lambert Academic Publishing;Koln, DEU;;;;2012;9783843390095;;;;"Contemporary software development is characterised by failures, runaway projects, late delivery, exceeded budgets, reduced functionality and questionable quality. Generally, as the complexity and scale of attempted projects increases, the ability to bring such projects to a successful completion decreases. Indeed, while the software engineering community is technically capable of producing software, there is a growing lack of confidence in its ability to control such undertakings. A key obstacle is that traditional software development is predicated on constraints and limitations that are either no longer valid or that pertain to well-structured situations. Many of the problems tackled by software developers are simply not of that type. Rethinking Software Development, a reprint of the original work which still maintains its relevance, challenges the dominant mindset and introduces an alternative; a more pluralistic perspective supportive of continuous delivery, learning and dynamic resolution processes. The discussion explores problem solving, decisions, wicked problems, systems, design, change, economics, complexity and knowledge as part of the search for lasting solutions.";;;;
Book;Smart JF;Jenkins: The Definitive Guide;;2011;;;;;O'Reilly Media, Inc.;;;;;2011;9781449305352;;;;Streamline software development with Jenkins, the popular Java-based open source tool that has revolutionized the way teams think about Continuous Integration (CI). This complete guide shows you how to automate your build, integration, release, and deployment processes with Jenkinsand demonstrates how CI can save you time, money, and many headaches. Ideal for developers, software architects, and project managers, Jenkins: The Definitive Guide is both a CI tutorial and a comprehensive Jenkins reference. Through its wealth of best practices and real-world tips, you'll discover how easy it is to set up a CI service with Jenkins. Learn how to install, configure, and secure your Jenkins server Organize and monitor general-purpose build jobs Integrate automated tests to verify builds, and set up code quality reporting Establish effective team notification strategies and techniques Configure build pipelines, parameterized jobs, matrix builds, and other advanced jobs Manage a farm of Jenkins servers to run distributed builds Implement automated deployment and continuous delivery;;;;
Journal Article;Mahmoud HH,Amer AA,Ismail T;6G: A Comprehensive Survey on Technologies, Applications, Challenges, and Research Problems;Trans. Emerg. Telecommun. Technol.;2021;32;4;;;John Wiley & Sons, Inc.;USA;;;;2021-04;;2161-3915;"https://doi-org.proxy.bnl.lu/10.1002/ett.4233;http://dx.doi.org/10.1002/ett.4233";10.1002/ett.4233;The inherent limitations of the network keep on going to be revealed with the continuous deployment of cellular networks. The next generation 6G is motivated by these drawbacks to properly integrate important rate‐hungry applications such as extended reality, wireless brain‐computer interactions, autonomous vehicles, and so on. Also, to support significant applications, 6G will handle large amounts of data transmission in smart cities with much lower latency. It combines many state‐of‐the‐art trends and technology to provide higher data rates for ultra‐reliable and low latency communications. By outlining the system requirements, potential trends, technologies, services, applications, and research progress, this article comprehensively conceptualized the 6G cellular system. Open research issues and current research groups in their field of research are summarized to provide readers with the technology road‐map and the potential challenges to consider in their 6G research.The next generation 6G is motivated by these drawbacks to properly integrate important rate‐hungry applications such as 6G, driving technologies, telecommunications, augmented reality applications, mobile edge computing, quantum communications, millimeter‐wave, and optical wireless communications. image;;;;
Conference Paper;Wiedemann A,Wiesche M,Krcmar H;Integrating Development and Operations in Cross-Functional Teams - Toward a DevOps Competency Model;;2019;;;14–19;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2019 on Computers and People Research Conference;Nashville, TN, USA;2019;9781450360883;;"https://doi-org.proxy.bnl.lu/10.1145/3322385.3322400;http://dx.doi.org/10.1145/3322385.3322400";10.1145/3322385.3322400;The integration of cross-functional teams for new product development is still an elusive aim. Cross-functional information technology (IT) teams are used to provide new initiatives in fast-changing and challenging environments. Moreover, concepts such as Development and Operations (DevOps) appear in practice and bring software development and operations tasks in one team. Organizations are currently searching for necessary, suitable competencies for setting up high collaborative cross-functional teams that manage the tasks of the software delivery lifecycle. Therefore, in this paper, employing a multi-perspective research approach, we conducted a workshop and a multiple-case study. Hence, this paper presents a competency model for enabling a high level of collaboration within a team and explains how these competencies are implemented in IT functions. Additionally, we identified six competencies and two major challenges associated with DevOps team setups.;organizational transformation, competency model, devops, multiple-case study;;;SIGMIS-CPR '19
Conference Paper;Moltchanov B,Rocha OR;Cloud Wave Smart Middleware for DevOps in Clouds;;2014;;;835–837;;IEEE Computer Society;USA;;Proceedings of the 2014 IEEE 11th Intl Conf on Ubiquitous Intelligence and Computing and 2014 IEEE 11th Intl Conf on Autonomic and Trusted Computing and 2014 IEEE 14th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom);;2014;9781479976461;;"https://doi-org.proxy.bnl.lu/10.1109/UIC-ATC-ScalCom.2014.47;http://dx.doi.org/10.1109/UIC-ATC-ScalCom.2014.47";10.1109/UIC-ATC-ScalCom.2014.47;Nowadays the IT Clouds are used to provide services and run applications (in a flexible and scalable way) where the entire lifecycle of the application or service is under the control of the Cloud Management Subsystem that is able to automatically and autonomously start, stop, restart a server or an application. Additionally, it is able to determine when a certain application or service is running under overload conditions and reduce the load by adding additional virtual machines hosting the affected software or releasing the resources not used anymore. These are classic operations performed by nowadays Clouds. However little effort has been dedicated to support a developer during the application development process or during the service execution by changing the application behavior dependently on the service's components response and availability. The Cloud Wave project founded by the European Commission within the FP7 Research Program aims to contribute on these underdeveloped concepts. It contributes to the development process of a service or application in a feedback-driven way and also to the service execution by adapting the service accordingly to the execution environment and condition changes.;cloud, adaptation, feedback, monitoring, application, service;;;UIC-ATC-SCALCOM '14
Conference Paper;Christensen HB;Teaching DevOps and Cloud Computing Using a Cognitive Apprenticeship and Story-Telling Approach;;2016;;;174–179;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education;Arequipa, Peru;2016;9781450342315;;"https://doi-org.proxy.bnl.lu/10.1145/2899415.2899426;http://dx.doi.org/10.1145/2899415.2899426";10.1145/2899415.2899426;DevOps is a new way of developing software that is challenging from a teaching perspective. In this paper, we outline these challenges and propose teaching methods that focus on skill acquisition and technical practices that focus on performant virtualization to overcome them. We describe central elements from our course Cloud Computing and Architecture that has been designed and executed upon these methods and practices and report our experiences and lessons learned.;cloud computing, course design, programming education, virtualization, devops;;;ITiCSE '16
Conference Paper;Cruz-Filipe L,Di Nitto E,Mauro J;Session Details: Theme: Distributed Systems: MiDOS - Microservices, DevOps, and Service-Oriented Architecture Track;;2019;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing;Limassol, Cyprus;2019;9781450359337;;"https://doi-org.proxy.bnl.lu/10.1145/3329379;http://dx.doi.org/10.1145/3329379";10.1145/3329379;Service-oriented architectures have changed our vision of the Web, bringing a paradigmatic shift in the methodologies when designing and implementing distributed systems. Originally, the Web was mainly seen as a means of presenting information to a wide spectrum of people, but service-oriented programming triggered a radical transformation of the Web towards a computational fabric where loosely coupled services interact, can be discovered and then invoked. More recently, the microservices architectural style has been proposed, where applications are developed as a collection of fine-grained services running as independent processes. Distributed applications can then be constructed from independently deployable services taking advantage of the properties of the microservice architecture (e.g., flexibility, maintainability, reusability, compositionality, and scalability) as well as the elasticity of cloud infrastructure. From the practical point of view, the deployment and maintenance of (micro)services architectures are performed using DevOps, i.e., a collection of practices linking software development (Dev) with software operations (Ops). DevOps strongly advocates for automation and monitoring at all steps of software construction, from integration, testing, releasing to deployment and infrastructure management. By using the DevOps methodology, it is possible to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality.;;;;SAC '19
Book Chapter;Meedeniya D,Thennakoon H;Impact Factors and Best Practices to Improve Effort Estimation Strategies and Practices in DevOps;;2021;;;11–17;;Association for Computing Machinery;New York, NY, USA;2021 The 11th International Conference on Information Communication and Management;;;2021;9781450390194;;https://doi-org.proxy.bnl.lu/10.1145/3484399.3484401;;"Effort estimation plays an important role in the software development process by supporting the decision-making process for the stakeholders. DevOps has become a widely used software engineering practice with the collaboration of the development and operational teams. This paper addresses the factors that affect the effort estimation strategies and practices in DevOps based software development in Sri Lanka. This study explains the research approach, generation of the conceptual model and the quantitative data analysis process in detail. A survey is conducted among the software professionals who are working in DevOps-based software development in the Sri Lanka IT industry and a detailed data analysis is performed using statistical techniques to identify the reliability, correlation and significance of the considered factors. With an extensive analysis the independent variables namely, exploration, communication, and technology stack are identified as highly impacted factors to the effort estimation in DevOps-based software development. We also provide recommendations for the effort estimation strategies and practices; hence the managerial decision can be made for the improvements of the development process.";;;;
Conference Paper;Caraturan SB,Goya DH;Major Challenges of Systems-of-Systems with Cloud and DevOps: A Financial Experience Report;;2019;;;10–17;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 7th International Workshop on Software Engineering for Systems-of-Systems and 13th Workshop on Distributed Software Development, Software Ecosystems and Systems-of-Systems;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/SESoS/WDES.2019.00010;http://dx.doi.org/10.1109/SESoS/WDES.2019.00010";10.1109/SESoS/WDES.2019.00010;The term Systems-of-Systems (SoS) refers to a complex system that comprises other systems (the constituent systems), which have operational and managerial independence, geographical distribution, emergent behavior, and evolutionary development processes. DevSecOps (or SecDevOps) offers an approach to guide the implementation of IT Processes, which in turn may support the integration of a cloud environment to a systems-of-systems environment, incorporating information security practices, as well as fostering collaboration between both development and operation teams. It also aims to promote automation of IT processes so that the development of applications and / or services is fast and secure. However, there is a lack of detail in the process definitions to guide the implementation and use of DevSecOps in a Systems-of-Systems environment, especially when it is intended to merge cloud computing into pre-existing conventional infrastructures. In this context, this paper aims at describe the main actions, concerns and lessons learned, during planning and implementation phases, about IT Processes and IT Governance Model to transform an IT traditional environment into Systems-of-Systems environment, considering DevSecOps standards in a large Brazilian financial institution. It will show how IT Processes and IT Governance Model should be changed for incorporating a Cloud environment to a SoS. For doing so, we proposed the use of DevOps techniques as a means to reduce development time without to affect the quality and information security.;IT governance, DevSecOps, systems-of-systems, financial institution, cloud, IT processes;;;SESoS-WDES '19
Conference Paper;Xu X,Zhu L,Fu M,Sun D,Tran AB,Rimba P,Dwarakanathan S,Bass L;Crying Wolf and Meaning It: Reducing False Alarms in Monitoring of Sporadic Operations through POD-Monitor;;2015;;;69–75;;IEEE Press;Florence, Italy;;Proceedings of the First International Workshop on Complex FaUlts and Failures in LargE Software Systems;;2015;;;;;"When monitoring complex applications in cloud systems, a difficult problem for operators is receiving false positive alarms. This becomes worse when the system is sporadically being changed and upgraded due to the emerging continuous deployment practice. Other legitimate but sporadic maintenance operations, such as log compression, garbage collection and data reconstruction in distributed systems can also trigger false alarms. Consequently, traditional baseline-based anomaly detection and monitoring is less effective. A normal but dangerous practice is to turn off normal monitoring during sporadic operations such as upgrade and maintenance. In this paper, we report on the use of the process context information of sporadic operations to suppress false positive alarms. We use the context information both directly and in machine learning. Our experimental evaluation shows that 1) using process context directly improves the alarm precision up to 0.226 (36.1% improvement); 2) using process-context trained machine learning models improves the precision rate up to 0.421 (84.7% improvement).";monitoring, alarm, operation;;;COUFLESS '15
Conference Paper;Günalp O,Gürgen L,Lestideau V,Lalanda P;Autonomic Pervasive Applications Driven by Abstract Specifications;;2012;;;19–24;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2012 International Workshop on Self-Aware Internet of Things;San Jose, California, USA;2012;9781450317535;;"https://doi-org.proxy.bnl.lu/10.1145/2378023.2378028;http://dx.doi.org/10.1145/2378023.2378028";10.1145/2378023.2378028;Pervasive application architectures present stringent requirements that make their development especially hard. In particular, they need to be flexible in order to cope with dynamism in different forms (e.g. service and data providers and consumers). The current trend to build applications out of remote services makes the availability of constituent application components inherently dynamic. Developers can no longer assume that applications are static after development or at run time. Unfortunately, developing applications that are able to cope with dynamism is very complex. Existing development approaches do not provide explicit support for managing dynamism. In this paper we describe Rondo, a tool suite for designing pervasive applications. More specifically, we present our propositions in pervasive application specification, which borrows concepts from service-oriented component assembly, model-driven engineering (MDE) and continuous deployment, resulting in a more flexible approach than traditional application definitions. Then the capabilities of our application model are demonstrated with an example application scenario designed using our approach.;internet of things, service-oriented computing, autonomic computing, pervasive computing;;;Self-IoT '12
Book;Chaganti R;Windows PowerShell Desired State Configuration Revealed;;2014;;;;1st;Apress;USA;;;;2014;9781484200179;;;;Desired State Configuration (DSC) is a powerful new configuration management platform that makes it easier than ever to perform cross-platform configuration management of your infrastructure, whether on-premise or in the cloud. DSC provides the management platform and Application Programming Interface (API) that can be used with any programming language. Windows PowerShell Desired State Configuration Revealed will take you through this new technology from start to finish and demonstrates the DSC interfaces through Windows PowerShell. DSC allows you to manage target devices by simply declaring what state you want them to be in, using new declarative language extensions, rather than writing detailed instructions to get them into that state. This makes continuous delivery in Windows easier than ever before. In an environment where changes and deployments are happening all the time, DSC makes the necessary adjustments to the system so you dont have to. Windows PowerShell Desired State Configuration Revealed starts with an overview of the configuration management features in Windows, followed by a discussion of the architecture of DSC and its components. Youll then explore DSCs built-in features and resources, followed by some of the different methods provided for delivering configuration information within your ecosystem, and learn about configuration monitoring and reporting. In the latter part of the book, youll find out how to get more power out of DSC by writing your own custom DSC resources, including a range of useful examples, and the book concludes with vital information on deploying and troubleshooting DSC in a production environment, along with some expert tips and tricks you might find useful along the way. Windows PowerShell Desired State Configuration Revealed is your one-stop guide to this new technology and how it can change your working life for the better. What youll learn Why continuous delivery and configuration management are important Architecture and components of DSCHow to build the infrastructure required to automate configuration management How to use built-in resources and create configuration documents How to create custom DSC resources How to troubleshoot DSC configuration and custom resource issues Who this book is for Windows PowerShell Desired State Configuration Revealed is for IT administrators, developers and DevOps engineers working in Windows-based data center environments. With a little prior PowerShell scripting experience, this book can be used as an in-depth reference to creating, customizing and extending DSC in Windows. IT administrators with limited scripting experience will also find this book a useful overview of what DSC offers and how to use DSC resources to automate configuration management and deployment. DSC is available as part of Windows 8.1 and Windows Server 2012 R2. You can also get DSC on Windows 7, Windows Server 2008 R2 or Windows Server 2012 by installing Windows Management Framework 4.0.;;;;
Journal Article;Konersmann M,Fitzgerald B,Goedicke M,Holmström Olsson H,Bosch J,Krusche S;Rapid Continuous Software Engineering - State of the Practice and Open Research Questions: Report on the 6th International Workshop on Rapid Continuous Software Engineering (RCoSE 2020);SIGSOFT Softw. Eng. Notes;2021;46;1;25–27;;Association for Computing Machinery;New York, NY, USA;;;;2021-01;;0163-5948;"https://doi-org.proxy.bnl.lu/10.1145/3437479.3437486;http://dx.doi.org/10.1145/3437479.3437486";10.1145/3437479.3437486;We need to built software rapidly and with a high quality. These goals seem to be contradictory, but actually, implementing automation in build and deployment procedures as well as quality analysis can improve both the development pace and the resulting quality at the same time. Rapid Continuous Software Engineering describes novel software engineering approaches that focus on short release cycles, continuous deployment, delivery, and continuous improvement through rapid tool-assisted feedback to developers. To realize these approaches there is a need for research and innovation with respect to automation and tooling, and furthermore for research into the organizational changes that support high pace development. This paper reports on the results of the 6th International Workshop on Rapid Continuous Software Engineering (RCoSE 2020), which focuses on the challenges and potential solutions in the area of Rapid Continuous Software Engineering, before reporting on our discussions regarding the state of the practice and open research topics.;continuous software engineering, rapid software engineering;;;
Journal Article;Gerostathopoulos I,Konersmann M,Krusche S,Mattos DI,Bosch J,Bures T,Fitzgerald B,Goedicke M,Muccini H,Olsson HH,Brand T,Chatley R,Diamantopoulos N,Friedman A,Jiménez M,Johanssen JO,Manggala P,Koseki M,Melegati J,Munaiah N,Tamura G,Theodorou V,Wong J,Figalist I;Continuous Data-Driven Software Engineering - Towards a Research Agenda: Report on the Joint 5th International Workshop on Rapid Continuous Software Engineering (RCoSE 2019) and 1st International Works;SIGSOFT Softw. Eng. Notes;2019;44;3;60–64;;Association for Computing Machinery;New York, NY, USA;;;;2019-11;;0163-5948;"https://doi-org.proxy.bnl.lu/10.1145/3356773.3356811;http://dx.doi.org/10.1145/3356773.3356811";10.1145/3356773.3356811;The rapid pace with which software needs to be built, together with the increasing need to evaluate changes for end users both quantitatively and qualitatively calls for novel software engineering approaches that focus on short release cycles, continuous deployment and delivery, experiment-driven feature development, feedback from users, and rapid tool-assisted feedback to developers. To realize these approaches there is a need for research and innovation with respect to automation and tooling, and furthermore for research into the organizational changes that support flexible data-driven decision-making in the development lifecycle. Most importantly, deep synergies are needed between software engineers, managers, and data scientists. This paper reports on the results of the joint 5th International Workshop on Rapid Continuous Software Engineering (RCoSE 2019) and the 1st International Workshop on Data-Driven Decisions, Experimentation and Evolution (DDrEE 2019), which focuses on the challenges and potential solutions in the area of continuous data-driven software engineering.;experimentation, data-driven, continuous software engineering;;;
Conference Paper;Kablan M,Caldwell B,Han R,Jamjoom H,Keller E;Stateless Network Functions;;2015;;;49–54;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2015 ACM SIGCOMM Workshop on Hot Topics in Middleboxes and Network Function Virtualization;London, United Kingdom;2015;9781450335409;;"https://doi-org.proxy.bnl.lu/10.1145/2785989.2785993;http://dx.doi.org/10.1145/2785989.2785993";10.1145/2785989.2785993;"Newly virtualized network functions (like firewalls, routers, and intrusion detection systems) should be easy to consume. Despite recent efforts to improve their elasticity and high availability, network functions continue to maintain important flow state, requiring traditional development and deployment life cycles. At the same time, many cloud-scale applications are being rearchitected to be stateless by cleanly pushing application state into dedicated caches or backend stores. This state separation is enabling these applications to be more agile and support the so-called continuous deployment model. In this paper, we propose that network functions should be similarly redesigned to be stateless. Drawing insights from different classes of network functions, we describe how stateless network functions can leverage recent advances in low-latency network systems to achieve acceptable performance. Our Click-based prototype integrates with RAMCloud; using NAT as an example network function, we demonstrate that we are able to create stateless network functions that maintain the desired performance.";NFV, infiniband, NAT, RDMA, stateless architecture;;;HotMiddlebox '15
Conference Paper;Xu X,Zhu L,Fu M,Sun D,Tran AB,Rimba P,Dwarakanathan S,Bass L;Crying Wolf and Meaning It: Reducing False Alarms in Monitoring of Sporadic Operations through POD-Monitor;;2015;;;69–75;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 1st International Workshop on Complex FaUlts and Failures in LargE Software Systems;;2015;9781467370349;;"https://doi-org.proxy.bnl.lu/10.1109/COUFLESS.2015.18;http://dx.doi.org/10.1109/COUFLESS.2015.18";10.1109/COUFLESS.2015.18;When monitoring complex applications in cloud systems, a difficult problem for operators is receiving false positive alarms. This becomes worse when the system is sporadically being changed and upgraded due to the emerging continuous deployment practice. Other legitimate but sporadic maintenance operations, such as log compression, garbage collection and data reconstruction in distributed systems can also trigger false alarms. Consequently, traditional baseline-based anomaly detection and monitoring is less effective. A normal but dangerous practice is to turn off normal monitoring during sporadic operations such as upgrade and maintenance. In this paper, we report on the use of the process context information of sporadic operations to suppress false positive alarms. We use the context information both directly and in machine learning. Our experimental evaluation shows that 1) using process context directly improves the alarm precision up to 0.226 (36.1% improvement), 2) using process-context trained machine learning models improves the precision rate up to 0.421 (84.7% improvement).;Monitoring, Alarm, Operation;;;COUFLESS '15
Conference Paper;Philip AA,Bhagwan R,Kumar R,Maddila CS,Nagappan N;FastLane: Test Minimization for Rapidly Deployed Large-Scale Online Services;;2019;;;408–418;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 41st International Conference on Software Engineering;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE.2019.00054;http://dx.doi.org/10.1109/ICSE.2019.00054";10.1109/ICSE.2019.00054;Today, we depend on numerous large-scale services for basic operations such as email. These services, built on the basis of Continuous Integration/Continuous Deployment (CI/CD) processes, are extremely dynamic: developers continuously commit code and introduce new features, functionality and fixes. Hundreds of commits may enter the code-base in a single day. Therefore one of the most time-critical, yet resource-intensive tasks towards ensuring code-quality is effectively testing such large code-bases.This paper presents FastLane, a system that performs data-driven test minimization. FastLane uses light-weight machine-learning models built upon a rich history of test and commit logs to predict test outcomes. Tests for which we predict outcomes need not be explicitly run, thereby saving us precious test-time and resources. Our evaluation on a large-scale email and collaboration platform service shows that our techniques can save 18.04%, i.e., almost a fifth of test-time while obtaining a test outcome accuracy of 99.99%.;test prioritization, machine learning, commit risk;;;ICSE '19
Journal Article;Sun D,Chen S,Li G,Zhang Y,Atif M;Multi-Objective Optimisation of Online Distributed Software Update for DevOps in Clouds;ACM Trans. Internet Technol.;2019;19;3;;;Association for Computing Machinery;New York, NY, USA;;;;2019-08;;1533-5399;"https://doi-org.proxy.bnl.lu/10.1145/3338851;http://dx.doi.org/10.1145/3338851";10.1145/3338851;This article studies synchronous online distributed software update, also known as rolling upgrade in DevOps, which in clouds upgrades software versions in virtual machine instances even when various failures may occur. The goal is to minimise completion time, availability degradation, and monetary cost for entire rolling upgrade by selecting proper parameters. For this goal, we propose a stochastic model and a novel optimisation method. We validate our approach to minimise the objectives through both experiments in Amazon Web Service (AWS) and simulations.;software system reliability, Software operation, rolling upgrade, stochastic modelling, multi-objective optimisation;;;
Conference Paper;Yin L,Filkov V;Team Discussions and Dynamics during DevOps Tool Adoptions in OSS Projects;;2020;;;697–708;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering;Virtual Event, Australia;2020;9781450367684;;"https://doi-org.proxy.bnl.lu/10.1145/3324884.3416640;http://dx.doi.org/10.1145/3324884.3416640";10.1145/3324884.3416640;In Open Source Software (OSS) projects, pre-built tools dominate DevOps-oriented pipelines. In practice, a multitude of configuration management, cloud-based continuous integration, and automated deployment tools exist, and often more than one for each task. Tools are adopted (and given up) by OSS projects regularly. Prior work has shown that some tool adoptions are preceded by discussions, and that tool adoptions can result in benefits to the project. But important questions remain: how do teams decide to adopt a tool? What is discussed before the adoption and for how long? And, what team characteristics are determinant of the adoption?In this paper, we employ a large-scale empirical study in order to characterize the team discussions and to discern the teamlevel determinants of tool adoption into OSS projects' development pipelines. Guided by theories of team and individual motivations and dynamics, we perform exploratory data analyses, do deep-dive case studies, and develop regression models to learn the determinants of adoption and discussion length, and the direction of their effect on the adoption. From data of commit and comment traces of large-scale GitHub projects, our models find that prior exposure to a tool and member involvement are positively associated with the tool adoption, while longer discussions and the number of newer team members associate negatively. These results can provide guidance beyond the technical appropriateness for the timeliness of tool adoptions in diverse programmer teams.Our data and code is available at https://github.com/lkyin/tool_adoptions.;;;;ASE '20
Journal Article;Glazemakers K;Opening the Network to DevOps without Letting Threats Inside;Netw. Secur.;2021;2021;12;7–9;;Elsevier Science Publishers B. V.;NLD;;;;2021-12;;1353-4858;"https://doi-org.proxy.bnl.lu/10.1016/S1353-4858(21)00143-4;http://dx.doi.org/10.1016/S1353-4858(21)00143-4";10.1016/S1353-4858(21)00143-4;;;;;
Journal Article;Roche J;Adopting DevOps Practices in Quality Assurance: Merging the Art and Science of Software Development;Queue;2013;11;9;20–27;;Association for Computing Machinery;New York, NY, USA;;;;2013-09;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/2538031.2540984;http://dx.doi.org/10.1145/2538031.2540984";10.1145/2538031.2540984;Software life-cycle management was, for a very long time, a controlled exercise. The duration of product design, development, and support was predictable enough that companies and their employees scheduled their finances, vacations, surgeries, and mergers around product releases. When developers were busy, QA (quality assurance) had it easy. As the coding portion of a release cycle came to a close, QA took over while support ramped up. Then when the product released, the development staff exhaled, rested, and started the loop again while the support staff transitioned to busily supporting the new product.;;;;
Conference Paper;Spinoso S,Virgilio M,John W,Manzalini A,Marchetto G,Sisto R;Formal Verification of Virtual Network Function Graphs in an SP-DevOps Context;;;;;253–262;;Springer-Verlag;Berlin, Heidelberg;;Service Oriented and Cloud Computing;Taormina Italy;;9783319240718;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-319-24072-5_18;http://dx.doi.org/10.1007/978-3-319-24072-5_18";10.1007/978-3-319-24072-5_18;The role of software and its flexibility is becoming more and more important in todays networks. New emerging paradigms, such as Software Defined Networking (SDN) and Network Function Virtualization (NFV), are changing the rules of the game, shifting the focus on dynamicity and programmability. Perfectly aligned with this new spirit, the FP7 UNIFY European project aims at realizing this appealing vision by applying DevOps concepts to telecom operator networks and supporting the idea of fast network reconfiguration. However, the increased range of possibilities offered by the DevOps approach comes at the cost of designing new processes and toolkits to make SDN and NFV a concrete opportunity. In this paper we specifically focus on the verification process as part of the challenging tasks that must be addressed in this scenario and its fundamental role of automatically checking some desired network properties before deploying a particular configuration. Our preliminary results confirm the feasibility of the approach and encourage future efforts in this direction.;DevOps, Formal verification, Service graphs, Network function forwarding graph;;;
Book;Ratcliffe L,McNeill M;Agile Experience Design: A Digital Designer's Guide to Agile, Lean, and Continuous;;2011;;;;1st;New Riders Publishing;USA;;;;2011;9780321804815;;;;Agile development methodologies may have started life in IT, but their widespread and continuing adoption means there are many practitioners outside of IT--including designers--who need to change their thinking and adapt their practices. This is the missing book about agile that shows how designers, product managers, and development teams can integrate experience design into lean and agile product development. It equips you with tools, techniques and a framework for designing great experiences using agile methods so you can deliver timely products that are technically feasible, profitable for the business, and desirable from an end-customer perspective. This book will help yousuccessfully integrate your design process on an agile project and feel like part of the agile team.do good design faster by doing just enough, just in time.use design methods from disciplines such as design thinking, customer-centered design, product design, and service design.create successful digital products by considering the needs of the end-customer, the business, and technology.understand the next wave of thinking about continuous design and continuous delivery.;;;;
Conference Paper;Wolters D,Kirchhoff J,Engels G;Specifying Web Interfaces for Command-Line Applications Based on OpenAPI;;2019;;;30–41;;Springer-Verlag;Berlin, Heidelberg;;Service-Oriented Computing – ICSOC 2019 Workshops: WESOACS, ASOCA, ISYCC, TBCE, and STRAPS, Toulouse, France, October 28–31, 2019, Revised Selected Papers;Toulouse, France;2019;9783030459888;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-45989-5_3;http://dx.doi.org/10.1007/978-3-030-45989-5_3";10.1007/978-3-030-45989-5_3;Command-line applications help to deal with various different tasks, reaching from automation, text manipulation or document conversion to administrating databases or firewalls. Powerful orchestrations of those applications can be created, e.g., to build Continuous Delivery or decision support pipelines. If the functionality of those applications and their orchestrations shall be used within a service-oriented architecture or as a backend of a web application, a web-compatible interface is necessary, which is usually not provided. Thus, those applications need to be retrofitted with a web interface. In this paper, we present CL2HTTP, an approach to map command-line interfaces to HTTP interfaces using an extended form of the OpenAPI service description format. The extensions specify how HTTP requests are mapped to command-line invocations and how the command-line responses are mapped back to HTTP responses. Our approach does not require any programming to specify a web interface for command-line applications, is available for public use and supports deployment as a container or lambda function in cloud environments.;Interface adaptation, Web services, OpenAPI, Command-line;;;
Journal Article;Dan A,Sitaram D;Multimedia Caching Strategies for Heterogeneous Application and ServerEnvironments;Multimedia Tools Appl.;1997;4;3;279–312;;Kluwer Academic Publishers;USA;;;;1997-05;;1380-7501;"https://doi-org.proxy.bnl.lu/10.1023/A:1009637022889;http://dx.doi.org/10.1023/A:1009637022889";10.1023/A:1009637022889;In a multimedia system, storage and bandwidth are critical resources since any presentation requires a large volume of data to be delivered in real-time. Caching of multimedia documents in local storage can alleviate large retrieval bandwidth requirements. An important requirement for a multimedia caching policy is to guarantee continuous delivery even when a stream is served from cache. It should also cope with dynamic changes in workload and heterogeneity arising from large and small multimedia files. The proposed Generalized Interval Caching (GIC) policy, that caches intervals between successive streams of a large file as well as entire small files, satisfies all the above criteria. A caching policy needs to cope with additional challenges in a large scale distributed multimedia environment consisting of many heterogeneous servers. The issues include a) routing of requests to ensure good cache hits in each server, and b) balancing of loads across servers. For routing of requests, we introduce the notion of an asset group and propose an affinity routing policy based on this concept. Finally, we adapt the GIC policy for load balancing across servers.;interval caching, asset group, multimedia caching, affinity routing;;;
Conference Paper;Pereira IM,Carneiro T,Figueiredo E;A Systematic Review on the Use of DevOps in Internet of Things Software Systems;;2021;;;1569–1571;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 36th Annual ACM Symposium on Applied Computing;Virtual Event, Republic of Korea;2021;9781450381048;;"https://doi-org.proxy.bnl.lu/10.1145/3412841.3442126;http://dx.doi.org/10.1145/3412841.3442126";10.1145/3412841.3442126;Based on Systematic Literature Review (SLR), we search to investigate the relations of DevOps in IoT software systems. As a result, we characterize the benefits and challenges in the context of knowledge previously reported in primary studies.;IoT software systems, internet of things software systems, DevOps;;;SAC '21
Conference Paper;Gunawan F,K. Budiardjo E;A Quest of Software Process Improvements in DevOps and Kanban: A Case Study in Small Software Company;;2021;;;39–45;;Association for Computing Machinery;New York, NY, USA;;2021 The 4th International Conference on Software Engineering and Information Management;Yokohama, Japan;2021;9781450388955;;"https://doi-org.proxy.bnl.lu/10.1145/3451471.3451478;http://dx.doi.org/10.1145/3451471.3451478";10.1145/3451471.3451478;A good software process improves software products. In the case of a small software company, software development is a matter of survivability due to its limited resources to develop software. XYZ Company is a very small software company that adopted Kanban and DevOps and faced software delivery delays. It is necessary to recommend the software process improvements to solve this problem. Software process improvements are the outcomes of measurement and analysis of maturity levels using the ISO 29110 framework in a qualitative study. They are then analyzed using the Lean Six Sigma tools, namely gap analysis, root cause analysis, and Pareto analysis. Delphi method validated them and resulted in 18 improvement recommendations within four domains, namely (a) product, (b) people, (c) technology, and (d) process. The improvements span across two main processes within software development, namely (a) Project Management (PM) and (b) Software Implementation (SI). The XYZ Company or any agile-based software company could adopt the 18 improvement recommendations to enhance the software process and quality.;small software company, agile, SPI, Software Process Improvement, Kanban, ISO 29110, DevOps;;;ICSIM 2021
Conference Paper;Hugues J,Hristosov A,Hudak JJ,Yankel J;TwinOps - DevOps Meets Model-Based Engineering and Digital Twins for the Engineering of CPS;;2020;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings;Virtual Event, Canada;2020;9781450381352;;"https://doi-org.proxy.bnl.lu/10.1145/3417990.3421446;http://dx.doi.org/10.1145/3417990.3421446";10.1145/3417990.3421446;The engineering of Cyber-Physical Systems (CPS) requires a large set of expertise to capture the system requirements and to derive a correct solution. Model-based Engineering and DevOps aim to efficiently deliver software with increased quality. Model-based Engineering relies on models as first-class artifacts to analyze, simulate, and ultimately generate parts of a system. DevOps focuses on software engineering activities, from early development to integration, and then improvement through the monitoring of the system at run-time. We claim these can be efficiently combined to improve the engineering process of CPS.In this paper, we present TwinOps, a process that unifies Model-based Engineering, Digital Twins, and DevOps practice in a uniform workflow. TwinOps illustrates how to leverage several best practices in MBE and DevOps for the engineering Cyber-Physical systems. We illustrate our contribution using a Digital Twins case study to illustrate TwinOps benefits, combining AADL and Modelica models, and an IoT platform.;;;;MODELS '20
Conference Paper;Van Rossem S,Cai X,Cerrato I,Danielsson P,Németh F,Pechenot B,Pelle I,Risso F,Sharma S,Sköldström P,John W;NFV Service Dynamicity with a DevOps Approach: Insights from a Use-Case Realization;;2017;;;674–679;;IEEE Press;Lisbon, Portugal;;2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM);;2017;;;"https://doi-org.proxy.bnl.lu/10.23919/INM.2017.7987357;http://dx.doi.org/10.23919/INM.2017.7987357";10.23919/INM.2017.7987357;"This experience paper describes the process of leveraging the NFV orchestration platform built in the EU FP7 project UNIFY to deploy a dynamic network service exemplified by an elastic router. Elasticity is realized by scaling dataplane resources as a function of traffic load. To achieve this, the service includes a custom scaling logic and monitoring capabilities. An automated monitoring framework not only triggers elastic scaling, but also a troubleshooting process which detects and analyzes anomalies, pro-actively aiding both dev and ops personnel. Such a DevOps-inspired approach enables a shorter update cycle to the running service. We highlight multiple learnings yielded throughout the prototype realization, focussing on the functional areas of service decomposition and scaling; programmable monitoring; and automated troubleshooting. Such practical insights will contribute to solving challenges such as agile deployment and efficient resource usage in future NFV platforms.";;;;
Book Chapter;Berkovich S,Kam J,Wurster G;UBCIS: Ultimate Benchmark for Container Image Scanning;;2020;;;;;USENIX Association;USA;Proceedings of the 13th USENIX Conference on Cyber Security Experimentation and Test;;;2020;;;;;Containers are regularly used in modern cloud-native deployment practices. They support agile and continuous integration/ continuous deployment (CI/CD) paradigms, isolating services. As containers become more ubiquitous, container security becomes crucial as well. Scanning container images for known vulnerabilities caused by vulnerable software is a critical security activity of the CI/CD process. Both commercial and open-source tools exist for container image scanning. Results from these scanners, however, are inconsistent. Inconsistent results make it hard for developers to choose the best solution for their environment. In this paper, we present the Ultimate Benchmark for Container Image Scanning (UBCIS), a benchmark for evaluating image scanners. UBCIS contains a classification of known vulnerabilities in common base container images, as well as a framework for running container vulnerability scanning tools. UBCIS makes it possible to evaluate scanners. We discuss intricacies of classifying vulnerabilities, presenting a process that can be used when determining the relevance of vulnerability. Finally, we provide recommendations for choosing the best scanner for a specific environment.;;;;
Conference Paper;Zhang Y,Yang J,Jin Z,Sethi U,Rodrigues K,Lu S,Yuan D;Understanding and Detecting Software Upgrade Failures in Distributed Systems;;2021;;;116–131;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles;Virtual Event, Germany;2021;9781450387095;;"https://doi-org.proxy.bnl.lu/10.1145/3477132.3483577;http://dx.doi.org/10.1145/3477132.3483577";10.1145/3477132.3483577;Upgrade is one of the most disruptive yet unavoidable maintenance tasks that undermine the availability of distributed systems. Any failure during an upgrade is catastrophic, as it further extends the service disruption caused by the upgrade. The increasing adoption of continuous deployment further increases the frequency and burden of the upgrade task. In practice, upgrade failures have caused many of today's high-profile cloud outages. Unfortunately, there has been little understanding of their characteristics.This paper presents an in-depth study of 123 real-world upgrade failures that were previously reported by users in 8 widely used distributed systems, shedding lights on the severity, root causes, exposing conditions, and fix strategies of upgrade failures. Guided by our study, we have designed a testing framework DUPTester that revealed 20 previously unknown upgrade failures in 4 distributed systems, and applied a series of static checkers DUPChecker that discovered over 800 cross-version data-format incompatibilities that can lead to upgrade failures. DUPChecker has been requested by HBase developers to be integrated into their toolchain.;bug detection, distributed systems, study, upgrade failure;;;SOSP '21
Book Chapter;Mehta S,Farmahinifarahani F,Bhagwan R,Guptha S,Jafari S,Kumar R,Saini V,Santhiar A;Data-Driven Test Selection at Scale;;2021;;;1225–1235;;Association for Computing Machinery;New York, NY, USA;Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;;;2021;9781450385626;;https://doi-org.proxy.bnl.lu/10.1145/3468264.3473916;;Large-scale services depend on Continuous Integration/Continuous Deployment (CI/CD) processes to maintain their agility and code-quality. Change-based testing plays an important role in finding bugs, but testing after every change is prohibitively expensive at a scale where thousands of changes are committed every hour. Test selection models deal with this issue by running a subset of tests for every change. In this paper, we present a generic, language-agnostic and lightweight statistical model for test selection. Unlike existing techniques, the proposed model does not require complex feature extraction techniques. Consequently, it scales to hundreds of repositories of varying characteristics while capturing more than 99% of buggy pull requests. Additionally, to better evaluate test selection models, we propose application-specific metrics that capture both a reduction in resource cost and a reduction in pull-request turn-around time. By evaluating our model on 22 large repositories at Microsoft, we find that we can save 15%−30% of compute time while reporting back more than ≈99% of buggy pull requests.;;;;
Conference Paper;Rahman M,Gao J;A Reusable Automated Acceptance Testing Architecture for Microservices in Behavior-Driven Development;;2015;;;321–325;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE Symposium on Service-Oriented System Engineering;;2015;9781479983568;;"https://doi-org.proxy.bnl.lu/10.1109/SOSE.2015.55;http://dx.doi.org/10.1109/SOSE.2015.55";10.1109/SOSE.2015.55;Cloud Computing and Mobile Cloud Computing are reshaping the way applications are being developed and deployed due to their unique needs such as massive scalability, guaranteed fault tolerance, near zero downtime, etc. and also daunting challenges such as security, reliability, continuous deployment and update capability. Microservices architecture, where application is composed of a set of independently deployable services, is increasingly becoming popular due to its capability to address most of these needs and challenges. In recent years, the Behavior-Driven Development (BDD) has become one of the most popular agile software development processes, and frequently used in microservices development. The key to success of BDD is the executable acceptance tests that describe the expected behavior of a feature and its acceptance criteria in the form of scenarios using simple and business people readable syntax. The reusability, auditability, and maintainability become some of the major concerns when BDD test framework is applied for each microservice repository and no previous research addresses these concerns. In this paper, we present a reusable automated acceptance testing architecture to address all these concerns.;functional testing, Gherkin, executable automated acceptance testing, behavior-driven development, microservice;;;SOSE '15
Journal Article;Clear T;THINKING ISSUES<br><br>Meeting Employers Expectations of Devops Roles: Can Dispositions Be Taught?;ACM Inroads;2017;8;2;19–21;;Association for Computing Machinery;New York, NY, USA;;;;2017-05;;2153-2184;"https://doi-org.proxy.bnl.lu/10.1145/3078298;http://dx.doi.org/10.1145/3078298";10.1145/3078298;;;;;
Conference Paper;Gonzalez-Herrera I,Bourcier J,Daubert E,Rudametkin W,Barais O,Fouquet F,Jézéquel JM;Scapegoat: An Adaptive Monitoring Framework for Component-Based Systems;;2014;;;67–76;;IEEE Computer Society;USA;;Proceedings of the 2014 IEEE/IFIP Conference on Software Architecture;;2014;9781479934126;;"https://doi-org.proxy.bnl.lu/10.1109/WICSA.2014.49;http://dx.doi.org/10.1109/WICSA.2014.49";10.1109/WICSA.2014.49;Modern component frameworks support continuous deployment and simultaneous execution of multiple software components on top of the same virtual machine. However, isolation between the various components is limited. A faulty version of any one of the software components can compromise the whole system by consuming all available resources. In this paper, we address the problem of efficiently identifying faulty software components running simultaneously in a single virtual machine. Current solutions that perform permanent and extensive monitoring to detect anomalies induce high overhead on the system, and can, by themselves, make the system unstable. In this paper we present an optimistic adaptive monitoring system to determine the faulty components of an application. Suspected components are finely instrumented for deeper analysis by the monitoring system, but only when required. Unsuspected components are left untouched and execute normally. Thus, we perform localized just-in-time monitoring that decreases the accumulated overhead of the monitoring system. We evaluate our approach against a state-of-the-art monitoring system and show that our technique correctly detects faulty components, while reducing overhead by an average of 80%.;Monitoring, Software Adaptation, Models@runtime, Based Software Architecture;;;WICSA '14
Conference Paper;Mitzutani I,Ramanathan G,Mayer S;Semantic Data Integration with DevOps to Support Engineering Process of Intelligent Building Automation Systems;;2021;;;294–297;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation;Coimbra, Portugal;2021;9781450391146;;"https://doi-org.proxy.bnl.lu/10.1145/3486611.3492413;http://dx.doi.org/10.1145/3486611.3492413";10.1145/3486611.3492413;The reliable infrastructure of building automation (BA) systems forms the foundation of smart environments and energy systems in our building towards increasing occupant comfort and safety while reducing the ecological footprint of buildings. This is achieved through the processing of data points collected from sensors and the control of installed actuators, and increasingly incorporates machine learning components. However, engineering of BA systems is intricately linked with the planning, installation, (pre-)commissioning, and operation of building services such as HVAC, and it requires an extensive amount of manual coordination which is often prone to errors, many of which are only detected late in the lifecycle and tends to lose transparency in data provenance. To address this, we propose the application of DevOps, a highly successful paradigm in the field of software engineering, to BA engineering process coordination. In addition, the possibility of using semantic data to develop artifacts such as requirements, construction, and devices of BA systems opens up the avenue of achieving continuous verification of the system as it is built and commissioned. Concretely, we propose a novel approach that integrates a semantic reasoner using the machine-understandable data of the building along with interactions facilitated by Web of Thing Thing Description to the DevOps workflow. The proposed approach is expected to ameliorate limitations of existing workflow management methods and thus provide transparency in the data provenance to gain trust for data-driven AI applications for BA.;explainable CPS, cyber-physical systems, semantic data, building automation, DevOps, provenance;;;BuildSys '21
Book;;QUDOS 2015: Proceedings of the 1st International Workshop on Quality-Aware DevOps;;2015;;;;;Association for Computing Machinery;New York, NY, USA;;;Bergamo, Italy;2015;9781450338172;;;;;;;Proceedings;
Journal Article;El Beggar O;Multicriteria Decision Aid for Agile Methods Evaluation Using Fuzzy PROMETHEE;J. Softw. Evol. Process;2018;30;12;;;John Wiley & Sons, Inc.;USA;;;;2018-12;;2047-7473;"https://doi-org.proxy.bnl.lu/10.1002/smr.2108;http://dx.doi.org/10.1002/smr.2108";10.1002/smr.2108;The last decade is marked by the blossom of agile methods and their growing use in many IT projects. They shared common principles and values, such as customer collaboration, early and continuous delivery of releases, accept requirements changing, and other common principles advocated by the agile manifesto since 2001. Meanwhile, there are significant differences among the practices adopted by the agile methods to fulfill agility's principles and values. The differences could be interpreted in terms of how an agile method judges the relative importance of such principles or its orientation to a specific project viewpoint (organizational, technical, or conceptual) rather than others. This fact leads to a necessity of a deep evaluation of agile methods to choose the best‐fit method suited for a project. Moreover, vague and uncertain information used to evaluate those lightweight methodologies could represent an additional difficulty for decision makers (DM). To drawback this problem, the multiple criteria decision aid (MCDA) method fuzzy PROMETHEE is proposed to assess agile methods with regard to different conflicting criteria and handling besides uncertainty in decision making. Furthermore, a sensitivity analysis is provided to validate results and verify their stability.;MCDA, agile methods, fuzzy PROMETHEE, linguistic terms, decision making;;;
Conference Paper;Huijgens H,Greuter E,Brons J,van Doorn EA,Papadopoulos I,Martinez FM,Aniche M,Visser O,van Deursen A;Factors Affecting Cloud Infra-Service Development Lead Times: A Case Study at ING;;2019;;;233–242;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP.2019.00033;http://dx.doi.org/10.1109/ICSE-SEIP.2019.00033";10.1109/ICSE-SEIP.2019.00033;The development of Cloud Infra-Services has shifted over the past decade in the direction of a software code development process, also known as infrastructure as code (IaC). Contemporary continuous delivery settings in industry require fast feedback. As a consequence, companies need insight in time spent, especially in the development of such services. We examine a series of 28 Cloud Infra-Services within ING, and explore which factors affect their overall time to market and development time. An initial perception among several stakeholders in the Cloud Infra-Service development process, that Cloud Infra-Services within ING take longer than those in peer companies, is not confirmed by our benchmark. Development team members identified the time to internal market of services to be affected negatively by the portal where consumers can order a service and the Orchestration Workflows and by team dynamics. This perception is supported by additional metrics. We propose that promising ways to reduce lead time include reducing the complexity of the ING environment, by treating Cloud Infra-Services like regular software deliveries and by reducing the dependencies between teams in terms of tooling and collaboration.;continuous delivery, cloud infra-services, SaaS, IaaS, PaaS, ING, virtual machine, infrastructure as code;;;ICSE-SEIP '19
Book;;Cloud Native Java: Designing Resilient Systems with Spring Boot, Spring Cloud, and Cloud Foundry;;2017;;;;1st;O'Reilly Media, Inc.;;;;;2017;9781449374648;;;;"What separates the traditional enterprise from the likes of Amazon, Netflix, and Etsy? Those companies have refined the art of cloud native development to maintain their competitive edge and stay well ahead of the competition. This practical guide shows Java/JVM developers how to build better software, faster, using Spring Boot, Spring Cloud, and Cloud Foundry. Many organizations have already waded into cloud computing, test-driven development, microservices, and continuous integration and delivery. Authors Josh Long and Kenny Bastani fully immerse you in the tools and methodologies that will help you transform your legacy application into one that is genuinely cloud native. In four sections, this book takes you through: The Basics: learn the motivations behind cloud native thinking; configure and test a Spring Boot application; and move your legacy application to the cloud Web Services: build HTTP and REST ful services with Spring; route requests in your distributed system; and build edge services closer to the data Data Integration: manage your data with Spring Data, and integrate distributed services with Springs support for event-driven, messaging-centric architectures Production: make your system observable; use service brokers to connect stateful services; and understand the big ideas behind continuous delivery";;;;
Conference Paper;Beigi-Mohammadi N,Litoiu M,Emami-Taba M,Tahvildari L,Fokaefs M,Merlo E,Onut IV;A DevOps Framework for Quality-Driven Self-Protection in Web Software Systems;;2018;;;270–274;;IBM Corp.;USA;;Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering;Markham, Ontario, Canada;2018;;;;;Modern software is developed, deployed and operates continuously. At the same time, cyberattacks are on the rise. The continuity of development and operations and the constant threat of attacks requires novel approaches to identify, analyze and address potential security vulnerabilities. In this continuous and volatile execution environment, factors like security, performance, cost and functionality may not be able to be guaranteed in the same degree at the same time. In this work, we propose a DevOps framework for security adaptation that enables the development and operations teams to collaborate and address security vulnerabilities. The proposed framework spans across the different phases of software (development, operations, maintenance) and considers all other factors (performance, cost, functionality), when deciding for security adaptations. We demonstrate the approach on a prototype tool that shows how teams work together to tackle security concerns.;web software, software defined infrastructure, self-protection, security, self-adaptive systems, devops;;;CASCON '18
Conference Paper;Zhou P,Ali Khan AA,Liang P,Badshah S;System and Software Processes in Practice: Insights from Chinese Industry;;2021;;;394–401;;Association for Computing Machinery;New York, NY, USA;;Evaluation and Assessment in Software Engineering;Trondheim, Norway;2021;9781450390538;;"https://doi-org.proxy.bnl.lu/10.1145/3463274.3463786;http://dx.doi.org/10.1145/3463274.3463786";10.1145/3463274.3463786;Software development processes play a key role in the software and system development life cycle. Processes are becoming complex and evolve rapidly due to the modern-day continuous software engineering (CSE) concepts, which are mainly based on continuous integration, continuous delivery, infrastructure-as-code, automation and more. The fast growing Chinese software development industry adopts various processes to achieve potential benefits offered in the international market. This study is conducted with the aim to investigate the trends of processes in practice in the Chinese industry. The survey questionnaire data is collected from 34 practitioners working in software development firms across the China and the results highlight that iterative and agile processes are extensively used in industrial setting. Furthermore, agile and traditional approaches are combined to develop the hybrid processes. Most of the participants are satisfied using the current development processes, however, they show interest to continuously improve the existing process models and methods. Finally, we noticed that majority of the software development organizations used the ISO 9001 standard for process assessment and improvement activities. The given results provide preliminary overview of processes deployed in the Chinese industry.;Process Improvement Standards, Survey, Chinese industry, Software processes;;;EASE 2021
Journal Article;Romero EE,Camacho CD,Montenegro CE,Acosta ÓE,Crespo RG,Gaona EE,Martínez MH;Integration of DevOps Practices on a Noise Monitor System with CircleCI and Terraform;ACM Trans. Manage. Inf. Syst.;2021;;;;;Association for Computing Machinery;New York, NY, USA;;;;2021-12;;2158-656X;"https://doi-org.proxy.bnl.lu/10.1145/3505228;http://dx.doi.org/10.1145/3505228";10.1145/3505228;Lowering pollution levels is one of the main principles of Sustainable Development goals dictated by the United Nations. Consequently, developments on noise monitoring contribute in great manner to this purpose, since they give the opportunity to governments and institutions to maintain track on the matter. While developing a software product for this purpose, with the growth in terms of functional and non-functional requirements, elements such as infrastructure, source code and others also scale up. Consequently if there are not good practices to face the new challenges of the software product, it could become more complex to refactor, maintain and scale, causing a decrease on delivery rate and the quality of the product. DevOps is an emerging concept but still hazy, which involves a set of practices that helps organizations to speed up delivery time, improve software quality and collaboration between teams. The aim of this paper is to document the implementation of some DevOps practices such as IaC, continuous integration and deployment, code quality control and collaboration on a noise monitor system to increase the product quality and automation of deployment. The final result is a set of automated pipelines which represents the entire integration and deployment cycle of the software integrated with platforms to improve quality and maintainability of the software components.;CI/CD, Classification, Sound, DeVOps, Serverless, CI/CD;Just Accepted;;
Conference Paper;Rahman A,Stallings J,Williams L;Defect Prediction Metrics for Infrastructure as Code Scripts in DevOps;;2018;;;414–415;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings;Gothenburg, Sweden;2018;9781450356633;;"https://doi-org.proxy.bnl.lu/10.1145/3183440.3195034;http://dx.doi.org/10.1145/3183440.3195034";10.1145/3183440.3195034;Use of infrastructure as code (IaC) scripts helps software teams manage their configuration and infrastructure automatically. Information technology (IT) organizations use IaC scripts to create and manage automated deployment pipelines to deliver services rapidly. IaC scripts can be defective, resulting in dire consequences, such as creating wide-scale service outages for end-users. Prediction of defective IaC scripts can help teams to mitigate defects in these scripts by prioritizing their inspection efforts. The goal of this paper is to help software practitioners in prioritizing their inspection efforts for infrastructure as code (IaC) scripts by proposing defect prediction model-related metrics. IaC scripts use domain specific languages (DSL) that are fundamentally different from object-oriented programming (OOP) languages. Hence, the OOP-based metrics that researchers used in defect prediction might not be applicable for IaC scripts. We apply Constructivist Grounded Theory (CGT) on defect-related commits mined from version control systems to identify metrics suitable for IaC scripts. By applying CGT, we identify 18 metrics. Of these metrics, 13 are related to IaC, for example, count of string occurrences in a script. Four of the identified metrics are related to churn, and one metric is lines of code.;continuous deployment, infrastructure as code, metrics, DevOps;;;ICSE '18
Journal Article;Chung S,Bang S;Identifying Knowledge, Skills, and Abilities (KSA) for Devops-Aware Server Side Web Application with the Grounded Theory;J. Comput. Sci. Coll.;2016;32;1;110–116;;Consortium for Computing Sciences in Colleges;Evansville, IN, USA;;;;2016-10;;1937-4771;;;The purpose of this research is to propose what fundamental Knowledge (K), Skills (S), and Abilities (A) should be taught in web development courses, which can support not only development but also operations, namely DevOps. Instead of focusing on client side web application development using standard web technologies, we focus on server side web application development which holds many challenges due to a diversity of languages and emerging technologies. The advent of cloud computing reduced the gap between web application development and deployment/operation. Also, it brought an emerging concept, DevOps, to the web application development community. We identify what KSAs are needed to support DevOps and attempt to include them in web development courses. When the KSAs are included in web application development courses, students are well prepared for the emerging practice and computing paradigm of DevOps.;;;;
Conference Paper;Masek P,Thulin M,Andrade H,Berger C,Benderius O;Systematic Evaluation of Sandboxed Software Deployment for Real-Time Software on the Example of a Self-Driving Heavy Vehicle;;2016;;;2398–2403;;IEEE Press;Rio de Janeiro, Brazil;;2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC);;2016;;;"https://doi-org.proxy.bnl.lu/10.1109/ITSC.2016.7795942;http://dx.doi.org/10.1109/ITSC.2016.7795942";10.1109/ITSC.2016.7795942;Companies developing and maintaining software-only products like web shops aim for establishing persistent links to their software running in the field. Monitoring data from real usage scenarios allows for a number of improvements in the software life-cycle, such as quick identification and solution of issues, and elicitation of requirements from previously unexpected usage. While the processes of continuous integration, continuous deployment, and continuous experimentation using sandboxing technologies are becoming well established in said software-only products, adopting similar practices for the automotive domain is more complex mainly due to real-time and safety constraints. In this paper, we systematically evaluate sandboxed software deployment in the context of a self-driving heavy vehicle that participated in the 2016 Grand Cooperative Driving Challenge (GCDC) in The Netherlands. We measured the system's scheduling precision after deploying applications in four different execution environments. Our results indicate that there is no significant difference in performance and overhead when sandboxed environments are used compared to natively deployed software. Thus, recent trends in software architecting, packaging, and maintenance using microservices encapsulated in sandboxes will help to realize similar software and system engineering for cyber-physical systems.;;;;
Conference Paper;Gerostathopoulos I,Kugele S,Segler C,Bures T,Knoll A;Automated Trainability Evaluation for Smart Software Functions;;2019;;;998–1001;;IEEE Press;San Diego, California;;Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering;;2019;9781728125084;;"https://doi-org.proxy.bnl.lu/10.1109/ASE.2019.00096;http://dx.doi.org/10.1109/ASE.2019.00096";10.1109/ASE.2019.00096;More and more software-intensive systems employ machine learning and runtime optimization to improve their functionality by providing advanced features (e. g. personal driving assistants or recommendation engines). Such systems incorporate a number of smart software functions (SSFs) which gradually learn and adapt to the users' preferences. A key property of SSFs is their ability to learn based on data resulting from the interaction with the user (implicit and explicit feedback)---which we call trainability. Newly developed and enhanced features in a SSF must be evaluated based on their effect on the trainability of the system. Despite recent approaches for continuous deployment of machine learning systems, trainability evaluation is not yet part of continuous integration and deployment (CID) pipelines. In this paper, we describe the different facets of trainability for the development of SSFs. We also present our approach for automated trainability evaluation within an automotive CID framework which proposes to use automated quality gates for the continuous evaluation of machine learning models. The results from our indicative evaluation based on real data from eight BMW cars highlight the importance of continuous and rigorous trainability evaluation in the development of SSFs.;smart software functions, continuous deployment, trainability;;;ASE '19
Conference Paper;Axelsson J,Kobetski A,Ni Z,Zhang S,Johansson E;MOPED: A Mobile Open Platform for Experimental Design of Cyber-Physical Systems;;2014;;;423–430;;IEEE Computer Society;USA;;Proceedings of the 2014 40th EUROMICRO Conference on Software Engineering and Advanced Applications;;2014;9781479957958;;"https://doi-org.proxy.bnl.lu/10.1109/SEAA.2014.38;http://dx.doi.org/10.1109/SEAA.2014.38";10.1109/SEAA.2014.38;Due to the increasing importance of cyber-physical and embedded systems in industry, there is a strong demand for engineers with an updated knowledge on contemporary technology and methods in the area. This is a challenge for educators, in particular when it comes to creating hands-on experiences of real systems, due to their complexity and the fact that they are usually proprietary. Therefore, a laboratory environment that is representative of the industrial solutions is needed, with a focus on software and systems engineering issues. This paper describes such an environment, called the Mobile Open Platform for Experimental Design (MOPED). It consists of a model car chassis, equipped with a network of three control units based on standard hardware, and running the automotive software standard AUTOSAR, which consists of operating system, middleware, and application software structures. It is equipped with various sensors and actuators, and is open to extensions both in hardware and software. It also contains elements of future systems, since it allows connectivity to cloud services, development of federated embedded systems, and continuous deployment of new functionality. In this way, the platform provides a very relevant learning environment for cyber-physical systems, today and in the future.;AUTOSAR, education, federated embedded systems, automotive, software engineering, cyber-physical systems;;;SEAA '14
Conference Paper;Ludwig H,Stamou K,Mohamed M,Mandagere N,Langston B,Alatorre G,Nakamura H,Anya O,Keller A;RSLA: Monitoring SLAs in Dynamic Service Environments;;2015;;;139–153;;Springer-Verlag;Berlin, Heidelberg;;Service-Oriented Computing: 13th International Conference, ICSOC 2015, Goa, India, November 16-19, 2015, Proceedings;Goa, India;2015;9783662486153;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-662-48616-0_9;http://dx.doi.org/10.1007/978-3-662-48616-0_9";10.1007/978-3-662-48616-0_9;Today’s application environments combine Cloud and on-premise infrastructure, as well as platforms and services from different providers to enable quick development and delivery of solutions to their intended users. The ability to use Cloud platforms to stand up applications in a short time frame, the wide availability of Web services, and the application of a continuous deployment model has led to very dynamic application environments. In those application environments, managing quality of service has become more important. The more external service vendors are involved the less control an application owner has and must rely on Service Level Agreements (SLAs). However, SLA management is becoming more difficult. Services from different vendors expose different instrumentation. In addition, the increasing dynamism of application environments entails that the speed of SLA monitoring set up must match the speed of changes to the application environment.This paper proposes the rSLA service and language that is both flexible enough to instrument virtually any environment and agile enough to scale and update SLA management as needed. Using rSLA the time of setting up SLA compliance monitoring of application environments involving infrastructure, platform, and application services can be significantly reduced.;Monitoring, Cloud Computing, Reporting, PaaS, Service Level Agreement;;;
Journal Article;Chung S,Bang S;Identifying Knowledge, Skills, and Abilities (KSA) for Devops-Aware Server Side Web Application with the Grounded Theory;J. Comput. Sci. Coll.;2016;32;1;110–116;;Consortium for Computing Sciences in Colleges;Evansville, IN, USA;;;;2016-10;;1937-4771;;;The purpose of this research is to propose what fundamental Knowledge (K), Skills (S), and Abilities (A) should be taught in web development courses, which can support not only development but also operations, namely DevOps. Instead of focusing on client side web application development using standard web technologies, we focus on server side web application development which holds many challenges due to a diversity of languages and emerging technologies. The advent of cloud computing reduced the gap between web application development and deployment/operation. Also, it brought an emerging concept, DevOps, to the web application development community. We identify what KSAs are needed to support DevOps and attempt to include them in web development courses. When the KSAs are included in web application development courses, students are well prepared for the emerging practice and computing paradigm of DevOps.;;;;
Book;Daschner S;Architecting Modern Java EE Applications: Designing Lightweight, Business-Oriented Enterprise Applications in the Age of Cloud, Containers, and Java EE 8;;2017;;;;;Packt Publishing;;;;;2017;9781788393850;;;;Find out how to craft effective, business-oriented Java EE 8 applications that target customers demands in the age of Cloud platforms and container technology. About This Book Understand the principles of modern Java EE and how to realize effective architectures Gain knowledge of how to design enterprise software in the age of automation, Continuous Delivery and Cloud platforms Learn about the reasoning and motivations behind state-of-the-art enterprise Java technology, that focuses on business Who This Book Is ForThis book is for experienced Java EE developers who are aspiring to become the architects of enterprise-grade applications, or software architects who would like to leverage Java EE to create effective blueprints of applications. What You Will Learn What enterprise software engineers should focus onImplement applications, packages, and components in a modern way Design and structure application architectures Discover how to realize technical and cross-cutting aspectsGet to grips with containers and container orchestration technology Realize zero-dependency, 12-factor, and Cloud-native applicationsImplement automated, fast, reliable, and maintainable software tests Discover distributed system architectures and their requirementsIn Detail Java EE 8 brings with it a load of features, mainly targeting newer architectures such as microservices, modernized security APIs, and cloud deployments. This book will teach you to design and develop modern, business-oriented applications using Java EE 8. It shows how to structure systems and applications, and how design patterns and Domain Driven Design aspects are realized in the age of Java EE 8. You will learn about the concepts and principles behind Java EE applications, and how to effect communication, persistence, technical and cross-cutting concerns, and asynchronous behavior. This book covers Continuous Delivery, DevOps, infrastructure-as-code, containers, container orchestration technologies, such as Docker and Kubernetes, and why and especially how Java EE fits into this world. It also covers the requirements behind containerized, zero-dependency applications and how modern Java EE application servers support these approaches. You will also learn about automated, fast, and reliable software tests, in different test levels, scopes, and test technologies. This book covers the prerequisites and challenges of distributed systems that lead to microservice, shared-nothing architectures. The challenges and solutions of consistency versus scalability will further lead us to event sourcing, event-driven architectures, and the CQRS principle. This book also includes the nuts and bolts of application performance as well as how to realize resilience, logging, monitoring and tracing in a modern enterprise world. Last but not least the demands of securing enterprise systems are covered. By the end, you will understand the ins and outs of Java EE so that you can make critical design decisions that not only live up to, but also surpass your clients' expectations. Style and approach This book focuses on solving business problems and meeting customer demands in the enterprise world. It covers how to create enterprise applications with reasonable technology choices, free of cargo-cult and over-engineering. The aspects shown in this book not only demonstrate how to realize a certain solution, but also explain its motivations and reasoning.;;;;
Book;;QUDOS 2016: Proceedings of the 2nd International Workshop on Quality-Aware DevOps;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;;Saarbrücken, Germany;2016;9781450344111;;;;;;;Proceedings;
Conference Paper;Kobylinski K;Agile Software Development for Bluemix with IBM DevOps Services;;2015;;;284–286;;IBM Corp.;USA;;Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering;Markham, Canada;2015;;;;;The pace is fast. New applications are popping up daily. If one wants to enter the market one needs to act quickly to implement the new idea. If one already has a presence in the market one needs to stay competitive and keep refining the application on an ongoing basis. The traditional development process was designed to support large releases offered months apart from one another. That is too slow for today's market. We cannot stay competitive if we deliver bug fixes and new cool features months from now. The fast pace applies also to the business growth. A number of small companies became disruptors in many areas of business. How did they do that one may ask. One of the factors enabling them to do that is developing new applications for cloud. The prevailing business model for cloud environments is based on the pay-as-you-go principle. There is no need to invest in own hardware and software infrastructure to host the applications. Everybody can now start small and add 'unlimited' resources as needed. This has its business merit but also provides a way to quickly adjust application capabilities to a rapid business growth.;;;;CASCON '15
Conference Paper;Li N,Guo J,Lei J,Li Y,Rao C,Cao Y;Towards Agile Testing for Railway Safety-Critical Software;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Scientific Workshop Proceedings of XP2016;Edinburgh, Scotland, UK;2016;9781450341349;;"https://doi-org.proxy.bnl.lu/10.1145/2962695.2962713;http://dx.doi.org/10.1145/2962695.2962713";10.1145/2962695.2962713;EN 50128 gives a general guidance for testing railway safety-critical software. However, it does not specify how to test safety-critical software in an agile development environment. Based on our observation, agile software development has not been applied to the development of the Chinese Train Control System (CTCS). Previous research focused on agile methods for managing and planning safety-critical software development. There exists little research about agile testing for developing railway safety-critical software in the literature.In this paper, we identify several major shortcomings of the existing practice of testing railway safety-critical software in China. In particular, we find out, that Continuous Integration (CI) and Continuous Delivery (CD) are missing from the current practice of agile testing. Furthermore, effective techniques and tools are lacking for CTCS. To address these shortcomings, we propose an agile testing framework for developing railway safety-critical software. In this framework, a build automation tool manages source code, unit tests, integration tests, resources and other tools. This test framework supports CI and CD, making agile testing possible. In addition, it includes effective unit and integration testing tools that allow rigorous tests to be generated. We believe this test framework will not only be applied to railway software, but also used for other safety-critical software.;Unit Testing, Railway Safety-critical System, Continuous Integration, Integration Testing, Continuous Delivery, Agile Testing;;;XP '16 Workshops
Journal Article;Dan A,Shahabuddin P,Sitaram D,Towsley D;Channel Allocation under Batching and VCR Control in Video-on-Demand Systems;J. Parallel Distrib. Comput.;1995;30;2;168–179;;Academic Press, Inc.;USA;;;;1995-11;;0743-7315;"https://doi-org.proxy.bnl.lu/10.1006/jpdc.1995.1135;http://dx.doi.org/10.1006/jpdc.1995.1135";10.1006/jpdc.1995.1135;"In order to guarantee continuous delivery of a video stream in an on-demand video server environment, a collection of resources (referred to as a logical channel) are reserved in advance. To conserve server resources, multiple client requests for the same video can be batched together and served by a single channel. Increasing the window over which all requests for a particular video are batched results in larger savings in server capacity; however, it also increases the reneging probability of a client. A complication introduced by batching is that if a batched client pauses, a new stream (which may not be immediately available) needs to be started when the client resumes. To provide short response time to resume requests, some channels are set aside and are referred to as contingency channels. To further improve resource utilization, even when a nonbatched client pauses, the channel is released and reacquired upon resume. In this paper, we first develop an analytical model that predicts the reneging probability and expected resume delay, and then use this model to optimally allocate channels for batching, on-demand playback, and contingency. The effectiveness of the proposed policy over a scheme with no contingency channels and no batching is also demonstrated.";;;;
Journal Article;Giat Y;Allocation of Scarce Resources in a Network with Periodic Deliveries and Customer Tolerable Wait;Comput. Ind. Eng.;2021;159;C;;;Pergamon Press, Inc.;USA;;;;2021-09;;0360-8352;"https://doi-org.proxy.bnl.lu/10.1016/j.cie.2021.107462;http://dx.doi.org/10.1016/j.cie.2021.107462";10.1016/j.cie.2021.107462;;Equitability, Window fill rate, Tolerable wait, Logistics, Spares allocation problem, Inventory;;;
Journal Article;Ragan T;21st-Century DevOps--an End to the 20th-Century Practice of Writing Static Build and Deploy Scripts;Linux J.;2013;2013;230;;;Belltown Media;Houston, TX;;;;2013-06;;1075-3583;;;Embracing 21st-century DevOps means letting go of 20th-century practices.;;;;
Conference Paper;Lampel J,Just S,Apel S,Zeller A;When Life Gives You Oranges: Detecting and Diagnosing Intermittent Job Failures at Mozilla;;2021;;;1381–1392;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Athens, Greece;2021;9781450385626;;"https://doi-org.proxy.bnl.lu/10.1145/3468264.3473931;http://dx.doi.org/10.1145/3468264.3473931";10.1145/3468264.3473931;Continuous delivery of cloud systems requires constant running of jobs (build processes, tests, etc.). One issue that plagues this continuous integration (CI) process are intermittent failures - non-deterministic, false alarms that do not result from a bug in the software or job specification, but rather from issues in the underlying infrastructure. At Mozilla, such intermittent failures are called oranges as a reference to the color of the build status indicator. As such intermittent failures disrupt CI and lead to failures, they erode the developers' trust in the jobs. We present a novel approach that automatically classifies failing jobs to determine whether job execution failures arise from an actual software bug or were caused by flakiness in the job (e.g., test) or the underlying infrastructure. For this purpose, we train classification models using job telemetry data to diagnose failure patterns involving features such as runtime, cpu load, operating system version, or specific platform with high precision. In an evaluation on a set of Mozilla CI jobs, our approach achieves precision scores of 73%, on average, across all data sets with some test suites achieving precision scores good enough for fully automated classification (i.e., precision scores of up to 100%), and recall scores of 82% on average (up to 94%).;intermittent failures, Software testing, continuous integration, machine learning, flaky tests;;;ESEC/FSE 2021
Book Chapter;Chen S,Shen B,Wee S,Zhang X;Streaming Flow Analyses for Prefetching in Segment-Based Proxy Caching to Improve Delivery Quality;;2004;;;171–186;;Kluwer Academic Publishers;USA;Web Content Caching and Distribution: Proceedings of the 8th International Workshop;;;2004;9781402022579;;;;Segment-based proxy caching schemes have been effectively used to deliver streaming media objects. However, this approach does not always guarantee continuous delivery because the to-be-viewed segments may not be cached in the proxy in time. The potential consequence is the playback jitter at the client side due to the proxy delay in fetching these uncached segments, thus we call the problem proxy jitter. Aiming at improving the media delivery quality for segment-based caching schemes, in this paper we propose two simple and effective prefetching methods, namely, look-ahead window based prefetching and active prefetching to address the problem of proxy jitter. We focus on presenting streaming flow analyses on proxy and network resource utilizations and consumptions, performance potentials and limits of the two prefetching methods for different segment-based schemes under different network bandwidth conditions. Our study also provides some new insights into relationships between proxy caching performance and the quality of streaming. For example, we show that the objective of improving the byte hit ratio in a conventional proxy and the unique objective of minimizing the proxy jitter to deliver streaming media objects can have conflicting interests. Trace-driven simulations show the effectiveness of our prefetching methods, and further confirm our analyses.;;;;
Conference Paper;Johng H,Kalia AK,Xiao J,Vuković M,Chung L;Harmonia: A Continuous Service Monitoring Framework Using DevOps and Service Mesh in a Complementary Manner;;;;;151–168;;Springer-Verlag;Berlin, Heidelberg;;Service-Oriented Computing;Toulouse France;;9783030337018;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-33702-5_12;http://dx.doi.org/10.1007/978-3-030-33702-5_12";10.1007/978-3-030-33702-5_12;Software teams today are required to deliver new or updated services frequently, rapidly and independently. Adopting DevOps and Microservices support the rapid service delivery model but leads to pushing code or service infrastructure changes across inter-dependent teams that are not collectively assessed, verified, or notified. In this paper, we propose Harmonia - a continuous service monitoring framework utilizing DevOps and Service Mesh in a complementary manner to improve coordination and change management among independent teams. Harmonia can automatically detect changes in services, including changes that violate performance SLAs and user experience, notify the changes to affected teams, and help them resolve the changes quickly. We applied Harmonia to a standard application in describing Microservice management to assist with an initial understanding and strengths of Harmonia. During the demonstration, we deployed faulty and normal services alternatively and captured changes from Jenkins, Github, Istio, and Kubernetes logs to form an application-centric cohesive view of the change and its impact and notify the affected teams.;Service Mesh, Enterprise Cloud Management, Microservice, DevOps, Monitoring;;;
Conference Paper;Rahman A,Partho A,Morrison P,Williams L;What Questions Do Programmers Ask about Configuration as Code?;;2018;;;16–22;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 4th International Workshop on Rapid Continuous Software Engineering;Gothenburg, Sweden;2018;9781450357456;;"https://doi-org.proxy.bnl.lu/10.1145/3194760.3194769;http://dx.doi.org/10.1145/3194760.3194769";10.1145/3194760.3194769;"Configuration as code (CaC) tools, such as Ansible and Puppet, help software teams to implement continuous deployment and deploy software changes rapidly. CaC tools are growing in popularity, yet what challenges programmers encounter about CaC tools, have not been characterized. A systematic investigation on what questions are asked by programmers, can help us identify potential technical challenges about CaC, and can aid in successful use of CaC tools. The goal of this paper is to help current and potential configuration as code (CaC) adoptees in identifying the challenges related to CaC through an analysis of questions asked by programmers on a major question and answer website. We extract 2,758 Puppet-related questions asked by programmers from January 2010 to December 2016, posted on Stack Overflow. We apply qualitative analysis to identify the questions programmers ask about Puppet. We also investigate the trends in questions with unsatisfactory answers, and changes in question categories over time. From our empirical study, we synthesize 16 major categories of questions. The three most common question categories are: (i) syntax errors, (ii) provisioning instances; and (iii) assessing Puppet's feasibility to accomplish certain tasks. Three categories of questions that yield the most unsatisfactory answers are (i) installation, (ii) security, and (iii) data separation.";programming, question, infrastructure as code, challenge, puppet, stack overflow, configuration as code, devops, continuous deployment;;;RCoSE '18
Conference Paper;Dobaj J,Iber J,Krisper M,Kreiner C;A Microservice Architecture for the Industrial Internet-Of-Things;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 23rd European Conference on Pattern Languages of Programs;Irsee, Germany;2018;9781450363877;;"https://doi-org.proxy.bnl.lu/10.1145/3282308.3282320;http://dx.doi.org/10.1145/3282308.3282320";10.1145/3282308.3282320;With the introduction of Internet-of-Things (IoT) and cyber-physical system (CPS) concepts the industrial automation sector is undergoing enormous change towards highly interconnected and globally distributed automation systems. Following this trend the industry is facing interoperability challenges between devices and systems, which origin in the market and technology fragmentation of the past years. However, established integration techniques from the IoT domain cannot be fully adapted in industrial Internet-of-Things (IIoT) environments due to stricter dependability and real time constraints.Since design patterns offer a practical means to gain a deeper understanding of the problem domain, patterns are applied in this paper to develop a software architecture that is suitable for the deployment in the upcoming IIoT environments. The resulting software architecture combines ideas from the IoT world, industrial automation systems, as well as modern information technology (IT) and cloud architectures. Its lightweight and flexible design, along with the support of state-of-the-art development approaches (containerization, continuous integration (CI), continuous deployment (CD)) make the architecture equally suitable for the deployment on cloud, fog and edge devices. All in all, these features facilitate the deployment of services and communication protocols on device level, to enable the transparent and automatic integration of heterogenous devices and protocols, on demand.;Industry 4.0, Patterns, Microservice, Software Architecture, Industrial Automation, IoT, IIoT, SoA, CPS;;;EuroPLoP '18
Book;Classon I;Migrating ASP.NET Microservices to ASP.NET Core: By Example;;2019;;;;1st;Apress;USA;;;;2019;9781484243268;;;;Migrate your existing microservice cluster from ASP .NET to ASP .NET Core. While improved performance and cross-platform support are evident, this book helps you cut through the noise to determine how, when, and to what extent a migration is needed. Microsoft's introduction of .NET Core has created a lot of excitement, but also a lot of confusion for developers accustomed to ASP applications and services. This book gives you specific steps to embark on a partial or full SaaS microservices system migration, factoring in limited resources, time, and finances. In addition to practical advice and real-world examples, many mishaps will be shared, providing you with a complete 360-degree view of a migration. As a developer intimately familiar with the migration process, author Iris Classon shares prescriptive guidance on every part of the system?from code, dependencies, editors, integration, and the deployment pipeline to a distribution model. You will come away with all the information you need to plan and prepare your migration to ASP.NET Core. What You'll Learn Conduct an in-depth, pre-migration analysis of your system Know the differences between ASP .NET and ASP .NET Core Plan for and execute a full or partial migration to ASP .NET Core Understand the continuous integration and deployment process Gain insight on tools and templates that will accelerate and facilitate the migration process Leverage a real-world migration example, complete with genuine challenges Migrate specific components such as logging, authentication, data access, and more Who This Book Is For Developers who are considering or are tasked with migrating an existing microservice cluster from ASP.NET to ASP.NET Core. Experience with C#, Web API, ASP.NET, Visual Studio, and PowerShell is helpful.;;;;
Conference Paper;Ardagna D,Casale G,van Hoorn A,Willnecker F,Di Nitto E,Leitner P;Session Details: Third International Workshop on Quality-Aware DevOps (QUDOS'17);;2017;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3254604;http://dx.doi.org/10.1145/3254604";10.1145/3254604;;;;;ICPE '17 Companion
Conference Paper;Rahman MT,Querel LP,Rigby PC,Adams B;Feature Toggles: Practitioner Practices and a Case Study;;2016;;;201–211;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 13th International Conference on Mining Software Repositories;Austin, Texas;2016;9781450341868;;"https://doi-org.proxy.bnl.lu/10.1145/2901739.2901745;http://dx.doi.org/10.1145/2901739.2901745";10.1145/2901739.2901745;Continuous delivery and rapid releases have led to innovative techniques for integrating new features and bug fixes into a new release faster. To reduce the probability of integration conflicts, major software companies, including Google, Facebook and Netflix, use feature toggles to incrementally integrate and test new features instead of integrating the feature only when it's ready. Even after release, feature toggles allow operations managers to quickly disable a new feature that is behaving erratically or to enable certain features only for certain groups of customers. Since literature on feature toggles is surprisingly slim, this paper tries to understand the prevalence and impact of feature toggles. First, we conducted a quantitative analysis of feature toggle usage across 39 releases of Google Chrome (spanning five years of release history). Then, we studied the technical debt involved with feature toggles by mining a spreadsheet used by Google developers for feature toggle maintenance. Finally, we performed thematic analysis of videos and blog posts of release engineers at major software companies in order to further understand the strengths and drawbacks of feature toggles in practice. We also validated our findings with four Google developers. We find that toggles can reconcile rapid releases with long-term feature development and allow flexible control over which features to deploy. However they also introduce technical debt and additional maintenance for developers.;;;;MSR '16
Conference Paper;Di Sorbo A,Panichella S,Alexandru CV,Visaggio CA,Canfora G;SURF: Summarizer of User Reviews Feedback;;2017;;;55–58;;IEEE Press;Buenos Aires, Argentina;;Proceedings of the 39th International Conference on Software Engineering Companion;;2017;9781538615898;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-C.2017.5;http://dx.doi.org/10.1109/ICSE-C.2017.5";10.1109/ICSE-C.2017.5;Continuous Delivery (CD) enables mobile developers to release small, high quality chunks of working software in a rapid manner. However, faster delivery and a higher software quality do neither guarantee user satisfaction nor positive business outcomes. Previous work demonstrates that app reviews may contain crucial information that can guide developer's software maintenance efforts to obtain higher customer satisfaction. However, previous work also proves the difficulties encountered by developers in manually analyzing this rich source of data, namely (i) the huge amount of reviews an app may receive on a daily basis and (ii) the unstructured nature of their content. In this paper, we propose SURF (Summarizer of User Reviews Feedback), a tool able to (i) analyze and classify the information contained in app reviews and (ii) distill actionable change tasks for improving mobile applications. Specifically, SURF performs a systematic summarization of thousands of user reviews through the generation of an interactive, structured and condensed agenda of recommended software changes. An end-to-end evaluation of SURF, involving 2622 reviews related to 12 different mobile applications, demonstrates the high accuracy of SURF in summarizing user reviews content. In evaluating our approach we also involve the original developers of some apps, who confirm the practical usefulness of the software change recommendations made by SURF.Demo URL: https://youtu.be/Yf-U5ylJXvoDemo webpage: http://www.ifi.uzh.ch/en/seal/people/panichella/tools/SURFTool.html;mobile applications, summarization, natural language processing, software maintenance;;;ICSE-C '17
Conference Paper;Vieira CS,Lohmann PA,Magdaleno AM,Engiel P;APRUMO (Agile Process Modeling) – A Method to Process Modeling Using Agile BPM;;2020;;;;;Association for Computing Machinery;New York, NY, USA;;XVI Brazilian Symposium on Information Systems;São Bernardo do Campo, Brazil;2020;9781450388733;;"https://doi-org.proxy.bnl.lu/10.1145/3411564.3411631;http://dx.doi.org/10.1145/3411564.3411631";10.1145/3411564.3411631;Agile BPM is the integration and adaptation of agile practices, deriving from the software development to the BPM (Business Process Management) cycle as an alternative to the traditional BPM approach. Agile BPM recommends iterative process management, with continuous delivery, customer approximation through validations and information sharing, turning the BPM evolution more visible and resulting in suitable modeling to specific customer needs. The proposal of this paper consists of the definition of APRUMO (Agile Process Modelling) where Agile BPM concepts are applied in the business process modeling phase. The method is organized in phases and with roles and responsibilities defined. A case study was planned and conducted in a real company for 5 months and involved 5 professionals of the company. At the end of the study, 2 sprints and 10 meetings were performed, delivering 7 process models. A questionnaire answered by participants showed that simplicity and flexibility were positive points and, on the other hand, they needed extra working time on it. This study demonstrated the method's agile practices viability, resulting in participative customer and improved information extraction during the gathering process. It was also possible to identify some difficulties to apply APRUMO such as the need for a process team with modeling experience, the need of customer engagement and other as the need for complementary documents to produced models.;BPM, Business Process Management, Agile, Agile BPM;;;SBSI'20
Conference Paper;Veeraragavan NR,Montecchi L,Nostro N,Bondavalli A,Vitenberg R,Meling H;Understanding the Quality of Experience in Modern Distributed Interactive Multimedia Applications in Presence of Failures: Metrics and Analysis;;2013;;;439–446;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 28th Annual ACM Symposium on Applied Computing;Coimbra, Portugal;2013;9781450316569;;"https://doi-org.proxy.bnl.lu/10.1145/2480362.2480450;http://dx.doi.org/10.1145/2480362.2480450";10.1145/2480362.2480450;"Recent technological advances have made it possible to design bandwidth demanding distributed interactive multimedia applications such as the World Opera application. In this application artists from different opera houses across the globe, can participate in a single united performance and interact almost as if they were co-located.One of the main design challenges in this application domain is to determine the composition of system components necessary to satisfy the desired quality of service in presence of failures and budget constraints. This challenge is exacerbated by the fact that quality of service depends on a multitude of factors such as human perception of video and audio, the type of audience, performance elements, etc. These factors cannot be captured by traditional approaches for dependability evaluation such as reliability, i.e., continuous delivery of correct service. This calls for developing a more comprehensive ""Quality of Experience"" concept.In this paper, we propose a novel method to assess the quality of experience in presence of failures, based on a new metric called perceived reliability. This method can help the system designers and engineers compare architectural variants and to determine the dependability budget. We show the feasibility of our method by applying it to a World Opera performance. Our experimental results provide useful guidelines for system engineers towards improving the quality of experience of World Opera performances despite presence of failures.";distributed interactive multimedia applications, quality of experience, reliability analysis, world opera;;;SAC '13
Conference Paper;Sankaranarayanan S,Fainekos G;Simulating Insulin Infusion Pump Risks by In-Silico Modeling of the Insulin-Glucose Regulatory System;;2012;;;322–341;;Springer-Verlag;Berlin, Heidelberg;;Proceedings of the 10th International Conference on Computational Methods in Systems Biology - Volume 7605;London, UK;2012;9783642336355;;;;We present a case study on the use of robustness-guided and statistical model checking approaches for simulating risks due to insulin infusion pump usage by diabetic patients. Insulin infusion pumps allow for a continuous delivery of insulin with varying rates and delivery profiles to help patients self-regulate their blood glucose levels. However, the use of infusion pumps and continuous glucose monitors can pose risks to the patient including chronically elevated blood glucose levels hyperglycemia or dangerously low glucose levels hypoglycemia.In this paper, we use mathematical models of the basic insulin-glucose regulatory system in a diabetic patient, insulin infusion pumps, and the user's interaction with these pumps defined by commonly used insulin infusion strategies for maintaining normal glucose levels. These strategies include common guidelines taught to patients by physicians and certified diabetes educators and have been implemented in commercially available insulin bolus calculators. Furthermore, we model the failures in the devices themselves along with common errors in the usage of the pump. We compose these models together and analyze them using two related techniques: a robustness guided state-space search to explore worst-case scenarios and b statistical model checking techniques to assess the probabilities of hyper- and hypoglycemia risks. Our technique can be used to identify the worst-case effects of the combination of many different kinds of failures and place high confidence bounds on their probabilities.;;;;CMSB 2012
Ph.D. Thesis;Zhygulskyy M;Automated, Scheduled and Ci /Cd Web Injection;;2021;;;;;Instituto Politecnico de Leiria (Portugal);;;;;2021;;;;;This report is made within the Curricular Unit (UC) Project, in the 2nd year of the Master in Cyber-security and Forensic Informatics (MCIF) provided by the Polytechnic Institute of Leiria (IPL). The purpose of this project is to study SQL Injection vulnerabilities in web applications. According to OWASP (Open Web Application Security Project) [20][19], this is one of the more prevalent attacks on web applications. As part of this work a web application was implemented, which can from a URL address, go through all the endpoints of the target application and test for SQL Injection vulnerabilities. The application also makes allows for scheduling of the tests and it is integrable with Continuous Integration / Continuous Delivery (CI/CD) environments. According to the literature on the subject, there are several algorithms that can be employed to test for existing SQL Injection vulnerabilities in a web application. In this document, we analyze them both from a theoretical and an implementation point of view. In order to better understand the subject, and produce a useful tool in this space. With the development of this project, we concluded that it is possible to integrate SQL vulnerability tests, with CI/CD pipeline and automate the development process of an application, with the execution of SQL injection tests in an automated way.;;AAI28787630;Ph.D. Thesis;
Conference Paper;Mohagheghi P,Lassenius C;Organizational Implications of Agile Adoption: A Case Study from the Public Sector;;2021;;;1444–1454;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Athens, Greece;2021;9781450385626;;"https://doi-org.proxy.bnl.lu/10.1145/3468264.3473937;http://dx.doi.org/10.1145/3468264.3473937";10.1145/3468264.3473937;While agile software development is increasingly adopted in large organizations, there is still a lack of studies on how traditionally organized enterprises adopt and scale agile forms of organization. This industrial multiple embedded case study explores how the organizational model of a large public sector entity evolved over four years to support the adoption of agile software development methods. Data was collected through semi-structured interviews and document analysis. We describe the change in three phases: pre-transformation, initial transformation, and maturing. Changes in three subcases of organizational units are further described in detail. Moving from an outsourced project-based way-of-working with separate business, IT and vendor organizations, the new organizational design emphasizes internal development capability, cross-functional autonomous teams organized around products and grouped in product areas, and continuous delivery. Starting from the IT department, the transformation expanded to the whole organization, and went beyond software development to the finance and leadership. We describe the target and intermediate organizations employed when adopting agile development methods for the whole organization and three organizational units responsible for different services. Defining suitable product boundaries, achieving alignment across teams, enhancing the competence of product owners, the coexistence of old and new types of systems, processes, and structures, and balancing the teams’ need for autonomy with the organizational needs for coordination and control are remaining challenges.;Large-scale agile software development, agile adoption, team autonomy, agile organization;;;ESEC/FSE 2021
Book;Collier KW;Agile Analytics: A Value-Driven Approach to Business Intelligence and Data Warehousing;;2011;;;;1st;Addison-Wesley Professional;;;;;2011;9780321504814;;;;"Using Agile methods, you can bring far greater innovation, value, and quality to any data warehousing (DW), business intelligence (BI), or analytics project. However, conventional Agile methods must be carefully adapted to address the unique characteristics of DW/BI projects. In Agile Analytics, Agile pioneer Ken Collier shows how to do just that. Collier introduces platform-agnostic Agile solutions for integrating infrastructures consisting of diverse operational, legacy, and specialty systems that mix commercial and custom code. Using working examples, he shows how to manage analytics development teams with widely diverse skill sets and how to support enormous and fast-growing data volumes. Colliers techniques offer optimal value whether your projects involve back-end data management, front-end business analysis, or both. Part I focuses on Agile project management techniques and delivery team coordination, introducing core practices that shape the way your Agile DW/BI project community can collaborate toward success Part II presents technical methods for enabling continuous delivery of business value at production-quality levels, including evolving superior designs; test-driven DW development; version control; and project automation Collier brings together proven solutions you can apply right nowwhether youre an IT decision-maker, data warehouse professional, database administrator, business intelligence specialist, or database developer. With his help, you can mitigate project risk, improve business alignment, achieve better resultsand have fun along the way.";;;;
Book;Morimoto R,Yardeni G;Maximizing Microsoft's Azure for Dev, Test, and DevOps Scenarios - Volume 3;;2014;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2014;9781505608793;;;;Microsoft's Azure cloud-based hosted environment is more than just a Platform as a Service (PaaS) or Infrastruture as a Service (IaaS) environment. Rather, Microsoft Azure is highly leveraged by developers of enterprise organizations in their application lifecycle management processes. This book covers the key solution areas where Microsoft Azure helps developers extend their development platforms into the cloud, and not just for Microsoft-based development in .NET or SQL, but also for development on Linux and Windows for Perl, C#, Bash, and Python managed by tools like Puppet, Chef, and System Center. Solution guidance are shared on day to day operational controls, release management, and experience of developers who have successfully created a hybrid cloud application development and deployment process leveraging the cloud capabilities of Microsoft Azure.;;;;
Conference Paper;Li CJ,Shih HJ;The One-Key Seamless Integrating Platform for Open-Source DevOps Tools, to Solve Interconnecting Issues and Boost CI/CD Efficiency;;2021;;;80–83;;Association for Computing Machinery;New York, NY, USA;;2021 3rd International Conference on Information Technology and Computer Communications;Guangzhou, China;2021;9781450389884;;"https://doi-org.proxy.bnl.lu/10.1145/3473465.3473479;http://dx.doi.org/10.1145/3473465.3473479";10.1145/3473465.3473479;With the widespread of DevOps and agile developments, and IT industries are concerning about license and compliance issues while adopting commercial developing solutions. Those IT industries desperately need open-source alternative solutions, as well as guidelines to follow SDLC standards. This study planned to establish a one-key seamless open-source DevOps developing platform, to solve interconnecting issues between open-source DevOps tools, boost CI/CD efficiency, and assure quality of software developments and products.;;;;ITCC 2021
Journal Article;Powers S;The Open-Source Classroom: DevOps: Better than the Sum of Its Parts;Linux J.;2014;2014;247;;;Belltown Media;Houston, TX;;;;2014-11;;1075-3583;;;;;;;
Journal Article;Liu B,Bi J,Vasilakos AV;Toward Incentivizing Anti-Spoofing Deployment;Trans. Info. For. Sec.;2014;9;3;436–450;;IEEE Press;;;;;2014-03;;1556-6013;"https://doi-org.proxy.bnl.lu/10.1109/TIFS.2013.2296437;http://dx.doi.org/10.1109/TIFS.2013.2296437";10.1109/TIFS.2013.2296437;IP spoofing-based flooding attacks are a serious and open security problem on the current Internet. The best current antispoofing practices have long been implemented in modern routers. However, they are not sufficiently applied due to the lack of deployment incentives, i.e., an autonomous system (AS) can hardly gain additional protection by deploying them. In this paper, we propose mutual egress filtering (MEF), a novel antispoofing method, which provides continuous deployment incentives. The MEF is implemented on the AS border routers using access control lists (ACLs). It drops an outbound packet whose source address does not belong to the local AS if the packet is related to a spoofing attack against other MEF-enabled ASes. By this means, only the deployers of the MEF can gain protection, whereas nondeployers cannot free ride. As more ASes deploy MEF, deployment incentives become higher. We present the system design of MEF, and propose an optimal prefix compression algorithm to compact the ACL into the routers' limited hardware resource. With theoretical analysis and simulations with real Internet data, our evaluation results show that MEF is the only method that achieves monotonically increasing deployment incentives for all types of spoofing attacks, and the system design is lightweight and practical. The prefix compression algorithm advances the state-of-the-art by generalizing the functionalities and reducing the overhead in both time and space.;;;;
Book Chapter;Sildatke M,Karwanni H,Kraft B,Schmidts O,Zündorf A;Automated Software Quality Monitoring in Research Collaboration Projects;;2020;;;603–610;;Association for Computing Machinery;New York, NY, USA;Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops;;;2020;9781450379632;;https://doi-org.proxy.bnl.lu/10.1145/3387940.3391478;;In collaborative research projects, both researchers and practitioners work together solving business-critical challenges. These projects often deal with ETL processes, in which humans extract information from non-machine-readable documents by hand. AI-based machine learning models can help to solve this problem.Since machine learning approaches are not deterministic, their quality of output may decrease over time. This fact leads to an overall quality loss of the application which embeds machine learning models. Hence, the software qualities in development and production may differ.Machine learning models are black boxes. That makes practitioners skeptical and increases the inhibition threshold for early productive use of research prototypes. Continuous monitoring of software quality in production offers an early response capability on quality loss and encourages the use of machine learning approaches. Furthermore, experts have to ensure that they integrate possible new inputs into the model training as quickly as possible.In this paper, we introduce an architecture pattern with a reference implementation that extends the concept of Metrics Driven Research Collaboration with an automated software quality monitoring in productive use and a possibility to auto-generate new test data coming from processed documents in production.Through automated monitoring of the software quality and auto-generated test data, this approach ensures that the software quality meets and keeps requested thresholds in productive use, even during further continuous deployment and changing input data.;;;;
Conference Paper;Tërnava X,Lesoil L,Randrianaina GA,Khelladi DE,Acher M;On the Interaction of Feature Toggles;;2022;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 16th International Working Conference on Variability Modelling of Software-Intensive Systems;Florence, Italy;2022;9781450396042;;"https://doi-org.proxy.bnl.lu/10.1145/3510466.3510485;http://dx.doi.org/10.1145/3510466.3510485";10.1145/3510466.3510485;Feature toggling is a technique for enabling branching-in-code. It is increasingly used during continuous deployment to incrementally test and integrate new features before their release. In principle, feature toggles tend to be light, that is, they are defined as simple Boolean flags and used in conditional statements to condition the activation of some software features. However, there is a lack of knowledge on whether and how they may interact with each other, in that case their enabling and testing become complex. We argue that finding the interactions of feature toggles is valuable for developers to know which of them should be enabled at the same time, which are impacted by a removed toggle, and to avoid their mis-configurations. In this work, we mine feature toggles and their interactions in five open-source projects. We then analyse how they are realized and whether they tend to be multiplied over time. Our results show that 7% of feature toggles interact with each other, 33% of them interact with another code expression, and their interactions tend to increase over time (22%, on average). Further, their interactions are expressed by simple logical operators (i.e., and and or) and nested if statements. We propose to model them into a Feature Toggle Model, and believe that our results are helpful towards robust management approaches of feature toggles.;continuous deployment, feature flags, interaction of feature toggles;;;VaMoS '22
Journal Article;Cruz L,Abreu R,Lo D;To the Attention of Mobile Software Developers: Guess What, Test Your App!;Empirical Softw. Engg.;2019;24;4;2438–2468;;Kluwer Academic Publishers;USA;;;;2019-08;;1382-3256;"https://doi-org.proxy.bnl.lu/10.1007/s10664-019-09701-0;http://dx.doi.org/10.1007/s10664-019-09701-0";10.1007/s10664-019-09701-0;Software testing is an important phase in the software development lifecycle because it helps in identifying bugs in a software system before it is shipped into the hand of its end users. There are numerous studies on how developers test general-purpose software applications. The idiosyncrasies of mobile software applications, however, set mobile apps apart from general-purpose systems (e.g., desktop, stand-alone applications, web services). This paper investigates working habits and challenges of mobile software developers with respect to testing. A key finding of our exhaustive study, using 1000 Android apps, demonstrates that mobile apps are still tested in a very ad hoc way, if tested at all. However, we show that, as in other types of software, testing increases the quality of apps (demonstrated in user ratings and number of code issues). Furthermore, we find evidence that tests are essential when it comes to engaging the community to contribute to mobile open source software. We discuss reasons and potential directions to address our findings. Yet another relevant finding of our study is that Continuous Integration and Continuous Deployment (CI/CD) pipelines are rare in the mobile apps world (only 26% of the apps are developed in projects employing CI/CD) --- we argue that one of the main reasons is due to the lack of exhaustive and automatic testing.;Software testing, Open source software, Mobile applications, Software quality, Software metrics;;;
Journal Article;Imran M,Kuznetsov V,Dziedziniewicz-Wojcik KM,Pfeiffer A,Paparrigopoulos P,Trigazis S,Tedeschi T,Ciangottini D;Migration of CMSWEB Cluster at CERN to Kubernetes: A Comprehensive Study;Cluster Computing;2021;24;4;3085–3099;;Kluwer Academic Publishers;USA;;;;2021-12;;1386-7857;"https://doi-org.proxy.bnl.lu/10.1007/s10586-021-03325-0;http://dx.doi.org/10.1007/s10586-021-03325-0";10.1007/s10586-021-03325-0;The Compact Muon Solenoid (CMS) experiment heavily relies on the CMSWEB cluster to host critical services for its operational needs. The cluster is deployed on virtual machines (VMs) from the CERN OpenStack cloud and is manually maintained by operators and developers. The release cycle is composed of several steps, from building RPMs to their deployment, validation, and integration tests. To enhance the sustainability of the CMSWEB cluster, CMS decided to migrate its cluster to a containerized solution based on Docker and orchestrated with Kubernetes (K8s). This allows us to significantly speed up the release upgrade cycle, follow the end-to-end deployment procedure, and reduce operational cost. In this paper, we give an overview of the CMSWEB VM cluster and the issues we discovered during this migration. We discuss the architecture and the implementation strategy in the CMSWEB Kubernetes cluster. Even though Kubernetes provides horizontal pod autoscaling based on CPUs and memory, in this paper, we provide details of horizontal pod autoscaling based on the custom metrics of CMSWEB services. We also discuss automated deployment procedure based on the best practices of continuous integration/continuous deployment (CI/CD) workflows. We present performance analysis between Kubernetes and VM based CMSWEB deployments. Finally, we describe various issues found during the implementation in Kubernetes and report on lessons learned during the migration process.;LHC, Kubernetes, Container, CMS, Docker, Cluster computing, CMSWEB;;;
Journal Article;Gonzalez-Herrera I,Bourcier J,Daubert E,Rudametkin W,Barais O,Fouquet F,Jézéquel JM,Baudry B;ScapeGoat;J. Syst. Softw.;2016;122;C;398–415;;Elsevier Science Inc.;USA;;;;2016-12;;0164-1212;"https://doi-org.proxy.bnl.lu/10.1016/j.jss.2016.02.027;http://dx.doi.org/10.1016/j.jss.2016.02.027";10.1016/j.jss.2016.02.027;We provide an optimistic adaptive monitoring system.We model the resource requirement through contracts.We provide localized just-in-time injection and activation of monitoring probes.We guide the search of the faulty component through a specific heuristic.We used two use cases (one real world) from different domains to validate the system. Modern component frameworks support continuous deployment and simultaneous execution of multiple software components on top of the same virtual machine. However, isolation between the various components is limited. A faulty version of any one of the software components can compromise the whole system by consuming all available resources. In this paper, we address the problem of efficiently identifying faulty software components running simultaneously in a single virtual machine. Current solutions that perform permanent and extensive monitoring to detect anomalies induce high overhead on the system, and can, by themselves, make the system unstable. In this paper we present an optimistic adaptive monitoring system to determine the faulty components of an application. Suspected components are finely analyzed by the monitoring system, but only when required. Unsuspected components are left untouched and execute normally. Thus, we perform localized just-in-time monitoring that decreases the accumulated overhead of the monitoring system. We evaluate our approach on two case studies against a state-of-the-art monitoring system and show that our technique correctly detects faulty components, while reducing overhead by an average of 93%.;Models@Run.Time, Resource monitoring, Component;;;
Conference Paper;Gondor S,Kupper A,Uzun A,Bayer N,Kollecker L;A Traffic Injection Framework to Support the Evaluation of Effects of Reconfigurations on Energy Consumption in Multi-RAT Networks;;2012;;;595–598;;IEEE Computer Society;USA;;Proceedings of the 2012 IEEE International Conference on Green Computing and Communications;;2012;9780769548654;;"https://doi-org.proxy.bnl.lu/10.1109/GreenCom.2012.90;http://dx.doi.org/10.1109/GreenCom.2012.90";10.1109/GreenCom.2012.90;With the ongoing growth of mobile Internet usage numbers and the continuous deployment of additional mobile network nodes, the power consumption in mobile networks is increasing at dramatic rates leading to a huge amount of carbon emissions. Therefore, improving energy efficiency in mobile radio networks is of increasing relevance. The reduction of energy consumption in mobile radio networks can be achieved by adaptively reconfiguring mobile network components (e.g., switching on/off base stations) based on user behavior and predicted capacity demands for a certain cell or area. In the project Communicate Green, we evaluate and develop concepts and algorithms that can be utilized to apply a context-aware power management in heterogeneous Multi-RAT networks. One of the biggest problems we encountered during the evaluation of the proposed mechanisms in our test bed is the fact that test beds do not resemble realistic conditions due to a lack of actual users and therefore traffic. In this paper, we propose a Traffic Injection Framework to simulate various load scenarios in test beds. The architecture is implemented in the Multi-RAT Test bed in Berlin, Germany, which consists of multiple distinct radio access technologies. The Traffic Injection Framework features a distributed approach, where client applications are installed on the nodes of the test bed and remotely managed by a control server.;testbed, context-awareness, traffic generation, mobile networks, wireless networks, power management;;;GREENCOM '12
Conference Paper;Bosch J;Architecture in the Age of Compositionality;;2010;;;1–4;;Springer-Verlag;Berlin, Heidelberg;;Proceedings of the 4th European Conference on Software Architecture;Copenhagen, Denmark;2010;9783642151132;;;;The nature of software engineering is changing. Where as building systems was the predominant activity, more recently the focus has shifted toward composing systems from open-source, commercial and proprietary components and to only build the functionality that truly is competitively differentiating. In addition, the way software is developed has changed as well, especially focusing on short development cycles and frequent, or even continuous, deployment. Because of these requirements, often teams are organized around features, rather than components, and can change all components in the system, including their interfaces. A third trend is the increasing adoption of software ecosystems, where significant development of functionality relevant for customers occurs outside the platform organization. Obviously, however, the quality attributes that are necessary for system success remain important as well as the ability to easily incorporate new requirements in the system in a cost effective fashion. Because of the above, the role of software architecture and in particular the software architects is more important in this new world, but there is significant evolution in the implementation of the role. The paper starts by characterizing the new approach to software engineering and the role of compositionality. It then explores the implications for software architecture and the role of the software architect, Finally, it defines a number of research challenges for the ECSA community to explore.;compositionality, software architecture;;;ECSA'10
Conference Paper;Duque Anton SD,Fraunholz D,Krohmer D,Reti D,Schotten HD,Selgert F,Marosvölgyi M,Larsen M,Sudhakar K,Koch T,Witt T,Bassem C;Creating It from SCRATCh: A Practical Approach for Enhancing the Security of IoT-Systems in a DevOps-Enabled Software Development Environment;;2020;;;266–281;;Springer-Verlag;Berlin, Heidelberg;;Computer Safety, Reliability, and Security. SAFECOMP 2020 Workshops: DECSoS 2020, DepDevOps 2020, USDAI 2020, and WAISE 2020, Lisbon, Portugal, September 15, 2020, Proceedings;Lisbon, Portugal;2020;9783030555825;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-55583-2_20;http://dx.doi.org/10.1007/978-3-030-55583-2_20";10.1007/978-3-030-55583-2_20;DevOps describes a method to reorganize the way different disciplines in software engineering work together to speed up software delivery. However, the introduction of DevOps-methods to organisations is a complex task. A successful introduction results in a set of structured process descriptions. Despite the structure, this process leaves margin for error: Especially security issues are addressed in individual stages, without consideration of the interdependence. Furthermore, applying DevOps-methods to distributed entities, such as the Internet of Things (IoT) is difficult as the architecture is tailormade for desktop and cloud resources. In this work, an overview of tooling employed in the stages of DevOps processes is introduced. Gaps in terms of security or applicability to the IoT are derived. Based on these gaps, solutions that are being developed in the course of the research project SCRATCh are presented and discussed in terms of benefit to DevOps-environments.;DevOps, Cyber security, IoT;;;
Conference Paper;Dan A,Sitaram D,Shahabuddin P;Scheduling Policies for an On-Demand Video Server with Batching;;1994;;;15–23;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Second ACM International Conference on Multimedia;San Francisco, California, USA;1994;9780897916868;;"https://doi-org.proxy.bnl.lu/10.1145/192593.192614;http://dx.doi.org/10.1145/192593.192614";10.1145/192593.192614;In an on-demand video server environment, clients make requests for movies to a centralized video server. Due to the stringent response time requirements, continuous delivery of a video stream to the client has to be guaranteed by reserving sufficient resources required to deliver a stream. Hence there is a hard limit on the number of streams that can be simultaneously delivered by a server. The server can satisfy multiple requests for the same movie using a single disk I/O stream by sending the same data pages to multiple clients (using the multicast facility if present in the system). This can be achieved by batching requests for the same movie that arrive within a short duration of time. In this paper, we consider various policies for selecting the movie to be multicast. The choice of a policy depends very much on the customer waiting time tolerance before reneging. We show that an FCFS policy that schedules the movie with the longest outstanding request can perform better than the MQL policy that chooses the movie with the maximum number of outstanding requests. Additionally, if the user behavior can be influenced by guaranteeing maximum waiting time then it may be beneficial to pre-allocate a fixed number of streams for popular movies. Finally, we demonstrate using empirical distribution for movie requests, that a substantial reduction (of the order of 60%) in required server capacity can be achieved by batching.;;;;MULTIMEDIA '94
Book;Shah S;Maven for Eclipse;;2014;;;;;Packt Publishing;;;;;2014;9781783987122;;;;A fast-paced guide that helps you create a continuous delivery solution by integrating Maven with an Eclipse environment Who This Book Is ForIf you want to learn about Maven and use it from within Eclipse to develop Java projects, this is the book for you. Prior experience in developing Java projects and using the Eclipse IDE is presumed. Whether you are a beginner or an experienced developer, this book will get you up and running quickly, with a hands-on approach.About This BookUse m2eclipse, the Maven plugin for Eclipse, to develop Maven projectsCustomize Maven to suit your needs, generate artifacts, and build multi-module projectsSimplify Maven and utilize it with a hands-on, step-by-step approach In Detail Starting with an exploration of the Maven architecture and its installation, you will then learn how to install m2eclipse, which provides Maven integration with Eclipse. Furthermore, the book guides you through the stages of project creation, including building, testing, and executing the projects.You will learn to customize your projects by demonstrating different core concepts of the Maven project structure. Nevertheless, you will also become familiar with the build lifecycles that generate the required artifacts. Moreover, it will also guide you through the process of handling multimodule projects and working with them effectively.By the end of this book, you will have a good understanding of m2eclipse and will be able to use it efficiently with ease.;;;;
Journal Article;Golubchik L,Muntz RR,Chou CF,Berson S;Design of Fault-Tolerant Large-Scale VOD Servers: With Emphasis on High-Performance and Low-Cost;IEEE Trans. Parallel Distrib. Syst.;2001;12;4;363–386;;IEEE Press;;;;;2001-04;;1045-9219;"https://doi-org.proxy.bnl.lu/10.1109/71.920587;http://dx.doi.org/10.1109/71.920587";10.1109/71.920587;Recent technological advances in digital signal processing, data compression techniques, and high-speed communication networks have made Video-on-Demand (VOD) servers feasible. A challenging task in such systems is servicing multiple clients simultaneously while satisfying real-time requirements of continuous delivery of objects at specified rates. To accomplish these tasks and realize economies of scale associated with servicing a large user population, a VOD server requires a large disk subsystem. Although a single disk is fairly reliable, a large disk farm can have an unacceptably high probability of disk failure. Furthermore, due to real-time constraints, the reliability requirements of VOD systems are even more stringent than those of traditional information systems. Traditional RAID solutions are inadequate due to poor resource usage. Thus, in this paper, we present alternative schemes which provide a high degree of reliability at low disk storage, bandwidth, and memory costs for on-demand multimedia servers. Moreover, we discuss some of the main issues and trade-offs associated with providing fault tolerance in multidisk VOD systems. We would like to impress upon the reader that one of the main points of this paper is the exposition of trade-offs and issues associated with designing fault-tolerant VOD servers. It is not the case that one fault tolerance scheme is absolutely better than another, but rather that one must understand the trade-offs as well as one's system constraints and then choose a fault tolerance scheme accordingly.;multimedia, storage servers, video-on-demand., Fault tolerance, multidisk systems;;;
Book;;ESEM '16: Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;;Ciudad Real, Spain;2016;9781450344272;;;;The International Symposium on Empirical Software Engineering and Measurement (ESEM) is one of the most important forums at which to present and discuss empirical research on software engineering and measurement. Spain was the first country to host the ESEM in 2007. What, then, could be more natural than to return to Spain, this time in Ciudad Real, for the 10th ESEM conference?The papers cover a variety of research topics and research methods in empirical software engineering and measurement, including agile development, verification and validation, the innovative behavior of software engineers, repository mining for defect predictions, productivity measurement and improvement, bug-fixing, system safety and security, shared code, eye tracking, continuous delivery, code analysis, improved methods for systematic reviews and the sampling of subjects, evidence briefing to transfer knowledge to practitioners, blind analysis of data to avoid research bias and software maintenance.In addition to the research papers, we are delighted to include two very interesting keynote speeches. Prof. Claes Wohlin, from the Blekinge Institute of Technology (Karlskrona, Sweden), who presents a keynote about the need for more and better empirical software engineering research. He addresses the question of how to support an increased use of empirical evidence so as to guide important decisions in the software industry. Prof. Joe Peppard, from the European School of Management and Technology (Berlin, Germany), who tackles the importance of benefit management in software engineering, and how to ensure the usefulness and benefits of the software we build.;;;Proceedings;
Book;Nemeth E,Snyder G,Hein TR,Whaley B,Mackin D;UNIX and Linux System Administration Handbook (5th Edition);;2017;;;;5th;Addison-Wesley Professional;;;;;2017;9780134277554;;;;"As an author, editor, and publisher, I never paid much attention to the competitionexcept in a few cases. This is one of those cases. The UNIX System Administration Handbook is one of the few books we ever measured ourselves against. Tim OReilly, founder of OReilly Media This edition is for those whose systems live in the cloud or in virtualized data centers; those whose administrative work largely takes the form of automation and configuration source code; those who collaborate closely with developers, network engineers, compliance officers, and all the other worker bees who inhabit the modern hive. Paul Vixie, Internet Hall of Fame-recognized innovator and founder of ISC and Farsight Security This book is fun and functional as a desktop reference. If you use UNIX and Linux systems, you need this book in your short-reach library. It covers a bit of the systems history but doesnt bloviate. Its just straight-forward information delivered in a colorful and memorable fashion. Jason A. Nunnelley UNIX and Linux System Administration Handbook, Fifth Edition, is todays definitive guide to installing, configuring, and maintaining any UNIX or Linux system, including systems that supply core Internet and cloud infrastructure. Updated for new distributions and cloud environments, this comprehensive guide covers best practices for every facet of system administration, including storage management, network design and administration, security, web hosting, automation, configuration management, performance analysis, virtualization, DNS, security, and the management of IT service organizations. The authorsworld-class, hands-on technologistsoffer indispensable new coverage of cloud platforms, the DevOps philosophy, continuous deployment, containerization, monitoring, and many other essential topics. Whatever your role in running systems and networks built on UNIX or Linux, this conversational, well-written guide will improve your efficiency and help solve your knottiest problems.";;;;
Book Chapter;Alves I,Rocha C;Qualifying Software Engineers Undergraduates in DevOps - Challenges of Introducing Technical and Non-Technical Concepts in a Project-Oriented Course;;2021;;;144–153;;IEEE Press;;Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training;;;2021;9780738133201;;https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEET52601.2021.00024;;The constant changes in the software industry, practices, and methodologies impose challenges to teaching and learning current software engineering concepts and skills. DevOps is particularly challenging because it covers technical concepts, such as pipeline automation, and non-technical ones, such as team roles and project management. The present study investigates a course setup to introduce these concepts to software engineering undergraduates. We designed the course by employing coding to associate DevOps concepts to Agile, Lean, and Open source practices and tools. We present the main aspects of this project-oriented DevOps course, with 240 students enrolled it since its first offering in 2016. We conducted an empirical study, with both a quantitative and qualitative analysis, to evaluate this project-oriented course setup. We collected the data from the projects repository and students' perceptions from a questionnaire. We mined 148 repositories (corresponding to 72 projects) and obtained 86 valid responses to the questionnaire. We also mapped the concepts which are more challenging to students learn from experience. The results evidence that first-hand experience facilitates the comprehension of DevOps concepts and enriches classes discussions. we present a set of lessons learned, which may help professors better design and conduct project-oriented courses to cover DevOps concepts.;;;;
Conference Paper;Antunes RV,Navarro GM,Hanazumi S;Test Framework for Jenkins Shared Libraries;;2018;;;13–19;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the III Brazilian Symposium on Systematic and Automated Software Testing;SAO CARLOS, Brazil;2018;9781450365550;;"https://doi-org.proxy.bnl.lu/10.1145/3266003.3266008;http://dx.doi.org/10.1145/3266003.3266008";10.1145/3266003.3266008;Delivering new features to users as fast and efficiently as possible is a common challenge on software development. A continuous delivery and integration pipeline can be used for this purpose, since it provides an automated way to orchestrate a series of steps for building, versioning, testing and deploying an application code.The newest version of Jenkins works with a concept called pipeline-as-code, where instead of configuring jobs on Jenkins to build, deploy or test the application, the user can implement a shared library with the same purpose. As a result, Jenkins job settings have been transformed into Groovy code, which enables the development of automated unit tests. However, using this pipeline brings the challenge of guaranteeing the high quality of this orchestration process. Unit tests by themselves are not enough to make sure that the implementation of new pipeline features did not add new bugs or changed the pipeline behavior. To do this validation we need to write functional tests, but that requires understanding of Jenkins and Groovy which can make this task complex. For this reason, a test framework was created as a shared library to facilitate the creation of functional tests for Jenkins shared libraries. The framework can execute several pipeline scenarios described by the user and apply them to different projects. The framework helps to ensure a high quality in the pipeline code used to ship your application from development environment until production, resulting in a more reliable process.;Shared Library, Test Framework, Jenkins;;;SAST '18
Book;Ramachandran M,Mahmood Z;Software Engineering in the Era of Cloud Computing;;2020;;;;1st;Springer Publishing Company, Incorporated;;;;;2020;9783030336233;;;;This book focuses on the development and implementation of cloud-based, complex software that allows parallelism, fast processing, and real-time connectivity. Software engineering (SE) is the design, development, testing, and implementation of software applications, and this discipline is as well developed as the practice is well established whereas the Cloud Software Engineering (CSE) is the design, development, testing, and continuous delivery of service-oriented software systems and applications (Software as a Service Paradigm). However, with the emergence of the highly attractive cloud computing (CC) paradigm, the tools and techniques for SE are changing. CC provides the latest software development environments and the necessary platforms relatively easily and inexpensively. It also allows the provision of software applications equally easily and on a pay-as-you-go basis. Business requirements for the use of software are also changing and there is a need for applications in big data analytics, parallel computing, AI, natural language processing, and biometrics, etc. These require huge amounts of computing power and sophisticated data management mechanisms, as well as device connectivity for Internet of Things (IoT) environments. In terms of hardware, software, communication, and storage, CC is highly attractive for developing complex software that is rapidly becoming essential for all sectors of life, including commerce, health, education, and transportation. The book fills a gap in the SE literature by providing scientific contributions from researchers and practitioners, focusing on frameworks, methodologies, applications, benefits and inherent challenges/barriers to engineering software using the CC paradigm.;;;;
Conference Paper;Taibi D,Mandić V,Jabangwe R,Giallorenzo S;Session Details: MADE'18: Second International Workshop on Microservices: Agile and DevOps Experience;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th International Conference on Agile Software Development: Companion;Porto, Portugal;2018;9781450364225;;"https://doi-org.proxy.bnl.lu/10.1145/3329526;http://dx.doi.org/10.1145/3329526";10.1145/3329526;;;;;XP '18
Book;O'Grady A;GitLab Quick Start Guide: Migrate to GitLab for All Your Repository Management Solutions;;2018;;;;;Packt Publishing;;;;;2018;9781789534344;;;;Port projects over from GitHub and convert SVN projects to GitLab hosted git projects Key Features Effective guide for GitLab migration from GitHub and SVN Learn to implement DevOps with GitLab 11 Manage projects with issue boards and time tracking Book Description Gitlab is an open source repository management and version control toolkit with an enterprise offering. This book is the ideal guide to GitLab as a version control system (VCS), issue management tool, and a continuous integration platform. The book starts with an introduction to GitLab, a walkthrough of its features, and explores concepts such as version control systems, continuous integration, and continuous deployment. It then takes you through the process of downloading and installing a local copy of the on-premise version of GitLab in Ubuntu and/or CentOS. You will look at some common work?ows associated with GitLab work?ow and learn about project management in GitLab. You will see tools and techniques for migrating your code base from various version control systems such as GitHub and SVN to GitLab. By the end of the book, you will be using Gitlab for repository management, and be able to migrate projects from other VCSs to GitLab. What you will learn Set up CI and test builds for your projects Understand the benefits and limitations of GitLab work?ow Migrate from other common VCS platforms to Gitlab Create, review, and merge code changes Learn to branch local code and create a new branch in GitLab Configure sequential stages and simultaneous stages for CI/CD Access Mattermost for on-premise GitLab Discover the issue tracking features of GitLab Who this book is for The book is intended for the developers, SREs, and DevOps professionals who are looking for techniques to port their codebase to GitLab from GitHub or are looking to work with GitLab as their version control system of choice. If you've used other VCSs before, that will help with this book.;;;;
Book Chapter;Colantoni A,Berardinelli L,Wimmer M;DevOpsML: Towards Modeling DevOps Processes and Platforms;;2020;;;;;Association for Computing Machinery;New York, NY, USA;Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings;;;2020;9781450381352;;https://doi-org.proxy.bnl.lu/10.1145/3417990.3420203;;DevOps and Model Driven Engineering (MDE) provide differently skilled IT stakeholders with methodologies and tools for organizing and automating continuous software engineering activities-from development to operations, and using models as key engineering artifacts, respectively. Both DevOps and MDE aim at shortening the development life-cycle, dealing with complexity, and improve software process and product quality.The integration of DevOps and MDE principles and practices in low-code engineering platforms (LCEP) are gaining attention by the research community. However, at the same time, new requirements are upcoming for DevOps and MDE as LCEPs are often used by non-technical users, to deliver fully functional software. This is in particular challenging for current DevOps processes, which are mostly considered on the technological level, and thus, excluding most of the current LCEP users. The systematic use of models and modeling to lowering the learning curve of DevOps processes and platforms seems beneficial to make them also accessible for non-technical users.In this paper, we introduce DevOpsML, a conceptual framework for modeling and combining DevOps processes and platforms. Tools along with their interfaces and capabilities are the building blocks of DevOps platform configurations, which can be mapped to software engineering processes of arbitrary complexity. We show our initial endeavors on DevOpsML and present a research roadmap how to employ the resulting DevOpsML framework for different use cases.;;;;
Conference Paper;Stillwell M,Coutinho JG;A DevOps Approach to Integration of Software Components in an EU Research Project;;2015;;;1–6;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1st International Workshop on Quality-Aware DevOps;Bergamo, Italy;2015;9781450338172;;"https://doi-org.proxy.bnl.lu/10.1145/2804371.2804372;http://dx.doi.org/10.1145/2804371.2804372";10.1145/2804371.2804372;We present a description of the development and deployment infrastructure being created to support the integration effort of HARNESS, an EU FP7 project. HARNESS is a multi-partner research project intended to bring the power of heterogeneous resources to the cloud. It consists of a number of different services and technologies that interact with the OpenStack cloud computing platform at various levels. Many of these components are being developed independently by different teams at different locations across Europe, and keeping the work fully integrated is a challenge. We use a combination of Vagrant based virtual machines, Docker containers, and Ansible playbooks to provide a consistent and up-to-date environment to each developer. The same playbooks used to configure local virtual machines are also used to manage a static testbed with heterogeneous compute and storage devices, and to automate ephemeral larger-scale deployments to Grid'5000. Access to internal projects is managed by GitLab, and automated testing of services within Docker-based environments and integrated deployments within virtual-machines is provided by Buildbot.;DevOps, Automated Testing, OpenStack, Vagrant, BuildBot, Docker, GitLab, Ansible, Configuration Management;;;QUDOS 2015
Conference Paper;Xu X,Zhu L,Weber I,Bass L,Sun D;POD-Diagnosis: Error Diagnosis of Sporadic Operations on Cloud Applications;;2014;;;252–263;;IEEE Computer Society;USA;;Proceedings of the 2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks;;2014;9781479922338;;"https://doi-org.proxy.bnl.lu/10.1109/DSN.2014.94;http://dx.doi.org/10.1109/DSN.2014.94";10.1109/DSN.2014.94;"Applications in the cloud are subject to sporadic changes due to operational activities such as upgrade, redeployment, and on-demand scaling. These operations are also subject to interferences from other simultaneous operations. Increasing the dependability of these sporadic operations is non-trivial, particularly since traditional anomaly-detection-based diagnosis techniques are less effective during sporadic operation periods. A wide range of legitimate changes confound anomaly diagnosis and make baseline establishment for ""normal"" operation difficult. The increasing frequency of these sporadic operations (e.g. due to continuous deployment) is exacerbating the problem. Diagnosing failures during sporadic operations relies heavily on logs, while log analysis challenges stemming from noisy, inconsistent and voluminous logs from multiple sources remain largely unsolved. In this paper, we propose Process Oriented Dependability (POD)-Diagnosis, an approach that explicitly models these sporadic operations as processes. These models allow us to (i) determine orderly execution of the process, and (ii) use the process context to filter logs, trigger assertion evaluations, visit fault trees and perform on-demand assertion evaluation for online error diagnosis and root cause analysis. We evaluated the approach on rolling upgrade operations in Amazon Web Services (A WS) while performing other simultaneous operations. During our evaluation, we correctly detected all of the 160 injected faults, as well as 46 interferences caused by concurrent operations. We did this with 91.95% precision. Of the correctly detected faults, the accuracy rate of error diagnosis is 96.55%.";system administration, cloud, deployment, process mining, error detection, error diagnosis, DevOps;;;DSN '14
Conference Paper;Ortu M,Pinna A,Tonelli R,Marchesi M,Bowes D,Destefanis G;Angry-Builds: An Empirical Study of Affect Metrics and Builds Success on Github Ecosystem;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th International Conference on Agile Software Development: Companion;Porto, Portugal;2018;9781450364225;;"https://doi-org.proxy.bnl.lu/10.1145/3234152.3234160;http://dx.doi.org/10.1145/3234152.3234160";10.1145/3234152.3234160;"Automatic and repeatable builds are an established software engineering practices for achieving continuous integration and continuous delivery processes. The building phase of modern software systems is an important part of the development process such that dedicated roles as ""Release Engineer"" are more and more required. Software development is a collaborative activity, and when multiple developers work on the same project, they will be changing a shared master development branch at overlapping intervals. This overlap occurs because developers create parallel branches for working and then merge these branches when features are completed. Continuous integration, CI, is a workflow strategy which helps ensure everyoneâĂŹs changes will integrate with the current version of the project. This activity allows developers to catch bugs and reduce merge conflicts. Improving the building process leads to higher productivity and therefore shorter time to market, but understanding or measuring such a delicate phase is a big challenge. Open Source Communities provide valuable empirical data such as GitHub an Travis CI. These repositories represent a golden mine containing important data which can help researchers understanding the process behind the manufacturing of a software artifact. By analyzing Travis CI logs, we can directly connect a particular build with the development process behind it, not only regarding code changes but also regarding human activities, such as discussions about the implementation of a specific feature or bug resolution. Thanks to this information we can analyze the social activities of the build process enabling us to apply the same approach used for the development process.";;;;XP '18
Book Chapter;Luo L,Schäf M,Sanchez D,Bodden E;IDE Support for Cloud-Based Static Analyses;;2021;;;1178–1189;;Association for Computing Machinery;New York, NY, USA;Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;;;2021;9781450385626;;https://doi-org.proxy.bnl.lu/10.1145/3468264.3468535;;Integrating static analyses into continuous integration (CI) or continuous delivery (CD) has become the best practice for assuring code quality and security. Static Application Security Testing (SAST) tools fit well into CI/CD, because CI/CD allows time for deep static analyses on large code bases and prevents vulnerabilities in the early stages of the development lifecycle. In CI/CD, the SAST tools usually run in the cloud and provide findings via a web interface. Recent studies show that developers prefer seeing the findings of these tools directly in their IDEs. Most tools with IDE integration run lightweight static analyses and can give feedback at coding time, but SAST tools used in CI/CD take longer to run and usually are not able to do so. Can developers interact directly with a cloud-based SAST tool that is typically used in CI/CD through their IDE? We investigated if such a mechanism can integrate cloud-based SAST tools better into a developers’ workflow than web-based solutions. We interviewed developers to understand their expectations from an IDE solution. Guided by these interviews, we implemented an IDE prototype for an existing cloud-based SAST tool. With a usability test using this prototype, we found that the IDE solution promoted more frequent tool interactions. In particular, developers performed code scans three times more often. This indicates better integration of the cloud-based SAST tool into developers’ workflow. Furthermore, while our study did not show statistically significant improvement on developers’ code-fixing performance, it did show a promising reduction in time for fixing vulnerable code.;;;;
Journal Article;Tamma BR,Badam A,Siva Ram Murthy C,Rao RR;K-Tree: A Multiple Tree Video Multicast Protocol for Ad Hoc Wireless Networks;Comput. Netw.;2010;54;11;1864–1884;;Elsevier North-Holland, Inc.;USA;;;;2010-08;;1389-1286;"https://doi-org.proxy.bnl.lu/10.1016/j.comnet.2010.02.013;http://dx.doi.org/10.1016/j.comnet.2010.02.013";10.1016/j.comnet.2010.02.013;In this paper, we address the problem of video multicast over Ad hoc wireless networks. Multicasting is an efficient means of one-to-many communication and is typically implemented by creating a multicast tree. Video multicasting demands high quality of service with a continuous delivery to receivers. However, most of the existing multicast solutions do not guarantee this because they are not resilient to mobility of the nodes and do not exploit error-resilient nature of recently available video coding techniques. Uninterrupted video transmission requires continuous reachability to receivers which emphasizes the usage of path-diversity. Hence, we propose a multiple tree multicast protocol which maintains maximally node-disjoint multicast trees in the network to attain robustness against path breaks. We further enhance the robustness by using the error-resilient multiple description coding (MDC) for video encoding. We prove that finding a given number of node-disjoint multicast trees for a multicast session in a given network is NP-Hard. Then we propose a protocol called K-Tree which maintains the maximal node-disjointedness property of K trees by using a distributed online heuristic. Through extensive simulation experiments, we show how the proposed protocol improves the video quality as we use two or three trees instead of a single tree for multicasting video stream. We also show, through simulations, that the protocol efficiently, in terms of overhead, provides high quality video as compared to an existing two tree video multicast protocol and a well known mesh-based multicast protocol.;Ad hoc wireless networks, Multicast trees, Video multicasting, Multiple description coding, Path-diversity;;;
Conference Paper;Grohmann J,Nicholson PK,Iglesias JO,Kounev S,Lugones D;Monitorless: Predicting Performance Degradation in Cloud Applications with Machine Learning;;2019;;;149–162;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 20th International Middleware Conference;Davis, CA, USA;2019;9781450370097;;"https://doi-org.proxy.bnl.lu/10.1145/3361525.3361543;http://dx.doi.org/10.1145/3361525.3361543";10.1145/3361525.3361543;Today, software operation engineers rely on application key performance indicators (KPIs) for sizing and orchestrating cloud resources dynamically. KPIs are monitored to assess the achievable performance and to configure various cloud-specific parameters such as flavors of instances and autoscaling rules, among others. Usually, keeping KPIs within acceptable levels requires application expertise which is expensive and can slow down the continuous delivery of software. Expertise is required because KPIs are normally based on application-specific quality-of-service metrics, like service response time and processing rate, instead of generic platform metrics, like those typical across various environments (e.g., CPU and memory utilization, I/O rate, etc.)In this paper, we investigate the feasibility of outsourcing the management of application performance from developers to cloud operators. In the same way that the serverless paradigm allows the execution environment to be fully managed by a third party, we discuss a monitorless model to streamline application deployment by delegating performance management. We show that training a machine learning model with platform-level data, collected from the execution of representative containerized services, allows inferring application KPI degradation. This is an opportunity to simplify operations as engineers can rely solely on platform metrics -- while still fulfilling application KPIs -- to configure portable and application agnostic rules and other cloud-specific parameters to automatically trigger actions such as autoscaling, instance migration, network slicing, etc.Results show that monitorless infers KPI degradation with an accuracy of 97% and, notably, it performs similarly to typical autoscaling solutions, even when autoscaling rules are optimally tuned with knowledge of the expected workload.;Monitoring, Cloud computing, DevOps, Machine learning;;;Middleware '19
Journal Article;Mahdavi-Hezaveh R,Dremann J,Williams L;Software Development with Feature Toggles: Practices Used by Practitioners;Empirical Softw. Engg.;2021;26;1;;;Kluwer Academic Publishers;USA;;;;2021-01;;1382-3256;"https://doi-org.proxy.bnl.lu/10.1007/s10664-020-09901-z;http://dx.doi.org/10.1007/s10664-020-09901-z";10.1007/s10664-020-09901-z;;Feature toggle, Continuous delivery, Practice, Continuous integration;;;
Conference Paper;Farroha BS,Farroha DL;A Framework for Managing Mission Needs, Compliance, and Trust in the DevOps Environment;;2014;;;288–293;;IEEE Computer Society;USA;;Proceedings of the 2014 IEEE Military Communications Conference;;2014;9781479967704;;"https://doi-org.proxy.bnl.lu/10.1109/MILCOM.2014.54;http://dx.doi.org/10.1109/MILCOM.2014.54";10.1109/MILCOM.2014.54;The expanding pace of business competitiveness and increasing demand velocity for developing and deploying updated Operational and Security capabilities has created an environment where development and operations needed to work even closer together. The need was further enhanced due to the fact that all capabilities are being developed in a shared platform with no formal requirement processes, and no analysis of the overall enterprise capabilities and architecture. On the surface, the process lacks the usual discipline that most engineers are used to, but operationally it has the potential of bringing capabilities to operations at a quicker rate. The goal of providing continuously updated services should make sure that the overall enterprise performance and security posture are not compromised while the quick turnaround capability deployment is achieved. The proposed framework focuses on ensuring the continuity of strategic posturing while allowing maximum flexibility to tactical enhancements to meet emerging demands.;;;;MILCOM '14
Book;Filipova O,Vilo R;Software Development From A to Z: A Deep Dive into All the Roles Involved in the Creation of Software;;2018;;;;1st;Apress;USA;;;;2018;9781484239445;;;;"Understand the big picture of the software development process. We use software every day operating systems, applications, document editing programs, home banking but have you ever wondered who creates software and how its created? This book guides you through the entire process, from conception to the finished product with the aid of user-centric design theory and tools. Software Development: From A to Zprovidesan overview of backend development - from databases to communication protocols including practical programming skills in Java and of frontend development - from HTML and CSS to npm registry and Vue.js framework. You'll review quality assurance engineering, including the theory about different kind of tests and practicing end-to-end testing using Selenium. Dive into the devops world where authors discuss continuous integration and continuous delivery processes along with each topic's associated technologies. You'll then explore insightful product and project management coverage where authors talk about agile, scrum and other processes from their own experience. The topics that are covered do not require a deep knowledge of technology in general; anyone possessing basic computer and programming knowledge will be able to complete all the tasks and fully understand the concepts this book aims at delivering. You'll wear the hat of a project manager, product owner, designer, backend, frontend, QA and devops engineer, and find your favorite role. What You'll Learn Understand the processes and roles involved in the creation of software Organize your ideas when building the concept of a new product Experience the work performed by stakeholders and other departments of expertise, their individual challenges, and how to overcome possible threats Improve the ways stakeholders and departments can work with each other Gain ideas on how to improve communication and processes Who This Book Is For Anyone who is on a team that creates software and is curious to learn more about other stakeholders or departments involved. Those interested in a career change and want to learn about how software gets created. Those who want to build technical startups and wonder what roles might be involved in the process.";;;;
Conference Paper;Shah D,Lindsay L,Brunet T,Asghar A,Pandhi C;Hands-on: Accessibility in the DevOps Era;;2017;;;361;;IBM Corp.;USA;;Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering;Markham, Ontario, Canada;2017;;;;;Through the last few years, IBM has undergone a major transformation, embracing continuous integration (CI) and DevOps practices. This transformation focuses on building solutions that work well for people while using tools that improve delivery collaboration and responsiveness to user needs.;;;;CASCON '17
Book;Chiaretta S;Front-End Development with ASP.NET Core, Angular, and Bootstrap;;2018;;;;1st;Wrox Press Ltd.;GBR;;;;2018;9781119181316;;;;Stay ahead of the web evolution with elegant combination front-end development Front-End Development with ASP.NET Core, Angular, and Bootstrap is the professional's guide to fast, responsive web development. Utilizing the most popular combination of web technologies for Microsoft developers, this guide provides the latest best practices and ASP.NET MVP guidance to get you up to speed quickly. The newest ASP.NET - now called ASP.NET Core - is leaner, easier to use, and less bound to the operating system and IDE.colle, giving you the perfect opportunity to leverage third-party frameworks and libraries that provide functionalities not native to ASP.NET Core and Visual Studio. This book shows you how to integrate ASP.NET Core with Angular, Bootstrap, and similar frameworks, with a bit of Nuget, continuous deployment, Bower dependencies, and Gulp build systems, including development beyond Windows on Mac and Linux. With clear, concise instruction and expert insight, this guide is an invaluable resource for meeting the demands of modern web development. Combine ASP.NET Core with different tools, frameworks, and libraries Utilize third-party libraries with non-native functionalities Adopt the most up-to-date best practices for front-end development Develop flexible, responsive design sites The world of web development is evolving faster than ever before, and the trend is toward small, focused frameworks with modular capabilities. Microsoft has noticed, and upgraded ASP.NET Core to align with the latest industry expectations. Front-End Development with ASP.NET Core, Angular, and Bootstrap helps you elegantly integrate these technologies to develop the sites that the industry demands.;;;;
Conference Paper;Agarwal P;Continuous SCRUM: Agile Management of SAAS Products;;2011;;;51–60;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 4th India Software Engineering Conference;Thiruvananthapuram, Kerala, India;2011;9781450305594;;"https://doi-org.proxy.bnl.lu/10.1145/1953355.1953362;http://dx.doi.org/10.1145/1953355.1953362";10.1145/1953355.1953362;"Hosted software-as-a-service products provide an opportunity to provide consumers with continuous deployment of new features, as opposed to scheduled version upgrades as is the norm for products installed on-premise. In order to exploit this opportunity, a SaaS provider needs to adopt an agile process that is capable of releasing new features rapidly. The SCRUM [5,6] process is ideally suited for this purpose: However, when SCRUM has been used for agile development of an installed product, parallel, overlapping 'sprints' are executed by separate teams, each dealing with short, medium, and longer-term enhancements to the product[3]; with the result that version upgrades are therefore easier to manage. In contrast, in the case of a SAAS product, version upgrades are no longer a constraint, so we can do better. In this paper we describe 'Continuous SCRUM', a variant of Type-C SCRUM, augmented with engineering best practices, in a manner ideally suited for managing SAAS products. In our approach, bug-fixes, minor enhancements, as well as major features are released continuously, on a weekly basis by a single team, in contrast to ""Meta-SCRUM"" [3]. We also present field data from our experience with using Continuous SCRUM for a hosted platform-as-a-service product for more than two years. Our experience reinforces other recent evidence [11] that rapid, smaller releases are often preferable to infrequent, larger ones. Continuous SCRUM provides a mechanism to achieve and sustain a rapid release cycle, for SAAS products as well as, we believe, for custom applications developed in-house.";SCRUM, agile process, configuration management, PAAS, continuous deployment, SAAS, release management;;;ISEC '11
Conference Paper;Korlepara P,Grigoriou M,Kontogiannis K,Brealey C,Giammaria A;Combining Domain Expert Knowledge and Machine Learning for the Identification of Error Prone Files;;2021;;;153–162;;IBM Corp.;USA;;Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering;Toronto, Canada;2021;;;;;Identifying as early as possible fault prone modules in order to facilitate continuous delivery in large software systems, has been an area where significant attention has been paid over the past few years. Recent efforts consider source code metrics and process metrics for training machine learning models to predict whether a software source code file is fault prone or not. In such prediction frameworks the accuracy of the trained model relies heavily on the features selected and the profiles of the metrics used for training the model which are unique to each system. Furthermore, these models act as black-boxes, where the end-user does not know how a specific prediction was reached. In this paper, we propose an approach which allows for domain expert knowledge to be combined with machine learning in order to yield fault-proneness prediction models that both exhibit high levels of recall and at the same time are able to provide explanations to the developers as to how and why these predictions were reached. For this paper we apply two rule-based inferencing techniques namely, Fuzzy reasoning, and Markov Logic Networks. The main contribution of this work is that it allows for expert developers to identify in the form of if-then rules domain logic that pertains to the fault-proneness of a source code file in the specific system being analysed. Results obtained from 19 open source systens indicate that MLNs perform better than Fuzzy Logic models and that project-customized rules achieve better results than generic rules. Furthermore, results indicate that its possible to compile a common set of rules that yields consistently acceptable results across different projects.;process metrics, fault-proneness prediction, continuous software engineering, software repositories;;;CASCON '21
Book;Macero M;Microservices - The Practical Way;;2017;;;;1st;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2017;9781974307456;;;;This book is a complete guide to building a Microservices Architecture, supported by an application that evolves from a small monolith to a microservice ecosystem. The author follows a very pragmatic approach to explain the benefits of using this type of software architecture, instead of keeping the reader distracted with just theoretical concepts. A practical, evolving example This book, in contrast to guides available on the Internet, is based on a realistic, evolving example. Short guides can't focus on the multiple aspects of building microservices, and normally don't fit into more complex scenarios. Besides, trying to combine these short guides to make up a real application means facing a lot of gaps in the big puzzle of microservices. Guides are too shallow to help you building something real. On the other hand, most books about microservices are sometimes too focused on theory. Some books are usually on the other side of the spectrum. They explain topics like Domain Driven Design, Event Sourcing, Service Discovery, API Gateway, Centralized Logging, Continuous Deployment, DevOps, Reactive Systems, Circuit-Breaker patterns, etc. But that might be overwhelming: where to start? Is it needed to use all of these concepts in a microservice architecture? How to put them in practice? Those are the questions answered in this book, supported with code examples from the included application. Covered topics This book covers some of the state-of-the-art techniques in computer programming, from a practical point of view: - Microservices with Spring Boot - Event Driven Architecture and Messaging with RabbitMQ - RESTful services with Spring - Service Discovery with Eureka and Load Balancing with Ribbon - Routing requests with Zuul as your API Gateway - Test Driven Development: write your tests first - End to End Tests for an Event Driven Architecture using Cucumber - Continuous Integration and Deployment - On the other hand, this book also helps the reader to focus on what's important, - starting with the Minimum Viable Product but keeping the flexibility to evolve it.;;;;
Conference Paper;Rong G,Jin Z,Zhang H,Zhang Y,Ye W,Shao D;DevDocOps: Towards Automated Documentation for DevOps;;2019;;;243–252;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP.2019.00034;http://dx.doi.org/10.1109/ICSE-SEIP.2019.00034";10.1109/ICSE-SEIP.2019.00034;The proliferation of DevOps enables significant acceleration and automation of the delivery and deployment of massive software products. Unfortunately, the development of supporting documents that is vital for large scale software systems in many cases does not keep pace with the rhythm of feature delivery using DevOps in practice, which becomes the bottleneck for many software organizations to deliver full value to the customers as claimed by DevOps. This paper proposes, implements, and evaluates a new approach, DevDocOps, for continuous automated documentation, in particular for DevOps. With DevDocOps, developers are able to create the documents simultaneously with their working versions of software, which largely guarantees the accuracy and integrity of documents as well as significantly increases their delivery speed. Within an established delivery chain, a set of templates are created to collect and transform the required information from its origin to the target documents for delivery. A real system, iDoc, is implemented to map, collect, and synthesizethe information from document templates and automate the documentation process. The iDoc system supports the generation of documents in minutes and the instant feedback loop as well. DevDocOps has been successfully adopted in over 30 large software projects in a top tier global telecommunication enterprise. The lag time between the releases of the product version and its supporting document has been shortened from 1--2 months on average to less than 2 days. DevDocOps extends the scope of DevOps and enhances the value delivery by supporting continuous documentation and bridging the gap between feature delivery and document delivery with automation.;continuous delivery, DevOps;;;ICSE-SEIP '19
Conference Paper;Mattos DI,Bosch J,Holmström Olsson H;ACE: Easy Deployment of Field Optimization Experiments;;;;;264–279;;Springer-Verlag;Berlin, Heidelberg;;Software Architecture;Paris France;;9783030299828;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-29983-5_18;http://dx.doi.org/10.1007/978-3-030-29983-5_18";10.1007/978-3-030-29983-5_18;"Optimization of software parameters is a recurring activity in the life-cycle of many software products, from prototypes and simulations, test beds and hardware-in-the-loop scenarios, field calibrations to the evolution of continuous deployment cycles. To perform this activity, software companies require a combination of software developers and optimization experts with domain specific knowledge. Moreover, in each of life-cycle steps, companies utilize a plethora of different tools, tailored for specific domains or development stages. To most companies, this scenario leads to an excessive cost in the optimization of smaller features or in cases where it is not clear what the returned value will be.In this work we present a new optimization system based on field experiments, that is aimed to facilitate the adoption of optimization in all stages of development. We provide two main contributions. First, we present the architecture of a new optimization system that allows existing software systems to perform optimization procedures in different domains and in different development stages. This optimization system utilizes domain-agnostic interfaces to allow existing systems to perform optimization procedures with minimal invasiveness and optimization expertise. Second, we provide an overview of the deployments, discuss the advantages and limitations and evaluate the optimization system in three empirical scenarios: (1) offline optimization with simulations; (2) optimization of a communication system in a test bed in collaboration with Ericsson; (3) live optimization of a mobile application in collaboration with Sony Mobile. We aim to provide practitioners with a single optimization tool that can leverage their optimization activities from offline to live systems, with minimal invasiveness and optimization expertise.";Software architecture, Black-box optimization, Field experiments, Optimization;;;
Conference Paper;Mertens J,Denil J;The Digital Twin as a Common Knowledge Base in DevOps to Support Continuous System Evolution;;2021;;;158–170;;Springer-Verlag;Berlin, Heidelberg;;Computer Safety, Reliability, and Security. SAFECOMP 2021 Workshops: DECSoS, MAPSOD, DepDevOps, USDAI, and WAISE, York, UK, September 7, 2021, Proceedings;York, United Kingdom;2021;9783030839055;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-83906-2_12;http://dx.doi.org/10.1007/978-3-030-83906-2_12";10.1007/978-3-030-83906-2_12;There is an industry wide push for faster and more feature rich systems, also in the development of Cyber-Physical Systems (CPS). Therefore, the need for applying agile development practices in the model-based design of CPS is becoming more widespread. This is no easy feat, as CPS are inherently complex, and their model-based development is less suited for agile development. Model-based development does suit the concept of digital twin, that is, design models representing a system instance in operation. In this paper we present an approach where the digital twins of system instances serve as a common-knowledge base for the entire agile development cycle of the system when performing system updates. Doing so enables interesting possibilities, such as the identification and detection of system variants, which is beneficial for the verification and validation of the system update. It also brings along challenges, as the executable physics based digital twin is generally computationally expensive. In this paper we introduce this approach by means of a small example of a swiveling pick and place robotic arm. We also elaborate on related work, and open future challenges.;DevOps, Cyber-physical system, Digital twin;;;
Conference Paper;Jaatun MG,Cruzes DS;Session Details: SecSE 2018: International Workshop on Secure Software Engineering in DevOps and Agile Development;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th International Conference on Agile Software Development: Companion;Porto, Portugal;2018;9781450364225;;"https://doi-org.proxy.bnl.lu/10.1145/3329522;http://dx.doi.org/10.1145/3329522";10.1145/3329522;;;;;XP '18
Conference Paper;Liu B,Zhang H,Yang L,Dong L,Shen H,Song K;An Experimental Evaluation of Imbalanced Learning and Time-Series Validation in the Context of CI/CD Prediction;;2020;;;21–30;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Evaluation and Assessment in Software Engineering;Trondheim, Norway;2020;9781450377317;;"https://doi-org.proxy.bnl.lu/10.1145/3383219.3383222;http://dx.doi.org/10.1145/3383219.3383222";10.1145/3383219.3383222;"Background: Machine Learning (ML) has been widely used as a powerful tool to support Software Engineering (SE). The fundamental assumptions of data characteristics required for specific ML methods have to be carefully considered prior to their applications in SE. Within the context of Continuous Integration (CI) and Continuous Deployment (CD) practices, there are two vital characteristics of data prone to be violated in SE research. First, the logs generated during CI/CD for training are imbalanced data, which is contrary to the principles of common balanced classifiers; second, these logs are also time-series data, which violates the assumption of cross-validation. Objective: We aim to systematically study the two data characteristics and further provide a comprehensive evaluation for predictive CI/CD with the data from real projects. Method: We conduct an experimental study that evaluates 67 CI/CD predictive models using both cross-validation and time-series-validation. Results: Our evaluation shows that cross-validation makes the evaluation of the models optimistic in most cases, there are a few counter-examples as well. The performance of the top 10 imbalanced models are better than the balanced models in the predictions of failed builds, even for balanced data. The degree of data imbalance has a negative impact on prediction performance. Conclusion: In research and practice, the assumptions of the various ML methods should be seriously considered for the validity of research. Even if it is used to compare the relative performance of models, cross-validation may not be applicable to the problems with time-series features. The research community need to revisit the evaluation results reported in some existing research.";continuous deployment, continuous integration, imbalanced learning, time-series-validation, cross-validation;;;EASE '20
Conference Paper;Carvalho L,Seco JC;Deep Semantic Versioning for Evolution and Variability;;2021;;;;;Association for Computing Machinery;New York, NY, USA;;23rd International Symposium on Principles and Practice of Declarative Programming;Tallinn, Estonia;2021;9781450386890;;"https://doi-org.proxy.bnl.lu/10.1145/3479394.3479416;http://dx.doi.org/10.1145/3479394.3479416";10.1145/3479394.3479416;The development cycles in the software industry are shrinking due to the increasing demands for shorter time to market and the incremental development style of agile methodologies. Pragmatic software engineering approaches rely on careful product management, a strong versioning discipline, and a feature development strategy to avoid that newly merged code disrupts existing systems. Versioning is critical when managing software product lines and ensuring that all their variants are kept in operation amidst all the performed changes. Such methodologies enforce functional correctness through strong efforts in regression testing, with the associated exponential growth in complexity. In this paper, we propose a language-based approach to software versioning. Unlike the traditional approach of mainstream VCS, where each evolution step is represented by a textual diff, we treat versions as first-class citizens. Each evolution step, merge operation, and version relationship, is represented as code in the program. We extend prior work, Versioned Featherweight Java, to support a full-fledged version control system. First, we introduce multi-branching and merge operations, which allow for more advanced workflows. We also present a slicing procedure implemented in a compile-time tool that extracts well-typed Featherweight Java code for any single version out of a versioned codebase. We present formal soundness results that ensure that the sliced code for any version is well-behaved and has the same behaviour as the multi-version source code. We believe that our developments effectively model relevant domains of software evolution, such as feature-oriented programming, software product lines, and continuous delivery scenarios. By lifting the versioning aspect, usually represented by text diffs, to the language level, we pave the way for tools that interact with software repositories (e.g. CI/CD, GitHub Actions) to have more insight regarding the evolution of the software semantics.;Type system, Program versioning, Program evolution;;;PPDP 2021
Book;Enriquez R,Salazar A;Software Architecture with Spring 5.0: Design and Architect Highly Scalable, Robust, and High-Performance Java Applications;;2018;;;;;Packt Publishing;;;;;2018;9781788992992;;;;Discover how different software architectural models can help you solve problems, and learn best practices for the software development cycle Key Features Learn concepts related to software architecture and embrace them using the latest features of Spring 5Discover architectural models and learn when to apply them Gain knowledge of architectural principles and how they can be used to provide accountability and rationale for architectural decisions Book Description Spring 5 and its ecosystem can be used to build robust architectures effectively. Software architecture is the underlying piece that helps us accomplish our business goals whilst supporting the features that a product demands. This book explains in detail how to choose the right architecture and apply best practices during your software development cycle to avoid technical debt and support every business requirement. Choosing the right architecture model to support your business requirements is one of the key decisions you need to take when a new product is being created from scratch or is being refactored to support new business demands. This book gives you insights into the most common architectural models and guides you when and where they can be used. During this journey, youll see cutting-edge technologies surrounding the Spring products, and understand how to use agile techniques such as DevOps and continuous delivery to take your software to production effectively. By the end of this book, youll not only know the ins and outs of Spring, but also be able to make critical design decisions that surpass your clients expectations. What you will learn Understand the key principles of software architecture Uncover the most common architectural models available Analyze scenarios where an architecture model should be used Implement agile techniques to take your software to production Secure the products you are working on Master tricks that will help you build high-performant applications Use cutting-edge technologies to build products Who this book is for If youre an experienced Spring developer aspiring to become an architect of enterprise-grade applications, this book is for you. Its also ideal for software architects who want to leverage Spring to create effective application blueprints.;;;;
Book;Northwood C;The Full Stack Developer: Your Essential Guide to the Everyday Skills Expected of a Modern Full Stack Web Developer;;2018;;;;1st;Apress;USA;;;;2018;9781484241516;;;;Understand the technical foundations, as well as the non-programming skills needed to be a successful full stack web developer. This book reveals the reasons why a truly successful full stack developer does more than write code. You will learn the principles of the topics needed to help a developer new to agile or full stack working UX, project management, QA, product management, and more all from the point of view of a developer. Covering these skills alongside the fundamentals and foundations of modern web development, rather than specifics of current technologies and frameworks (which can age quickly), all programming examples are given in the context of the web as it is in 2018. Although you need to feel comfortable working on code at the system, database, API, middleware or user interface level, depending on the task in hand, you also need to be able to deal with the big picture and the little details. The Full Stack Developer recognizes skills beyond the technical, and gives foundational knowledge of the wide set of skills needed in a modern software development team. What You'll Learn Plan your work including Agile vs Waterfall, tools, scrum, kanban and continuous delivery Translate UX into code: grids, component libraries and style guides Design systems and system architectures (microservices to monoliths) Review patterns for APIs (SOAP, AJAX, REST), defining API domains, patterns for REST APIs and more API goodness Study the various front-end design patterns you need to know Store data, what to consider for security, deployment, in production and more Who This Book Is For New graduates or junior developers who are transitioning to working as part of a larger team structure in a multi-disciplinary teams and developers previously focused on only front-end or back-end dev transitioning into full stack.;;;;
Conference Paper;Maria TJ,Dizon GR,Esquivel VA,Deja JA,Chua U;Designing Grit: Discovering Features Towards Supporting Novice Programmer DevOps Integration;;2020;;;41–44;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2020 Symposium on Emerging Research from Asia and on Asian Contexts and Cultures;Honolulu, HI, USA;2020;9781450387682;;"https://doi-org.proxy.bnl.lu/10.1145/3391203.3391214;http://dx.doi.org/10.1145/3391203.3391214";10.1145/3391203.3391214;DevOps is usually an industry approach that is practiced by seasoned and experienced programmers and developers. In most university settings especially in the Philippine context, DevOps is not usually part of the curriculum and in some cases are only introduced to learner programmers as an elective or as bonus material. We refer to these students in computing degree programs starting out in learning programming, as novice programmers. Upon graduation, these developers transition into industry roles where they are expected to be familiar with DevOps practices [18]. In most cases, they are not prepared, and fortunately, a great number of them are given training before fully transitioning into their hired roles. In this paper, we attempt to discover and design an intervention mechanism that can assist and prepare novice programmers to easily learn DevOps at an early stage. We gathered data and insights from novice programmers and inquired into their pains and struggles in learning and practicing DevOps. To help them in this process, we propose Grit, a prototype tool to support novice programmers in integrating DevOps. Initial insights provided affordances and design elements for a version control prototype with targetted intervention features. In the long run we intend to discover more insights involving the other stages in DevOps beyond version control.;DevOps, programmer support, novice programmers;;;AsianCHI '20
Journal Article;Behere S,Törngren M;A Functional Reference Architecture for Autonomous Driving;Inf. Softw. Technol.;2016;73;C;136–150;;Butterworth-Heinemann;USA;;;;2016-05;;0950-5849;"https://doi-org.proxy.bnl.lu/10.1016/j.infsof.2015.12.008;http://dx.doi.org/10.1016/j.infsof.2015.12.008";10.1016/j.infsof.2015.12.008;"ContextAs autonomous driving technology matures toward series production, it is necessary to take a deeper look at various aspects of electrical/electronic (E/E) architectures for autonomous driving.ObjectiveThis paper describes a functional reference architecture for autonomous driving, along with various considerations that influence such an architecture. The functionality is described at the logical level, without dependence on specific implementation technologies.MethodEngineering design has been used as the research method, which focuses on creating solutions intended for practical application. The architecture has been refined and applied over a 5 year period to the construction of prototype autonomous vehicles in three different categories, with both academic and industrial stakeholders.ResultsThe architectural components are divided into categories pertaining to (i) perception, (ii) decision and control, and (iii) vehicle platform manipulation. The architecture itself is divided into two layers comprising the vehicle platform and a cognitive driving intelligence. The distribution of components among the architectural layers considers two extremes: one where the vehicle platform is as ""dumb"" as possible, and the other, where the vehicle platform can be treated as an autonomous system with limited intelligence. We recommend a clean split between the driving intelligence and the vehicle platform. The architecture description includes identification of stakeholder concerns, which are grouped under the business and engineering categories. A comparison with similar architectures is also made, wherein we claim that the presence of explicit components for world modeling, semantic understanding, and vehicle platform abstraction seem unique to our architecture.ConclusionThe concluding discussion examines the influences of implementation technologies on functional architectures and how an architecture is affected when a human driver is replaced by a computer. The discussion also proposes that reduction and acceleration of testing, verification, and validation processes is the key to incorporating continuous deployment processes.";Autonomous driving, Reference architecture, Functional architecture, E/E architecture;;;
Conference Paper;Kostromin R,Feoktistov A;Agent-Based DevOps of Software and Hardware Resources for Digital Twins of Infrastructural Objects;;2020;;;;;Association for Computing Machinery;New York, NY, USA;;The 4th International Conference on Future Networks and Distributed Systems (ICFNDS);St.Petersburg, Russian Federation;2020;9781450388863;;"https://doi-org.proxy.bnl.lu/10.1145/3440749.3442599;http://dx.doi.org/10.1145/3440749.3442599";10.1145/3440749.3442599;Nowadays, the problem of automating the software delivery processes and resource configuring in computing environments with parallel and distributed architectures to ensure the functioning of digital twins is highly relevant. A large spectrum of the well-known tools for software configuration management is available. However, most of them do not solve problems emerging in the considered subject domain fully. To this end, we propose a new framework for implementing preparing, debugging, delivering, testing, deploying, and configuring virtualized software of digital twins. Currently, we are developing such twins for analyzing the operation of environmentally friendly equipment of infrastructural objects located in the Baikal natural territory. The proposed framework is based on the integrated applying methods and tools of knowledge engineering, multi-agent technologies, conceptual and service-oriented programming, and administration of hybrid distributed computing systems. These systems can include both personal resources and resources of public access centers, grid systems, and cloud or fog platforms. We carried out the practical experiments with the framework prototype. The obtained results have shown that significant speedup in performing the aforementioned processes can be achieved.;multi-agent system, DevOps, digital twin, Baikal natural territory, infrastructural object;;;ICFNDS '20
Book Chapter;Park J,An S,Youn D,Kim G,Ryu S;JEST: N+1-Version Differential Testing of Both Javascript Engines and Specification;;2021;;;156–157;;IEEE Press;;Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings;;;2021;;;https://doi-org.proxy.bnl.lu/10.1109/ICSE-Companion52605.2021.00065;;Modern programming follows the continuous integration (CI) and continuous deployment (CD) approach rather than the traditional waterfall model. Even the development of modern programming languages uses the CI/CD approach to swiftly provide new language features and to adapt to new development environments. Unlike in the conventional approach, in the modern CI/CD approach, a language specification is no more the oracle of the language semantics because both the specification and its implementations (interpreters or compilers) can co-evolve. In this setting, both the specification and implementations may have bugs, and guaranteeing their correctness is non-trivial.In this paper, we propose a novel N+1-version differential testing to resolve the problem. Unlike the traditional differential testing, our approach consists of three steps: 1) to automatically synthesize programs guided by the syntax and semantics from a given language specification, 2) to generate conformance tests by injecting assertions to the synthesized programs to check their final program states, 3) to detect bugs in the specification and implementations via executing the conformance tests on multiple implementations, and 4) to localize bugs on the specification using statistical information. We actualize our approach for the JavaScript programming language via JEST, which performs N+1-version differential testing for modern JavaScript engines and ECMAScript, the language specification describing the syntax and semantics of JavaScript in a natural language. We evaluated JEST with four JavaScript engines that support all modern JavaScript language features and the latest version of ECMAScript (ES11, 2020). JEST automatically synthesized 1,700 programs that covered 97.78% of syntax and 87.70% of semantics from ES11. Using the assertion-injected JavaScript programs, it detected 44 engine bugs in four different engines and 27 specification bugs in ES11.;;;;
Book Chapter;Park J,An S,Youn D,Kim G,Ryu S;JEST: N+1-Version Differential Testing of Both JavaScript Engines and Specification;;2021;;;13–24;;IEEE Press;;Proceedings of the 43rd International Conference on Software Engineering;;;2021;9781450390859;;https://doi-org.proxy.bnl.lu/10.1109/ICSE43902.2021.00015;;Modern programming follows the continuous integration (CI) and continuous deployment (CD) approach rather than the traditional waterfall model. Even the development of modern programming languages uses the CI/CD approach to swiftly provide new language features and to adapt to new development environments. Unlike in the conventional approach, in the modern CI/CD approach, a language specification is no more the oracle of the language semantics because both the specification and its implementations (interpreters or compilers) can co-evolve. In this setting, both the specification and implementations may have bugs, and guaranteeing their correctness is non-trivial.In this paper, we propose a novel N+1-version differential testing to resolve the problem. Unlike the traditional differential testing, our approach consists of three steps: 1) to automatically synthesize programs guided by the syntax and semantics from a given language specification, 2) to generate conformance tests by injecting assertions to the synthesized programs to check their final program states, 3) to detect bugs in the specification and implementations via executing the conformance tests on multiple implementations, and 4) to localize bugs on the specification using statistical information. We actualize our approach for the JavaScript programming language via JEST, which performs N+1-version differential testing for modern JavaScript engines and ECMAScript, the language specification describing the syntax and semantics of JavaScript in a natural language. We evaluated JEST with four JavaScript engines that support all modern JavaScript language features and the latest version of ECMAScript (ES11, 2020). JEST automatically synthesized 1,700 programs that covered 97.78% of syntax and 87.70% of semantics from ES11. Using the assertion-injected JavaScript programs, it detected 44 engine bugs in four different engines and 27 specification bugs in ES11.;;;;
Book;Reynders F;Modern API Design with ASP.NET Core 2: Building Cross-Platform Back-End Systems;;2018;;;;1st;Apress;USA;;;;2018;9781484235188;;;;"Use ASP.NET Core 2 to create durable and cross-platform web APIs through a series of applied, practical scenarios. Examples in this book help you build APIs that are fast and scalable. Youll progress from the basics of the framework through to solving the complex problems encountered in implementing secure RESTful services. The book is packed full of examples showing how Microsofts ground-up rewrite of ASP.NET Core 2 enables native cross-platform applications that are fast and modular, allowing your cloud-ready server applications to scale as your business grows. Major topics covered in the book include the fundamentals and core concepts of ASP.NET Core 2. You'll learn about building RESTful APIs with the MVC pattern using proven best practices and following the six principles of REST. Examples in the book help in learning to develop world-class web APIs and applications that can run on any platform, including Windows, Linux, and MacOS. You can even deploy to Microsoft Azure and automate your delivery by implementing Continuous Integration and Continuous Deployment pipelines. What You Will Learn Incorporate automated API tooling such as Swagger from the Open API specification Standardize query and response formats using Facebooks Graph QL query language Implement security by applying authentication and authorization using ASP.NET Identity Ensure the safe storage of sensitive data using the data protection stack Create unit and integration tests to guarantee code quality Who This Book Is For Developers who build server applications such as web sites and web APIs that need to run fast and cross platform; programmers who want to implement practical solutions for real-world problems; those who want in-depth knowledge of the latest bits of ASP.NET Core 2.0";;;;
Conference Paper;Gregg B;System Methodology—Holistic Performance Analysis on Modern Systems;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Applicative 2016;New York, NY, USA;2016;9781450344647;;"https://doi-org.proxy.bnl.lu/10.1145/2959689.2960079;http://dx.doi.org/10.1145/2959689.2960079";10.1145/2959689.2960079;Traditional systems performance engineering makes do with vendor-supplied metrics, often involving interpretation and inference, and with numerous blind spots. Much in the field of systems performance is still living in the past: documentation, procedures, and analysis GUIs built upon the same old metrics. For modern systems, we can choose the metrics, and can choose ones we need to support new holistic performance analysis methodologies. These methodologies provide faster, more accurate, and more complete analysis, and can provide a starting point for unfamiliar systems.Methodologies are especially helpful for modern applications and their workloads, which can pose extremely complex problems with no obvious starting point. There are also continuous deployment environments such as the Netflix cloud, where these problems must be solved in shorter time frames. Fortunately, with advances in system observability and tracers, we have virtually endless custom metrics to aid performance analysis. The problem becomes which metrics to use, and how to navigate them quickly to locate the root cause of problems.System methodologies provide a starting point for analysis, as well as guidance for quickly moving through the metrics to root cause. They also pose questions that the existing metrics may not yet answer, which may be critical in solving the toughest problems. System methodologies include the USE method, workload characterization, drill-down analysis, off-CPU analysis, and more.This talk will discuss various system performance issues, and the methodologies, tools, and processes used to solve them. The focus is on single systems (any operating system), including single cloud instances, and quickly locating performance issues or exonerating the system. Many methodologies will be discussed, along with recommendations for their implementation, which may be as documented checklists of tools, or custom dashboards of supporting metrics. In general, you will learn to think differently about your systems, and how to ask better questions.;;;;Applicative 2016
Conference Paper;Alonso J,Orue-Echevarria L,Escalante M,Benguria G;DECIDE: DevOps for Trusted, Portable and Interoperable Multi-Cloud Applications towards the Digital Single Market;;2017;;;397–404;;SCITEPRESS - Science and Technology Publications, Lda;Setubal, PRT;;Proceedings of the 7th International Conference on Cloud Computing and Services Science;Porto, Portugal;2017;9789897582431;;"https://doi-org.proxy.bnl.lu/10.5220/0006292403970404;http://dx.doi.org/10.5220/0006292403970404";10.5220/0006292403970404;The main objective of the DECIDE action is to provide a new generation of multi-cloud service-basedsoftware framework, enabling techniques and mechanisms to design, develop, and dynamically deploymulti-cloud aware applications in an ecosystem of reliable, interoperable, and legal compliant cloudservices. Three use cases will be conducted to validate the proposed approach.;Multi-Cloud Architectural Patterns., Run-Time Monitoring, Self-adaptation, Deployment Simulation, Intermediation and Federation of Heterogeneous Resources;;;CLOSER 2017
Conference Paper;Miglierina M,Tamburri DA;Towards Omnia: A Monitoring Factory for Quality-Aware DevOps;;2017;;;145–150;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3053600.3053629;http://dx.doi.org/10.1145/3053600.3053629";10.1145/3053600.3053629;Modern DevOps pipelines entail extreme automation and speed as paramount assets for continuous application improvement. Likewise, monitoring is required to assess the quality of service and user-experience such that applications can continuously evolve towards use-centric excellence. In this scenario however, it is increasingly difficult to pull up and maintain efficient monitoring infrastructures which are frictionless, i.e., they do not introduce any slowdown neither in the DevOps pipeline nor in the DevOps organizational and social structure comprising multiple roles and responsibilities. Using an experimental prototype, this paper elaborates Omnia an approach for structured monitoring configuration and rollout based around a monitoring factory, i.e., a re-interpretation of the factory design-pattern for building and managing ad-hoc monitoring platforms. Comparing with practitioner surveys and the state of the art, we observed that Omnia shows the promise of delivering an effective solution that tackles the steep learning curve and entry costs needed to embrace cloud monitoring and monitoring-based DevOps continuous improvement.;monitoring, monitoring factory, monitoring interface, monitoring configuration as code, monitoring infrastructure as code, monitoring management;;;ICPE '17 Companion
Book;Pacheco VF;Microservice Patterns and Best Practices: Explore Patterns like CQRS and Event Sourcing to Create Scalable, Maintainable, and Testable Microservices;;2018;;;;;Packt Publishing;;;;;2018;9781788474030;;;;Explore the concepts and tools you need to discover the world of microservices with various design patterns Key Features Get to grips with the microservice architecture and build enterprise-ready microservice applicationsLearn design patterns and the best practices while building a microservice applicationObtain hands-on techniques and tools to create high-performing microservices resilient to possible failsBook DescriptionMicroservices are a hot trend in the development world right now. Many enterprises have adopted this approach to achieve agility and the continuous delivery of applications to gain a competitive advantage. This book will take you through different design patterns at different stages of the microservice application development along with their best practices. Microservice Patterns and Best Practices starts with the learning of microservices key concepts and showing how to make the right choices while designing microservices. You will then move onto internal microservices application patterns, such as caching strategy, asynchronism, CQRS and event sourcing, circuit breaker, and bulkheads. As you progress, you'll learn the design patterns of microservices. The book will guide you on where to use the perfect design pattern at the application development stage and how to break monolithic application into microservices. You will also be taken through the best practices and patterns involved while testing, securing, and deploying your microservice application. At the end of the book, you will easily be able to create interoperable microservices, which are testable and prepared for optimum performance. What you will learn How to break monolithic application into microservices Implement caching strategies, CQRS and event sourcing, and circuit breaker patterns Incorporate different microservice design patterns, such as shared data, aggregator, proxy, and chained Utilize consolidate testing patterns such as integration, signature, and monkey tests Secure microservices with JWT, API gateway, and single sign on Deploy microservices with continuous integration or delivery, Blue-Green deployment Who This Book Is ForThis book is for architects and senior developers who would like implement microservice design patterns in their enterprise application development. The book assumes some prior programming knowledge.;;;;
Conference Paper;Bang SK,Chung S,Choh Y,Dupuis M;A Grounded Theory Analysis of Modern Web Applications: Knowledge, Skills, and Abilities for DevOps;;2013;;;61–62;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2nd Annual Conference on Research in Information Technology;Orlando, Florida, USA;2013;9781450324946;;"https://doi-org.proxy.bnl.lu/10.1145/2512209.2512229;http://dx.doi.org/10.1145/2512209.2512229";10.1145/2512209.2512229;Since 2009, DevOps, the combination of development and operation, has been adopted within organizations in industry, such as Netflix, Flickr, and Fotopedia. Configuration management tools have been used to support DevOps. However, in this paper we investigate which Knowledge, Skills, and Abilities (KSA) have been employed in developing and deploying modern web applications and how these KSAs support DevOps. By applying a qualitative analysis approach, namely grounded theory, to three web application development projects, we discover that the KSAs for both Software Development and IT Operator practitioners support the four perspectives of DevOps: collaboration culture, automation, measurement, and sharing.;skills and abilities, knowledge, grounded theory, devops;;;RIIT '13
Conference Paper;Kumar R,Bansal C,Maddila C,Sharma N,Martelock S,Bhargava R;Building Sankie: An AI Platform for DevOps;;2019;;;48–53;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 1st International Workshop on Bots in Software Engineering;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/BotSE.2019.00020;http://dx.doi.org/10.1109/BotSE.2019.00020";10.1109/BotSE.2019.00020;There has been a fundamental shift amongst software developers and engineers in the past few years. The software development life cycle (SDLC) for a developer has increased in complexity and scale. Changes that were developed and deployed over a matter of days or weeks are now deployed in a matter of hours. Due to greater availability of compute, storage, better tooling, and the necessity to react, developers are constantly looking to increase their velocity and throughput of developing and deploying changes. Consequently, there is a great need for more intelligent and context sensitive DevOps tools and services that help developers increase their efficiency while developing and debugging. Given the vast amounts of heterogeneous data available from the SDLC, such intelligent tools and services can now be built and deployed at a large scale to help developers achieve their goals and be more productive. In this paper, we present Sankie, a scalable and general service that has been developed to assist and impact all stages of the modern SDLC. Sankie provides all the necessary infrastructure (back-end and front-end bots) to ingest data from repositories and services, train models based on the data, and eventually perform decorations or provide information to engineers to help increase the velocity and throughput of changes, bug fixes etc. This paper discusses the architecture as well as some of the key observations we have made from wide scale deployment of Sankie within Microsoft.;Azure, DevOps, scale, infrastructure, pull request, empirical software engineering, machine learning, bot, software development life cycle;;;BotSE '19
Book;Wadia Y;AWS Administration - The Definitive Guide - Second Edition: Design, Build, and Manage Your Infrastructure on Amazon Web Services;;2018;;;;2nd;Packt Publishing;;;;;2018;9781788478793;;;;Leverage this step-by-step guide to build a highly secure, fault-tolerant, and scalable Cloud environment Key Features Learn how to leverage various Amazon Web Services (AWS) components and services to build a secure, reliable, and robust environment to host your applications on. Delve into core AWS service offerings with hands-on tutorials, real-world use case scenarios, and best practices. A self-paced, systematic, and step-by-step guide to learning and implementing AWS in your own environment. Book Description Many businesses are moving from traditional data centers to AWS because of its reliability, vast service offerings, lower costs, and high rate of innovation. AWS can be used to accomplish a variety of both simple and tedious tasks. Whether you are a seasoned system admin or a rookie, this book will help you to learn all the skills you need to work with the AWS cloud. This book guides you through some of the most popular AWS services, such as EC2, Elastic Beanstalk, EFS, CloudTrail, Redshift, EMR, Data Pipeline, and IoT using a simple, real-world, application-hosting example. This book will also enhance your application delivery skills with the latest AWS services, such as CodeCommit, CodeDeploy, and CodePipeline, to provide continuous delivery and deployment, while also securing and monitoring your environment's workflow. Each chapter is designed to provide you with maximal information about each AWS service, coupled with easy to follow, hands-on steps, best practices, tips, and recommendations. By the end of the book, you will be able to create a highly secure, fault-tolerant, and scalable environment for your applications to run on. What you will learnTake an in-depth look at what's new with AWS, along with how to effectively manage and automate your EC2 infrastructure with AWS Systems Manager Deploy and scale your applications with ease using AWS Elastic Beanstalk and Amazon Elastic File System Secure and govern your environments using AWS CloudTrail, AWS Config, and AWS Shield Learn the DevOps way using a combination of AWS Code Commit, AWS Code Deploy, and AWS Code PipelineRun big data analytics and workloads using Amazon EMR and Amazon Redshift Learn to back up and safeguard your data using AWS Data Pipeline Get started with the Internet of Things using AWS IoT and AWS Greengrass Who This Book Is ForThis book is for those who want to learn and leverage the rich plethora of services provided by AWS. Although no prior experience with AWS is required, it is recommended that you have some hands-on experience of Linux, Web Services, and basic networking.;;;;
Book;Farmer R,Jain R,Wu D;Cloud Foundry for Developers: Deploy, Manage, and Orchestrate Cloud-Native Applications with Ease;;2017;;;;;Packt Publishing;;;;;2017;9781788391443;;;;Deploy and scale applications on Cloud FoundryAbout This BookGain hands-on experience using Cloud FoundryImplement deployment, management and scaling of applications on Cloud FoundryLearn best practices and troubleshooting tips for running applications on Cloud FoundryWho This Book Is ForThis book is aimed at developers, engineers and architects who want to learn key aspects of developing and running applications on the Cloud Foundry Platform. Prior knowledge Cloud Foundry is not necessary. What You Will LearnUnderstand Cloud Foundry (CF) tools and concepts. Understand the breadth of possibilities unleashed through a lightweight agile approach to building and deploying applications. Design and deploy cloud native applications that run well on Cloud Foundry. Learn Microservice design concepts and worker applications. Customize service brokers to publish your services in the Cloud Foundry marketplace. Using, managing and creating buildpacks for the Cloud Foundry Platform. Troubleshoot applications on Cloud FoundryPerform zero-downtime deployments using blue/green routes, A/B testing, and painless rollbacks to earlier versions of the application. In DetailCloud Foundry is the open source platform to deploy, run, and scale applications. Cloud Foundry is growing rapidly and a leading product that provides PaaS (Platform as a Service) capabilities to enterprise, government, and organizations around the globe. Giants like Dell Technologies, GE, IBM, HP and the US government are using Cloud Foundry innovate faster in a rapidly changing world. Cloud Foundry is a developers dream. Enabling them to create modern applications that can leverage the latest thinking, techniques and capabilities of the cloud, including: DevOps Application Virtualization Infrastructure agnosticism Orchestrated containers Automation Zero downtime upgrades A/B deploymen tQuickly scaling applications out or in This book takes readers on a journey where they will first learn the Cloud Foundry basics, including how to deploy and scale a simple application in seconds. Readers will build their knowledge of how to create highly scalable and resilient cloud-native applications and microservices running on Cloud Foundry. Readers will learn how to integrate their application with services provided by Cloud Foundry and with those external to Cloud Foundry. Readers will learn how to structure their Cloud Foundry environment with orgs and spaces. After that, well discuss aspects of continuous integration/continuous delivery (CI/CD), monitoring and logging. Readers will also learn how to enable health checks, troubleshoot and debug applications. By the end of this book, readers will have hands-on experience in performing various deployment and scaling tasks. Additionally, they will have an understanding of what it takes to migrate and develop applications for Cloud Foundry. Style and Approach A practitioner's guide to Cloud Foundry that covers the areas of application development, deployment and services.;;;;
Book;Arora T;Microsoft Team Foundation Server Cookbook;;2016;;;;;Packt Publishing;;;;;2016;9781784391058;;;;Over 80 hands-on DevOps and ALM-focused recipes for Scrum Teams to enable the Continuous Delivery of high-quality Software... Faster!About This BookRelease high quality, reliable software quickly through building, testing, and deployment automationImprove the predictability, reliability, and availability of TFS in your organization by scheduling administration and maintenance activitiesExtend, customize, and integrate tools with TFS, enabling your teams to manage their application lifecycles effectivelyWho This Book Is ForThis book is aimed at software professionals including Developers, Testers, Architects, Configuration Analysts, and Release Managers who want to understand the capabilities of TFS to deliver better quality software faster.A working setup of TFS 2015 and some familiarity with the concepts of software life cycle management is assumed.What You Will LearnCreating a Team Project with Dashboards, Assigning License, Adding users, and Auditing AccessSetting up a Git repository in an existing TFVC-based Team ProjectSetting up branch policies and conducting Pull requests with code reviewsMapping, assigning and tracking work items shared by multiple teamsSetting up and customizing Backlogs, Kanban board, Sprint Taskboard, and dashboardsCreating a Continuous Integration, Continuous Build, and Release PipelineIntegrating SonarQube with TFBuild to manage Technical DebtTriggering Selenium Web Tests on a Selenium Test Grid using TFBuildUsing Visual Studio Team Services Cloud load testing capability with new Build frameworkExtending and customizing the capabilities of Team Foundation Server using API and Process EditorIn DetailTeam Foundation Server (TFS) allows you to manage code repositories, build processes, test infrastructure, and deploy labs. TFS supports your team, enabling you to connect, collaborate, and deliver on time. Microsoft's approach to Application Lifecycle Management (ALM) provides a flexible and agile environment that adapts to the needs of your team, removes barriers between roles, and streamlines processes.The book introduces you to creating and setting up team projects for scrum teams. You'll explore various source control repositories, branching, and merging activities, along with a demonstration of how to embed quality into every code check-in. Then, you'll discover agile project planning and management tools. Later, emphasis is given to the testing and release management features of TFS which facilitate the automation of the release pipeline in order to create potentially shippable increments.By the end of the book, you'll have learned to extend and customize TFS plugins to incorporate them into other platforms and enable teams to manage the software lifecycle effectively.Style and approachThis book is a recipe-based guide that uses a problem-solution format to call out inefficiencies in the software development lifecycle and then guides you, step-by-step, on how you can use Team Foundation Server to your advantage in those areas.;;;;
Book;;Leading the Transformation: Applying Agile and DevOps Principles at Scale;;2015;;;;;IT Revolution Press;;;;;2015;9781942788010;;;;Software is becoming more and more important across a broad range of industries, yet most technology executives struggle to deliver software improvements their businesses require.Leading-edge companies like Amazon and Google are applying DevOps and Agile principles to deliver large software projects faster than anyone thought possible. But most executives dont understand how to transform their current legacy systems and processes to scale these principles across their organizations.Leading the Transformation is executive guide, providing a clear framework for improving development and delivery. Instead of the traditional Agile and DevOps approaches that focus on improving the effectiveness of teams, this book targets the coordination of work across teams in large organizationsan improvement that executives are uniquely positioned to lead.;;;;
Journal Article;Panichella S,Zaugg N;An Empirical Investigation of Relevant Changes and Automation Needs in Modern Code Review;Empirical Softw. Engg.;2020;25;6;4833–4872;;Kluwer Academic Publishers;USA;;;;2020-11;;1382-3256;"https://doi-org.proxy.bnl.lu/10.1007/s10664-020-09870-3;http://dx.doi.org/10.1007/s10664-020-09870-3";10.1007/s10664-020-09870-3;"Recent research has shown that available tools for Modern Code Review (MCR) are still far from meeting the current expectations of developers. The objective of this paper is to investigate the approaches and tools that, from a developer’s point of view, are still needed to facilitate MCR activities. To that end, we first empirically elicited a taxonomy of recurrent review change types that characterize MCR. The taxonomy was designed by performing three steps: (i) we generated an initial version of the taxonomy by qualitatively and quantitatively analyzing 211 review changes/commits and 648 review comments of ten open-source projects; then (ii) we integrated into this initial taxonomy, topics, and MCR change types of an existing taxonomy available from the literature; finally, (iii) we surveyed 52 developers to integrate eventually missing change types in the taxonomy. Results of our study highlight that the availability of new emerging development technologies (e.g., Cloud-based technologies) and practices (e.g., Continuous delivery) has pushed developers to perform additional activities during MCR and that additional types of feedback are expected by reviewers. Our participants provided recommendations, specified techniques to employ, and highlighted the data to analyze for building recommender systems able to automate the code review activities composing our taxonomy. We surveyed 14 additional participants (12 developers and 2 researchers), not involved in the previous survey, to qualitatively assess the relevance and completeness of the identified MCR change types as well as assess how critical and feasible to implement are some of the identified techniques to support MCR activities. Thus, with a study involving 21 additional developers, we qualitatively assess the feasibility and usefulness of leveraging natural language feedback (automation considered critical/feasible to implement) in supporting developers during MCR activities. In summary, this study sheds some more light on the approaches and tools that are still needed to facilitate MCR activities, confirming the feasibility and usefulness of using summarization techniques during MCR activities. We believe that the results of our work represent an essential step for meeting the expectations of developers and supporting the vision of full or partial automation in MCR.";Empirical study, Automated software engineering., Code review process and practices;;;
Book;Bosch J;Continuous Software Engineering;;2014;;;;;Springer Publishing Company, Incorporated;;;;;2014;9783319112824;;;;This book provides essential insights on the adoption of modern software engineering practices at large companies producing software-intensive systems, where hundreds or even thousands of engineers collaborate to deliver on new systems and new versions of already deployed ones. It is based on the findings collected and lessons learned at the Software Center (SC), a unique collaboration between research and industry, with Chalmers University of Technology, Gothenburg University and Malm University as academic partners and Ericsson, AB Volvo, Volvo Car Corporation, Saab Electronic Defense Systems, Grundfos, Axis Communications, Jeppesen (Boeing) and Sony Mobile as industrial partners. The 17 chapters present the Stairway to Heaven model, which represents the typical evolution path companies move through as they develop and mature their software engineering capabilities. The chaptersdescribe theoretical frameworks, conceptual models and, most importantly, the industrial experiences gained by the partner companies in applying novel software engineering techniques. The books structure consists of six parts. Part I describes the model in detail and presents an overview of lessons learned in the collaboration between industry and academia. Part II deals with the first step of the Stairway to Heaven, in which R&D adopts agile work practices. Part III of the book combines the next two phases, i.e., continuous integration (CI) and continuous delivery (CD), as they are closely intertwined. Part IV is concerned with the highest level, referred to as R&D as an innovation system, while Part V addresses a topic that is separate from the Stairway to Heaven and yet critically important in large organizations: organizational performance metrics that capture data, and visualizations of the status of software assets, defects and teams. Lastly, Part VI presents the perspectives of two of the SC partner companies. The book is intended for practitioners and professionals in the software-intensive systems industry, providing concrete models, frameworks and case studies that show the specific challenges that the partner companies encountered, their approaches to overcoming them, and the results. Researchers will gain valuable insights on the problems faced by large software companies, and on how to effectively tackle them in the context of successful cooperation projects.;;;;
Book;Pouclet R;Pro IOS Continuous Integration;;2014;;;;1st;Apress;USA;;;;2014;9781484201251;;;;Pro iOS Continuous Integration teaches you how to utilize the strengths of continuous integration in your everyday work. CI is more popular now than ever, as iOS developers realize how time-consuming building and deploying an application for testing purposes and quality assurance can be. This book shows you how to make your developing life easier, with real-world applications and examples. With this book, you will learn what continuous integration and continuous delivery really are and how they can be used in your iOS projects. You will learn how to release an iOS application outside the App Store using Xcode. You'll understand how to leverage the power of the command line to build your projects, and run your tests. You'll use Jenkins and Bamboo to architect automatic builds and automate the whole build process. In addition, you'll also learn how to use Xcode server and bots, what quality assurance tools can be used to measure the quality of your code, and how to send builds to your beta testers. Author Romain Pouclet provides hands-on, practical experience in iOS continuous integration and, using this book, you will see that it's not actually that hard to set up a fully-featured continuous integration platform, whether you are an independent iOS developer working from home or a member of a team in a big company. What youll learn Learn what continuous integration really is and how you can benefit from it Use Xcode to develop and release an application without the app store Stop wasting time tracking environment related bugs Automate the execution of unit and functional tests Use quality insurance tools to track bugs and other misconceptions Who this book is for Pro iOS Continuous Integration is for iOS developers who are working from home or as a member of a team in a large company, who want to learn how to implement continuous integration into their workflow. If you are struggling to understand the widespread info that's currently available - this book succinctly brings the available tools and workflows together in one, easy-to-understand volume.;;;;
Book;Campbell GA,Papapetrou PP;SonarQube in Action;;2013;;;;1st;Manning Publications Co.;USA;;;;2013;9781617290954;;;;Summary SonarQube in Action shows developers how to use the SonarQube platform to help them continuously improve their source code. The book presents SonarQube's core Seven Axes of Quality: design/architecture, duplications, comments, unit tests, complexity, potential bugs, and coding rules. You'll find simple, easy-to-follow discussion and examples as you learn to integrate SonarQube into your development process. About the Technology SonarQube is a powerful open source tool for continuous inspection, a process that makes code quality analysis and reporting an integral part of the development lifecycle. Its unique dashboards, rule-based defect analysis, and tight build integration result in improved code quality without disruption to developer workflow. It supports many languages, including Java, C, C++, C#, PHP, and JavaScript. About the Book SonarQube in Action teaches you how to effectively use SonarQube following the continuous inspection model. This practical book systematically explores SonarQube's core Seven Axes of Quality (design, duplications, comments, unit tests, complexity, potential bugs, and coding rules). With well-chosen examples, it helps you learn to use SonarQube's review functionality and IDE integration to implement continuous inspection best practices in your own quality management process. The book's Java-based examples translate easily to other development languages. No prior experience with SonarQube or continuous delivery practice is assumed Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. What's InsideGather meaningful quality metrics Integrate with Ant, Maven, and Jenkins Write your own plugins Master the art of continuous inspectionAbout the Authors Ann Campbellb and Patroklos Papapetrou are experienced developers and team leaders. Both actively contribute to the SonarQube community. Table of ContentsPART 1 WHAT THE NUMBERS ARE TELLING YOU An introduction to SonarQubeIssues and coding standardsEnsuring that your code is doing things rightWorking with duplicate codeOptimizing source code documentationKeeping your source code files elegantImproving your application designPART 2 SETTLING IN WITH SONARQUBE Planning a strategy and expanding your insightContinuous Inspection with SonarQubeLetting SonarQube drive code reviewsIDE integrationPART 3 ADMINISTERING AND EXTENDING Security: users, groups, and roles Rule profile administration Making SonarQube fit your needsManaging your projectsWriting your own plugins;;;;
Book;Hunter T,Porter S;Google Cloud Platform for Developers: Build Highly Scalable Cloud Solutions with the Power of Google Cloud Platform;;2018;;;;;Packt Publishing;;;;;2018;9781788837675;;;;Develop, deploy, and scale your applications with Google Cloud Platform Key Features Create and deploy your applications on Google Cloud Platform Store and manage source code and debug Cloud-hosted apps with plugins and IDEs Streamline developer workflows with tools for alerting and managing deployments Book Description Google Cloud Platform (GCP) provides autoscaling compute power and distributed in-memory cache, task queues, and datastores to write, build, and deploy Cloud-hosted applications. With Google Cloud Platform for Developers, you will be able to develop and deploy scalable applications from scratch and make them globally available in almost any language. This book will guide you in designing, deploying, and managing applications running on Google Cloud. Youll start with App Engine and move on to work with Container Engine, compute engine, and cloud functions. Youll learn how to integrate your new applications with the various data solutions on GCP, including Cloud SQL, Bigtable, and Cloud Storage. This book will teach you how to streamline your workflow with tools such as Source Repositories, Container Builder, and Stack Driver. Along the way, youll see how to deploy and debug services with IntelliJ, implement continuous delivery pipelines, and configure robust monitoring and alerting for your production systems. By the end of this book, youll be well-versed with all the development tools of Google Cloud Platform, and youll develop, deploy, and manage highly scalable and reliable applications. What you will learn Understand the various service offerings on GCP Deploy and run services on managed platforms such as App Engine and Container Engine Securely maintain application states with Cloud Storage, Datastore, and Bigtable Leverage Stack Driver monitoring and debugging to minimize downtime and mitigate issues without impacting users Design and implement complex software solutions utilizing Google Cloud Integrate with best-in-class big data solutions such as Bigquery, Dataflow, and Pub/Sub Who this book is for Google Cloud Platform for Developers is for application developers. This book will enable you to fully leverage the power of Google Cloud Platform to build resilient and intelligent software solutions.;;;;
Conference Paper;Luz WP,Pinto G,Bonifácio R;Building a Collaborative Culture: A Grounded Theory of Well Succeeded Devops Adoption in Practice;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Oulu, Finland;2018;9781450358231;;"https://doi-org.proxy.bnl.lu/10.1145/3239235.3240299;http://dx.doi.org/10.1145/3239235.3240299";10.1145/3239235.3240299;"Background. DevOps is a set of practices and cultural values that aims to reduce the barriers between development and operations teams. Due to its increasing interest and imprecise definitions, existing research works have tried to characterize DevOps---mainly using a set of concepts and related practices.Aims. Nevertheless, little is known about the practitioners practitioners' understanding about successful paths for DevOps adoption. The lack of such understanding might hinder institutions to adopt DevOps practices. Therefore, our goal here is to present a theory about DevOps adoption, highlighting the main related concepts that contribute to its adoption in industry.Method. Our work builds upon Classic Grounded Theory. We interviewed practitioners that contributed to DevOps adoption in 15 companies from different domains and across 5 countries. We empirically evaluate our model through a case study, whose goal is to increase the maturity level of DevOps adoption at the Brazilian Federal Court of Accounts, a Brazilian Government institution.Results. This paper presents a model to improve both the understanding and guidance of DevOps adoption. The model increments the existing view of DevOps by explaining the role and motivation of each category (and their relationships) in the DevOps adoption process. We organize this model in terms of DevOps enabler categories and DevOps outcome categories. We provide evidence that collaboration is the core DevOps concern, contrasting with an existing wisdom that implanting specific tools to automate building, deployment, and infrastructure provisioning and management is enough to achieve DevOps.Conclusions. Altogether, our results contribute to (a) generating an adequate understanding of DevOps, from the perspective of practitioners; and (b) assisting other institutions in the migration path towards DevOps adoption.";grounded theory, devops, software development, software operations;;;ESEM '18
Book;Pasquali S;Deploying Node.Js;;2015;;;;;Packt Publishing;;;;;2015;9781783981403;;;;Learn how to build, test, deploy, monitor, and maintain your Node.js applications at scale About This BookGain comprehensive information on scaling Node.js both vertically and horizontally in the cloud and across virtual machinesLearn how to use Gulp, Mocha, Chai, PhantomJS, Git, Browserify, Docker, and other tools to construct a simple, fast, and intelligent build-and-deploy systemUtilize the easy-to-understand examples to explore data caching strategies, application monitoring tips and tricks, and other professional techniques that are useful for maintaining lightweight, fast, and robust applicationsWho This Book Is ForIf you are an intermediate or advanced developer deploying your Node.js applications, then this book is for you. If you have already built a Node application or module and want to take your knowledge to the next level, this book will help you find your way.What You Will LearnLearn the strengths of Node.js and how to optimize your code to make it ready for deployment into productionUse Docker and Vagrant to create many virtual instances of your Node.js applicationsDeploy Node.js repositories to the cloud using Heroku, OpenShift, and DigitalOceanUtilize native Node.js modules, or Nginx, to load balance your applicationsOptimize your Node runtime by tweaking V8, managing memory intelligently, and using Redis to manage state dataDiscover how to use Gulp, Browserify, npm, Mocha, Chai, Sinon, and other tools to simplify your build/test/release processManage your production deployments with Git, Jenkins, and AnsibleIn DetailNode.js is a popular choice for teams that need to design, build, test, deploy, maintain, and monitor large-scale distributed systems. Starting with a detailed overview of the Node.js architecture, this book covers topics that will help in application development, testing, deployment, and maintenance.You will learn about concurrency, event loops, callbacks and streams. Furthermore, step-by-step instructions on deploying applications to providers such as DigitalOcean and Heroku will be provided, including information on setting up load balancers and proxies. Message queues and other techniques for managing state and session data at scale will also be covered.A series of examples on deploying your Node.js applications in production environments are provided, including a discussion on setting up continuous deployment and integration for your team. Popular tools for testing, deploying, building, and monitoring Node.js applications are covered, helping you get up and running quickly.;;;;
Book;Traukina A,Thomas J,Tyagi P,Reddipalli K;Industrial Internet Application Development: Simplify IIoT Development Using the Elasticity of Public Cloud and Native Cloud Services;;2018;;;;;Packt Publishing;;;;;2018;9781788298599;;;;Your one-stop guide to designing, building, managing, and operating Industrial Internet of Things (IIoT) applications Key Features Build IIoT applications and deploy them on Platform as a Service (PaaS) Learn data analytics techniques in IIoT using Spark and TensorFlow Understand and combine Predix services to accelerate your development Book Description The Industrial Internet refers to the integration of complex physical machines with networked sensors and software. The current growth in the number of sensors deployed in heavy machinery and industrial equipment will lead to an exponential increase in data being captured that needs to be analyzed for predictive analytics. This also opens up a new avenue for developers who want to build exciting industrial applications. Industrial Internet Application Development serves as a one-stop guide for software professionals wanting to design, build, manage, and operate IIoT applications. You will develop your first IIoT application and understand its deployment and security considerations, followed by running through the deployment of IIoT applications on the Predix platform. Once you have got to grips with what IIoT is, you will move on to exploring Edge Development along with the analytics portions of the IIoT stack. All this will help you identify key elements of the development framework, and understand their importance when considering the overall architecture and design considerations for IIoT applications. By the end of this book, you will have grasped how to deploy IIoT applications on the Predix platform, as well as incorporate best practices for making fault-tolerant and reliable IIoT systems. What you will learn Connect prototype devices to Cloud Store data in IIoT applications Explore data management techniques and implementation Study IIoT applications analytics using Spark ML and TensorFlow Deploy analytics and visualize the outcomes as Alerts Understand continuous deployment using Docker and Cloud Foundry Make your applications fault-tolerant and monitor them with New Relic Understand IIoT platform architecture and implement IIoT applications on the platform Who this book is for This book is intended for software developers, architects, product managers, and executives keen to gain insights into Industrial Internet development. A basic knowledge of any popular programming language such as Python will be helpful.;;;;
Journal Article;Bailey J,Stuart S;Faucet: Deploying SDN in the Enterprise: Using OpenFlow and DevOps for Rapid Development;Queue;2016;14;5;54–68;;Association for Computing Machinery;New York, NY, USA;;;;2016-10;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/3012426.3015763;http://dx.doi.org/10.1145/3012426.3015763";10.1145/3012426.3015763;While SDN as a technology continues to evolve and become even more programmable, Faucet and OpenFlow 1.3 hardware together are sufficient to realize benefits today. This article describes specifically how to take advantage of DevOps practices to develop and deploy features rapidly. It also describes several practical deployment scenarios, including firewalling and network function virtualization.;;;;
Book;Atkinson B,Edwards D;Generic Pipelines Using Docker: The DevOps Guide to Building Reusable, Platform Agnostic CI/CD Frameworks;;2018;;;;1st;Apress;USA;;;;2018;9781484236543;;;;Create generic pipelines to reduce your overall DevOps workload and allow your team to deliver faster. This book helps you get up to speed on the pros and cons of generic pipeline methodology, and learn to combine shell scripts and Docker to build generic pipelines. In todays world of micro-services and agile practices, DevOps teams need to move as fast as feature teams. This can be extremely challenging if youre creating multiple pipelines per application or tech stack. What if your feature teams could utilize a generic pipeline that could build, test, and deploy any application, regardless of tech stack? What if that pipeline was also cloud and platform agnostic? Too good to be true? Well think again! Generic Pipelines Using Dockerexplores the principles and implementations that allow you to do just that. You will learn from real-world examples and reusable code. After reading this book you will have the knowledge to build generic pipelines that any team can use. What You'll Learn Explore the pros and cons of generic pipeline methodology Combine shell scripts and Docker to build a generic pipeline Implement a pipeline across CI/CD platforms Build a pipeline that lends itself well to both centralized and federated DevOps teams Construct a modular pipeline with components that can be added, removed, or replaced as needed Who This Book Is For Professionals who use DevOps or are part of a DevOps team, and are seeking ways to streamline their pipelines and drive more deployments while using less code;;;;
Book;Krochmalski J;Docker and Kubernetes for Java Developers: Scale, Deploy, and Monitor Multi-Container Applications;;2017;;;;;Packt Publishing;;;;;2017;9781786468390;;;;Key Features Master using Docker and Kubernetes to build, deploy and manage Java applications in a jiffLearn how to create your own Docker image and customize your own cluster using Kubernetes Empower the journey from development to production using this practical guide. Book Description Imagine creating and testing Java EE applications on Apache Tomcat Server or Wildfly Application server in minutes along with deploying and managing Java applications swiftly. Sounds too good to be true? But you have a reason to cheer as such scenarios are only possible by leveraging Docker and Kubernetes. This book will start by introducing Docker and delve deep into its networking and persistent storage concepts. You will then proceed to learn how to refactor monolith application into separate services by building an application and then packaging it into Docker containers. Next, you will create an image containing Java Enterprise Application and later run it using Docker. Moving on, the book will focus on Kubernetes and its features and you will learn to deploy a Java application to Kubernetes using Maven and monitor a Java application in production. By the end of the book, you will get hands-on with some more advanced topics to further extend your knowledge about Docker and Kubernetes. What you will learn Package Java applications into Docker images Understand the running of containers locally Explore development and deployment options with Docker Integrate Docker into Maven builds Manage and monitor Java applications running on Kubernetes clusters Create Continuous Delivery pipelines for Java applications deployed to Kubernetes About the Author Jaroslaw Krochmalski is a passionate software designer and developer who specializes in the financial business domain. He has over 12 years' experience in software development. He is a clean-code and software craftsmanship enthusiast. He is a Certified Scrum Master and a fan of Agile. His professional interests include new technologies in web application development, design patterns, enterprise architectures, and integration patterns. He has been designing and developing software professionally since 2000 and has been using Java as his primary programming language since 2002. In the past, he worked for companies such as Kredyt Bank (KBC) and Bank BPS on many large-scale projects such as international money orders, express payments, and collection systems. He currently works as a consultant at Danish company 7N as an infrastructure architect for the Nykredit bank. You can reach him via Twitter at @jkroch or by e-mail at jarek@finsys.pl.;;;;
Book;Kim G,Behr K,Spafford G;The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win;;2018;;;;5th;IT Revolution Press;;;;;2018;9781942788294;;;;Five years after this sleeper hit took on the world of IT and flipped it on it's head, the 5th Anniversary Edition of The Phoenix Project continues to guide IT in the DevOps revolution. In this newly updated and expanded edition of the bestselling The Phoenix Project, co-author Gene Kim includes a new afterword and a deeper delve into the Three Ways as described in The DevOps Handbook. Bill, an IT manager at Parts Unlimited, has been tasked with taking on a project critical to the future of the business, code named Phoenix Project. But the project is massively over budget and behind schedule. The CEO demands Bill must fix the mess in ninety days or else Bill's entire department will be outsourced. With the help of a prospective board member and his mysterious philosophy of The Three Ways, Bill starts to see that IT work has more in common with a manufacturing plant work than he ever imagined. With the clock ticking, Bill must organize work flow streamline interdepartmental communications, and effectively serve the other business functions at Parts Unlimited. In a fast-paced and entertaining style, three luminaries of the DevOps movement deliver a story that anyone who works in IT will recognize. Readers will not only learn how to improve their own IT organizations, they'll never view IT the same way again.;;;;
Book;Kim G,Behr K,Spafford G;The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win;;2018;;;;5th;IT Revolution Press;;;;;2018;9781942788294;;;;Five years after this sleeper hit took on the world of IT and flipped it on it's head, the 5th Anniversary Edition of The Phoenix Project continues to guide IT in the DevOps revolution. In this newly updated and expanded edition of the bestselling The Phoenix Project, co-author Gene Kim includes a new afterword and a deeper delve into the Three Ways as described in The DevOps Handbook. Bill, an IT manager at Parts Unlimited, has been tasked with taking on a project critical to the future of the business, code named Phoenix Project. But the project is massively over budget and behind schedule. The CEO demands Bill must fix the mess in ninety days or else Bill's entire department will be outsourced. With the help of a prospective board member and his mysterious philosophy of The Three Ways, Bill starts to see that IT work has more in common with a manufacturing plant work than he ever imagined. With the clock ticking, Bill must organize work flow streamline interdepartmental communications, and effectively serve the other business functions at Parts Unlimited. In a fast-paced and entertaining style, three luminaries of the DevOps movement deliver a story that anyone who works in IT will recognize. Readers will not only learn how to improve their own IT organizations, they'll never view IT the same way again.;;;;
Book;Saito H,Lee HC,Hsu KJ;Kubernetes Cookbook;;2016;;;;;Packt Publishing;;;;;2016;9781785880063;;;;Learn how to automate and manage your Linux containers and improve the overall performance of your system About This Book Are you using containers in your organization and want to better manage, scale, and orchestrate apps on the container? Use the recipes in the book to find a reliable solution from experts This is the first and only book on the market on Kubernetes, and it will show how to manage your containers in production using Kubernetes Buy this book, simply follow the recipes, and you will be the master of your Linux containers Who This Book Is For The book is aimed at system administrators who have intermediate level of knowledge with Kubernetes and want to better manage their applications deployed over containers. Also, it will help those administrators who want to maintain and scale applications on these containers. What You Will LearnGet to know how to build your own container cluster Deploy and manage highly scalable applications using Kubernetes Discover how to build high availability Kubernetes clustersFind out how to build a continuous delivery pipeline for your application Track metrics and logs for every container running in your clusterStreamline the way you deploy and manage your applications with large-scale container orchestration In Detail Kubernetes is Google's solution to managing a cluster of containers. Kubernetes provides a declarative API to manage clusters while giving us a lot of flexibility. This book will provide you with recipes to better manage containers in different scenarios in production using Kubernetes. We will start by giving you a quick brush up on how Kubernetes works with containers along with an overview of the main Kubernetes features such as Pods, Replication Controllers, and more. Next, we will teach you how to create Kubernetes cluster and how to run programs on Kubernetes. We'll explain features such as High Availability Kubernetes master setup, using Kubernetes with Docker, and orchestration with Kubernetes using AWS. Later, will show you how to use Kubernetes-UI, and how to set up and manage Kubernetes clusters on the cloud and bare metal. Upon completion of this book, you will be able use Kubernetes in production and will have a better understanding of how to manage your containers using Kubernetes. Style and approachThis recipe-based book precisely teaches you how to use Kubernetes in production and how to better manage your containers using Kubernetes.;;;;
Book;Olausson M,Rossberg J,Ehn J,Skld M;Pro Team Foundation Service;;2013;;;;1st;Apress;USA;;;;2013;9781430259954;;;;Pro Team Foundation Service gives you a jump-start into Microsofts cloud-based Application Lifecycle Management platform,taking you through the different stages of software development. Every project needs to plan, develop, test and release software and with agile practices often at a higher pace than ever before. Microsoft's Team Foundation Service is a cloud-based platform that givesyou tools for agile planning and work tracking. It has a code repository that can be used not only from Visual Studio but from Java platforms and Mac OS X. The testing tools allow testers to start testing at the same time as developers start developing. The book also covers how to set up automated practices such as build, deploy and test workflows. This book: Takes you through the major stages in a software development project. Gives practical development guidance for the whole team. Enables you to quickly get started with modern development practices. With Microsoft Team Foundation Service comes a collaboration platform that gives you and your team the tools to better perform your tasks in a fully integrated way. What youll learn What ALM is and what it can do for you. Leverage a cloud-based ALM platform for quick improvements in your development process. Improve your agile development process using integrated tools and practices. Develop automated build, deployment and testing processes. Integrate different development tools with one collaboration platform. Get started with ALM best-practices first time round. Who this book is for Pro Team Foundation Service is for any development team that wants to take their development practices to the next level. Microsoft Team Foundation Service is an excellent platform for managing the entire application development lifecycle and being a cloud-based offering it is very easy to get started. Pro Team Foundation Service is a great guide for anyone in a team who wants to get started with the service and wants to get expert guidance to do it right. Table of Contents Introduction to Application Lifecycle Management Introduction to Agile Planning, Development, and Testing Deciding on a Hosted Service Getting Started Working withthe InitialProduct Backlog Managing Team and Alerts Initial Sprint Planning Running the Sprint Kanban Engaging the Customer Choosing Source Control Options Working with Team Foundation Version Control in Visual Studio Working with Git in Visual Studio Working in Heterogeneous Environments Configuring Build Services Working with Builds Customizing Builds Continuous Deployment AgileTesting Test Management Lab Management;;;;
Conference Paper;Abdelkebir S,Maleh Y,Belaissaoui M;An Agile Framework for ITS Management In Organizations: A Case Study Based on DevOps;;2017;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2nd International Conference on Computing and Wireless Communication Systems;Larache, Morocco;2017;9781450353069;;"https://doi-org.proxy.bnl.lu/10.1145/3167486.3167556;http://dx.doi.org/10.1145/3167486.3167556";10.1145/3167486.3167556;Agility means the capability to swiftly and efficiently respond to internal and environmental organization changes. For IT, it is the ability to provide new services and IT solutions to support the innovative business processes. In the ever-changing business world of today, improving agility is the best way to face future challenges. IT service management is the capacity to collect data, analyze, report and implement agile improvements. Successful IT must be efficient and agile to promote the traditional company transformation to a digital enterprise. The propose of this work is a holistic and practical strategic framework to improve ITSM service management processes with the additions of two drivers Agility management based on DevOps, and an agility Process Maturity Framework (APMF). This research will enable decision-makers to improve and measure agility enhancements and hence compare the agility of Information Systems before and after APMF deploying.;DevOps, IT Service Management, Organization, Agility;;;ICCWCS'17
Book;Newton T,Villarreal O,Verspohl L;Learning D3.Js 4 Mapping - Second Edition: Build Cutting-Edge Maps and Visualizations with JavaScript;;2017;;;;2nd;Packt Publishing;;;;;2017;9781787280175;;;;Key FeaturesDive into D3.js and apply its powerful data binding ability in order to create stunning visualizationsLearn the key concepts of SVG, JavaScript, CSS and the DOM to bring data and shapes to live in the browserSolve common problems faced while building interactive mapsAcquire key web development skills from the creating your interactive to testing and finally publishing it. Book DescriptionD3.js is a visualization library used for the creation and control of dynamic and interactive graphical forms. It is a library used to manipulate HTML and SVG documents as well as the Canvas element based on data. Using D3.js, developers can create interactive maps for the web, that look and feel beautiful. This book will show you how build and design maps with D3.js and gives you great insight into projections, colors, and the most appropriate types of map. The book begins by helping you set up all the tools necessary to build visualizations and maps. Then it covers obtaining geographic data, modifying it to your specific needs, visualizing it with augmented data using D3.js. It will further show you how to draw and map with the Canvas API and how to publish your visualization. By the end of this book, you'll be creating maps like the election maps and the kind of infographics you'll find on sites like the New York Times. What you will learn Work with SVG geometric shapes Learn to manage map data and plot it with D3.js Add interactivity and points of interest to your mapsCompress and manipulate geoJSON files with the use of topoJSON Learn how to write testable D3.js visualizationsBuild a globe with D3.js and Canvas and add interactivity to it. Create a hexbin map with D3.js About the Author Thomas Newton has over 20 years of experience in software engineering, creating highly scalable and flexible software solutions for clients. During this period, he has developed a broad range of expertise ranging from data visualizations, to large-scale cloud platforms, to continuous delivery and DevOps. When not going in a new technology, he spends time with his beautiful family. Oscar Villarreal has been building web applications and visualizations for the past 15 years. He's worked with all kinds of businesses and organizations globally, helping them visualize and interact with data in more meaningful ways. He enjoys spending time with his wife and kid, as well as hanging from the edge of a rock wall when climbing. Lars Verspohl has been modeling and visualizing data for over 15 years. He works with businesses and organisations from all over the world to turn their often complex data into intelligible interactive visualizations. He also writes and builds stuff at datamake.io. His ideal weekend is spent either at a lake or on a mountain with his kids, although it can be hard to tear them away from the computer games he wrote for them.;;;;
Book;Chandrasekara C,Herath P;Hands-on Azure Boards: Configuring and Customizing Process Workflows in Azure DevOps Services;;2019;;;;1st;Apress;USA;;;;2019;9781484250457;;;;Understand and explore the features and management of Azure Boards with this book, which also covers Azure Boards configuration and advanced administration. This book starts by setting up projects with Azure DevOps and gives an overview of Azure Boards and its features. You will then learn to set up team projects and how to effectively use Azure Boards to plan and execute work. Hands-on Azure Boards explains customizations, where you will understand the available options to track your work considering different scenarios. Next, you will learn visualizing with queries, charts, and dashboards along with reporting of Azure Boards. The author gives you hands-on lessons to set up Azure Boards and shows you how to handle multiple modules that are taken care of by different teams. You will also explore the security options in Azure Boards as well as a detailed demonstration of working with the REST API and CLI. Finally, you will work with useful extensions for Azure Boards and see how to use them more effectively and efficiently. After reading this book, you will be able to work with the Azure Boards capabilities available in Azure DevOps on-premise server and services to improve your software delivery process. What You Will Learn Plan and manage work with Azure Boards Use the REST API and command line interface with Azure Boards Extend Azure Boards with useful extensions to enhance its capabilities Customize Azure Boards to adapt it to your process Report and visualize work progress with Azure Boards Who This Book Is For Anyone working in Azure DevOps developing applications targeting any platform using any language.;;;;
Ph.D. Thesis;Sheu FH,Hua KA;Scalable Technologies for Distributed Multimedia Systems;;1999;;;;;University of Central Florida;USA;;;;1999;9780599404601;;;;The two main operating constraints of today's multimedia servers are the storage bandwidth and communication bandwidth limitations. Many efforts have been made to efficiently utilize these capacities in streaming multimedia data to users. The common objective is to improve service latency and system throughput. In this dissertation, I present several scalable techniques for cost-effective Video-on-Demand (VoD) systems, using videos as media objects in general multimedia systems. Since video playback bears time-synchronous nature, continuous delivery of a video stream requires reserving a storage-I/O stream and an isochronous channel for jitter freedom. The minimal number of storage-I/O streams and network channels essentially determines the server capacity. Dedicating a stream for each viewer, however, will quickly exhaust the server capacity. Subsequent users will experience long waits. Therefore, the strategy to facilitate stream sharing among users is very important for the system to scale beyond the hard limitations of the media server. To address the storage bandwidth limitation, I investigate an efficient buffer management technique to cache I/O streams based on the skew between pairs of successive I/O streams. The smaller the skew, the higher priority the streams to be buffered. Moreover, I extend this knowledge to resolve the network-I/O constraint using respective Pull and Push approaches as follows: (1) On-demand multicast . When a server stream becomes available, the server selects the requests for the same video as a batch to multicast according to some scheduling policy. All the users can tune to the specific multicast channel for the same service, sharing the multicast stream. (2) Periodic broadcast . The server actively broadcasts a new stream every time interval for each video to provide the guaranteed service latency. Any user can render the current multicast stream right away, while it is also possible to prefetch the other shared streams for latter usage. Both are intensively delved in my study. Particularly, for each service model, I present a novel approach to optimize the server network-I/O's efficiency by elegantly pipelining video streams through clients' disk buffers. Thus, the server can employ a single server stream to service a large population of clients, yielding significant performance improvements over many conventional techniques. Besides the simulation results and mathematical analyses, I also demonstrate the superiority of one such technique by system implementation. The experiments from this research prototype substantiate that many users can be served instantly without compromising the excellent quality of individual playback.;;AAI9939127;Ph.D. Thesis;
Journal Article;Wiedemann A,Forsgren N,Wiesche M,Gewald H,Krcmar H;Research for Practice: The DevOps Phenomenon;Commun. ACM;2019;62;8;44–49;;Association for Computing Machinery;New York, NY, USA;;;;2019-07;;0001-0782;"https://doi-org.proxy.bnl.lu/10.1145/3331138;http://dx.doi.org/10.1145/3331138";10.1145/3331138;An executive crash course.;;;;
Book;Kim G,Behr K,Spafford G;The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win;;2013;;;;1st;IT Revolution Press;;;;;2013;9780988262591;;;;Bill is an IT manager at Parts Unlimited. It's Tuesday morning and on his drive into the office, Bill gets a call from the CEO. The company's new IT initiative, code named Phoenix Project, is critical to the future of Parts Unlimited, but the project is massively over budget and very late. The CEO wants Bill to report directly to him and fix the mess in ninety days or else Bill's entire department will be outsourced. With the help of a prospective board member and his mysterious philosophy of The Three Ways, Bill starts to see that IT work has more in common with manufacturing plant work than he ever imagined. With the clock ticking, Bill must organize work flow streamline interdepartmental communications, and effectively serve the other business functions at Parts Unlimited. In a fast-paced and entertaining style, three luminaries of the DevOps movement deliver a story that anyone who works in IT will recognize. Readers will not only learn how to improve their own IT organizations, they'll never view IT the same way again.;;;;
Book;Kim G,Behr K,Spafford G;The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win;;2014;;;;;IT Revolution Press;;;;;2014;9780988262508;;;;Bill is an IT manager at Parts Unlimited. It's Tuesday morning and on his drive into the office, Bill gets a call from the CEO. The company's new IT initiative, code named Phoenix Project, is critical to the future of Parts Unlimited, but the project is massively over budget and very late. The CEO wants Bill to report directly to him and fix the mess in ninety days or else Bill's entire department will be outsourced. With the help of a prospective board member and his mysterious philosophy of The Three Ways, Bill starts to see that IT work has more in common with manufacturing plant work than he ever imagined. With the clock ticking, Bill must organize work flow streamline interdepartmental communications, and effectively serve the other business functions at Parts Unlimited. In a fast-paced and entertaining style, three luminaries of the DevOps movement deliver a story that anyone who works in IT will recognize. Readers will not only learn how to improve their own IT organizations, they'll never view IT the same way again.;;;;
Conference Paper;Castellanos C,Varela CA,Correal D;Measuring Performance Quality Scenarios in Big Data Analytics Applications: A DevOps and Domain-Specific Model Approach;;2019;;;165–172;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 13th European Conference on Software Architecture - Volume 2;Paris, France;2019;9781450371421;;"https://doi-org.proxy.bnl.lu/10.1145/3344948.3344986;http://dx.doi.org/10.1145/3344948.3344986";10.1145/3344948.3344986;Big data analytics (BDA) applications use advanced analysis algorithms to extract valuable insights from large, fast, and heterogeneous data sources. These complex BDA applications require software design, development, and deployment strategies to deal with volume, velocity, and variety (3vs) while sustaining expected performance levels. BDA software complexity frequently leads to delayed deployments, longer development cycles and challenging performance monitoring. This paper proposes a DevOps and Domain Specific Model (DSM) approach to design, deploy, and monitor performance Quality Scenarios (QS) in BDA applications. This approach uses high-level abstractions to describe deployment strategies and QS enabling performance monitoring. Our experimentation compares the effort of development, deployment and QS monitoring of BDA applications with two use cases of near mid-air collisions (NMAC) detection. The use cases include different performance QS, processing models, and deployment strategies. Our results show shorter (re)deployment cycles and the fulfillment of latency and deadline QS for micro-batch and batch processing.;big data analytics, DevOps, performance quality scenarios, software architecture, domain specific model;;;ECSA '19
Book;Sacks M;Pro Website Development and Operations: Streamlining DevOps for Large-Scale Websites;;2012;;;;1st;Apress;USA;;;;2012;9781430239697;;;;Pro Website Development and Operationsgives you the experience you need to create and operate a large-scale production website. Large-scale websites have their own unique set of problems regarding their designproblems that can get worse when agile methodologies are adopted for rapid results. Managing large-scale websites, deploying applications, and ensuring they are performing well often requires a full scale team involving the development and operations sides of the companytwo departments that don't always see eye to eye. When departments struggle with each other, it adds unnecessary complexity to the work, and that result shows in the customer experience. Pro Website Development and Operationsshows you how to streamline the work of web development and operations - incorporating the latestinsights and methodologies of DevOps - so that your large-scale website is up and running quickly, with little friction and extreme efficiency between divisions. This book provides critical knowledge for any developer engaged in delivering thebusiness and software engineering goals required tocreate and operatea large-scale production website. It addresses how developers can collaborate effectively with business and engineering teams to ensure applications are smoothly transitioned from product inception to implementation, and are properly deployed and managed. Pro Website Development and Operations provides unique insights into how systems, code, and process can all work together to make large-scale website development and operations ultra-efficient. What youll learn How to tear down efficiency-hampering walls between development and operations How to speed up product launches How to spend less time managing your IT infrastructure, andmore time speeding up team collaboration How to better understand how software engineering and system administration can work together How to improve communications between engineering and operations How to reduce software launch errors Who this book is for Software developers and engineers working to create professional, large-scale websites.;;;;
Book;Oliveira J,Bruchet M;Learning ASP.NET Core 2.0: Build Modern Web Apps with ASP.NET Core 2.0, MVC, and EF Core 2;;2017;;;;;Packt Publishing;;;;;2017;9781788476638;;;;Learn how web applications can be built efficiently using ASP.NET Core 2.0 and related frameworks Key Features Get to grips with the new features and APIs introduced in ASP.NET Core 2.0Leverage the MVC framework and Entity Framework Core 2 to build efficient applications Learn to deploy your web applications in new environments such as the cloud and DockerBook DescriptionThe ability to develop web applications that are highly efficient but also easy to maintain has become imperative to many businesses. ASP.NET Core 2.0 is an open source framework from Microsoft, which makes it easy to build cross-platform web applications that are modern and dynamic. This book will take you through all of the essential concepts in ASP.NET Core 2.0, so you can learn how to build powerful web applications. The book starts with a brief introduction to the ASP.NET Core framework and the improvements made in the latest release, ASP.NET Core 2.0. You will then build, test, and debug your first web application very quickly. Once you understand the basic structure of ASP.NET Core 2.0 web applications, you'll dive deeper into more complex concepts and scenarios. Moving on, we'll explain how to take advantage of widely used frameworks such as Model View Controller and Entity Framework Core 2 and you'll learn how to secure your applications. Finally, we'll show you how to deploy and monitor your applications using Azure, AWS, and Docker. After reading the book, you'll be able to develop efficient and robust web applications in ASP.NET Core 2.0 that have high levels of customer satisfaction and adoption. What you will learnSet up your development environment using Visual Studio 2017 and Visual Studio CodeCreate a fully automated continuous delivery pipeline using Visual Studio Team ServicesGet to know the basic and advanced concepts of ASP.NET Core 2.0 with detailed examplesBuild an MVC web application and use Entity Framework Core 2 to access data Add Web APIs to your web applications using RPC, REST, and HATEOAS Authenticate and authorize users with built-in ASP.NET Core 2.0 features Use Azure, Amazon Web Services, and Docker to deploy and monitor your applications Who This Book Is For This book is for developers who would like to build modern web applications with ASP.NET Core 2.0. No prior knowledge of ASP.NET or .NET Core is required. However, basic programming knowledge is assumed. Additionally, previous Visual Studio experience will be helpful but is not required, since detailed instructions will guide through the samples of the book. This book can also help people, who work in infrastructure engineering and operations, to monitor and diagnose problems during the runtime of ASP.NET Core 2.0 web applications.;;;;
Book;Charlebois-Laprade N,Naguib JE;Beginning PowerShell for SharePoint 2016: A Guide for Administrators, Developers, and DevOps Engineers;;2017;;;;2nd;Apress;USA;;;;2017;9781484228838;;;;Use the latest tools to manage and automate tasks on Microsoft's SharePoint platform. You will achieve time and cost savings, increase reliability of deployments, and learn how to safely and efficiently migrate from a previous version, all while gaining valuable skills in PowerShell scripting. Authors Nik Charlebois-Laprade and John Edward Naguib begin by explaining the fundamental concepts behind the PowerShell language. Then, with copious real-world examples and scripts, they introduce PowerShell operations in the context of deploying, migrating, managing, and monitoring SharePoint 2016. What You'll Learn Whats New in this Edition? Learn about the new SharePoint 2016 capabilities and min role Extend the default set of available PowerShell cmdlets for SharePoint 2016 by creating your own reusable Cmdlet functions with PowerShell 5.0 Upgrade your on-premises SharePoint 2013 environment to SharePoint 2016 using PowerShell Who This Book Is For Administrators, developers, and DevOps engineers working with SharePoint 2016. No experience with PowerShell is required.;;;;
Conference Paper;Krasic C,Walpole J;Priority-Progress Streaming for Quality-Adaptive Multimedia;;2001;;;463–464;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Ninth ACM International Conference on Multimedia;Ottawa, Canada;2001;9781581133943;;"https://doi-org.proxy.bnl.lu/10.1145/500141.500212;http://dx.doi.org/10.1145/500141.500212";10.1145/500141.500212;The Internet's ubiquity amply motivates us to harness it for video distribution, however, its best-effort service model is in direct conflict with video's inherent timeliness requirements. Today, the Internet is unrivaled in its rich composition, consisting of an unparalleled assortment of networks and hosts. This richness is the result of an architecture that emphasizes interoperability over predictable performance. From the lowest levels, the Internet architecture prefers the best effort service model. We feel current solutions for media-streaming have yet to adequately address this conflict between timeliness and best-effort service.We propose that streaming-media solutions targetted at the Internet must fully embrace the notion of graceful degradation, they must be architected with the expectation that they operate within a continuum of service levels, adjusting quality-resource trade-offs as necessary to achieve timeliness requirements. In the context of the Internet, the continuum of service levels spans across a number oftime scales, ranging from sub-second timescales to timescales as long as months and years. We say sub-second timescales in relation to short-term dynamics such as network traffic and host workloads, while timescales of months and years relate to the continuous deployment of improving network, compute and storage infrastructure.We support our thesis with a proposal for a streaming model which we claim is simple enough to use end-to-end, yet expressive enough to tame the conflict between real-time and best-effort personalities of Internet streaming. The model is called Priority-Progress streaming. In this proposal, we will describe the main features of Priority-Progress streaming, which we have been implemented in a software-based streaming video system, called the Quasar pipeline.Our work is primarily concerned with the class of streaming applications. To prevent confusion, we now clarify the important distinction between streaming and other forms of distribution, namely download. For a video, we assume download is defined so that the transfer of the video must complete before the video is viewed. Transfer and viewing are temporally sequential. With this definition, it is a simple matter to employ Quality-adaptive video. One algorithm would be to deliver the entire video in the order from low to high quality components. The user may terminate the download early, and the incomplete video will automatically have as high quality as was possible. Thus, Quality-adaptive download can be implemented in an entirely best-effort, time-insensitive, fashion. On the other hand, we assume streaming means that the user views the video at the same time that the transfer occurs. Transfer and viewing are concurrent. There are timeliness requirements inherent in this definition, which can only be reconciled with best-effort delivery through a time-sensitive adaptive approach.;;;;MULTIMEDIA '01
Book;Chandrasekara C,Herath P;Hands-on Azure Repos: Understanding Centralized and Distributed Version Control in Azure DevOps Services;;2019;;;;1st;Apress;USA;;;;2019;9781484254240;;;;"Use Azure Repos to manage your code in both centralized and distributed version control systems. This book will show you how to work with Team Foundation Version Control (TFVC) and distributed version control (Git), while exploring their best practices. You'll start with an introduction to Azure Repos, focusing on TFVC and Git, and then gradually transition to hands on lessons of working with TVFC. Next, you'll see how to set up and work with TFVC branches and tracking systems followed by usage of command line and security in TFVC Repos. Create and work on Git Repos in Azure DevOps and use branching with Azure Git Repos and Git command line in Visual Studio and vscode. The book then explores security in Git Repos and advanced options you can use to import from external Repos. With Hands-on Azure Repos as your guide, you'll be able to work with these version control tools on any platform and with any language. What You'll Learn Integrate Azure Repos with Azure Boards to enable tracking work with code.; Create guidelines to tackle difficult situations in using Azure Repos; Clone Azure Repo to local using Visual Studio and vscode; Work with shelvesets, code reviews and lock types; Perform activities using REST API with Azure Repos; Who This Book Is For Software developers, tech leads and architects.";;;;
Book;Forsgren N,Humble J,Kim G;Accelerate: The Science of Lean Software and DevOps Building and Scaling High Performing Technology Organizations;;2018;;;;1st;IT Revolution Press;;;;;2018;9781942788331;;;;Accelerate your organization to win in the marketplace. How can we apply technology to drive business value? For years, we've been told that the performance of software delivery teams doesn't matterthat it can't provide a competitive advantage to our companies. Through four years of groundbreaking research to include data collected from the State of DevOps reports conducted with Puppet, Dr. Nicole Forsgren, Jez Humble, and Gene Kim set out to find a way to measure software delivery performanceand what drives itusing rigorous statistical methods. This book presents both the findings and the science behind that research, making the information accessible for readers to apply in their own organizations. Readers will discover how to measure the performance of their teams, and what capabilities they should invest in to drive higher performance. This book is ideal for management at every level.;;;;
Book;Rossberg J,Olausson M;Pro Application Lifecycle Management with Visual Studio 2012;;2012;;;;2nd;Apress;USA;;;;2012;9781430243441;;;;You can have the best coders in the world working in your teams, but if your project management isnt up to scratch, your project is almost certain to be delayed, to come in over budget, and in some cases to fail entirely. By taking precise control of your application development process, you can make changes, both large and small, throughout your projects life cycle that will lead to betterquality finished products that are consistently delivered on time and within budget. Application lifecycle management (ALM) is an area of rapidly growing interest within the development community. Because its techniques allow you to deal with the process of developing applications across many areas of responsibility and across many different disciplines, its effects on your project can be wide ranging and pronounced. It is a project management tool that has practical implications for the whole teamfrom architects to designers, from developers to testers. Pro Application Lifecycle Management with Visual Studio 2012focuses on the most powerful ALM tool available for the Microsoft .NET Framework: Visual Studio Team Foundation Server. It demonstrates the key concepts and techniques of ALM at first with a guide to the overall methodology, and then delves into architecture and testing--illustrating all of the concepts, tips and tricks using the tools TFS provides. The book serves as a complete guide to the ALM style--with no fluff and many relevant code samples and examples. After reading the book, you will understand how TFS can be used to generate continuous meaningful reporting on your projects health for the decision makers on your team as well as for your projects sponsors. What youll learn What ALM is and what it can do for you How to achieve traceability in your projects How to improve your development process Why TFS is so much more than just a version control tool The new features in TFS that help encourage ALM best practices, especially within Metro and .NET 4.5 applications What the importance of welldesigned and welldefined processes is and how to implement these things Who this book is for This book will be of value for anyone developing applications with Visual Studio Team Foundation Server, whether they are working in a small team of just a few people or in a large enterprise environment. Table of Contents Why Application Lifecycle Management Matters Introduction to Application Lifecycle Management Development Processes and Frameworks ALM Assessments Working with TFS to Enhance the ALM Process Introduction to Agile Planning Work Item Tracking and Process Customization Agile Project Management with TFS Metrics and ALM Assessment Prototyping/Storyboarding + Feedback Tracking Top Down Design Studies (UML) Using Architecture Explorer Using Layer Diagrams Metrics and ALM Assessment Version Control Unit Testing Code Analysis, Code Metrics, Code Clones, Code Review Performance and Profiling Metrics and ALM Assessment Overview of Software Testing Manual Testing Automated Testing Test Lab Management Metrics and ALM Assessment Continuous Delivery Build Automation Deployment Release Management Metrics and ALM Assessment Architecture, Implementation and Planning Installation, Migration and Administration TFS Reporting Working in Heterogeneous Environments TFS in the Cloud;;;;
Conference Paper;Miguel FS,Mareddy N,Moorthy AK,Liu X;Microservices for Multimedia: Video Encoding;;2022;;;89;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 1st Mile-High Video Conference;Denver, Colorado;2022;9781450392228;;"https://doi-org.proxy.bnl.lu/10.1145/3510450.3517298;http://dx.doi.org/10.1145/3510450.3517298";10.1145/3510450.3517298;"Netflix has been one of the pioneers that has driven the industry adoption of a new paradigm of system architecture referred to as ""microservices"". Microservices, or more accurately, microservice architecture refers to an architecture where applications are modeled as a collection of services which are: highly maintainable and independently testable, loosely coupled, independently deployable and organized around business capabilities. Typically, each microservice is owned by a small team of developers that is responsible for its development, testing and deployment, i.e., its end-to-end lifecycle. Traditional microservices such as those used outside of multimedia processing at Netflix typically consist of an API with stateless business logic which is autoscaled based on request load. These APIs provide strong contracts and separate the application data and binary dependencies from systems.As useful as traditional microservices are, several peculiarities of multimedia applications render such stateless services non ideal for media processing. Specifically, media processing (which includes video/audio processing, media encoding, timed-text processing, computer vision analysis etc.) relies on data that is embedded in files where the files themselves are contracts as opposed to fully visible data models that are common in non-media applications. At Netflix, media processing is resource intensive and bursty in nature. It is also highly parallelizable and re-triable, and so, even though work is generally a continuous stream with deadlines and priorities, the system can balance resources by evicting jobs as needed which can be retried at a later time.In this talk, we will summarize Cosmos, a project that we've developed in order to enable workflow-driven media processing using a microservice architecture.Cosmos is a computing platform that combines the best aspects of microservices with asynchronous workflows and serverless functions. It is designed specifically for resource intensive algorithms which are coordinated via complex hierarchical workflows. Cosmos supports both high throughput and low-latency workloads. The Cosmos platform offers: observability through built in logging, tracing, monitoring, alerting and error classification; modularity (both compile-time and run-time) through an opinionated framework for structuring a service; productivity through tooling such as code generators, containers, and command line interfaces; and delivery through a managed continuous-delivery pipelines.The Cosmos platform allows media developers to build and run domain-specific, scale-agnostic components which are built atop three scale-aware subsystems that handle distributing the work. Each component can thus be independently developed, tested and deployed with clear abstraction from the underlying platform thereby providing a logical separation between the application and platform so that the details of distributed computing are hidden from media developersCosmos enables our media developers to take a service from commit to deployment in a matter of hours. To ensure the success of the large-scale overall system with independent fast-moving microservice development, innovative testing strategies are applied with various testing tools and quick rollback capability in production.In the talk, using the Netflix Video Encoder Service as an example, we will describe the Cosmos architecture and our migration to microservices-based media processing. The talk will also cover our learnings around managing a large-scale migration and the mindset required in order to plan and execute a multi-year goal.";cosmos, video encoding, microservices;;;MHV '22
Book;Beach B;Pro PowerShell for Amazon Web Services: DevOps for the AWS Cloud;;2014;;;;1st;Apress;USA;;;;2014;9781430264514;;;;Pro PowerShell for Amazon Web Services is written specifically for Windows professionals who already know PowerShell and want to learn to host Windows workloads in the Amazon Elastic Cloud Compute (EC2) cloud service. The cloud offers information technology workers significant cost savings and agility unimaginable even just a few years ago. Tasks that traditionally took weeks of work, costing thousands of dollars, can be completed in minutes for a fraction of a penny. This book is a resource for using Microsoft's powerful scripting language, PowerShell, to create, host, manage, and administer workloads using a service widely recognized as the industry leader in cloud computing. Inside, find scripts to create and manage virtual machines, provision storage, configure networks with agility, and more--all using your preferred Windows scripting language. Use your PowerShell knowledge to harness the power of Amazon EC2 today!What youll learn Create, manage, and terminate Windows servers in the cloud Manage storage options including backup and recovery Configure a virtual network including subnets and route tables Secure your servers using security groups and access control lists Use Auto Scaling to respond to changing conditions Deploy SQL Server using Relational Database ServiceUse Simple Storage Service (S3) to reliably store and archive data Control access to resources using Identity and Access Management (IAM) Who this book is forPro PowerShell for Amazon Web Servicesis for the intermediate to advanced Windows professional who is ready to make the leap to the Amazon cloud.;;;;
Journal Article;Xie T,van Hoorn A,Wang H,Weber I;Introduction to the Special Issue on Emerging Software Technologies for Internet-Based Systems: Internetware and DevOps;ACM Trans. Internet Technol.;2018;18;2;;;Association for Computing Machinery;New York, NY, USA;;;;2018-03;;1533-5399;"https://doi-org.proxy.bnl.lu/10.1145/3173572;http://dx.doi.org/10.1145/3173572";10.1145/3173572;;;;;
Conference Paper;Stöckle P,Pruteanu I,Grobauer B,Pretschner A;Hardening with Scapolite: A DevOps-Based Approach for Improved Authoring and Testing of Security-Configuration Guides in Large-Scale Organizations;;2022;;;137–142;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Twelveth ACM Conference on Data and Application Security and Privacy;Baltimore, MD, USA;2022;9781450392204;;"https://doi-org.proxy.bnl.lu/10.1145/3508398.3511525;http://dx.doi.org/10.1145/3508398.3511525";10.1145/3508398.3511525;"Security Hardening is the process of configuring IT systems to ensure the security of the systems' components and data they process or store. In many cases, so-called security-configuration guides are used as a basis for security hardening. These guides describe secure configuration settings for components such as operating systems and standard applications. Rigorous testing of security-configuration guides and automated mechanisms for their implementation and validation are necessary since erroneous implementations or checks of hardening guides may severely impact systems' security and functionality. At Siemens, centrally maintained security-configuration guides carry machine-readable information specifying both the implementation and validation of each required configuration step. The guides are maintained within git repositories; automated pipelines generate the artifacts for implementation and checking, e.g., PowerShell scripts for Windows, and carry out testing of these artifacts on AWS images. This paper describes our experiences with our DevOps-inspired approach for authoring, maintaining, and testing security-configuration guides. We want to share these experiences to help other organizations with their security hardening and increase their systems' security.";security configuration, hardening;;;CODASPY '22
Book;Simon F,Landman Y,Sadogursky B;Liquid Software: How to Achieve Trusted Continuous Updates in the DevOps World;;2018;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2018;9781981855728;;;;Software affects everything in our lives. Imagine that software could be constantly updated without our involvement! No need to figure out hardware specifications. Nothing to interrupt our digital activities. No waiting for lengthy downloads and reboots. What if it all just happened in the background, and we could simply enjoy the benefits? Liquid Software explores a future in which developers code high-quality applications that securely flow to end-users with zero downtime. The authors bring insights from their more than 50 years of collective experience in building software in modern development environments. They explain that what sounds like Software Utopia is possible and practical! Were at the dawn of the next great leap forward in computing the achievement of continuous software updates. The Liquid Software revolution has begun!;;;;
Book;Akopkokhyants S,Radford S;Learning Web Development with Bootstrap and Angular - Second Edition;;2016;;;;2nd;Packt Publishing;;;;;2016;9781785880810;;;;Key Features Updated for the latest releases of Angular and Bootstrap, this book shows you how to build web applications with cutting-edge web technologies Combine the best of both worlds to build single page apps with elegant user interfaces Build, develop, and customize your application using Angular and Bootstrap Packed with tips to help you avoid potential stumbling blocks while developing Book Description Two of the most popular frontend frameworks, Angular and Bootstrap, have undergone a major overhaul to embrace emerging web technologies so that developers can build cutting-edge web applications. Inside this title you'll dive, fingers first, into the basics of both the tools, and once you're familiar with them, you'll move onto Bootstrap's new grid system and Angular's built-in directives. You'll then learn how to format output using Angular's pipes and how to make use of the built-in router to set up routes for all your components. Webpack will be your buddy to wrap up your project. Then, after throwing in some SASS to make things pretty, you'll learn how to validate the forms you've built and debug your application. Finally, you'll go on to learn how to obtain smooth transitioning from Bootstrap to Angular and then how to hook up with a server and use Firebase as the persistence layer. Once you're done with this book, you'll not only have a lovely little e-commerce application running, but you'll also take with you the confidence to innovate and build your own applications with ease. What you will learn Develop Angular 2 single page applications using an ecosystem of helper tools Get familiar with Bootstraps new grid and helper classes Embrace TypeScript and ECMA Script 2015 to write more maintainable code Use custom directives for Bootstrap 4 with the ng2-bootstrap library Understand the component-oriented structure of Angular 2 and its router Make use of the built-in HTTP library to work with API endpoints Use observables and streams to manage the apps data and state Combine Angular 2 and Bootstrap 4 along with Firebase in the development of a solid example About the Author Sergey Akopkokhyants is a software architect with more than 20 years of professional experience in designing and developing client and server-side applications. He is also a certified Java developer and project manager. He has general knowledge of many tools, languages, and platforms. For the last decade, Sergey has been responsible for customizing and producing weboriented applications for wholesale business management solutions projects for several worldwide mobile communication companies. His responsibilities have included: architecture design and guidance of client software development using Flex, CSS, HTML, JavaScript, TypeScript, and Dart, and client-server integration with Java. He is also the founder and an active contributor to several open source projects on GitHub. Sergey is passionate about web design and development and likes sharing his expertise with others, helping them to increase their skills and productivity. He is author of the book Mastering Dart and also he was one of reviewers of the books Learning Dart and Dart Cookbook. Stephen Radford is a full-stack web and app developer based in the heart of England--Leicester. Originally from Bristol, Stephen moved to Leicester after studying Graphic Design at college to accept a job at one of the UKs largest online marketing companies. Whilst working at a number of agencies, Stephen developed several side projects, including FTPloy, a SaaS designed to make continuous deployment available to everyone. The project was subsequently a finalist in the .NET Awards Side Project of the Year category. He and his business partner now run Cocoon, a web development company that builds and maintains web and mobile apps. Cocoon also works closely with a handful of startups and businesses to develop ideas into websites and apps.;;;;
Book;Chou E;Mastering Python Networking: Your One-Stop Solution to Using Python for Network Automation, DevOps, and Test-Driven Development, 2nd Edition;;2018;;;;2nd;Packt Publishing;;;;;2018;9781789135992;;;;Master the art of using Python for a diverse range of network engineering tasks Key Features Explore the power of Python libraries to tackle difficult network problems efficiently and effectively Use Python for network device automation, DevOps, and software-defined networkingBecome an expert in implementing advanced network-related tasks with Python Book Description Networks in your infrastructure set the foundation for how your application can be deployed, maintained, and serviced. Python is the ideal language for network engineers to explore tools that were previously available to systems engineers and application developers. In this second edition of Mastering Python Networking, youll embark on a Python-based journey to transition from traditional network engineers to network developers ready for the next-generation of networks. This book begins by reviewing the basics of Python and teaches you how Python can interact with both legacy and API-enabled network devices. As you make your way through the chapters, you will then learn to leverage high-level Python packages and frameworks to perform network engineering tasks for automation, monitoring, management, and enhanced security. In the concluding chapters, you will use Jenkins for continuous network integration as well as testing tools to verify your network. By the end of this book, you will be able to perform all networking tasks with ease using Python. What you will learn Use Python libraries to interact with your network Integrate Ansible 2.5 using Python to control Cisco, Juniper, and Arista eAPI network devices Leverage existing frameworks to construct high-level APIs Learn how to build virtual networks in the AWS Cloud Understand how Jenkins can be used to automatically deploy changes in your network Use PyTest and Unittest for Test-Driven Network Development Who this book is for Mastering Python Networking is for network engineers and programmers who want to use Python for networking. Basic familiarity with Python programming and networking-related concepts such as Transmission Control Protocol/Internet Protocol (TCP/IP) will be useful.;;;;
Journal Article;Limoncelli TA;The Time I Stole $10,000 from Bell Labs: Or Why DevOps Encourages Us to Celebrate Outages;Queue;2020;18;5;26–35;;Association for Computing Machinery;New York, NY, USA;;;;2020-10;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/3434571.3434773;http://dx.doi.org/10.1145/3434571.3434773";10.1145/3434571.3434773;If IT workers fear they will be punished for outages, they will adopt behavior that leads to even larger outages. Instead, we should celebrate our outages: Document them blamelessly, discuss what we've learned from them openly, and spread that knowledge generously. An outage is not an expense. It is an investment in the people who have learned from it. We can maximize that investment through management practices that maximize learning for those involved and by spreading that knowledge across the organization. Managed correctly, every outage makes the organization smarter. In short, the goal should be to create a learning culture?one that seeks to make only new mistakes.;;;;
Conference Paper;Zheng E,Gates-Idem P,Lavin M;Building a Virtually Air-Gapped Secure Environment in AWS: With Principles of Devops Security Program and Secure Software Delivery;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 5th Annual Symposium and Bootcamp on Hot Topics in the Science of Security;Raleigh, North Carolina;2018;9781450364553;;"https://doi-org.proxy.bnl.lu/10.1145/3190619.3190642;http://dx.doi.org/10.1145/3190619.3190642";10.1145/3190619.3190642;This paper presents the development and configuration of a virtually air-gapped cloud environment in AWS, to secure the production software workloads and patient data (ePHI) and to achieve HIPAA compliance.;cloud, AWS, risk management, cybersecurity, trust, devops, security;;;HoTSoS '18
Book;;Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, ChâTeau de Villebrumier, France, May 6–8, 2019, Revised Selected Papers;;2019;;;;;Springer-Verlag;Berlin, Heidelberg;;;Villebrumier, France;2019;9783030393052;;;;;;;Proceedings;
Journal Article;Couto LD,Tran-Jørgensen PW,Nilsson RS,Larsen PG;Enabling Continuous Integration in a Formal Methods Setting;Int. J. Softw. Tools Technol. Transf.;2020;22;6;667–683;;Springer-Verlag;Berlin, Heidelberg;;;;2020-12;;1433-2779;"https://doi-org.proxy.bnl.lu/10.1007/s10009-019-00546-y;http://dx.doi.org/10.1007/s10009-019-00546-y";10.1007/s10009-019-00546-y;In modern software development, the practices of continuous integration and DevOps are widely used to increase delivery speed and reduce the time it takes to deploy software changes to production. If formal method tools cannot be efficiently integrated in a DevOps paradigm, then their impact on software development will be reduced. In this paper, we present work addressing this issue through a series of extensions for the Overture tool supporting the Vienna Development Method. These extensions enable Overture to be used in a DevOps setting, through continuous integration and validation of models and generated code via integration with the Jenkins automation server. We frame the integration of formal methods and DevOps in a series of principles, demonstrate the value of this integration through a case study, and reflect on our experiences using formal methods and DevOps in an industrial setting. We hope that this work can help other formal method practitioners integrate their tools with DevOps.;Code generation, Modelling, VDM, Simulation, Continuous integration, DevOps, Test automation;;;
Conference Paper;Kampik T,Amaral CJ,Hübner JF;Developer Operations and Engineering Multi-Agent Systems;;2021;;;175–186;;Springer-Verlag;Berlin, Heidelberg;;Engineering Multi-Agent Systems: 9th International Workshop, EMAS 2021, Virtual Event, May 3–4, 2021, Revised Selected Papers;;2021;9783030974565;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-97457-2_10;http://dx.doi.org/10.1007/978-3-030-97457-2_10";10.1007/978-3-030-97457-2_10;In this paper, we propose the integration of approaches to Engineering Multi-Agent Systems (EMAS) with the Developer Operations (DevOps) industry best practice. Whilst DevOps facilitates the organizational autonomy of software teams, as well as the technological automation of testing, deployment, and operations pipelines, EMAS and the agent-oriented programming paradigm help instill autonomy into software artifacts. We discuss the benefits of integrating DevOps and EMAS, for example by highlighting the need for agent-oriented abstractions for quality assurance and test automation approaches. More generally, we introduce an agent-oriented perspective on the DevOps life-cycle and list a range of research challenges that are relevant for the integration of the DevOps and EMAS perspectives.;Developer Operations, Engineering Multi-Agent Systems, Agent-oriented programming;;;
Conference Paper;Ferry N,Dominiak J,Gallon A,González E,Iturbe E,Lavirotte S,Martinez S,Metzger A,Muntés-Mulero V,Nguyen PH,Palm A,Rego A,Rios E,Riviera D,Solberg A,Song H,Tigli JY,Winter T;Development and Operation of Trustworthy Smart IoT Systems: The ENACT Framework;;2019;;;121–138;;Springer-Verlag;Berlin, Heidelberg;;Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Château de Villebrumier, France, May 6–8, 2019, Revised Selected Papers;Villebrumier, France;2019;9783030393052;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-39306-9_9;http://dx.doi.org/10.1007/978-3-030-39306-9_9";10.1007/978-3-030-39306-9_9;To unleash the full potential of IoT, it is critical to facilitate threation and operation of trustworthy Smart IoT Systems (SIS). Software development and delivery of SIS would greatly benefit from DevOps as devices and IoT services requirements for reliability, quality, security and safety are paramount. However, DevOps practices are far from widely adopted in the IoT, in particular, due to a lack of key enabling tools. In last year paper at DevOps’18, we presented the ENACT research roadmap that identified the critical challenges to enable DevOps in the realm of trustworthy SIS. In this paper, we present the ENACT DevOps Framework as our current realization of these methods and tools.;DevOps, Internet-of-Things, Trustworthiness;;;
Book Chapter;Meyers B,Gadeyne K,Oakes BJ,Bernaerts M,Vangheluwe H,Denil J;A Model-Driven Engineering Framework to Support the Functional Safety Process;;2019;;;619–623;;IEEE Press;;Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems;;;2019;9781728151250;;https://doi-org.proxy.bnl.lu/10.1109/MODELS-C.2019.00094;;The design of safety-related systems traditionally has long and costly development cycles due to the highly manual safety engineering process, which is guided by industry standards. In this paper, we present a modelling framework that supports DevOps principles of continuous testing and fast development iterations for the design of safety-critical systems. We show how modelling can help introducing DevOps in the context of functional safety analysis, and we also report how DevOps was used during the development of the framework.;;;;
Journal Article;Woods E;Operational: The Forgotten Architectural View;IEEE Softw.;2016;33;3;20–23;;IEEE Computer Society Press;Washington, DC, USA;;;;2016-05;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2016.86;http://dx.doi.org/10.1109/MS.2016.86";10.1109/MS.2016.86;The emerging DevOps movement emphasizes development and operations staff working together as early as possible--sharing tools, processes, and practices that smooth the production path. This article is part of a theme issue on DevOps.;;;;
Book Chapter;Sánchez-Gordón M,Colomo-Palacios R;Security as Culture: A Systematic Literature Review of DevSecOps;;2020;;;266–269;;Association for Computing Machinery;New York, NY, USA;Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops;;;2020;9781450379632;;https://doi-org.proxy.bnl.lu/10.1145/3387940.3392233;;DevOps goes beyond automation, continuous integration and delivery processes, since it also encompasses people. In fact, DevOps promotes the collaboration between the development team and the operations team. When security comes into DevOps routines, people play an even more relevant role involving the collaboration between those teams and security team. Moreover, security is especially relevant while developing critical systems where we need to manage goals, risks and evidences. After implementing security into the DevOps toolchain, work only starts. We also need to start with behavioral changes in order to create a security culture. Several authors underlined DevSecOps, as one of the proposals for solving or, at least, minimizing this challenge. However, to date, the characterization of such a culture remains unclear. In this paper, a Systematic Literature Review was carried out to provide a better understanding of this topic from the human factor's perspective. However it raises the following question: Is DevSecOps going to become mainstream?;;;;
Conference Paper;Révész Á,Pataki N;Continuous A/B Testing in Containers;;2019;;;11–14;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2019 2nd International Conference on Geoinformatics and Data Analysis;Prague, Czech Republic;2019;9781450362450;;"https://doi-org.proxy.bnl.lu/10.1145/3318236.3318254;http://dx.doi.org/10.1145/3318236.3318254";10.1145/3318236.3318254;Software version ranking plays an important role in improved user experience and software quality. A/B testing is a technique to distinguish between the popularity and usability of two quite similar versions (A and B) of a product, marketing strategy, search ad, etc. It is a kind of two-sample hypothesis testing, used in the field of statistics. This controlled experiment can evaluate user engagement or satisfaction with a new service, feature, or product. A/B testing is typically used in evaluation of user-experience design in software technology. DevOps is an emerging software methodology in which the development and operations are not independent processes, they affect each other. DevOps emphasizes the usage of virtualization technologies (e.g. containers). Docker is widely-used technology for containerization. In this paper, we deal with a new approach for regular A/B testing via Docker containers. Our solution provides an API that can be available from many DevOps tools. This approach is DevOps-style A/B testing because after the evaluation the better version remains in production.;DevOps, A/B testing, Docker, containers;;;ICGDA 2019
Journal Article;Limoncelli TA;The Time I Stole $10,000 from Bell Labs;Commun. ACM;2021;64;2;44–46;;Association for Computing Machinery;New York, NY, USA;;;;2021-01;;0001-0782;"https://doi-org.proxy.bnl.lu/10.1145/3434224;http://dx.doi.org/10.1145/3434224";10.1145/3434224;Why DevOps encourages us to celebrate outages.;;;;
Conference Paper;Zimmerer P;Strategy for Continuous Testing in IDevOps;;2018;;;532–533;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings;Gothenburg, Sweden;2018;9781450356633;;"https://doi-org.proxy.bnl.lu/10.1145/3183440.3183465;http://dx.doi.org/10.1145/3183440.3183465";10.1145/3183440.3183465;This tutorial presentation describes the state-of-the-art in the emerging area of continuous testing in a DevOps context. It specifies the building blocks of a strategy for continuous testing in industrial-grade DevOps projects (iDevOps) and shares our motivations, achievements, and experiences on our journey to transform testing into the iDevOps world.;continuous integration (CI), continuous testing (CT), test strategy, test architecture, mindset, continuous delivery (CD), DevOps;;;ICSE '18
Journal Article;Bailey J,Stuart S;Faucet: Deploying SDN in the Enterprise;Commun. ACM;2016;60;1;45–49;;Association for Computing Machinery;New York, NY, USA;;;;2016-12;;0001-0782;"https://doi-org.proxy.bnl.lu/10.1145/3009828;http://dx.doi.org/10.1145/3009828";10.1145/3009828;Using OpenFlow and DevOps for rapid development.;;;;
Conference Paper;van Deursen A;Software Engineering without Borders;;2017;;;3;;IEEE Press;Urbana-Champaign, IL, USA;;Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering;;2017;9781538626849;;;;DevOps approaches software engineering by advocating the removal of borders between development and operations. DevOps emphasizes operational resilience, continuous feedback from operations back to development, and rapid deployment of features developed. In this talk we will look at selected (automation) aspects related to DevOps, based on our collaborations with various industrial partners. For example, we will explore (automated) methods for analyzing log data to support deployments and monitor REST API integrations, (search-based) test input generation for reproducing crashes and testing complex database queries, and zero downtime database schema evolution and deployment. We will close by looking at borders beyond those between development and operations, in order to see whether there are other borders we need to remove in order to strengthen the impact of software engineering research.;;;;ASE 2017
Conference Paper;Müller HA,Rivera LF,Jiménez M,Villegas NM,Tamura G,Akkiraju R,Watts I,Erpenbach E;Proactive AIOps through Digital Twins;;2021;;;275–276;;IBM Corp.;USA;;Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering;Toronto, Canada;2021;;;;;The rise of advanced IT environments (IT ·Envs) that meet ever increasing user expectations on software quality necessitates innovative practices in the development and operation of software-intensive systems. DevOps teams find themselves searching for ways to deliver value by attacking operational challenges that tend to overwhelm human capabilities. Most of these challenges relate to the structural and behavioural complexities of modern IT·Envs. While the former concerns the orchestration of multiple technologies, the latter involves the exploitation of the huge data streams produced that are integral to DevOps activities. As automation, autonomy, and artificial intelligence technologies are maturing and permeating various activities in the software development lifecycle, opportunities arise from their integration with DevOps practices to improve risk mitigation, root cause analysis, problem resolution, and operational optimization in IT·Envs. This CASCON x EVOKE 2021 workshop discussed challenges and opportunities in developing proactive AIOps through digital twin technologies.;AIOps, machine learning, DevOps, cloud, AI, fault prediction, IT operations, digital twins;;;CASCON '21
Conference Paper;Light J,Pfeiffer P,Bennett B;An Evaluation of Continuous Integration and Delivery Frameworks for Classroom Use;;2021;;;204–208;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2021 ACM Southeast Conference;Virtual Event, USA;2021;9781450380683;;"https://doi-org.proxy.bnl.lu/10.1145/3409334.3452085;http://dx.doi.org/10.1145/3409334.3452085";10.1145/3409334.3452085;Continuous integration and delivery (CI/CD) frameworks are a core element of DevOps-based software development. A PHP-based case study assessed the suitability of five such frameworks---JFrog Arti-factory, Bitbucket Pipelines, Jenkins, Azure DevOps, and TeamCity---for instructional use. The five were found to be roughly equivalent in terms of their usability for simple configurations. The effort needed to implement CI/CD substantially increased for more realistic production scenarios, like deployments to cloud and load-balanced platforms. These results suggest a need to limit CI/CD-based academic projects to simple infrastructure and technology stacks: e.g., a web application on a single instance web server.;information systems education, computer science education, software engineering, DevOps, CI/CD;;;ACM SE '21
Book;Buchanan S,Rangama J,Bellavance N;Introducing Azure Kubernetes Service: A Practical Guide to Container Orchestration;;2019;;;;1st;Apress;USA;;;;2019;9781484255186;;;;"Go from zero to sixty deploying and running a Kubernetes cluster on Microsoft Azure! This hands-on practical guide to Microsoft's Azure Kubernetes Service (AKS), a managed container orchestration platform, arms you with the tools and knowledge you need to easily deploy and operate on this complex platform. Take a journey inside Docker containers, container registries, Kubernetes architecture, Kubernetes components, and core Kubectl commands. Drawing on hard-earned experience in the field, the authors provide just enough theory to help you grasp important concepts, teaching the practical straightforward knowledge you need to start running your own AKS cluster. You will dive into topics related to the deployment and operation of AKS, including Rancher for management, security, networking, storage, monitoring, backup, scaling, identity, package management with HELM, and AKS in CI/CD. What You Will Learn Develop core knowledge of Docker containers, registries, and Kubernetes; Gain AKS skills for Microsoft's fastest growing services in the cloud; Understand the pros and cons of deploying and operating AKS; Deploy and manage applications on the AKS platform; Use AKS within a DevOps CI/CD process; Who This Book Is For IT professionals who work with DevOps, the cloud, Docker, networking, storage, Linux, or Windows. Experience with cloud, DevOps, Docker, or application development is helpful.";;;;
Book;Leonard A;Data Integration Life Cycle Management with SSIS: A Short Introduction by Example;;2017;;;;1st;Apress;USA;;;;2017;9781484232750;;;;Build a custom BimlExpress framework that generates dozens of SQL Server Integration Services (SSIS) packages in minutes. Use this framework to execute related SSIS packages in a single command. You will learn to configure SSIS catalog projects, manage catalog deployments, and monitor SSIS catalog execution and history. Data Integration Life Cycle Management with SSISshows you how to bring DevOps benefits to SSIS integration projects. Practices in this book enable faster time to market, higher quality of code, and repeatable automation. Code will be created that is easier to support and maintain. The book teaches you how to more effectively manage SSIS in the enterprise environment by drawing on the art and science of modern DevOps practices. What You'll Learn Generate dozens of SSIS packages in minutes to speed your integration projects Reduce the execution of related groups of SSIS packages to a single command Successfully handle SSIS catalog deployments and their projects Monitor the execution and history of SSIS catalog projects Manage your enterprise data integration life cycle through automated tools and utilities Who This Book Is For Database professionals working with SQL Server Integration Services in enterprise environments. The book is especially useful to those readers following, or wishing to follow, DevOps practices in their use of SSIS.;;;;
Book;Gajda W;Pro Vagrant;;2015;;;;1st;Apress;USA;;;;2015;9781484200742;;;;"Pro Vagrant teaches you how to effectively implement and optimize Vagrant in your everyday work environment. Master the creation and configuration of virtual development environments with an easy-to-use workflow, and focus on automation. Vagrant lowers development environment setup time, increases development/production parity, and makes the ""works on my machine"" excuse a relic of the past. DevOps is mainstream best practice nowadays, and Vagrant sits firmly in the DevOps toolkit. This book will take you from basic usage and getting started, to provisioning with Shell, Puppet, and Chef. You will see how to use Vagrant in real-life scenarios, so that you can start to use Vagrant day-to-day in your work. Author Wodimierz Gajda is a Vagrant expert and now brings his experience to you in Pro Vagrant. This is an indispensable book for anyone using Vagrant - add it to your library today. What youll learn Get started with Vagrant, basic usage Provisioning with Shell, Puppet, and Chef How to use Vagrant in real-life scenarios Who this book is for This book is for anyone wishing to implement Vagrant as a DevOps tool, to master the creation and configuration of virtual development environments with an easy-to-use workflow, and focus on automation.";;;;
Conference Paper;Shi Z,Farshidi S,Zhou H,Zhao Z;An Auction and Witness Enhanced Trustworthy SLA Model for Decentralized Cloud Marketplaces;;2021;;;109–114;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Conference on Information Technology for Social Good;Roma, Italy;2021;9781450384780;;"https://doi-org.proxy.bnl.lu/10.1145/3462203.3475876;http://dx.doi.org/10.1145/3462203.3475876";10.1145/3462203.3475876;"Cloud computing has become one of the most important technologies that have changed the traditional application development and operation (DevOps) lifecycle. However, current cloud software DevOps often faces the following key challenges: 1) selecting the best fitting service providers, customizing services and planning capacities for large-scale distributed applications; 2) guaranteeing high-quality and trustworthy service level agreements (SLAs) among multiple service providers; 3) enhancing the interoperability of cloud services across providers; 4) designing incentive model effectively among players. In this study, a framework called AWESOME is proposed to build a decentralized cloud marketplace and to address the above challenges. The proposed framework contains four subsystems including a customizable auction model, an incentive witness mechanism, and a social behavior-based simulator as one automated framework. We also provide a proof of concept to demonstrate that the AWESOME framework is feasible.";service level agreement, auction, decentralized cloud marketplace;;;GoodIT '21
Conference Paper;Pourmajidi W,Miranskyy A,Steinbacher J,Erwin T,Godwin D;Dogfooding: Using IBM Cloud Services to Monitor IBM Cloud Infrastructure;;2019;;;344–353;;IBM Corp.;USA;;Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering;Toronto, Ontario, Canada;2019;;;;;The stability and performance of Cloud platforms are essential as they directly impact customers' satisfaction. Cloud service providers use Cloud monitoring tools to ensure that rendered services match the quality of service requirements indicated in established contracts such as service-level agreements.Given the enormous number of resources that need to be monitored, highly scalable and capable monitoring tools are designed and implemented by Cloud service providers such as Amazon, Google, IBM, and Microsoft. Cloud monitoring tools monitor millions of virtual and physical resources and continuously generate logs for each one of them. Considering that logs magnify any technical issue, they can be used for disaster detection, prevention, and recovery. However, logs are useless if they are not assessed and analyzed promptly. Thus, we argue that the scale of Cloud-generated logs makes it impossible for DevOps teams to analyze them effectively. This implies that one needs to automate the process of monitoring and analysis (e.g., using machine learning and artificial intelligence). If the automation will witness an anomaly in the logs --- it will alert DevOps staff.The automatic anomaly detectors require a reliable and scalable platform for gathering, filtering, and transforming the logs, executing the detector models, and sending out the alerts to the DevOps staff. In this work, we report on implementing a prototype of such a platform based on the 7-layered architecture pattern, which leverages micro-service principles to distribute tasks among highly scalable, resources-efficient modules. The modules interact with each other via an instance of the Publish-Subscribe architectural pattern. The platform is deployed on the IBM Cloud service infrastructure and is used to detect anomalies in logs emitted by the IBM Cloud services, hence the dogfooding. In particular, we leverage IBM Cloud Functions to deploy the computing modules, IBM Event Streams to establish communication among the modules, and IBM Cloud Object Storage and IBM Cloudant for persistent storage.The prototype efficiency is promising: it takes the platform 17 seconds or less from the point of receiving a new log record to emitting an alert to the IBM Cloud DevOps team.;;;;CASCON '19
Conference Paper;Wang R;Learning Performance Models Automatically;;2020;;;40–46;;Springer-Verlag;Berlin, Heidelberg;;Service-Oriented Computing – ICSOC 2020 Workshops: AIOps, CFTIC, STRAPS, AI-PA, AI-IOTS, and Satellite Events, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings;Dubai, United Arab Emirates;2020;9783030763510;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-76352-7_6;http://dx.doi.org/10.1007/978-3-030-76352-7_6";10.1007/978-3-030-76352-7_6;To ensure the quality of frequent releases in DevOps context, performance models enable system performance simulation and prediction. However, building performance models for microservice or serverless-based applications in DevOps is costly and error-prone. Thus, we propose to employ model discovery learning for performance models automatically. To generate basic models to represent the application, we first introduce performance-related TOSCA models as architectural models. Then we transform TOSCA models into layered queueing network models. A main challenge of performance model generation is model parametrization. We propose to learn parametric dependencies from monitoring data and systems analysis to capture the relationship between input data and resource demand. With frequent releases of new features, we consider employing detecting parametric dependencies incrementally to keep updating performance models in each iteration.;Model discovery, Model parameterization, Parametric dependencies, Performance models;;;
Conference Paper;Sousa TB,Correia FF,Ferreira HS;Patterns for Software Orchestration on the Cloud;;2015;;;;;The Hillside Group;USA;;Proceedings of the 22nd Conference on Pattern Languages of Programs;Pittsburgh, Pennsylvania;2015;9781941652039;;;;Software businesses are redirecting their expansion towards service-oriented businesses models, highly supported by cloud computing. While cloud computing is not a new research subject, there's a clear lack of documented best practices on how to orchestrate cloud environments, either public, private or hybrid. This paper is targeted at DevOps practitioners and explores solutions for cloud orchestration, describing them as three patterns: a) Software Containerization, providing resource sharing with minimal virtualization overhead, b) Local Reverse Proxy, allowing applications to access any service in a cluster abstracting its placement and c) Orchestration by Resource Offering, ensuring applications get orchestrated in a machine with the required resources to run it. The authors believe that these three DevOps patterns will help researchers and newcomers to cloud orchestration to identify and adopt existing best practices earlier, hence, simplifying software life cycle management.;DevOps patterns, design-patterns, cloud computing;;;PLoP '15
Book;Dash S;Desops: Prepare Today for the Future of Design!;;2018;;;;;Blurb;;;;;2018;9780464682530;;;;DesOps is an approach to design inspired by the culture of DevOps. This book is based on a talk delivered at DevConf India 2018, about the overview of DesOps and how the cultural aspect of the enterprise is important for a DesOps enterprise.;;;;
Journal Article;Khoshkbarforoushha A,Wang M,Ranjan R,Wang L,Alem L,Khan SU,Benatallah B;Dimensions for Evaluating Cloud Resource Orchestration Frameworks;Computer;2016;49;2;24–33;;IEEE Computer Society Press;Washington, DC, USA;;;;2016-02;;0018-9162;"https://doi-org.proxy.bnl.lu/10.1109/MC.2016.56;http://dx.doi.org/10.1109/MC.2016.56";10.1109/MC.2016.56;Despite the proliferation of cloud resource orchestration frameworks (CROFs), DevOps managers and application developers still have no systematic tool for evaluating their features against desired criteria. The authors present generic technical dimensions for analyzing CROF capabilities and understanding prominent research to refine them.;;;;
Conference Paper;Brown K,Woolf B;Implementation Patterns for Microservices Architectures;;2016;;;;;The Hillside Group;USA;;Proceedings of the 23rd Conference on Pattern Languages of Programs;Monticello, Illinois;2016;;;;;Abstract In this paper we describe a set of implementation patterns for building applications using microservices. We discuss the application types and requirements that lead to the need for microservices, examine different types of microservices, and discuss patterns required for implementing data storage and devops in a microservices environment.;agile development, software architectures, pattern languages, microservices;;;PLoP '16
Conference Paper;Steffen B,Howar F,Tegeler T,Steffen B;Agile Business Engineering: From Transformation Towards ContinuousInnovation;;2021;;;77–94;;Springer-Verlag;Berlin, Heidelberg;;Leveraging Applications of Formal Methods, Verification and Validation: 10th International Symposium on Leveraging Applications of Formal Methods, ISoLA 2021, Rhodes, Greece, October 17–29, 2021, Proceedings;Rhodes, Greece;2021;9783030891589;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-89159-6_6;http://dx.doi.org/10.1007/978-3-030-89159-6_6";10.1007/978-3-030-89159-6_6;We discuss how to overcome the often fatal impact of violating integral quality constraints: seemingly successful (software) development projects turn into failures because of a mismatch with the business context. We investigate the similarities and differences between the today popular DevOps scenarios for aligning development and operations and the more general alignment problem concerning software and business engineering based on 33 structured expert interviews. It appears that both scenarios are driven by creativity in a continuous collaboration process relying on continuous goal validation. On the other hand, differences appear when considering Thorngate’s trade-off between accuracy, generality and simplicity: the different level of accuracy is the main hurdle for transferring the automation-driven DevOps technology. The paper closes with the hypothesis that this hurdle may be overcome by increasing the accuracy within the business context using domain-specific languages, a hypothesis supported by the interviews that now needs further confirmation via case studies.;Domain-specific languages, Software engineering, Integral quality constraint, Agile business engineering, DevOps;;;
Conference Paper;Jayaram KR;Towards Explicitly Elastic Programming Frameworks;;2015;;;619–622;;IEEE Press;Florence, Italy;;Proceedings of the 37th International Conference on Software Engineering - Volume 2;;2015;;;;;"It is a widely held view that software engineers should not be ""burdened"" with the responsibility of making their application components elastic; and that elasticity should be either be implicit and automatic in the programming framework; or that it is the responsibility of the cloud provider's operational staff (DevOps) to make distributed applications written for dedicated clusters elastic and execute them on cloud environments.In this paper, we argue the opposite -- we present a case for explicit elasticity, where software engineers are given the flexibility to explicitly engineer elasticity into their distributed applications. We present several scenarios where elasticity retrofitted to applications by DevOps is ineffective, present preliminary empirical evidence that explicit elasticity improves efficiency, and argue for elastic programming languages and frameworks to reduce programmer effort in engineering elastic distributed applications. We also present a bird's eye view of ongoing work on two explicitly elastic programming frameworks -- ElasticThrift (based on Apache Thrift [6]) and ElasticJava, an extension of Java with support for explicit elasticity.";;;;ICSE '15
Journal Article;Dunne J,Malone D;Obscured by the Cloud;J. Syst. Softw.;2017;131;C;218–229;;Elsevier Science Inc.;USA;;;;2017-09;;0164-1212;"https://doi-org.proxy.bnl.lu/10.1016/j.jss.2017.06.022;http://dx.doi.org/10.1016/j.jss.2017.06.022";10.1016/j.jss.2017.06.022;A technique to model inter-arrival and service times of Cloud outages.A novel queue model approach to predict DevOps busy times.An evaluation of our model to demonstrate its effectiveness.A thorough approach to determine inter-arrival and service time correlation.A check for independence concerning overlapping outage events. As Small Medium Enterprises (SMEs) adopt Cloud technologies to provide high value customer offerings, uptime is considered important. Cloud outages represent a challenge to SMEs and micro teams to maintain a services platform. If a Cloud platform suffers from downtime this can have a negative effect on business revenue. Additionally, outages can divert resources from product development/delivery tasks to reactive remediation. These challenges are immediate for SMEs or micro teams with a small levels of resources. In this paper we present a framework that can model the arrival of Cloud outage events. This framework can be used by DevOps teams to manage their scarce pool of resources to resolve outages, thereby minimising impact to service delivery. We analysed over 300 Cloud outage events from an enterprise data set. We modelled the inter-arrival and service times of each outage event and found a Pareto and a lognormal distribution to be a suitable fit. We used this result to produce a special case of the G/G/1 queue system to predict busy times of DevOps personnel. We also investigated dependence between overlapping outage events. Our predictive queuing model compared favourably with observed data, 72% precision was achieved using one million simulations.;Resource allocation model, Outage simulation, Queuing theory, Cloud computing;;;
Journal Article;Biddle R,Brown JM,Greenspan S;From Incident to Insight: Incident Responders and Software Innovation;IEEE Softw.;2019;36;1;56–62;;IEEE Computer Society Press;Washington, DC, USA;;;;2019-01;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2017.442103917;http://dx.doi.org/10.1109/MS.2017.442103917";10.1109/MS.2017.442103917;Over The Last decade, new software processes have appeared that emphasize collaboration among people involved in creating successful software. For example, agile methods stress collaboration between development teams and business clients, 1 and DevOps emphasizes better collaboration between development teams and deployment teams.;;;;
Conference Paper;Zaeske W,Durak U;Leveraging Semi-Formal Approaches for DepDevOps;;2020;;;217–222;;Springer-Verlag;Berlin, Heidelberg;;Computer Safety, Reliability, and Security. SAFECOMP 2020 Workshops: DECSoS 2020, DepDevOps 2020, USDAI 2020, and WAISE 2020, Lisbon, Portugal, September 15, 2020, Proceedings;Lisbon, Portugal;2020;9783030555825;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-55583-2_16;http://dx.doi.org/10.1007/978-3-030-55583-2_16";10.1007/978-3-030-55583-2_16;While formal methods have long been praised by the dependable Cyber-Physical System community, continuous software engineering practices are now employing or promoting semi-formal approaches for achieving lean and agile processes. This paper is a discussion about using Behaviour Driven Development, particularly Gherkin and RSpec for DepDevOps, DevOps for dependable Cyber-Physical Systems.;Semi-formal approaches, Dependable systems, Agile;;;
Conference Paper;Jimenez I,Lofstead J,Maltzahn C;Creating Repeatable, Reusable Experimentation Pipelines with Popper: Tutorial;;2019;;;441–442;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 24th Symposium on Principles and Practice of Parallel Programming;Washington, District of Columbia;2019;9781450362252;;"https://doi-org.proxy.bnl.lu/10.1145/3293883.3302575;http://dx.doi.org/10.1145/3293883.3302575";10.1145/3293883.3302575;Popper is an experimentation protocol for conducting scientific explorations and writing academic articles following a DevOps approach. The Popper CLI tool helps researchers automate the execution and validation of an experimentation pipeline. In this tutorial we give an introduction to the concepts and CLI tool, and go over hands-on exercises that help.;;;;PPoPP '19
Conference Paper;Amaral CJ,Kampik T,Cranefield S;A Framework for Collaborative and Interactive Agent-Oriented Developer Operations;;2020;;;2092–2094;;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;;Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems;Auckland, New Zealand;2020;9781450375184;;;;"Considering the increasing prevalence of autonomous systems in today's society, one could expect that agent-oriented programming (AOP) is gaining traction among mainstream software engineering practitioners. However, the tools and frameworks that are used and developed in the academic multi-agent systems engineering community struggle to keep up with recent developments in the software industry in regards to how complex information systems are developed and maintained. An important aspect of recent changes in software engineering practices is the application of technologies that supports the increasingly fast iteration of a programming-testing-deployment cycle. Such approaches require intense collaboration that crosses boundaries between traditionally separated roles like software development, quality assurance, and operations; these approaches are often referred to as DevOps. Researchers need to explore what additional value AOP has to offer in the context of new paradigms and practices. In this paper, we work towards the integration of DevOps and AOP by introducing an extension of jacamo-web, an Integrated Development Environment (IDE) that supports the collaborative, web-based development and real-time continuous integration of autonomous agents and Multi-Agent Systems (MAS).";iterative software development, ide, engineering multi-agent systems, agent-oriented programming;;;AAMAS '20
Book;Limoncelli TA,Chalup SR,Hogan CJ;The Practice of Cloud System Administration: Designing and Operating Large Distributed Systems, Volume 2;;2014;;;;1st;Addison-Wesley Professional;;;;;2014;9780321943187;;;;"Theres an incredible amount of depth and thinking in the practicesdescribed here, and its impressive to see it all in one place. Win Treese, coauthor of Designing Systems for Internet Commerce The Practice of Cloud System Administration, Volume 2, focuses on distributed or cloud computing and brings a DevOps/SRE sensibility to the practice of system administration. Unsatisfied with books that cover either design or operations in isolation, the authors created this authoritative reference centered on a comprehensive approach. Case studies and examples from Google, Etsy, Twitter, Facebook, Netflix, Amazon, and other industry giants are explained in practical ways that are useful to all enterprises. The new companion to the best-selling first volume, The Practice of System and Network Administration, Second Edition, this guide offers expert coverage of the following and many other crucial topics: Designing and building modern web and distributed systems Fundamentals of large system design Understand the new software engineering implications of cloud administration Make systems that are resilient to failure and grow and scale dynamically Implement DevOps principles and cultural changes IaaS/PaaS/SaaS and virtual platform selection Operating and running systems using the latest DevOps/SRE strategies Upgrade production systems with zero down-time What and how to automate; how to decide what not to automate On-call best practices that improve uptime Why distributed systems require fundamentally different system administration techniques Identify and resolve resiliency problems before they surprise you Assessingand evaluating your teams operational effectiveness Manage thescientific process of continuous improvement A forty-page, pain-free assessment system you can start using today";;;;
Conference Paper;Yuen E,Peters E,Senthilnathan R,Faisal MJ,Hung S;Hands-on: Easy Microservices Application Development with Microclimate;;2018;;;361;;IBM Corp.;USA;;Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering;Markham, Ontario, Canada;2018;;;;;Microclimate is a brand-new, cloud native development environment that offers a complete, end-to-end development experience for Microservices. Since Microclimate has been designed with a focus on containerization, it can run anywhere from your local laptop, to an IBM Cloud private cluster. With Microclimate, you can create or import Java, Node.js, or Swift applications into the development environment, and using any editor of your choosing, you can quickly start development on your application in a containerized environment. Through a process called Rapid Iteration, Microclimate will quickly detect any changes that occur in your project and determine the minimal and best course of action to update your application. From there, using our integrated DevOps pipeline, you can deploy your application with Jenkins to a live ICP cluster. With these features, Microclimate offers a fully featured development experience that many other environments don't offer today. During the hands-on workshop, we will give you an introduction to Microclimate, starting from product installation to write Microservices applications to run on Microclimate in a Docker environment. You will get hands on experiences to create new applications and import existing applications into Microclimate. For developers, a crucial part of the development cycle is the ability to quickly develop and test applications changes on a running application. The develop-deploy-test-repeat cycle must be as short as possible in order to prevent lost developer productivity due to deployment downtime. You will be given the opportunity to experience this rapid iterative development support by developing Java and JavaScript applications in this workshop. Finally, during the workshop we will introduce the integrated DevOps pipeline functions provided that allows you get into production fast with a preconfigured DevOps pipeline and deploy application to IBM Cloud Private (ICP). We will also show you the diagnostic services that helps you to do problem determination in production.;;;;CASCON '18
Journal Article;Sanders S,Border C;Private Cloud Deployment with Docker and Kubernetes;J. Comput. Sci. Coll.;2018;33;3;58–59;;Consortium for Computing Sciences in Colleges;Evansville, IN, USA;;;;2018-01;;1937-4771;;;Automated software development has been a goal of applications developers. Several new technologies are now available to realize that goal. As revealed in a recent study by LinkedIn, Site reliability engineers (SRE) are among the highest paid occupations at $140,000 [11]. They are experts at maintaining infrastructure and web development, as well as pivotal individuals who manage DevOps Engineers.;;;;
Journal Article;Basiri A,Behnam N,de Rooij R,Hochstein L,Kosewski L,Reynolds J,Rosenthal C;Chaos Engineering;IEEE Softw.;2016;33;3;35–41;;IEEE Computer Society Press;Washington, DC, USA;;;;2016-05;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2016.60;http://dx.doi.org/10.1109/MS.2016.60";10.1109/MS.2016.60;Modern software-based services are implemented as distributed systems with complex behavior and failure modes. Many large tech organizations are using experimentation to verify such systems' reliability. Netflix engineers call this approach chaos engineering. They've determined several principles underlying it and have used it to run experiments. This article is part of a theme issue on DevOps.;;;;
Journal Article;Border C;Development of a Configuration Management Course for Computing Operations Students;J. Comput. Sci. Coll.;2020;36;3;89–101;;Consortium for Computing Sciences in Colleges;Evansville, IN, USA;;;;2020-10;;1937-4771;;;"The Operations side of deploying a modern computing application necessarily involves multiple groups working in concert to develop the application and the server side configuration that will support that application. This paper reports on efforts to develop a course that encourages students to dig into issues related to configuration management, security policy development, application auditing, business control issues, and most importantly, team work. While the course is entitled ""Configuration Management"" it is much more about students creating a process for secure iterative application deployment that borrows extensively from the DevOps movement.Ansible, our chosen configuration management tool, is relatively easy to work with at the level of complexity that can be reached in an undergraduate class. What made this class different was the attempt made to create a process that would more closely mimic the Operations side of a DevOps workflow. Initial results from the class were encouraging and many lessons were learned.";;;;
Conference Paper;Theunissen T,Van Heesch U;Specification in Continuous Software Development;;2017;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 22nd European Conference on Pattern Languages of Programs;Irsee, Germany;2017;9781450348485;;"https://doi-org.proxy.bnl.lu/10.1145/3147704.3147709;http://dx.doi.org/10.1145/3147704.3147709";10.1145/3147704.3147709;"The procession of lean, agile and DevOps development processes introduces new challenges and offers new chances regarding software specification and documentation. Challenges for instance because specifications, just like code and applications, are subject to continuous change; chances, because continuous software processes make use of a high degree of automation which also introduces efficient means for specification and documentation.In this paper, we describe the continuous software design specification pattern, which contains guidelines and principles for specification in continuous development processes. In these processes, a software system is an evolution of life cycles where each iteration has a start, continuation and end of defining specifications. Therefore, the pattern explicitly distinguishes specifications to be created at the start of an iteration, specifications during an iteration, and a specification-refactoring at the end of each iteration. Apart from the pattern description, this paper describes the principles of continuous software development derived from lean software development, agile, and DevOps.";Software engineering, Agile, Continuous Development, Lean, DevOps;;;EuroPLoP '17
Book;Watson P;Cucumber With Java: Beginner's Guide;;2016;;;;1st;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2016;9781535323741;;;;This book is for software developers, automation testers, Devops and engineers working on IT project. Whether you are a beginner or an experienced developer, this book will help you master the skills on Cucumber. The book starts with introduction of Cucumber and then dives into key concepts like creating project in IntelliJ IDEA, using tags, plugins, integration with Junit, executing selenium tests, using picocontainer and lamda expressions.;;;;
Conference Paper;Papamichail M,Diamantopoulos T,Matsoukas V,Athanasiadis C,Symeonidis A;Towards Extracting the Role and Behavior of Contributors in Open-Source Projects;;2019;;;536–543;;SCITEPRESS - Science and Technology Publications, Lda;Setubal, PRT;;Proceedings of the 14th International Conference on Software Technologies;Prague, Czech Republic;2019;9789897583797;;"https://doi-org.proxy.bnl.lu/10.5220/0007966505360543;http://dx.doi.org/10.5220/0007966505360543";10.5220/0007966505360543;Lately, the popular open source paradigm and the adoption of agile methodologies have changed the way software is developed. Effective collaboration within software teams has become crucial for building successful products. In this context, harnessing the data available in online code hosting facilities can help towards understanding how teams work and optimizing the development process. Although there are several approaches that mine contributions data, they usually view contributors as a uniform body of engineers, and focus mainly on the aspect of productivity while neglecting the quality of the work performed. In this work, we design a methodology for identifying engineer roles in development teams and determine the behaviors that prevail for each role. Using a dataset of GitHub projects, we perform clustering against the DevOps axis, thus identifying three roles: developers that are mainly preoccupied with code commits, operations engineers that focus on task assignment and acceptance testing, and the lately popular role of DevOps engineers that are a mix of both. Our analysis further extracts behavioral patterns for each role, this way assisting team leaders in knowing their team and effectively directing responsibilities to achieve optimal workload balancing and task allocation.;GitHub Contributions, Developer Role Identification, Developer Behavior Extraction, DevOps, Agile.;;;ICSOFT 2019
Conference Paper;Czarnecki K;Software Engineering for Automated Vehicles: Addressing the Needs of Cars That Run on Software and Data;;2019;;;6–8;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-Companion.2019.00024;http://dx.doi.org/10.1109/ICSE-Companion.2019.00024";10.1109/ICSE-Companion.2019.00024;Automated vehicles are AI-based safety-critical robots that fulfill transportation needs while interacting with the general public in traffic. Software engineering for automated vehicles requires a DevOps-style process with special considerations for functions based on machine learning and incremental safety assurance at vehicle and fleet level. This technical briefing reviews current challenges, industry practices, and opportunities for future research in software engineering for automated vehicles.;;;;ICSE '19
Journal Article;Limoncelli TA;The Small Batches Principle: Reducing Waste, Encouraging Experimentation, and Making Everyone Happy;Queue;2016;14;2;24–41;;Association for Computing Machinery;New York, NY, USA;;;;2016-04;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/2927299.2945077;http://dx.doi.org/10.1145/2927299.2945077";10.1145/2927299.2945077;The small batches principle is part of the DevOps methodology. It comes from the lean manufacturing movement, which is often called just-in-time manufacturing. It can be applied to just about any kind of process. It also enables the MVP (minimum viable product) methodology, which involves launching a small version of a service to get early feedback that informs the decisions made later in the project.;;;;
Book;Watson P;Git - Version Control System: Beginner's Guide;;2016;;;;1st;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2016;9781535096324;;;;This book is for software developers, automation testers, Devops and engineers working on IT project. Whether you are a beginner or an experienced developer, this book will help you master the skills on Git. The book starts with introduction of Git and then dives into key concepts like Branching and merging, resolving conflicts, pushing and pulling to remote repositories and integration with Intelli J IDEA.;;;;
Journal Article;Carter K;Francois Raynaud on DevSecOps;IEEE Softw.;2017;34;5;93–96;;IEEE Computer Society Press;Washington, DC, USA;;;;2017-01;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2017.3571578;http://dx.doi.org/10.1109/MS.2017.3571578";10.1109/MS.2017.3571578;Host Kim Carter talks with Francois Raynaud about how to easily apply DevOps principles to security, and how this helps improve the relationship between security and development teams and ultimately the success of a product or business. The full podcast of this interview is at www.se-radio.net/2017/04/se-radio-episode-288-devsecops.;;;;
Book;Brikman Y;Terraform: Up and Running Writing Infrastructure as Code;;2017;;;;1st;O'Reilly Media, Inc.;;;;;2017;9781491977088;;;;Terraform has emerged as a key player in the DevOps world for defining, launching, and managing infrastructure as code (IAC) across a variety of cloud and virtualization platforms, including AWS, Google Cloud, and Azure. This hands-on book is the fastest way to get up and running with Terraform. Gruntwork co-founder Yevgeniy (Jim) Brikman walks you through dozens of code examples that demonstrate how to use Terraforms simple, declarative programming language to deploy and manage infrastructure with just a few commands. Whether youre a novice developer, aspiring DevOps engineer, or veteran sysadmin, this book will take you from Terraform basics to running a full tech stack capable of supporting a massive amount of traffic and a large team of developers. Compare Terraform to other IAC tools, such as Chef, Puppet, Ansible, and Salt Stack Use Terraform to deploy server clusters, load balancers, and databases Learn how Terraform manages the state of your infrastructure and how it impacts file layout, isolation, and locking Create reusable infrastructure with Terraform modules Try out advanced Terraform syntax to implement loops, if-statements, and zero-downtime deployment Use Terraform as a team, including best practices for writing, testing, and versioning Terraform code;;;;
Conference Paper;Rademacher F,Sorgalla J,Sachweh S,Zündorf A;A Model-Driven Workflow for Distributed Microservice Development;;2019;;;1260–1262;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing;Limassol, Cyprus;2019;9781450359337;;"https://doi-org.proxy.bnl.lu/10.1145/3297280.3300182;http://dx.doi.org/10.1145/3297280.3300182";10.1145/3297280.3300182;Model-driven Development (MDD) is a software engineering approach that abstracts a software's design leveraging models. In particular, the development of complex, service-based architectures is considered to benefit from MDD techniques like model validation, transformation, and code generation. This paper presents an MDD-based workflow for distributed, DevOps-based microservice development and identifies the involved model types. They provide the foundation for the subsequent development of modeling languages to employ MDD for MSA engineering.;modeling languages, microservice architecture, viewpoint modeling, model-driven microservice development, distributed microservice development;;;SAC '19
Conference Paper;Daoudagh S,Lonetti F,Marchetti E;Continuous Development and Testing of Access and Usage Control: A Systematic Literature Review;;2020;;;51–59;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2020 European Symposium on Software Engineering;Rome, Italy;2020;9781450377621;;"https://doi-org.proxy.bnl.lu/10.1145/3393822.3432330;http://dx.doi.org/10.1145/3393822.3432330";10.1145/3393822.3432330;Context: Development and testing of access/usage control systems is a growing research area. With new trends in software development such as DevOps, the development of access/usage control also has to evolve. Objective: The main aim of this paper is to provide an overview of research proposals in the area of continuous development and testing of access and usage control systems. Method: The paper uses a Systematic Literature Review as a research method to define the research questions and answer them following a systematic approach. With the specified search string, 210 studies were retrieved. After applying the inclusion and exclusion criteria in two phases, a final set of 20 primary studies was selected for this review. Results: Results show that primary studies are mostly published in security venues followed by software engineering venues. Furthermore, most of the studies are based on the standard XACML access control language. In addition, a significant portion of the proposals for development and testing is automated with test assessment and generation the most targeted areas. Some general guidelines for leveraging continuous developing and testing of the usage and access control systems inside the DevOps process are also provided.;Testing, Systematic Literature Review, Access Control, DevOps, XACML;;;ESSE 2020
Conference Paper;Erich F,Amrit C,Daneva M;Cooperation between Information System Development and Operations: A Literature Review;;2014;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Torino, Italy;2014;9781450327749;;"https://doi-org.proxy.bnl.lu/10.1145/2652524.2652598;http://dx.doi.org/10.1145/2652524.2652598";10.1145/2652524.2652598;Software development can profit from improvements in the deployment and maintenance phases. DevOps improves these phases through a collection of principles and practices, centered around close collaboration between Development and Operations personnel. Both sides have paid little attention to issues faced by each other. Yet knowledge sharing is invaluable. Development personnel can for example make software more robust by implementing scalability and performance features desired by operations personnel.;continuous delivery, sharing, culture, measurement, operations, automation, cloud computing, services, DevOps, development, service oriented architecture;;;ESEM '14
Conference Paper;Charpentier E,Delima N,Mah J,Pape D,Yuen V;Build, Deploy and Administer Microservices Using Kubernetes and IBM Cloud API Management;;2019;;;391–392;;IBM Corp.;USA;;Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering;Toronto, Ontario, Canada;2019;;;;;In recent years companies have increased their adoption of cloud computing not just to improve IT operational efficiencies but also to drive growth through business innovation and gain a competitive advantage. Legacy applications are being modernized to run in cloud environments and new cloud native applications with enhanced artificial intelligence are being developed. Microservices, containers and DevOps are at the core of application modernization and cloud native application development.;;;;CASCON '19
Journal Article;Li Y,Jiang ZM,Li H,Hassan AE,He C,Huang R,Zeng Z,Wang M,Chen P;Predicting Node Failures in an Ultra-Large-Scale Cloud Computing Platform: An AIOps Solution;ACM Trans. Softw. Eng. Methodol.;2020;29;2;;;Association for Computing Machinery;New York, NY, USA;;;;2020-04;;1049-331X;"https://doi-org.proxy.bnl.lu/10.1145/3385187;http://dx.doi.org/10.1145/3385187";10.1145/3385187;Many software services today are hosted on cloud computing platforms, such as Amazon EC2, due to many benefits like reduced operational costs. However, node failures in these platforms can impact the availability of their hosted services and potentially lead to large financial losses. Predicting node failures before they actually occur is crucial, as it enables DevOps engineers to minimize their impact by performing preventative actions. However, such predictions are hard due to many challenges like the enormous size of the monitoring data and the complexity of the failure symptoms. AIOps (Artificial Intelligence for IT Operations), a recently introduced approach in DevOps, leverages data analytics and machine learning to improve the quality of computing platforms in a cost-effective manner. However, the successful adoption of such AIOps solutions requires much more than a top-performing machine learning model. Instead, AIOps solutions must be trustable, interpretable, maintainable, scalable, and evaluated in context. To cope with these challenges, in this article we report our process of building an AIOps solution for predicting node failures for an ultra-large-scale cloud computing platform at Alibaba. We expect our experiences to be of value to researchers and practitioners, who are interested in building and maintaining AIOps solutions for large-scale cloud computing platforms.;AIOps, ultra-large-scale platforms, cloud computing, failure prediction;;;
Journal Article;Limoncelli TA;10 Optimizations on Linear Search: The Operations Side of the Story;Queue;2016;14;4;20–33;;Association for Computing Machinery;New York, NY, USA;;;;2016-08;;1542-7730;"https://doi-org.proxy.bnl.lu/10.1145/2984629.2984631;http://dx.doi.org/10.1145/2984629.2984631";10.1145/2984629.2984631;System administrators (DevOps engineers or SREs or whatever your title) must deal with the operational aspects of computation, not just the theoretical aspects. Operations is where the rubber hits the road. As a result, operations people see things from a different perspective and can realize opportunities outside of the basic O() analysis. Let’s look at the operational aspects of the problem of trying to improve something that is theoretically optimal already.;;;;
Conference Paper;Román Portabales A,Nores ML;Dockemu: Extension of a Scalable Network Simulation Framework Based on Docker and NS3 to Cover IoT Scenarios;;2018;;;175–182;;SCITEPRESS - Science and Technology Publications, Lda;Setubal, PRT;;Proceedings of 8th International Conference on Simulation and Modeling Methodologies, Technologies and Applications;Porto, Portugal;2018;9789897583230;;"https://doi-org.proxy.bnl.lu/10.5220/0006913601750182;http://dx.doi.org/10.5220/0006913601750182";10.5220/0006913601750182;The purpose of this project was to extend an existing open-source simulation framework called Dockemu in order to make it suitable to perform IoT simulations. The work covered some improvements with goes from the support of more network technologies to the use of setup and deployment tools used by modern devops professionals. The paper explains the architecture, the newly-added features and the specific advantages it offers for research works in IoT network simulations.;ns-3 Network Simulation Docker Real-time Containers.;;;SIMULTECH 2018
Conference Paper;Syed MH,Fernandez EB;The Software Container Pattern;;2015;;;;;The Hillside Group;USA;;Proceedings of the 22nd Conference on Pattern Languages of Programs;Pittsburgh, Pennsylvania;2015;9781941652039;;;;A Software Container provides an execution environment for applications sharing a host operating system, binaries, and libraries with other containers with strong isolation between them. Software containers although not new, have become very important to support convenient, secure, and low overhead applications. Containers facilitate application deployment and distribution across computing environments. We present a pattern for a Software Containers which describes advantages and liabilities of the container in addition to examples of existing solutions. Containers have made a significant difference in supporting agile development frameworks like DevOps.;architecture patterns, security, security patterns, software containers, virtualization;;;PLoP '15
Conference Paper;Bass L,Jeffery R,Wada H,Weber I,Zhu L;Eliciting Operations Requirements for Applications;;2013;;;5–8;;IEEE Press;San Francisco, California;;Proceedings of the 1st International Workshop on Release Engineering;;2013;9781467364416;;;;"The DevOps community advocates communication between the operations staff and the development staff as a means of ensuring that the developers understand the issues associated with operations. This paper argues that ""communication"" is too vague and that there are a variety of specific and well known sources that developers can examine to determine requirements to support the installation and operations of an application product. These sources include standards, process descriptions, studies about sources of failure in configuration and upgrade, and models that include both product and process.";devops, operations processes, applications requirements;;;RELENG '13
Conference Paper;Sheridan C,Whigham D,Artač M;DICE Fault Injection Tool;;2016;;;36–37;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2nd International Workshop on Quality-Aware DevOps;Saarbrücken, Germany;2016;9781450344111;;"https://doi-org.proxy.bnl.lu/10.1145/2945408.2945415;http://dx.doi.org/10.1145/2945408.2945415";10.1145/2945408.2945415;In this paper, we describe the motivation, innovation, design, running example and future development of a Fault Inject Tool (FIT). This tool enables controlled causing of cloud platform issues such as resource stress and service or VM outages, the purpose being to observe the subsequent effect on deployed applications. It is being designed for use in a DevOps workflow for tighter correlation between application design and cloud operation, although not limited to this usage, and helps improve resiliency for data intensive applications by bringing together fault tolerance, stress testing and benchmarking in a single tool.;fault injection cloud IaaS DevOps quality driven tolerance;;;QUDOS 2016
Book;S. SK;Practical LXC and LXD: Linux Containers for Virtualization and Orchestration;;2017;;;;1st;Apress;USA;;;;2017;9781484230237;;;;Use Linux containers as an alternative virtualization technique to virtualize your operating system environment. This book will cover LXCs unmatched flexibility with virtualization and LXDs smooth user experience. Practical LXC and LXD begins by introducing you to Linux containers (LXC and LXD). You will then go through use cases based on LXC and LXD. Next, you will see the internal workings of LXC and LXD by considering the repositories and templates used. You will then learn how to integrate LXC and LXD with common virtualization and orchestration tools such as libvirt and SaltStack. Finally, you will dive into containerization and security. The book will explore some of the common problems in security and provide a case study on how containerization can help mitigate some of the operating system-level security issues in an IoT environment. What You Will LearnGet an introduction to Linux containers Discover the basics of LXC and LXD See use cases that can be solved with LXC and LXD for developers, devops, and system administrators Master LXC and LXD repositories Use LXC and LXD with common virtualization and orchestration tools Consider a containerization and security in IoT case study Who This Book Is ForThe audience for this book should have basic knowledge of Linux and software development in general. The intended readership is primarily software developers, operations engineers, and system administrators who are interested in devops, though managers and enthusiasts will also benefit from this book.;;;;
Journal Article;Spinellis D;Package Management Systems;IEEE Softw.;2012;29;2;84–86;;IEEE Computer Society Press;Washington, DC, USA;;;;2012-03;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2012.38;http://dx.doi.org/10.1109/MS.2012.38";10.1109/MS.2012.38;A package management system organizes and simplifies the installation and maintenance of software by standardizing and organizing the production and consumption of software collections. As a software developer, you can benefit from package managers in two ways: through a rich and stable development environment and through friction-free reuse.Promisingly, the structure that package managers bring both to the tools we use in our development process and the libraries we reuse in our products ties nicely with the recent move emphasizing DevOps (development operations) as an integration between software development and IT operations.;package management system, shared library, software reuse, DevOps, module dependencies;;;
Book;Das S,Modi J;AWS Networking Cookbook: Powerful Recipes to Overcome the Pain Points of Optimizing Your Virtual Private Cloud (VPC);;2017;;;;;Packt Publishing;;;;;2017;9781787123243;;;;Key FeaturesMaster AWS networking concepts with AWS Networking Cookbook. Design and implement highly available connectivity and multi-regioned AWS solutionsA recipe-based guide that will eliminate the complications of AWS networking. A guide to automate networking services and featuresBook DescriptionThis book starts with practical recipes on the fundamentals of cloud networking and gradually moves on to configuring networks and implementing infrastructure automation. This book then supplies in-depth recipes on networking components like Network Interface, Internet Gateways, DNS, Elastic IP addresses, and VPN CloudHub. Later, this book also delves into designing, implementing, and optimizing static and dynamic routing architectures, multi-region solutions, and highly available connectivity for your enterprise. Finally, this book will teach you to troubleshoot your VPC's network, increasing your VPC's efficiency. By the end of this book, you will have advanced knowledge of AWS networking concepts and technologies and will have mastered implementing infrastructure automation and optimizing your VPC. What you will learnCreate basic network in AWS Create production grade network in AWSCreate global scale network in AWS Security and Compliance with AWS Network Troubleshooting, best practices and limitations of AWS network Pricing model of AWS network components Route 53 and Cloudfront concepts and routing policies VPC Automation using Ansible and Cloud Formation About the AuthorSatyajit Das has more than sixteen years of IT experience. He is currently working as an AWS CoE lead cloud architect in a large enterprise. He has also worked as an enterprise architect, solution architect, and technical architect in recent engagements. He has guided, designed, integrated, implemented, and governed enterprise-grade applications. He works on building solutions using microservices on the hybrid cloud using DevOps principles. He has extensively worked on IoT, AWS, and cloud migration. Satyajit has worked in leading organizations, such as Wipro, Infosys, PwC, and Accenture, in various challenging roles. Jhalak Modi is a DevOps, cloud architect, and an AWS trainer with a deep interest and expertise in implementing multi-tier architectures, cluster platforms, and automation solutions. She is an AWS certified solutions architect professional and a certified DevOps professional with 10+ certifications in trending technologies. Jhalak is also a public speaker at various AWS events, colleges/universities, and meet-ups, and has provided AWS and Linux training at several renowned institutes and corporates. Currently, she is working with KOGENTiX and has worked with Wipro Technologies and Electromech Corporation in the past.;;;;
Conference Paper;Dittrich Y,Nørbjerg J,Tell P,Bendix L;Researching Cooperation and Communication in Continuous Software Engineering;;2018;;;87–90;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 11th International Workshop on Cooperative and Human Aspects of Software Engineering;Gothenburg, Sweden;2018;9781450357258;;"https://doi-org.proxy.bnl.lu/10.1145/3195836.3195856;http://dx.doi.org/10.1145/3195836.3195856";10.1145/3195836.3195856;Continuous Software Engineering (CSE)---continuous development and deployment of software---and DevOps---the close cooperation or integration of operations and software development---is about to change how software is developed. Together with the tighter integration of development and operations also with usage this will change coordination and collaboration both between IT professionals and between developers and users. In this short paper, we discuss the CHASE dimension of three core research themes that begin to crystallize in literature. This position paper is intended as a 'call to arms' for the CHASE community to study CSE.;continuous software engineering, devops;;;CHASE '18
Conference Paper;Gias AU,van Hoorn A,Zhu L,Casale G,Düllmann TF,Wurster M;Performance Engineering for Microservices and Serverless Applications: The RADON Approach;;2020;;;46–49;;Association for Computing Machinery;New York, NY, USA;;Companion of the ACM/SPEC International Conference on Performance Engineering;Edmonton AB, Canada;2020;9781450371094;;"https://doi-org.proxy.bnl.lu/10.1145/3375555.3383120;http://dx.doi.org/10.1145/3375555.3383120";10.1145/3375555.3383120;Microservices and serverless functions are becoming integral parts of modern cloud-based applications. Tailored performance engineering is needed for assuring that the applications meet their requirements for quality attributes such as timeliness, resource efficiency, and elasticity. A novel DevOps-based framework for developing microservices and serverless applications is being developed in the RADON project. RADON contributes to performance engineering by including novel approaches for modeling, deployment optimization, testing, and runtime management. This paper summarizes the contents of our tutorial presented at the 11th ACM/SPEC International Conference on Performance Engineering (ICPE).;performance engineering, microservices, serverless;;;ICPE '20
Book;Williamson L,Barcia R,Chandgadkar O,Mathur A,Ray S,Schrag D,Snook R;Enterprise Class Mobile Application Development: A Complete Lifecycle Approach for Producing Mobile Apps;;2015;;;;1st;IBM Press;;;;;2015;9780133478631;;;;Build and Deploy Mobile Business Apps That Smoothly Integrate with Enterprise IT For todays enterprises, mobile apps can have a truly transformational impact. However, to maximize their value, you cant build them in isolation. Your new mobile apps must reflect the revolutionary mobile paradigm and delight todays mobile users--but they must also integrate smoothly with existing systems and leverage previous generations of IT investment. In this guide, a team of IBMs leading experts show how to meet all these goals. Drawing on extensive experience with pioneering enterprise clients, they cover every facet of planning, building, integrating, and deploying mobile apps in large-scale production environments. Youll find proven advice and best practices for architecture, cloud integration, security, user experience, coding, testing, and much more. Each chapter can stand alone to help you solve specific real-world problems. Together, they help you establish a flow of DevOps activities and lifecycle processes fully optimized for enterprise mobility. Coverage Includes How mobile applications motivate business innovation--and why they present unique challenges for enterprise IT Understanding how the enterprise mobile app lifecycle resembles and differs from conventional development Designing mobile business apps that delight their users Choosing more effective mobile development techniques, languages, and architectural approaches Optimizing linkages between mobile front-ends and enterprise back-end systems Testing for complex, constantly changing device environments Practicing DevOps to accelerate and increase value, from ideation to delivery;;;;
Journal Article;Tamburri DA,Kazman R,Fahimi H;The Architect's Role in Community Shepherding;IEEE Softw.;2016;33;6;70–79;;IEEE Computer Society Press;Washington, DC, USA;;;;2016-11;;0740-7459;"https://doi-org.proxy.bnl.lu/10.1109/MS.2016.144;http://dx.doi.org/10.1109/MS.2016.144";10.1109/MS.2016.144;"Software architects don't just design architecture components or champion architecture qualities; they often must guide and harmonize the entire community of project stakeholders. The community-shepherding aspects of the architect's role have been gaining attention, given the increasing importance of complex ""organizational rewiring"" scenarios such as DevOps, open source strategies, transitions to agile development, and corporate acquisitions. In these scenarios, architects would benefit by having effective models to align communities with architectures. This article discusses the ""smells"" indicating that a community isn't functioning efficiently, offers a set of mitigations for those smells, and provides an overview of community types.";;;;
Conference Paper;Theunissen T,Overbeek S,Hoppenbrouwers S;Continuous Learning with the Sandwich of Happiness and Result Planning;;2021;;;;;Association for Computing Machinery;New York, NY, USA;;26th European Conference on Pattern Languages of Programs;Graz, Austria;2021;9781450389976;;"https://doi-org.proxy.bnl.lu/10.1145/3489449.3489974;http://dx.doi.org/10.1145/3489449.3489974";10.1145/3489449.3489974;With an increase in fast time-to-market and keeping up with fast mandatory legal changes, we observe a demand for continuous software development which is reflected by the emergence of Lean, Agile, and DevOps approaches. At the same time, we observe the phenomenon of lifelong learning that is both manifest and propagated by government, industry, and education. We introduce two patterns that match these two phenomena: the Sandwich of Happiness and Result Planning. Together, these patterns support learning for students in an educational setting and continuous learning for professionals in industry, especially in the context of Continuous Software Development.;Agile, Continuous Learning, Continuous Software Development, Result Planning, Documentation, Sandwich of Happiness;;;EuroPLoP'21
Conference Paper;Lohrasbinasab I,Acharya PB,Colomo-Palacios R;BizDevOps: A Multivocal Literature Review;;2020;;;698–713;;Springer-Verlag;Berlin, Heidelberg;;Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part VI;Cagliari, Italy;2020;9783030588168;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-58817-5_50;http://dx.doi.org/10.1007/978-3-030-58817-5_50";10.1007/978-3-030-58817-5_50;BizDevOps as an extension of DevOps, reinforces the collaboration between business, development, and operation stakeholders in the organization in order to enhance the software cycle. While BizDevOps has not yet received much attention in academic circles, it has gained considerable prestige in the industry area. This situation reflects a gap between theory and practice in this context. In this work and by means of a Multivocal Literature Review authors gather visions from both academic and industry spheres on the topic. The result is a gathered image of BizDevOps, including definition, characteristics, related motivating issues, and potential challenges and benefits.;Multivocal literature review, BizDevOps, DevOps 2.0;;;
Book;Watson MP;Appium in Java: Beginner's Guide;;2016;;;;1st;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2016;9781536818635;;;;This book is for software developers, automation testers, Devops and engineers working on IT project. Whether you are a beginner or an experienced developer, this book will help you master the skills on Appium. The book starts with introduction of Appium and then dives into key concepts like creating appium project in IntelliJ IDEA, automating the native, hybrid and web Android as well as iOS applications. The book also covers advanced gestures like swiping, zooming, pinching, tapping operations as well. Book also covers how you can run your test on virtual devices as well as real phones.;;;;
Conference Paper;Castanheira L,Benson TA,Schaeffer-Filho A;The Case for More Flexible Distributed Tracing;;2020;;;27–28;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Student Workshop;Barcelona, Spain;2020;9781450381833;;"https://doi-org.proxy.bnl.lu/10.1145/3426746.3434058;http://dx.doi.org/10.1145/3426746.3434058";10.1145/3426746.3434058;Distributed tracing has been widely adopted as a means to troubleshoot distributed systems in which traditional, device-centric debugging loses traction. However, the debugging capabilities of tracing are underused today because of the immutable nature of tracing instrumentation. Additionally, current tracing solutions do not address in-network compute, and hence cannot be considered end-to-end.We argue for a new tracing workflow in which tracing instrumentation is made more flexible, allowing DevOps to use a query language to specify tracing tasks for computation happening both on x86 servers and network devices.;;;;CoNEXT'20
Conference Paper;Tegeler T,Teumert S,Schürmann J,Bainczyk A,Busch D,Steffen B;An Introduction to Graphical Modeling of CI/CD Workflows with Rig;;2021;;;3–17;;Springer-Verlag;Berlin, Heidelberg;;Leveraging Applications of Formal Methods, Verification and Validation: 10th International Symposium on Leveraging Applications of Formal Methods, ISoLA 2021, Rhodes, Greece, October 17–29, 2021, Proceedings;Rhodes, Greece;2021;9783030891589;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-89159-6_1;http://dx.doi.org/10.1007/978-3-030-89159-6_1";10.1007/978-3-030-89159-6_1;We present an introduction to the usage of Rig, our Cinco product for the graphical modeling of CI/CD workflows. While CI/CD has become a de facto standard in modern software engineering (e.g. DevOps) and the benefits of its practice are without a doubt, developers are still facing inconvenient solutions. We will briefly outline the basic concept of CI/CD and discuss the challenges involved in maintaining such workflows with current implementations before we explain and illustrate the advantages of our model-driven approach step by step along on the treatment of a typical web application.;Software engineering, Purpose-Specific Language, Domain-specific tools, Continuous Integration and Deployment, DevOps, Language-driven engineering, Graphical modeling;;;
Journal Article;Van Rossem S,Tavernier W,Colle D,Pickavet M,Demeester P;Introducing Development Features for Virtualized Network Services;Comm. Mag.;2018;56;8;184–192;;IEEE Press;;;;;2018-08;;0163-6804;"https://doi-org.proxy.bnl.lu/10.1109/MCOM.2018.1600104;http://dx.doi.org/10.1109/MCOM.2018.1600104";10.1109/MCOM.2018.1600104;Network virtualization and softwarizing network functions are trends aiming at higher network efficiency, cost reduction and agility. They are driven by the evolution in Software Defined Networking (SDN) and Network Function Virtualization (NFV). This shows that software will play an increasingly important role within telecommunication services, which were previously dominated by hardware appliances. Service providers can benefit from this, as it enables faster introduction of new telecom services, combined with an agile set of possibilities to optimize and fine-tune their operations. However, the provided telecom services can only evolve if the adequate software tools are available. In this article, we explain how the development, deployment and maintenance of such an SDN/NFV-based telecom service puts specific requirements on the platform providing it. A Software Development Kit (SDK) is introduced, allowing service providers to adequately design, test and evaluate services before they are deployed in production and also update them during their lifetime. This continuous cycle between development and operations, a concept known as DevOps, is a well known strategy in software development. To extend its context further to SDN/NFV-based services, the functionalities provided by traditional cloud platforms are not yet sufficient. By giving an overview of the currently available tools and their limitations, the gaps in DevOps for SDN/NFV services are highlighted. The benefit of such an SDK is illustrated by a secure content delivery network service (enhanced with deep packet inspection and elastic routing capabilities). With this use-case, the dynamics between developing and deploying a service are further illustrated.;;;;
Journal Article;Dipietro S;Performance Modelling and Optimisation of NoSQL Database Systems;SIGMETRICS Perform. Eval. Rev.;2020;47;3;10–13;;Association for Computing Machinery;New York, NY, USA;;;;2020-01;;0163-5999;"https://doi-org.proxy.bnl.lu/10.1145/3380908.3380912;http://dx.doi.org/10.1145/3380908.3380912";10.1145/3380908.3380912;Salvatore Dipietro is a final-year PhD candidate in Computing at Imperial College London. His current research focus is on performance modelling and optimization of NoSQL database systems. His work is supported by HiPEDS centre for doctoral training, funded by EPSRC. Before the PhD, Salvatore completed his MRes in Advance computing at Imperial College London (2015) and his MSc in computer security and forensics at Bedfordshire University (2013). Earlier he gained his undergraduate degree in computing engineering at Politecnico di Torino (2012). Besides, he also has extensive professional work experience as Cloud and DevOps engineer. His interest lies in performance and optimization, capacity planning, distributed applications and network security.;;;;
Conference Paper;Fox GC,Qiu J,Kamburugamuve S,Jha S,Luckow A;HPC-ABDS High Performance Computing Enhanced Apache Big Data Stack;;2015;;;1057–1066;;IEEE Press;Shenzhen, China;;Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing;;2015;9781479980062;;"https://doi-org.proxy.bnl.lu/10.1109/CCGrid.2015.122;http://dx.doi.org/10.1109/CCGrid.2015.122";10.1109/CCGrid.2015.122;We review the High Performance Computing Enhanced Apache Big Data Stack HPC-ABDS and summarize the capabilities in 21 identified architecture layers. These cover Message and Data Protocols, Distributed Coordination, Security & Privacy, Monitoring, Infrastructure Management, DevOps, Interoperability, File Systems, Cluster & Resource management, Data Transport, File management, NoSQL, SQL (NewSQL), Extraction Tools, Object-relational mapping, In-memory caching and databases, Inter-process Communication, Batch Programming model and Runtime, Stream Processing, High-level Programming, Application Hosting and PaaS, Libraries and Applications, Workflow and Orchestration. We summarize status of these layers focusing on issues of importance for data analytics. We highlight areas where HPC and ABDS have good opportunities for integration.;apache big data stack, HPC;;;CCGRID '15
Journal Article;Ferry N,Chauvel F,Song H,Rossini A,Lushpenko M,Solberg A;CloudMF: Model-Driven Management of Multi-Cloud Applications;ACM Trans. Internet Technol.;2018;18;2;;;Association for Computing Machinery;New York, NY, USA;;;;2018-01;;1533-5399;"https://doi-org.proxy.bnl.lu/10.1145/3125621;http://dx.doi.org/10.1145/3125621";10.1145/3125621;While the number of cloud solutions is continuously increasing, the development and operation of large-scale and distributed cloud applications are still challenging. A major challenge is the lack of interoperability between the existing cloud solutions, which increases the complexity of maintaining and evolving complex applications potentially deployed across multiple cloud infrastructures and platforms. In this article, we show how the Cloud Modelling Framework leverages model-driven engineering and supports the DevOps ideas to tame this complexity by providing: (i) a domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for their continuous provisioning, deployment, and adaptation.;models@run-time, Cloud computing, DevOps, multi-cloud, model-driven engineering;;;
Book;Jackson K,Bunch C;OpenStack Cloud Computing Cookbook;;2013;;;;2nd;Packt Publishing;;;;;2013;9781782167587;;;;Over 100 recipes to successfully set up and manage your OpenStack cloud environments with complete coverage of Nova, Swift, Keystone, Glance, Horizon, Neutron, and Cinder Overview Updated for OpenStack Grizzly Learn how to install, configure, and manage all of the OpenStack core projects including new topics like block storage and software defined networking Learn how to build your Private Cloud utilizing DevOps and Continuous Integration tools and techniques In Detail OpenStack is an open source cloud operating stack that was born from Rackspace and NASA and became a global success, developed by scores of people around the globe and backed by some of the leading players in the cloud space today. OpenStack Cloud Computing Cookbook, Second Edition will show you exactly how to install the components that are required to make up a private cloud environment. You will learn how to set up an environment that you manage just as you would a public cloud provider like Rackspace with the help of experienced OpenStack administrators and architects. We begin by configuring the key components such as identity, image compute, and storage in a safe, virtual environment that we will then build on this throughout the book. The book will also teach you about provisioning and managing OpenStack in the datacenter using proven DevOps tools and techniques. From installing or creating a sandbox environment using Vagrant and VirtualBox to installing OpenStack in the datacenter, from understanding logging to automating OpenStack installations, whatever level of experience or interest you have with OpenStack there is a chapter for you. Installation steps cover compute, object storage, identity, block storage volumes, image, horizon, software defined networking and DevOps tools for automating your infrastructure OpenStack Cloud Computing Cookbook, Second edition gives you clear step-by-step instructions to installing and running your own private cloud. What you will learn from this book Understand, install, configure, and manage Nova, the OpenStack cloud compute resource Dive headfirst into managing software defined networks with the OpenStack networking project and Open vSwitch Install and configure, Keystone, the OpenStack identity & authentication service Install, configure and operate the OpenStack block storage project: Neutron Install and manage Swift, the highly scalable OpenStack object storage service Gain hands on experience with the OpenStack dashboard Horizon Explore different monitoring frameworks to ensure your OpenStack cloud is always online and performing optimally Automate your installations using Vagrant and Chef. Create custom Windows and Linux images for use in your private cloud environment. Approach OpenStack Cloud Computing Cookbook Second Edition will give you clear step-by-step instructions to installing and running your own private cloud successfully. It is full of practical and applicable recipes that enable you to use the latest capabilities of OpenStack and implement them. The book explains every step in detail so that you can build your knowledge about how things work.;;;;
Conference Paper;Kroß J,Willnecker F,Zwickl T,Krcmar H;PET: Continuous Performance Evaluation Tool;;2016;;;42–43;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2nd International Workshop on Quality-Aware DevOps;Saarbrücken, Germany;2016;9781450344111;;"https://doi-org.proxy.bnl.lu/10.1145/2945408.2945418;http://dx.doi.org/10.1145/2945408.2945418";10.1145/2945408.2945418;Performance measurements and simulations produce large amounts of data in a short period of time. Release cycles are getting shorter due to the DevOps movement and heavily rely on live data from production or test environments. In addition, performance simulations increasingly become accurate and close to exact predictions. Results from these simulations are reliable and can be compared with live data to detect deviations from expected behavior. In this work, we present a comprehensive tool that can process and analyze measurement as well as simulation data quickly utilizing big data technologies. Live measurement data and simulation results can be analyzed for detecting performance problems, deviations from expected behavior or to simply compare a performance model with real world applications.;performance analysis, Performance evaluation;;;QUDOS 2016
Book;Meyler K,Buchanan S,Scholman M,Svendsen JG,Rangama J;Microsoft Hybrid Cloud Unleashed with Azure Stack and Azure;;2017;;;;1st;Sams publishing;;;;;2017;9780672338502;;;;"Microsoft Hybrid Cloud Unleashed brings together comprehensive and practical insights into hybrid cloud technologies, complete CloudOps and DevOps implementation strategies, and detailed guidance for deploying Microsoft Azure Stack in your environment. Written by five Microsoft Cloud and Datacenter Management MVPs, this book is built on real-world scenarios and the authors extraordinary hands-on experiences as early adopters. Step by step, the authors help you integrate your optimal mix of private and public cloud, with a unified management experience that lets you move workloads at will, achieving unprecedented flexibility. The authors also guide you through all aspects of building your own secure, high-performance hybrid cloud infrastructure. Youll discover how Azure Stack enables you to run data centers with the same scalability, redundancy, and reliability as Microsofts Azure data centers; how to integrate Azure infrastructure and platform services with internal operations; and how to manage crucial external dependencies. The book concludes with a deep dive into automating and customizing Azure Stack for maximum reliability, productivity, and cost savings. Detailed information on how to Run a private/hybrid cloud on your hardware in your data center, using APIs and code identical to public Azure Apply ITIL and DevOps lifecycles to your hybrid cloud implementation Gain a deep understanding of Azure Stack architecture, components, and internals Install and configure Azure Stack and master the Azure Stack Portal Integrate and utilize infrastructure, core, and custom resource providers Effectively provision, secure, and manage tenants Manage, monitor, troubleshoot, and back up Azure Stack with CloudOps Automate resource provisioning with PowerShell, the Azure CLI, templates, and Azure Stacks API Write your own Azure Resource Manager templates Centrally automate cloud management and complex tasks connected to external systems Develop customized, production-ready Azure Stack marketplace items";;;;
Conference Paper;Rubasinghe ID,Meedeniya DA,Perera I;Towards Traceability Management in Continuous Integration with SAT-Analyzer;;2017;;;77–81;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 3rd International Conference on Communication and Information Processing;Tokyo, Japan;2017;9781450353656;;"https://doi-org.proxy.bnl.lu/10.1145/3162957.3162985;http://dx.doi.org/10.1145/3162957.3162985";10.1145/3162957.3162985;Software system engineering is rapidly growing to larger scales and software maintenance tends to be complex. The number of involving software artefacts increases with the growth of software systems. Thus, different software development methodologies, processes and practices are getting introduced to ease the software management. Consequently, the management of excessive software artefacts is also important towards a successful maintenance. Therefore, the notion of traceability management of software artefacts is given prominence along with continuous integration. This paper explores the existing traceability management approaches to propose an optimized framework that overcomes current limitations. Hence, the previous work of this research, SAT-Analyzer, which is a prototype tool, is extended to support continuous integration with DevOps practices.;change detection, devops, impact analysis, continuous integration, traceability management;;;ICCIP '17
Book;Binnie C;Practical Linux Topics;;2015;;;;1st;Apress;USA;;;;2015;9781484217719;;;;Teaches you how to improve your hands-on knowledge of Linux using challenging, real-world scenarios. Each chapter explores a topic that has been chosen specifically to demonstrate how to enhance your base Linux system, and resolve important issues. This book enables sysadmins, DevOps engineers, developers, and other technical professionals to make full use of Linuxs rocksteady foundation. Explore specific topics in networking, email, filesystems, encryption, system monitoring, security, servers, and more-- including systemd and GPG. Understand salient security concerns and how to mitigate them. Applicable to almost all Linux flavors--Debian, Red Hat, Ubuntu, Linux Mint, CentOS--Practical Linux Topics can be used to reference other Unix-type systems with little modification. Improve your practical know-how and background knowledge on servers and workstations alike, increase your ability to troubleshoot and ultimately solve the daily challenges encountered by all professional Linux users. Empower your Linux skills by adding PowerLinux Topicsto your library today. What You'll Learn Solve a variety of challenges faced by sysadmins and DevOps engineers Understand the security implications of the actions you takeStudy the history behind some of the packages that you are using for a greater in-depth understanding Become a professional at troubleshooting Extend your knowledge by learning about multiple OSs and third-party packages Who This Book Is For Having mastered the basics of running Linux systems this book takes you one step further to help you master the elements of Linux which you may have struggled with in the past. You have progressed past the basic stages of using Linux and want to delve into the more complex aspects. Practical Linuxinstantly offers answers to problematic scenarios and provides invaluable information for future reference. It is an invaluable addition to any Linux library.;;;;
Journal Article;Jiang H,Chen X,He T,Chen Z,Li X;Fuzzy Clustering of Crowdsourced Test Reports for Apps;ACM Trans. Internet Technol.;2018;18;2;;;Association for Computing Machinery;New York, NY, USA;;;;2018-02;;1533-5399;"https://doi-org.proxy.bnl.lu/10.1145/3106164;http://dx.doi.org/10.1145/3106164";10.1145/3106164;DevOps is a new approach to drive a seamless Application (App) cycle from development to delivery. As a critical part to promote the successful implementation of DevOps, testing can significantly improve team productivity and reliably deliver user experience. However, it is difficult to use traditional testing to cover diverse mobile phones, network environments, operating systems, and so on. Hence, many large companies crowdsource their App testing tasks to workers from open platforms. In crowdsourced testing, test reports submitted by workers may be highly redundant, and their quality may vary sharply. Meanwhile, multi-bug test reports may be submitted, and their root causes are hard to diagnose. Hence, it is a time-consuming and tedious task for developers to manually inspect these test reports. To help developers address the above challenges, we issue the new problem of Fuzzy Clustering Test Reports (FULTER). Aiming to resolve FULTER, a series of barriers need to be overcome. In this study, we propose a new framework named Test Report Fuzzy Clustering Framework (TERFUR) by aggregating redundant and multi-bug test reports into clusters to reduce the number of inspected test reports. First, we construct a filter to remove invalid test reports to break through the invalid barrier. Then, a preprocessor is built to enhance the descriptions of short test reports to break through the uneven barrier. Last, a two-phase merging algorithm is proposed to partition redundant and multi-bug test reports into clusters that can break through the multi-bug barrier. Experimental results over 1,728 test reports from five industrial Apps show that TERFUR can cluster test reports by up to 78.15% in terms of AverageP, 78.41% in terms of AverageR, and 75.82% in terms of AverageF1 and outperform comparative methods by up to 31.69%, 33.06%, and 24.55%, respectively. In addition, the effectiveness of TERFUR is validated in prioritizing test reports for manual inspection.;duplicate detection, test report, fuzzy clustering, unsupervised method, Crowdsourced testing;;;
Conference Paper;Stirbu V,Mikkonen T;Introducing Traceability in GitHub for Medical Software Development;;2021;;;152–164;;Springer-Verlag;Berlin, Heidelberg;;Product-Focused Software Process Improvement: 22nd International Conference, PROFES 2021, Turin, Italy, November 26, 2021, Proceedings;Turin, Italy;2021;9783030914516;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-91452-3_10;http://dx.doi.org/10.1007/978-3-030-91452-3_10";10.1007/978-3-030-91452-3_10;Assuring traceability from requirements to implementation is a key element when developing safety critical software systems. Traditionally, this traceability is ensured by a waterfall-like process, where phases follow each other, and tracing between different phases can be managed. However, new software development paradigms, such as continuous software engineering and DevOps, which encourage a steady stream of new features, committed by developers in a seemingly uncontrolled fashion in terms of former phasing, challenge this view. In this paper, we introduce our approach that adds traceability capabilities to GitHub, so that the developers can act like they normally do in GitHub context but produce the documentation needed by the regulatory purposes in the process.;DevOps, Continuous software engineering, Traceability, Regulated software, GitHub;;;
Journal Article;Kumara I,Mundt P,Tokmakov K,Radolović D,Maslennikov A,González RS,Fabeiro JF,Quattrocchi G,Meth K,Di Nitto E,Tamburri DA,Van Den Heuvel WJ,Meditskos G;SODALITE@RT: Orchestrating Applications on Cloud-Edge Infrastructures;J. Grid Comput.;2021;19;3;;;Springer-Verlag;Berlin, Heidelberg;;;;2021-09;;1570-7873;"https://doi-org.proxy.bnl.lu/10.1007/s10723-021-09572-0;http://dx.doi.org/10.1007/s10723-021-09572-0";10.1007/s10723-021-09572-0;IoT-based applications need to be dynamically orchestrated on cloud-edge infrastructures for reasons such as performance, regulations, or cost. In this context, a crucial problem is facilitating the work of DevOps teams in deploying, monitoring, and managing such applications by providing necessary tools and platforms. The SODALITE@RT open-source framework aims at addressing this scenario. In this paper, we present the main features of the SODALITE@RT: modeling of cloud-edge resources and applications using open standards and infrastructural code, and automated deployment, monitoring, and management of the applications in the target infrastructures based on such models. The capabilities of the SODALITE@RT are demonstrated through a relevant case study.;TOSCA, Orchestration, Heterogeneous infrastructures, Cloud, Edge, Containers;;;
Conference Paper;López-Huguet S,García-Castro F,Alberich-Bayarri A,Blanquer I;A Cloud Architecture for the Execution of Medical Imaging Biomarkers;;2019;;;130–144;;Springer-Verlag;Berlin, Heidelberg;;Computational Science – ICCS 2019: 19th International Conference, Faro, Portugal, June 12–14, 2019, Proceedings, Part III;Faro, Portugal;2019;9783030227432;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-22744-9_10;http://dx.doi.org/10.1007/978-3-030-22744-9_10";10.1007/978-3-030-22744-9_10;Digital Medical Imaging is increasingly being used in clinical routine and research. As a consequence, the workload in medical imaging departments in hospitals has multiplied by over 20 in the last decade. Medical Image processing requires intensive computing resources not available at hospitals, but which could be provided by public clouds. The article analyses the requirements of processing digital medical images and introduces a cloud-based architecture centred on a DevOps approach to deploying resources on demand, adjusting them based on the request of resources and the expected execution time to deal with an unplanned workload. Results presented show a low overhead and high flexibility executing a lung disease biomarker on a public cloud.;Cloud computing, Medical imaging, DevOps;;;
Book;Chaganti R;Pro PowerShell Desired State Configuration: An In-Depth Guide to Windows PowerShell DSC;;2018;;;;2nd;Apress;USA;;;;2018;9781484234822;;;;Use Windows PowerShell Desired State Configuration (DSC) to configure your infrastructure on-premises and in the cloud. In an environment where changes and deployments are happening all the time, DSC makes the necessary adjustments to the system so you dont have to. Pro PowerShell Desired State Configurationshows you how. PowerShell Desired State Configuration (DSC) is a powerful configuration management platform that makes it easier than ever to perform configuration management of your infrastructure, whether on-premises or in the cloud. With Pro PowerShell Desired State Configuration, Ravikanth Chaganti revises and significantly expands his previous edition, bringing you a complete in-depth reference for applying this evolving technology in your day-to-day work. Whats new in this edition?Get up-to-date, in-depth guidance on DSC in the data center Understand the central role that DSC plays in DevOps today Integrate DSC into build and release management tools Learn to think and act like a developer when automating your configuration management, creating a testable, robust process that you can use again and again Find out why and how DSC has an important role to play in public and private cloud deployments Apply DSC in the cloud with Microsoft Azure or Amazon Web Services or Google Cloud Platform Who This Book Is ForIT administrators, developers and DevOps engineers working in Windows-based data center environments. With a little prior PowerShell scripting experience, this book can be used as an in-depth reference to creating, customizing, and extending DSC in Windows. IT administrators with limited scripting experience will also find this book a useful overview of what DSC offers and how to use DSC resources to automate configuration management and deployment.;;;;
Conference Paper;Demeyer S,Parsai A,Vercammen S,van Bladel B,Abdi M;Formal Verification of Developer Tests: A Research Agenda Inspired by Mutation Testing;;2020;;;9–24;;Springer-Verlag;Berlin, Heidelberg;;Leveraging Applications of Formal Methods, Verification and Validation: Engineering Principles: 9th International Symposium on Leveraging Applications of Formal Methods, ISoLA 2020, Rhodes, Greece, October 20–30, 2020, Proceedings, Part II;Rhodes, Greece;2020;9783030614690;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-61470-6_2;http://dx.doi.org/10.1007/978-3-030-61470-6_2";10.1007/978-3-030-61470-6_2;With the current emphasis on DevOps, automated software tests become a necessary ingredient for continuously evolving, high-quality software systems. This implies that the test code takes a significant portion of the complete code base—test to code ratios ranging from 3:1 to 2:1 are quite common.We argue that “testware” provides interesting opportunities for formal verification, especially because the system under test may serve as an oracle to focus the analysis. As an example we describe five common problems (mainly from the subfield of mutation testing) and how formal verification may contribute. We deduce a research agenda as an open invitation for fellow researchers to investigate the peculiarities of formally verifying testware.;Formal verification, Testware, Mutation testing;;;
Book;Bai H,Stolts D,Munoz SF;Exam Ref 70-535 Architecting Microsoft Azure Solutions;;2018;;;;1st;Microsoft Press;USA;;;;2018;9781509304684;;;;Prepare for Microsoft Exam 70-535and help demonstrate your real-world mastery of architecting complete cloud solutions on the Microsoft Azure platform. Designed for architects and other cloud professionals ready to advance their status, Exam Ref focuses on the critical thinking and decision-making acumen needed for success at the MCSA level. Focus on the expertise measured by these objectives: Design compute infrastructure Design data implementation Design networking implementation Design security and identity solutions Design solutions by using platform services Design for operations This Microsoft Exam Ref: Organizes its coverage by exam skills Features strategic, what-if scenarios to challenge you Includes DevOps and hybrid technologies and scenarios Assumes you have experience building infrastructure and applications on the Microsoft Azure platform, and understand the services it offers;;;;
Conference Paper;Segall I,Tzoref-Brill R;Feedback-Driven Combinatorial Test Design and Execution;;2015;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM International Systems and Storage Conference;Haifa, Israel;2015;9781450336079;;"https://doi-org.proxy.bnl.lu/10.1145/2757667.2757677;http://dx.doi.org/10.1145/2757667.2757677";10.1145/2757667.2757677;This work introduces a novel approach for online design and execution of load tests on Cloud applications. Our approach utilizes a Combinatorial Test Design (CTD) engine in order to exercise combinations of levels of resource utilization on the target system's subcomponents. In order to cope with the unpredictability and uncontrollability of Cloud environments, and to align with agile and DevOps paradigms, it designs and executes tests in an iterative online fashion. During test execution, monitoring information is collected from the Cloud, and leveraged for driving and adjusting the subsequent test scenarios. In this work we introduce the overall approach and the algorithms behind it, and demonstrate it on an example setting consisting of three sub-components comprising a typical installation of a web blogging application.;DevOps, combinatorial test design, performance testing, cloud, combinatorial testing;;;SYSTOR '15
Book;Pabbathi KK,ServiceManagers.Org;Guidance for Problem Management: According to ISO/IEC 20000 & 9001 Standards, Six Sigma and ITSM Best Practices;;2015;;;;;ServiceManagers.org;;;;;2015;9780991320554;;;;"Today there are numerous books on ITSM, but none which tells how to implement and improve ITSM practices for organizations and how to bring effectiveness in ITSM operations. Hence, I have chosen to write books in this area, providing detailed information; and this book ""Guidance for Problem Management"" is part of a series with explicit focus on problem management. And the focus is on topics like implementing problem management through Six Sigma's DMADV approach, improving problem management through Six Sigma's DMAIC approach, Roles and responsibilities in Problem management, Essentials for problem management operations, Integrations in problem management with other processes and functions, Best practices for problem management, Best practices for RCA, Problem management in DEVOPS and SCRUM, Advice for PM operations and many more interesting topics.";;;;
Conference Paper;Souza R,Rocha L,Silva F,Machado I;Investigating Agile Practices in Software Startups;;2019;;;317–321;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the XXXIII Brazilian Symposium on Software Engineering;Salvador, Brazil;2019;9781450376518;;"https://doi-org.proxy.bnl.lu/10.1145/3350768.3350786;http://dx.doi.org/10.1145/3350768.3350786";10.1145/3350768.3350786;Software development practices have smoothly shifted from traditional software development to new approaches that fit better to the real and unpredictable world. Agile practices might help practitioners respond quickly to customer change requests and deliver a working software on-schedule. Software startups are companies that develop innovative and software-intensive products and services in a dynamic and fast-growing market. This study aims to investigate the use of agile practices in software startups. We conducted 14 in-depth semi-structured interviews with the CEO and CTO from early-stage software startups. The results indicate that DevOps, Fundamentals, Design and Extreme Programming are the most used agile practice areas. Our results open up an opportunity to improve software engineering practices in early-stage software startups.;Agile practices, Software engineering, Software startups, Interview;;;SBES 2019
Conference Paper;Forbrig P;BizDevOps and the Role of S-BPM;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 10th International Conference on Subject-Oriented Business Process Management;Linz, Austria;2018;9781450353601;;"https://doi-org.proxy.bnl.lu/10.1145/3178248.3178250;http://dx.doi.org/10.1145/3178248.3178250";10.1145/3178248.3178250;"Recently discussed software development approaches are characterized by agility. New increments of software are developed in relatively short cycles. While previously new versions of software were delivered after several months, nowadays this happens sometimes daily. Tool chains that ensure quality attributes are needed for this purpose. They are classified as DevOps tools. The paper discusses an even broader approach that includes business process modelling activities. It can be characterized with the term BizDevOps. It has a lot of similarities with the idea of ""Continuous Software Engineering"". Additionally, it is discussed how subject-oriented modelling by S-BPM or task models can be used in this context. The domain specific language DSL-CoTaL is demonstrated as candidate for communications with domain experts.";Subject-Oriented Specification, Constraints, Continuous Software Engineering, Task model, Team model, Coordination model;;;S-BPM One '18
Journal Article;Anjum B;An Interview with Lauren Maffeo: Understanding the Risks of Machine Learning Bias;Ubiquity;2019;2019;January;;;Association for Computing Machinery;New York, NY, USA;;;;2019-01;;;"https://doi-org.proxy.bnl.lu/10.1145/3306159;http://dx.doi.org/10.1145/3306159";10.1145/3306159;Lauren Maffeo is a research analyst who joined the global technology sector in 2012. She started her career as a freelance journalist covering tech news for The Next Web and The Guardian. She has also worked with CEOs of pre-seed to profitable SaaS startups on media strategy. Lauren joined GetApp, a Gartner company, as a content editor in 2016. She covers the impact of emerging tech like AI on small and midsize business owners.Lauren has been cited by sources including Forbes, Fox Business, DevOps Digest, The Atlantic, and Inc.com. In 2017, Lauren was named to The Drum's 50 Under 30 list of women worth watching in digital. She holds an M.Sc. from The London School of Economics and a certificate in Artificial Intelligence: Implications for Business Strategy from MIT's Sloan School of Management.;;;;
Conference Paper;Shi Z,Zhou H,Hu Y,Koulouzis S,Rubia C,Zhao Z;Co-Located and Orchestrated Network Fabric (CONF): An Automated Cloud Virtual Infrastructure for Social Network Applications;;2019;;;464–475;;Springer-Verlag;Berlin, Heidelberg;;Euro-Par 2019: Parallel Processing Workshops: Euro-Par 2019 International Workshops, Göttingen, Germany, August 26–30, 2019, Revised Selected Papers;Göttingen, Germany;2019;9783030483395;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-48340-1_36;http://dx.doi.org/10.1007/978-3-030-48340-1_36";10.1007/978-3-030-48340-1_36;"Cloud environments can provide virtualized, elastic, controllable and high-quality on-demand infrastructure services for supporting complex distributed applications. However, existing IaaS (Infrastructure-as-a-Service) solutions mainly focus on the automated integration or deployment of generic applications; they lack flexible infrastructure planning and provisioning solutions and do not have rich support for the high service quality and trustworthiness required by social network applications. This paper introduces an automated cloud virtual infrastructure solution for social network applications, called Co-located and Orchestrated Network Fabric (CONF), which was conducted in a recently funded EU H2020 project ARTICONF. CONF aims to improve the existing infrastructure support in the DevOps lifecycle of social network applications to optimize QoS performance metrics as well as ensure fast recovery in the presence of faults or performance drops.";Social network applications, Cloud, Virtual infrastructure;;;
Journal Article;Clemm A,Zhani MF,Boutaba R;Network Management 2030: Operations and Control of Network 2030 Services;J. Netw. Syst. Manage.;2020;28;4;721–750;;Plenum Press;USA;;;;2020-10;;1064-7570;"https://doi-org.proxy.bnl.lu/10.1007/s10922-020-09517-0;http://dx.doi.org/10.1007/s10922-020-09517-0";10.1007/s10922-020-09517-0;The networking landscape is expected to undergo profound changes over the course of the next decade. New network services are expected to emerge that will enable new applications such as the Tactile Internet, Holographic-Type Communications, or Tele-Driving. Many of these services will be characterized by very high degrees of precision with which end-to-end service levels must be supported. This will have profound implications on the management of those networks and services, from the need to support new methods for assurance of ultra-high-precision services to the need for new network programming models that will allow the industry to move beyond DevOps and SDN towards User-Defined Networking. This article analyzes those implications and provides an overview of challenges along with possible solution approaches and opportunities for research.;New IP, Network programming models, Network operations, Intent, BPP, Research challenges, Service management, High precision networking, Service assurance;;;
Book;Watson P;Advanced Selenium in Java: With Examples;;2016;;;;1st;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2016;9781535485708;;;;This book is for software developers, automation testers, Devops and engineers working on selenium automation testing project. Whether you are a beginner or an experienced developer, this book will help you master the skills on Selenium. The book starts with introduction of Selenium and then dives into key concepts like setting up project in IntelliJ, integration with Junit and TestNG, integration with build tools like Gradle and Maven. You will also learn how to integrate selenium with Cucumber. In the end, you will learn how to run the Selenium tests on CI servers like TeamCity, Bamboo and Jenkins. You will also learn how to work with various types of frameworks like Page object models, Page factory Keyword driven frameworks etc. Book also touches the concepts related to mobile automation using Selenium.;;;;
Conference Paper;Weerasiri D,Benatallah B;Unified Representation and Reuse of Federated Cloud Resources Configuration Knowledge;;2015;;;142–150;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE 19th International Enterprise Distributed Object Computing Conference;;2015;9781467392037;;"https://doi-org.proxy.bnl.lu/10.1109/EDOC.2015.29;http://dx.doi.org/10.1109/EDOC.2015.29";10.1109/EDOC.2015.29;The proliferation of tools for different aspects of cloud resource configuration processes encourages DevOps to design end-to-end and automated configuration processes that span across a selection of best-of-breed tools. But heterogeneities among configuration knowledge representation models of such tools pose vital limitations for acquisition, discovery and curation of configuration knowledge for federated cloud application and resource requirements. We propose an embryonic data-model for representing cloud resource configuration knowledge artifacts. We also propose a rule based recommender service, which empowers (1) incremental knowledge acquisition and curation, and (2) declarative context driven knowledge recommendation. The paper describes the concepts, techniques and current implementation of the proposed system. Experiments on 36 real-life cloud resources show efficient re-use of configuration knowledge by our approach compared to traditional techniques.;Federated Cloud, Recommender services, Ripple Down Rules, Cloud Configuration Knowledge Representation;;;EDOC '15
Book;Ingeno J;Software Architect's Handbook: Become a Successful Software Architect by Implementing Effective Architecture Concepts;;2018;;;;;Packt Publishing;;;;;2018;9781788624060;;;;A comprehensive guide to exploring software architecture concepts and implementing best practices Key Features Enhance your skills to grow your career as a software architectDesign efficient software architectures using patterns and best practicesLearn how software architecture relates to an organization as well as software development methodologyBook DescriptionThe Software Architects Handbook is a comprehensive guide to help developers, architects, and senior programmers advance their career in the software architecture domain. This book takes you through all the important concepts, right from design principles to different considerations at various stages of your career in software architecture. The book begins by covering the fundamentals, benefits, and purpose of software architecture. You will discover how software architecture relates to an organization, followed by identifying its significant quality attributes. Once you have covered the basics, you will explore design patterns, best practices, and paradigms for efficient software development. The book discusses which factors you need to consider for performance and security enhancements. You will learn to write documentation for your architectures and make appropriate decisions when considering DevOps. In addition to this, you will explore how to design legacy applications before understanding how to create software architectures that evolve as the market, business requirements, frameworks, tools, and best practices change over time. By the end of this book, you will not only have studied software architecture concepts but also built the soft skills necessary to grow in this field. What you will learn Design software architectures using patterns and best practices Explore the different considerations for designing software architecture Discover what it takes to continuously improve as a software architect Create loosely coupled systems that can support change Understand DevOps and how it affects software architecture Integrate, refactor, and re-architect legacy applications Who this book is for The Software Architects Handbook is for you if you are a software architect, chief technical officer (CTO), or senior developer looking to gain a firm grasp of software architecture.;;;;
Book;Kocher PS;Microservices and Containers;;2018;;;;1st;Addison-Wesley Professional;;;;;2018;9780134598383;;;;Transition to Microservices and DevOps to Transform Your Software Development Effectiveness Thanks to the tech sectors latest game-changing innovationsthe Internet of Things (IoT), software-enabled networking, and software as a service (SaaS), to name a fewthere is now a seemingly insatiable demand for platforms and architectures that can improve the process of application development and deployment. In Microservices and Containers, longtime systems architect and engineering team leader Parminder Kocher analyzes two of the hottest new technology trends: microservices and containers. Together, as Kocher demonstrates, microservices and Docker containers can bring unprecedented agility and scalability to application development and deployment, especially in large, complex projects where speed is crucial but small errors can be disastrous. Learn how to leverage microservices and Docker to drive modular architectural design, on-demand scalability, application performance and reliability, time-to-market, code reuse, and exponential improvements in DevOps effectiveness. Kocher offers detailed guidance and a complete roadmap for transitioning from monolithic architectures, as well as an in-depth case study that walks the reader through the migration of an enterprise-class SOA system. Understand how microservices enable you to organize applications into standalone components that are easier to manage, update, and scale Decide whether microservices and containers are worth your investment, and manage the organizational learning curve associated with them Apply best practices for interprocess communication among microservices Migrate monolithic systems in an orderly fashion Understand Docker containers, installation, and interfaces Network, orchestrate, and manage Docker containers effectively Use Docker to maximize scalability in microservices-based applications Apply your learning with an in-depth, hands-on case study Whether you are a software architect/developer or systems professional looking to move on from older approaches or a manager trying to maximize the business value of these technologies, Microservices and Containers will be an invaluable addition to your library. Register your product at informit.com/register for convenient access to downloads, updates, and/or corrections as they become available.;;;;
Book Chapter;Henkel J,Bird C,Lahiri SK,Reps T;A Dataset of Dockerfiles;;2020;;;528–532;;Association for Computing Machinery;New York, NY, USA;Proceedings of the 17th International Conference on Mining Software Repositories;;;2020;9781450375177;;https://doi-org.proxy.bnl.lu/10.1145/3379597.3387498;;Dockerfiles are one of the most prevalent kinds of DevOps artifacts used in industry. Despite their prevalence, there is a lack of sophisticated semantics-aware static analysis of Dockerfiles. In this paper, we introduce a dataset of approximately 178,000 unique Dockerfiles collected from GitHub. To enhance the usability of this data, we describe five representations we have devised for working with, mining from, and analyzing these Dockerfiles. Each Dockerfile representation builds upon the previous ones, and the final representation, created by three levels of nested parsing and abstraction, makes tasks such as mining and static checking tractable. The Dockerfiles, in each of the five representations, along with metadata and the tools used to shepard the data from one representation to the next are all available at: https://doi-org.proxy.bnl.lu/10.5281/zenodo.3628771.;;;;
Book Chapter;Hodges S;Democratizing the Production of Interactive Hardware;;2020;;;5–6;;Association for Computing Machinery;New York, NY, USA;Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology;;;2020;9781450375146;;https://doi-org.proxy.bnl.lu/10.1145/3379337.3422877;;"The development of new hardware can be split into two phases: prototyping and production. A wide variety of tools and techniques have empowered people to build prototypes during the first phase, but the transition to production is still complex, costly and prone to failure. This means the second phase often requires an up-front commitment to large volume production in order to be viable. I believe that new tools and techniques can democratize hardware production. Imagine ""DevOps for hardware"" - everything from circuit simulation tools to re-usable hardware test jig designs; and from test-driven development for hardware to telepresence for remote factory visits. Supporting low volume production and organic scaling in this way would spur innovation and increase consumer choice. I encourage the UIST community to join me in pursuit of this vision.";;;;
Conference Paper;Avritzer A;Performance Assessment of High-Availability Systems Using Markov Chains;;2017;;;209;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3053600.3053645;http://dx.doi.org/10.1145/3053600.3053645";10.1145/3053600.3053645;As our society evolves, more and more aspects of our daily life depend on large-scale infrastructures such as software intensive computer infrastructures, rails and road networks, gas networks, water networks, power networks, and telecommunication networks, including the internet, wired and wireless telephony. Critical infrastructures are everywhere and they are becoming increasingly more interconnected and interdependent. Open source software repositories (e.g. Sonatype Nexus) have become central to these critical infrastructures, as they are used to support continuous system integration in several critical domains such as telecom, banking, airlines and government. In this keynote, we present an approach for Survivability Evaluation of Critical infrastructures and its application in a DevOps environment. We present examples of application to Water, Gas, Power, and Computer infrastructures. This work is the fruit of open global research collaboration with many colleagues in several Universities and research Labs.;survivability modeling, high-availability, open source development;;;ICPE '17 Companion
Book;Chelliah PR,Naithani S,Singh S;Practical Site Reliability Engineering: Automate the Process of Designing, Developing, and Delivering Highly Reliable Apps and Services with SRE;;2018;;;;;Packt Publishing;;;;;2018;9781788839563;;;;Create, deploy, and manage applications at scale using SRE principles Key Features Build and run highly available, scalable, and secure software Explore abstract SRE in a simplified and streamlined way Enhance the reliability of cloud environments through SRE enhancements Book Description Site reliability engineering (SRE) is being touted as the most competent paradigm in establishing and ensuring next-generation high-quality software solutions. This book starts by introducing you to the SRE paradigm and covers the need for highly reliable IT platforms and infrastructures. As you make your way through the next set of chapters, you will learn to develop microservices using Spring Boot and make use of RESTful frameworks. You will also learn about GitHub for deployment, containerization, and Docker containers. Practical Site Reliability Engineering teaches you to set up and sustain containerized cloud environments, and also covers architectural and design patterns and reliability implementation techniques such as reactive programming, and languages such as Ballerina and Rust. In the concluding chapters, you will get well-versed with service mesh solutions such as Istio and Linkerd, and understand service resilience test practices, API gateways, and edge/fog computing. By the end of this book, you will have gained experience on working with SRE concepts and be able to deliver highly reliable apps and services. What you will learn Understand how to achieve your SRE goals Grasp Docker-enabled containerization concepts Leverage enterprise DevOps capabilities and Microservices architecture (MSA) Get to grips with the service mesh concept and frameworks such as Istio and Linkerd Discover best practices for performance and resiliency Follow software reliability prediction approaches and enable patterns Understand Kubernetes for container and cloud orchestration Explore the end-to-end software engineering process for the containerized world Who this book is for Practical Site Reliability Engineering helps software developers, IT professionals, DevOps engineers, performance specialists, and system engineers understand how the emerging domain of SRE comes handy in automating and accelerating the process of designing, developing, debugging, and deploying highly reliable applications and services.;;;;
Book;Ambler SW,Lines M;An Executive's Guide to Disciplined Agile: Winning the Race to Business Agility (Volume 1);;2017;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2017;9781539852964;;;;The agile community has figured out how to build and then continually improve very high-performance software development teams. This is akin to creating a race car engine and then evolving it to get more power, better fuel efficiency, and greater speed. Sadly in many cases we take these great engines, put them into an organizational tractor, and then complain that were not winning the race. What we need to do is take our great race car engines (our development teams), put them into a race car (a DevOps ecosystem), have a great pit crew and driver (an effective IT organization), and then provide somewhere to race (an organization that can leverage IT to make money). Thats what this book is all about Moving from optimizing team performance to optimizing the entire enterprise. Business agility being an adaptive, lean, responsive, and learning organization is the race that enterprises need to win today. Yet there is no quick fix, no silver bullet, to attain business agility. This is a multi-year journey requiring hard work, experimentation, and most importantly a willingness to improve. The Disciplined Agile framework lowers risks and provides a path to accelerate your journey to business agility. The framework is unique in that it is the only one that puts all the pieces together into a cohesive enterprise roadmap for business agility transformation. This book begins with an overview of the challenges and opportunities that organizations face. We then describe seven principles that provide the underpinnings of the Disciplined Agile framework. Then the book works through Disciplined Agile Delivery (how to build a world-class engine), Disciplined DevOps (the race car), Disciplined Agile IT (the race car and its team), and what it means to be a Disciplined Agile Enterprise (the racing business). The book ends with a plan for starting with an Agile transformation and then evolving into a long-term continuous improvement strategy. Do you have the discipline it takes to win the race to business agility?;;;;
Conference Paper;Bruneo D,Longo F,Merlino G,Peditto N,Romeo C,Verboso F,Puliafito A;Enabling Collaborative Development in an OpenStack Testbed: The CloudWave Use Case;;2015;;;24–30;;IEEE Press;Florence, Italy;;Proceedings of the Seventh International Workshop on Principles of Engineering Service-Oriented and Cloud Systems;;2015;;;;;The CloudWave project embodies a challenging set of goals, including the development of software components that have to be integrated into a single multi-layer Cloud stack based on OpenStack, while cutting across the Infrastructure-asa-Service, Platform-as-a-Service, and Software-as-a-Service levels by targeting layer-spanning issues such as Feedback-Driven Development and Coordinated Adaptation. A DevOps-ready testbed environment should allow project partners to exert full control over deployed componentry and collaborate on development. Goals include providing a flexible infrastructure capable of emulating several multi-node Cloud environments, as well as enabling the automatic deployment of CloudWave artifacts into such environment in order to simplify integration activities. This paper takes a snapshot of the current situation with regards to the design and implementation of such a setup, trying to gain relevant insight out of this effort.;integration testbed, cloud computing, open-stack, continuous integration, virtual infrastructure, DevOps;;;PESOS '15
Conference Paper;Wu CF,Yu H,Jann J,Burugula RS,Dubey N,Nguyen M;Automation of Cloud Node Installation for Testing and Scalable Provisioning;;2017;;;79–84;;Association for Computing Machinery;New York, NY, USA;;Companion Proceedings of The10th International Conference on Utility and Cloud Computing;Austin, Texas, USA;2017;9781450351959;;"https://doi-org.proxy.bnl.lu/10.1145/3147234.3148135;http://dx.doi.org/10.1145/3147234.3148135";10.1145/3147234.3148135;Motivated by the lack of automated provisioning and testing tools for physical systems in modern cloud infrastructures, we developed a toolset to automate the installation of a commercial platform virtualization software: the IBM PowerVM NovaLink software. This toolset automates numerous manual installation steps and post-installation tests. The toolset uses Python programs to prepare the target system and to generate installation-configuration files through interaction with a web-interface of the POWER firmware. Expect scripts are used to drive the rest of the installation via interactions through a remote text console. With different scenarios of applying this automation toolset, we demonstrate its use in driving regression testing for the development of the NovaLink installer in a DevOps environment. Furthermore, we discuss its use in provisioning a large number of IBM POWER systems to be ready for cloud management software.;cloud provisioning, virtualization software, virtual machine, provisioning automation, test automation;;;UCC '17 Companion
Conference Paper;de Gouw S,Lienhardt M,Mauro J,Nobakht B,Zavattaro G;On the Integration of Automatic Deployment into the ABS Modeling Language;;;;;49–64;;Springer-Verlag;Berlin, Heidelberg;;Service Oriented and Cloud Computing;Taormina Italy;;9783319240718;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-319-24072-5_4;http://dx.doi.org/10.1007/978-3-319-24072-5_4";10.1007/978-3-319-24072-5_4;In modern software systems, deployment is an integral and critical part of application development (see, e.g., the DevOps approach to software development). Nevertheless, deployment is usually overlooked at the modeling level, thus losing the possibility to perform deployment conscious decisions during the early stages of development. In this paper, we address the problem of promoting deployment as an integral part of modeling, by focusing on the Abstract Behavioral Specification (ABS) language used for the specification of models of systems composed of concurrent objects consuming resources provided by deployment components. We extend ABS with class annotations expressing the resource requirements of the objects of that class. Then we define a tool that, starting from a high-level declaration of the desired system, computes a model instance of such system that optimally distributes objects over available deployment components.;Concurrent Object, Modeling Language, Code Metrics, Cloud Application, Deployment Scenario;;;
Journal Article;O'Connor RV,Houston D,Hebig R,Kuhrmann M;ICSSP 2018—Special Issue Introduction;J. Softw. Evol. Process;2019;31;5;;;John Wiley & Sons, Inc.;USA;;;;2019-05;;2047-7473;"https://doi-org.proxy.bnl.lu/10.1002/smr.2174;http://dx.doi.org/10.1002/smr.2174";10.1002/smr.2174;The International Conference on Software and System Processes (ICSSP) provides a leading forum for the exchange of research outcomes and industrial best practices in process development from software and systems disciplines. ICSSP 2018 was held in Gothenburg, Sweden, May 26 to 27, 2018, colocated with the 40th International Conference on Software Engineering (ICSE). The theme of ICSSP 2018 was studying “Demands on Processes, Processes on Demand” by recognizing the demands on processes that include the need for both well‐developed plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model‐based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise‐level architectures. This special issue includes the revised and extended versions of the five highest ranked full research papers and industry experience papers of ICSSP 2018, including the two award‐winning papers.;continuous development, data science, agile methods, product duality, deployment, project management, hybrid systems development;;;
Conference Paper;Martin D,Panichella S;The Cloudification Perspectives of Search-Based Software Testing;;2019;;;5–6;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 12th International Workshop on Search-Based Software Testing;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/SBST.2019.00009;http://dx.doi.org/10.1109/SBST.2019.00009";10.1109/SBST.2019.00009;To promote and sustain the future of our society, the most critical challenge of contemporary software engineering and cloud computing experts are related to the efficient integration of emerging cloudification and DevOps practices in the development and testing processes of modern systems. In this context, we argue that SBST can play a critical role in improving testing practices and automating the verification and validation (V&V) of cloudification properties of Cloud Native Applications (CNA). Hence, in this paper, we focus on the untouched side of SBST in the cloud field, by discussing (1) the testing challenges in the cloud research field and (2) summarizing the recent contributions of SBST in supporting development practices of CNA. Finally, we discuss the emerging research topics characterizing the cloudification perspectives of SBST in the cloud field.;test suite generation, search-based software testing, cloud native applications;;;SBST '19
Conference Paper;Versteeg S,Du M,Bird J,Schneider JG,Grundy J,Han J;Enhanced Playback of Automated Service Emulation Models Using Entropy Analysis;;2016;;;49–55;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the International Workshop on Continuous Software Evolution and Delivery;Austin, Texas;2016;9781450341578;;"https://doi-org.proxy.bnl.lu/10.1145/2896941.2896950;http://dx.doi.org/10.1145/2896941.2896950";10.1145/2896941.2896950;Service virtualisation is a supporting tool for DevOps to generate interactive service models of dependency systems on which a system-under-test relies. These service models allow applications under development to be continuously tested against production-like conditions. Generating these virtual service models requires expert knowledge of the service protocol, which may not always be available. However, service models may be generated automatically from network traces. Previous work has used the Needleman-Wunsch algorithm to select a response from the service model to play back for a live request. We propose an extension of the Needleman-Wunsch algorithm, which uses entropy analysis to automatically detect the critical matching fields for selecting a response. Empirical tests against four enterprise protocols demonstrate that entropy weighted matching can improve response accuracy.;;;;CSED '16
Conference Paper;Syed MH,Fernandez EB,Silva P;The Secure Software Container Pattern;;2017;;;;;The Hillside Group;USA;;Proceedings of the 24th Conference on Pattern Languages of Programs;Vancouver, British Columbia, Canada;2017;9781941652060;;;;Software containers have gained large popularity as portable lightweight virtualization components. They have enabled development approaches like DevOps by facilitating application deployment and distribution across computing environments. Containers offer operating-system-level virtualization where applications are executed in isolated environments sharing a host operating system (OS), binaries, and libraries with other containers. Containers offer low overhead and near native performance as compared to virtual machines (VMs). However, there are tradeoffs like flexibility and security when compared to VMs. This closer integration and interaction with their Host OS also results in an increased attack surface, host resources are exposed to the applications which can lead to security threats. The security of containers has improved since their inception but they still exhibit vulnerabilities that need to be addressed to enable their full adoption. We present a pattern for a Secure Software Container, which describes their security threats and possible defenses.;virtualization, architecture patterns, software containers, container ecosystem, security patterns, security;;;PLoP '17
Conference Paper;Birngruber E,Forai P,Zauner A;Total Recall: Holistic Metrics for Broad Systems Performance and User Experience Visibility in a Data-Intensive Computing Environment;;2015;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Second International Workshop on HPC User Support Tools;Austin, Texas;2015;9781450340007;;"https://doi-org.proxy.bnl.lu/10.1145/2834996.2835001;http://dx.doi.org/10.1145/2834996.2835001";10.1145/2834996.2835001;User support personnel, systems engineers, and administrators of HPC installations need to be aware of log and telemetry information from different systems in order to perform routine tasks ranging from systems management to user inquiries. We present an integrated, distributed HPC tailored monitoring system, based on a current generation software stack from the DevOps community, with integration into the work load management system. The goal of this system is to provide a quicker turnaround time for user inquiries in response to errors. Dashboards provide an overlay of system and node level events on top of correlated metrics data. This information is directly available for querying, manipulation, and filtering, allowing statistical analysis and aggregation of collected data. Furthermore, additional dashboards offer in-sight into how users are interacting with available resources and pin-point fluctuations in utilization. The system can integrate sources of information from other monitoring solutions and event-based sources.;job scheduling, user support tools, event correlation, time-series databases, HPC, DevOps, performance analysis, metrics, distributed systems monitoring, telemetry, systems performance;;;HUST '15
Conference Paper;Wettinger J,Andrikopoulos V,Strauch S,Leymann F;Characterizing and Evaluating Different Deployment Approaches for Cloud Applications;;2014;;;205–214;;IEEE Computer Society;USA;;Proceedings of the 2014 IEEE International Conference on Cloud Engineering;;2014;9781479937660;;"https://doi-org.proxy.bnl.lu/10.1109/IC2E.2014.32;http://dx.doi.org/10.1109/IC2E.2014.32";10.1109/IC2E.2014.32;Fully automated provisioning and deployment in order to reduce the costs for managing applications is one of the most essential requirements to make use of the benefits of Cloud computing. Several approaches and tools are available to automate the involved processes. The DevOps community, for example, provides tooling and artifacts to realize deployment automation on Infrastructure as a Service level in a mostly application-oriented manner. Platform as a Service frameworks are also available for the same purpose. In this paper we categorize and characterize available deployment approaches independently from the underlying technology used. For this purpose, we choose Web applications with different technology stacks and analyze their specific deployment requirements. Afterwards, we provision these applications using each of the identified types of deployment approaches in the Cloud. Finally, we discuss the evaluation results and derive recommendations which deployment approach to use based on the deployment requirements of an application.;DevOps, middleware-oriented deployment, application-oriented deployment, Cloud computing, decision support;;;IC2E '14
Conference Paper;Axelsson J;Architectural Allocation Alternatives and Associated Concerns in Cyber-Physical Systems: A Case Study;;2015;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2015 European Conference on Software Architecture Workshops;Dubrovnik, Cavtat, Croatia;2015;9781450333931;;"https://doi-org.proxy.bnl.lu/10.1145/2797433.2797448;http://dx.doi.org/10.1145/2797433.2797448";10.1145/2797433.2797448;Cyber-physical systems is an extension of traditional embedded systems, where communication to the outside world is given more emphasis. This leads to a new design space also for software development, allowing new allocation strategies for functionality. In traditional embedded systems, all functionality was inside the product, but now it becomes possible to partition the software between the embedded systems and IT systems outside the product. This paper investigates, through a case study from the automotive domain, possible new allocation alternatives where computation is offloaded from the embedded system to a server, and what additional architectural concerns this leads to, including performance, resource utilization, robustness, and lifecycle aspects. In addition, the paper addresses new opportunities created by allocating functionality outside the embedded systems, and thus making data available for extended services, as well as the larger concerns that result on the organizational level, including new competency in architecture and DevOps.;system-of-systems, allocation, Cyber-physical systems, architecture, cloud;;;ECSAW '15
Conference Paper;Islam MS,Pourmajidi W,Zhang L,Steinbacher J,Erwin T,Miranskyy A;Anomaly Detection in a Large-Scale Cloud Platform;;2021;;;150–159;;IEEE Press;Virtual Event, Spain;;Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice;;2021;9780738146690;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP52600.2021.00024;http://dx.doi.org/10.1109/ICSE-SEIP52600.2021.00024";10.1109/ICSE-SEIP52600.2021.00024;Cloud computing is ubiquitous: more and more companies are moving the workloads into the Cloud. However, this rise in popularity challenges Cloud service providers, as they need to monitor the quality of their ever-growing offerings effectively. To address the challenge, we designed and implemented an automated monitoring system for the IBM Cloud Platform. This monitoring system utilizes deep learning neural networks to detect anomalies in near-real-time in multiple Platform components simultaneously.After running the system for a year, we observed that the proposed solution frees the DevOps team's time and human resources from manually monitoring thousands of Cloud components. Moreover, it increases customer satisfaction by reducing the risk of Cloud outages.In this paper, we share our solutions' architecture, implementation notes, and best practices that emerged while evolving the monitoring system. They can be leveraged by other researchers and practitioners to build anomaly detectors for complex systems.;;;;ICSE-SEIP '21
Conference Paper;Bruneo D,Longo F,Merlino G,Peditto N,Romeo C,Verboso F,Puliafito A;Enabling Collaborative Development in an Open Stack Testbed: The Cloud Wave Use Case;;2015;;;24–30;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE/ACM 7th International Workshop on Principles of Engineering Service-Oriented and Cloud Systems;;2015;9781467370585;;"https://doi-org.proxy.bnl.lu/10.1109/PESOS.2015.12;http://dx.doi.org/10.1109/PESOS.2015.12";10.1109/PESOS.2015.12;The Cloud Wave project embodies a challenging set of goals, including the development of software components that have to be integrated into a single multi-layer Cloud stack based on Open Stack, while cutting across the Infrastructure-as-a-Service, Platform-as-a-Service, and Software-as-a-Service levels by targeting layer-spanning issues such as Feedback-Driven Development and Coordinated Adaptation. A DevOps-ready test bed environment should allow project partners to exert full control over deployed compo entry and collaborate on development. Goals include providing a flexible infrastructure capable of emulating several multi-node Cloud environments, as well as enabling the automatic deployment of Cloud Wave artifacts into such environment in order to simplify integration activities. This paper takes a snapshot of the current situation with regards to the design and implementation of such a setup, trying to gain relevant insight out of this effort.;virtual infrastructure, Openstack, integration testbed, DevOps, continuous integration, Cloud computing;;;PESOS '15
Conference Paper;Bermbach D,Eberhardt J;Audio-Visual Cues for Cloud Service Monitoring;;2017;;;467–474;;SCITEPRESS - Science and Technology Publications, Lda;Setubal, PRT;;Proceedings of the 7th International Conference on Cloud Computing and Services Science;Porto, Portugal;2017;9789897582431;;"https://doi-org.proxy.bnl.lu/10.5220/0006301804670474;http://dx.doi.org/10.5220/0006301804670474";10.5220/0006301804670474;When monitoring their systems' states, DevOps engineers and operations teams alike, today, have to choose whether they want to dedicate their full attention to a visual dashboard showing monitoring results or whether they want to rely on threshold- or algorithm-based alarms which always come with false positive and false negative signals. In this work, we propose an alternative approach which translates a stream of cloud monitoring data into a continuous, normalized stream of score changes. Based on the score level, we propose to gradually change environment factors, e.g., music output or ambient lighting. We do this with the goal of enabling developers to subconsciously become aware of changes in monitoring data while dedicating their full attention to their primary task. We evaluate this approach through our proof-of-concept implementation AudioCues, which gradually adds dissonances to music output, and an empirical study with said prototype. p>;Monitoring, Quality of Service., Cloud Services;;;CLOSER 2017
Conference Paper;Younoussi S,Roudies O;A New Reuse Capability and Maturity Model: An Overview;;2018;;;26–31;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2018 International Conference on Software Engineering and Information Management;Casablanca, Morocco;2018;9781450354387;;"https://doi-org.proxy.bnl.lu/10.1145/3178461.3178485;http://dx.doi.org/10.1145/3178461.3178485";10.1145/3178461.3178485;Throughout the last decade, increasingly sophisticated processes models, methods and tools have evolved as a result of structure and culture changes of software organizations. Software reuse is considered as a major factor for increasing productivity and quality. Reuse is implemented more and more by organizations, thereby giving them headway. To be more competitive these organizations try to invest in software reuse, by identifying the most effective reuse strategies, methods and practices. However, there is a high up-front risk of reuse adoption, because a significant initial organization investment is required, while the ROI is not guaranteed. Several Software Reuse Models have been suggested in literature to face the reuse adoption problem, but until now there is no widely accepted model. This paper proposed a new Reuse Capability Maturity Model based on international standards, literature and completed with the most recent and popular approaches as Lean and Devops, to help organizations implementing an efficient reuse program.;Software reuse, Capability Maturity Models, Maturity levels;;;ICSIM2018
Journal Article;Klein D;Micro-Segmentation: Securing Complex Cloud Environments;Netw. Secur.;2019;2019;3;6–10;;Elsevier Science Publishers B. V.;NLD;;;;2019-03;;1353-4858;"https://doi-org.proxy.bnl.lu/10.1016/S1353-4858(19)30034-0;http://dx.doi.org/10.1016/S1353-4858(19)30034-0";10.1016/S1353-4858(19)30034-0;;;;;
Book;Whitman ME,Mattord HJ;Principles of Information Security;;2017;;;;6th;Course Technology Press;Boston, MA, USA;;;;2017;9781337102063;;;;Master the latest technology and developments from the field with the book specifically oriented to the needs of information systems students like you -- PRINCIPLES OF INFORMATION SECURITY, 6E. Taking a managerial approach, this bestseller emphasizes all aspects of information security, rather than just a technical control perspective. You receive a broad overview of the entire field of information security and related elements with the detail to ensure understanding. You review terms used in the field and a history of the discipline as you learn how to manage an information security program. Current and relevant, this edition highlights the latest practices with fresh examples that explore the impact of emerging technologies, such as the Internet of Things, Cloud Computing, and DevOps. Updates address technical security controls, emerging legislative issues, digital forensics, and ethical issues in IS security, making this the ideal IS resource for business decision makers.;;;;
Conference Paper;Ellis HJ,Hislop GW;Student Participation in HFOSS: Challenges and Opportunities;;2018;;;150;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 19th Annual SIG Conference on Information Technology Education;Fort Lauderdale, Florida, USA;2018;9781450359542;;"https://doi-org.proxy.bnl.lu/10.1145/3241815.3241874;http://dx.doi.org/10.1145/3241815.3241874";10.1145/3241815.3241874;With the advent of cloud computing, containers, devops and other emerging IT technologies, there are increased opportunities for student learning. Many of these new technologies have their roots in open source as many of the major tools are open source such as Git (version control), Ansible (configuration management), Docker (containerization), and Jenkins (automation server). In addition, most major IT companies have a strategy for utilizing free and open source software (FOSS). Indeed, FOSS has become an important segment of the technology industry. Humanitarian FOSS (HFOSS) has the additional attraction of somehow benefiting the human condition. Given the rising emphasis on FOSS, it is important that IT students graduate with some understanding of FOSS. This poster presents an overview of HFOSS, summarizes recent research into student learning in HFOSS and also provides an overview of instructor experiences in teaching HFOSS.;information technology education, hfoss;;;SIGITE '18
Conference Paper;Rajagopalan S,Jamjoom H;App-Bisect: Autonomous Healing for Microservice-Based Apps;;2015;;;16;;USENIX Association;USA;;Proceedings of the 7th USENIX Conference on Hot Topics in Cloud Computing;Santa Clara, CA;2015;;;;;The microservice and DevOps approach to software design has resulted in new software features being delivered immediately to users, instead of waiting for long refresh cycles. On the downside, software bugs and performance regressions have now become an important cause of downtime. We propose app-bisect, an autonomous tool to troubleshoot and repair such software issues in production environments. Our insight is that the evolution of microservices in an application can be captured as mutations to the graph of microservice dependencies, such that a particular version of the graph from the past can be deployed automatically, as an interim measure until the problem is permanently fixed. Using canary testing and version-aware routing techniques, we describe how the search process can be sped up to identify such a candidate version. We present the overall design and key challenges towards implementing such a system.;;;;HotCloud'15
Book;Shirinkin K;Getting Started with Terraform;;2017;;;;;Packt Publishing;;;;;2017;9781786465108;;;;Key Features An up-to-date and comprehensive resource on Terraform that lets you quickly and efficiently launch your infrastructureLearn how to implement your infrastructure as code and make secure, effective changes to your infrastructure Learn to build multi-cloud fault-tolerant systems and simplify the management and orchestration of even the largest scale and most complex cloud infrastructures Book Description Terraform is a tool used to efficiently build, configure, and improve production infrastructure. It can manage existing infrastructure as well as create custom in-house solutions. This book shows you when and how to implement infrastructure as a code practices with Terraform. It covers everything necessary to set up complete management of infrastructure with Terraform, starting with the basics of using providers and resources. This book is a comprehensive guide that begins with very small infrastructure templates and takes you all the way to managing complex systems, all using concrete examples that evolve over the course of the book. It finishes with the complete workflow of managing a production infrastructure as code this is achieved with the help of version control and continuous integration. At the end of this book, you will be familiar with advanced techniques such as multi-provider support and multiple remote modules. What you will learn Understand what Infrastructure as Code (IaC) means and why it matters Install, configure, and deploy Terraform Take full control of your infrastructure in the form of code Manage complete complete infrastructure, starting with a single server and scaling beyond any limits Discover a great set of production-ready practices to manage infrastructure Set up CI/CD pipelines to test and deliver Terraform stacks Construct templates to simplify more complex provisioning tasks About the Author Kirill Shirinkin is an IT consultant who focuses on Cloud technologies and DevOps practices. He has worked in companies of different sizes and areas, from an online language learning leader to a major IT provider for the global travel industry and one of the largest management consultancies. He is also a cofounder of online mentorship platform mkdev.me, where he leads a team and teaches his students all about DevOps.;;;;
Conference Paper;Melegati J,Chanin R,Wang X,Sales A,Prikladnicki R;Perceived Benefits and Challenges of Learning Startup Methodologies for Software Engineering Students;;2019;;;204–210;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 50th ACM Technical Symposium on Computer Science Education;Minneapolis, MN, USA;2019;9781450358903;;"https://doi-org.proxy.bnl.lu/10.1145/3287324.3287382;http://dx.doi.org/10.1145/3287324.3287382";10.1145/3287324.3287382;The need of skills other than technical from software developers is becoming evident. The DevOps movement is an example of that applied to operational tasks. Startup development methodologies focus on business activities in innovative organizations. Several universities offer courses based on these methodologies to software engineering students, mainly to improve their creativity, problem solving, and business skills. This paper investigates how software engineering students learned startup development methodologies and discusses what are the challenges and benefits in their learning process. We conducted a multi-method study in three different universities. The data was collected in two phases and analyzed using thematic analysis. Our study reveals that students realized the importance of collaboration with other courses and the importance of user involvement in development. However, students tend to over-simplify concepts, trying to adapt them to what they are familiar with. The results indicate the necessity of business education for technical students and directions for improvements.;software engineering education, empirical study, lean startup;;;SIGCSE '19
Journal Article;Wang X,Liu F,Feng Y,Zhao J,Zhang Z;A Two-Layer Architecture for Failure Prediction Based on High-Dimension Monitoring Sequences;Complex.;2021;2021;;;;John Wiley & Sons, Inc.;USA;;;;2021-01;;1076-2787;"https://doi-org.proxy.bnl.lu/10.1155/2021/6623666;http://dx.doi.org/10.1155/2021/6623666";10.1155/2021/6623666;In recent years, the distributed architecture has been widely adopted by security companies with the rapid expansion of their business. A distributed system is comprised of many computing nodes of different components which are connected by high-speed communication networks. With the increasing functionality and complexity of the systems, failures of nodes are inevitable which may result in considerable loss. In order to identify anomalies of the possible failures and enable DevOps engineers to operate in advance, this paper proposes a two-layer prediction architecture based on the monitoring sequences of nodes status. Generally speaking, in the first layer, we make use of EXPoSE anomaly detection technique to derive anomaly scores in constant time which are then used as input data for ensemble learning in the second layer. Experiments are conducted on the data provided by one of the largest security companies, and the results demonstrate the predictability of the proposed approach.;;;;
Conference Paper;Weerasiri D,Barukh MC,Benatallah B,Cao J;A Model-Driven Framework for Interoperable Cloud Resources Management;;2016;;;186–201;;Springer-Verlag;Berlin, Heidelberg;;Service-Oriented Computing: 14th International Conference, ICSOC 2016, Banff, AB, Canada, October 10-13, 2016, Proceedings;Banff, Canada;2016;9783319462943;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-319-46295-0_12;http://dx.doi.org/10.1007/978-3-319-46295-0_12";10.1007/978-3-319-46295-0_12;The proliferation of cloud computing has enabled powerful virtualization capabilities and outsourcing strategies. Suitably, a vast variety of cloud resource configuration and management tools have emerged to meet this needs, whereby DevOps are empowered to design end-to-end and automated cloud management tasks that span across a selection of best-of-breed tools. However, inherent heterogeneities among resource description models and management capabilities of such tools pose fundamental limitations when managing complex and dynamic cloud resources. In this paper we thus propose the notion of “Domain-specific Models” – a higher-level model-driven approach for describing elementary and federated cloud resources as reusable knowledge artifacts over existing tools. We also propose a pluggable architecture to translate these artifacts into lower-level resource descriptions and management rules. This paper describes concepts, techniques and a prototypical implementation. Experiments on real-world federated cloud resources display significant improvements in productivity. As well as notably enhanced usability achieved by our approach in comparison to traditional techniques.;Interoperability, DevOps, Cloud resource management;;;
Journal Article;Boettiger C;An Introduction to Docker for Reproducible Research;SIGOPS Oper. Syst. Rev.;2015;49;1;71–79;;Association for Computing Machinery;New York, NY, USA;;;;2015-01;;0163-5980;"https://doi-org.proxy.bnl.lu/10.1145/2723872.2723882;http://dx.doi.org/10.1145/2723872.2723882";10.1145/2723872.2723882;As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.;;;;
Conference Paper;Akbar MA,Huang Z,Yu Z,Mehmood F,Hussain Y,Hamza M;Towards Continues Code Recommendation and Implementation System: An Initial Framework;;2020;;;439–444;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Evaluation and Assessment in Software Engineering;Trondheim, Norway;2020;9781450377317;;"https://doi-org.proxy.bnl.lu/10.1145/3383219.3383282;http://dx.doi.org/10.1145/3383219.3383282";10.1145/3383219.3383282;In the current era, the auto and reliable recommendation system plays a significant role in human life. The code recommender systems are being used in various source code databases to recommend the most suitable source code to the user. While code recommendation, the code analysis concerning 'code quality' and 'code implementation' is important to recommend the most reliable code by considering the objective of the user. The ultimate aim of this research work is to propose a code recommendation and implementation model using the characteristics of DevOps that assist in extracting, analyzing, implementing, and updating the recommender system continuously. The current study presents an initial framework of the proposed code recommender model. The design of the model is based on the data collected through literature review and by conducting an empirical study with experts. We believe that the proposed model will assist the researchers and practitioners to recommend the most secure and suitable source code according to their requirement.;Code recommendation system, Empirical investigation, DevOps;;;EASE '20
Conference Paper;Zerouali A,Cosentino V,Robles G,Gonzalez-Barahona JM,Mens T;ConPan: A Tool to Analyze Packages in Software Containers;;2019;;;592–596;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 16th International Conference on Mining Software Repositories;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/MSR.2019.00089;http://dx.doi.org/10.1109/MSR.2019.00089";10.1109/MSR.2019.00089;Deploying software packages and services into containers is a popular software engineering practice that increases portability and reusability. Docker, the most popular containerization technology, helps DevOps practitioners in their daily activities. Despite being successfully and increasingly employed, containers may include buggy and vulnerable packages that put at risk the environments in which the containers have been deployed. Existing quality and security monitoring tools provide only limited support to analyze Docker containers, thus forcing practitioners to perform additional manual work or develop adhoc scripts when the analysis goes beyond security purposes. This limitation also affects researchers desiring to empirically study the evolution dynamics of Docker containers and their contained packages. To overcome this limitation, we present ConPan, an automated tool to inspect the characteristics of packages in Docker containers, such as their outdatedness and other possible flaws (e.g., bugs and security vulnerabilities). ConPan comes with a CLI and API, and the analysis results can be presented to the user in a variety of formats.;docker, vulnerabilities, outdated software, containers, bugs;;;MSR '19
Conference Paper;Ghezzi C;Dependability of Adaptable and Evolvable Distributed Systems;;2016;;;36–60;;Springer-Verlag;Berlin, Heidelberg;;Advanced Lectures of the 16th International School on Formal Methods for the Quantitative Evaluation of Collective Adaptive Systems - Volume 9700;;2016;9783319340951;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-319-34096-8_2;http://dx.doi.org/10.1007/978-3-319-34096-8_2";10.1007/978-3-319-34096-8_2;This article is a tutorial on how to achieve software evolution and adaptation in a dependable manner, by systematically applying formal modelling and verification. It shows how software can be designed upfront to tolerate different sources of uncertainty that cause continuous future changes. If possible changes can be predicted, and their occurrence can be detected, it is possible to design the software to be self-adaptable. Otherwise, continuous evolution has to be supported and continuous flow into operation has to be ensured. In cases where systems are designed to be continuously running, it is necessary to support safe continuous software deployment that guarantees correct operation in the presence of dynamic reconfigurations. The approaches we survey here have been mainly developed in the context of the SMScom project, funded by the European Commission ---Programme IDEAS-ERC http://erc-smscom.dei.polimi.it/. --- and lead by the author. It is argued that these approaches fit well the current agile methods for development and operations that are popularized as DevOps.;Dynamic reconfiguration, Environment uncertainty, Requirements, Cyber-physical systems, Software evolution, Distributed, pervasive systems, ubiquitous;;;
Journal Article;Kim M,Mohindra A,Muthusamy V,Ranchal R,Salapura V,Slominski A,Khalaf R;Building Scalable, Secure, Multi-Tenant Cloud Services on IBM Bluemix;IBM J. Res. Dev.;2016;60;2–3;8:1–8:12;;IBM Corp.;USA;;;;2016-03;;0018-8646;"https://doi-org.proxy.bnl.lu/10.1147/JRD.2016.2516942;http://dx.doi.org/10.1147/JRD.2016.2516942";10.1147/JRD.2016.2516942;While an infrastructure-as-a-service cloud provides an economic alternative to managing information technology on premises, it does not provide ready-to-use advanced functionalities for solution management. A platform-as-a-service cloud (PaaS), on the other hand, provides application management and offers a catalog of services, which developers can easily use to host their solutions in the cloud. It also provides DevOps capabilities, which facilitate the management of a solution lifecycle. In this paper, we offer insights into the benefits and challenges that developers, who want to develop applications or offer services, would face in using a PaaS. We describe the step-by-step process of developing applications and offering services on IBM Bluemix, which is a PaaS cloud. We identify the key ingredients to achieve service scalability, security, and multi-tenancy. We also demonstrate the entire process through case studies of two Bluemix services: Rating-as-a-Service (RaaS) and the beta release of the Workflow Service.;;;;
Conference Paper;Melegati J,Chanin R,Wang X,Sales A,Prikladnicki R;Perceived Benefits and Challenges of Learning Startup Methodologies for Software Engineering Students;;2019;;;204–210;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 50th ACM Technical Symposium on Computer Science Education;Minneapolis, MN, USA;2019;9781450358903;;"https://doi-org.proxy.bnl.lu/10.1145/3287324.3287382;http://dx.doi.org/10.1145/3287324.3287382";10.1145/3287324.3287382;The need of skills other than technical from software developers is becoming evident. The DevOps movement is an example of that applied to operational tasks. Startup development methodologies focus on business activities in innovative organizations. Several universities offer courses based on these methodologies to software engineering students, mainly to improve their creativity, problem solving, and business skills. This paper investigates how software engineering students learned startup development methodologies and discusses what are the challenges and benefits in their learning process. We conducted a multi-method study in three different universities. The data was collected in two phases and analyzed using thematic analysis. Our study reveals that students realized the importance of collaboration with other courses and the importance of user involvement in development. However, students tend to over-simplify concepts, trying to adapt them to what they are familiar with. The results indicate the necessity of business education for technical students and directions for improvements.;software engineering education, empirical study, lean startup;;;SIGCSE '19
Conference Paper;Akbar MA,Huang Z,Yu Z,Mehmood F,Hussain Y,Hamza M;Towards Continues Code Recommendation and Implementation System: An Initial Framework;;2020;;;439–444;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Evaluation and Assessment in Software Engineering;Trondheim, Norway;2020;9781450377317;;"https://doi-org.proxy.bnl.lu/10.1145/3383219.3383282;http://dx.doi.org/10.1145/3383219.3383282";10.1145/3383219.3383282;In the current era, the auto and reliable recommendation system plays a significant role in human life. The code recommender systems are being used in various source code databases to recommend the most suitable source code to the user. While code recommendation, the code analysis concerning 'code quality' and 'code implementation' is important to recommend the most reliable code by considering the objective of the user. The ultimate aim of this research work is to propose a code recommendation and implementation model using the characteristics of DevOps that assist in extracting, analyzing, implementing, and updating the recommender system continuously. The current study presents an initial framework of the proposed code recommender model. The design of the model is based on the data collected through literature review and by conducting an empirical study with experts. We believe that the proposed model will assist the researchers and practitioners to recommend the most secure and suitable source code according to their requirement.;Code recommendation system, Empirical investigation, DevOps;;;EASE '20
Conference Paper;Zerouali A,Cosentino V,Robles G,Gonzalez-Barahona JM,Mens T;ConPan: A Tool to Analyze Packages in Software Containers;;2019;;;592–596;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 16th International Conference on Mining Software Repositories;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/MSR.2019.00089;http://dx.doi.org/10.1109/MSR.2019.00089";10.1109/MSR.2019.00089;Deploying software packages and services into containers is a popular software engineering practice that increases portability and reusability. Docker, the most popular containerization technology, helps DevOps practitioners in their daily activities. Despite being successfully and increasingly employed, containers may include buggy and vulnerable packages that put at risk the environments in which the containers have been deployed. Existing quality and security monitoring tools provide only limited support to analyze Docker containers, thus forcing practitioners to perform additional manual work or develop adhoc scripts when the analysis goes beyond security purposes. This limitation also affects researchers desiring to empirically study the evolution dynamics of Docker containers and their contained packages. To overcome this limitation, we present ConPan, an automated tool to inspect the characteristics of packages in Docker containers, such as their outdatedness and other possible flaws (e.g., bugs and security vulnerabilities). ConPan comes with a CLI and API, and the analysis results can be presented to the user in a variety of formats.;docker, vulnerabilities, outdated software, containers, bugs;;;MSR '19
Conference Paper;Wang Y;Characterizing Developer Behavior in Cloud Based IDEs;;2017;;;48–57;;IEEE Press;Markham, Ontario, Canada;;Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;;2017;9781509040391;;"https://doi-org.proxy.bnl.lu/10.1109/ESEM.2017.27;http://dx.doi.org/10.1109/ESEM.2017.27";10.1109/ESEM.2017.27;Background: Cloud based integrated development environments (IDEs) are rapidly gaining popularity for its native support and potential to accelerate DevOps. However, there is little research of how developers behave when interacting with these environments.Aims: To develop empirical knowledge about how developers behave when interacting with cloud based IDEs to deal with programming tasks at various difficulty levels.Method: We conducted a user study using a cloud based IDE, JazzHub. We collected and coded session trace data, self-reported effort and frustration levels, and screen recordings.Results: We built a Markov activity transition model that describes the transitions among common development activities such as coding, debugging, and searching for information. It also captures extended interactions with remote resources. We correlated activity transition with different code growth trajectories. Conclusion: The findings are an early step toward realizing the potential for enhanced interactions in cloud based IDEs. Our study provides empirical evidence that may inspire the future evolution of cloud based IDE designs and features.;developer behavior, cloud based IDE, code growth trajectory, activity transition;;;ESEM '17
Conference Paper;Chen HM,Kazman R,Haziyev S,Kropov V,Chtchourov D;Big Data as a Service: A Neo-Metropolis Model Approach for Innovation;;2016;;;5458–5467;;IEEE Computer Society;USA;;Proceedings of the 2016 49th Hawaii International Conference on System Sciences (HICSS);;2016;9780769556703;;"https://doi-org.proxy.bnl.lu/10.1109/HICSS.2016.674;http://dx.doi.org/10.1109/HICSS.2016.674";10.1109/HICSS.2016.674;Big data as a Service (BDaaS) provides a viable alternative to circumvent many obstacles in implementing a big data strategy. Many BDaaS vendors are providing cloud platforms utilizing microservices and DevOps technologies to enable big data analytics for organizations that seek cost-effective and elastic deployments. However, existing models of BDaaS are mostly proprietary, closed-world operations and this can limit the potential for innovation. In this article, we argue for a new model called the Neo-Metropolis model -- a variant of the Metropolis model -- that offers an organized, coherent set of open-world innovation opportunities for vendors as well as for the platform's edge customers. We identify Neo-Metropolis model characteristics and illustrate Neo-Metropolis principles for developing BDaaS using a case study of Cisco's Intercloud Analytics platform. The implications of the Neo-Metropolis model are far beyond just BDaaS and it is foreseen to be an important model for future service platform development.;;;;HICSS '16
Journal Article;Du M,Versteeg S,Schneider JG,Han J,Grundy J;Interaction Traces Mining for Efficient System Responses Generation;SIGSOFT Softw. Eng. Notes;2015;40;1;1–8;;Association for Computing Machinery;New York, NY, USA;;;;2015-02;;0163-5948;"https://doi-org.proxy.bnl.lu/10.1145/2693208.2693221;http://dx.doi.org/10.1145/2693208.2693221";10.1145/2693208.2693221;Software service emulation is an emerging technique for creating realistic executable models of server-side behaviour. It is particularly useful in quality assurance and DevOps, replicating production-like conditions for large-scale enterprise software systems. Existing approaches can automatically build client-server and server-server interaction models of complex software systems directly from analysis of service interaction trace data. However, when these interaction traces become large, searching an entire trace library to generate a run-time responses can become very slow. In this paper we describe a new technique that utilises data mining, specifically clustering algorithms, to pre-process large amounts of recorded interaction trace data. With the obtained clusters we facilitate efficient yet well-formed runtime response generation in our Enterprise System emulation environment. We evaluate our approach using two common application-layer protocols: LDAP and SOAP. Our experimental results show that by utilising clustering techniques in the pre-processing step, the response generation time can be reduced by 99% on average compared with existing approaches.;Automatic modelling, Traces clustering, Interaction emulation, Service emulation;;;
Conference Paper;Kitajima S,Sekiguchi A;Latest Image Recommendation Method for Automatic Base Image Update In Dockerfile;;2020;;;547–562;;Springer-Verlag;Berlin, Heidelberg;;Service-Oriented Computing: 18th International Conference, ICSOC 2020, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings;Dubai, United Arab Emirates;2020;9783030653095;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-65310-1_40;http://dx.doi.org/10.1007/978-3-030-65310-1_40";10.1007/978-3-030-65310-1_40;In recent years, an application deployment method using Docker container has attracted attention by researchers. Docker containers are fast and lightweight, can improve the portability and reproducibility of applications, and are thus often used with CI/CD and DevOps to accelerate the release cycle. However, if a Docker image is not updated, problems such as security risks or a lack of the latest features may occur. Therefore, in this paper, we propose a method for automatically updating the base image to the latest version when the image is considered to be the old version. Our method extracts the information of the base image from the Dockerfile described by the user, and infers the version of the base image that is considered to be certainly used. By applying our method, the user can regularly update the base image. Based on the evaluation result, we confirmed that our method recommends an approximately correct version to the users.;Automatic update, Semantic versioning, Dockerfile, PaaS;;;
Conference Paper;Marron M;Log++ Logging for a Cloud-Native World;;2018;;;25–36;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 14th ACM SIGPLAN International Symposium on Dynamic Languages;Boston, MA, USA;2018;9781450360302;;"https://doi-org.proxy.bnl.lu/10.1145/3276945.3276952;http://dx.doi.org/10.1145/3276945.3276952";10.1145/3276945.3276952;Logging is a fundamental part of the software development and deployment lifecycle but logging support is often provided as an afterthought via limited library APIs or third-party modules. Given the critical nature of logging in modern cloud, mobile, and IoT development workflows, the unique needs of the APIs involved, and the opportunities for optimization using semantic knowledge, we argue logging should be included as a central part of the language and runtime designs. This paper presents a rethinking of the logger for modern cloud-native workflows. Based on a set of design principles for modern logging we build a logging system, that supports near zero-cost for disabled log statements, low cost lazy-copying for enabled log statements, selective persistence of logging output, unified control of logging output across different libraries, and DevOps integration for use with modern cloud-based deployments. To evaluate these concepts we implemented the Log++ logger for Node.js hosted JavaScript applications.;Logging, JavaScript, Runtime Monitoring;;;DLS 2018
Conference Paper;John W,Moradi F,Pechenot B,Sköldström P;Meeting the Observability Challenges for VNFs in 5G Systems;;2017;;;1127–1130;;IEEE Press;Lisbon, Portugal;;2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM);;2017;;;"https://doi-org.proxy.bnl.lu/10.23919/INM.2017.7987445;http://dx.doi.org/10.23919/INM.2017.7987445";10.23919/INM.2017.7987445;5G mobile communication systems will need to accommodate a variety of use-cases, resulting in a diverse set of requirements. To meet these requirements, 5G systems take advantage of modern virtualization possibilities offered by Network Function Virtualization (NFV), enabling deployment agility and dynamicity of virtualized network functions. With the transformation of telecom towards virtualized environments, advanced observability possibilities gain increasing importance as one of the essential prerequisites, especially for successful DevOps operations. However, deployment agility also puts specific requirements on monitoring solutions in order to adapt automatically and continuously to frequent changes in service deployments. In this short-paper, we establish and discuss essential properties of observability systems for virtual network functions in a 5G context. We take these properties as guiding design principles for our software-defined monitoring framework and outline how to evolve our existing components towards a flexible, scalable, and programmable observability solution for microservice-based NFV with features for increased manageability.;;;;
Conference Paper;Cito J;Developer Targeted Analytics: Supporting Software Development Decisions with Runtime Information;;2016;;;892–895;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering;Singapore, Singapore;2016;9781450338455;;"https://doi-org.proxy.bnl.lu/10.1145/2970276.2975939;http://dx.doi.org/10.1145/2970276.2975939";10.1145/2970276.2975939;"Runtime information of deployed software has been used by business and operations units to make informed decisions under the term ``analytics"". However, decisions made by software engineers in the course of evolving software have, for the most part, been based on personal belief and gut-feeling. This could be attributed to software development being, for the longest time, viewed as an activity that is detached from the notion of operating software in a production environment. In recent years, this view has been challenged with the emergence of the DevOps movement, which aim is to promote cross-functional capabilities of development and operations activities within teams. This shift in process and mindset requires analytics tools that specifically target software developers. In this research, I investigate approaches to support developers in their decision-making by incorporating runtime information in source code and provide live feedback in IDEs by predicting the impact of code changes.";Performance Engineering, Software Analytics, Developer Targeted Analytics;;;ASE 2016
Conference Paper;Kopczyńska S,Craviee De Abreu Vieira D,Ochodek M;On Testing Security Requirements in Industry – A Survey Study;;2022;;;183–198;;Springer-Verlag;Berlin, Heidelberg;;Requirements Engineering: Foundation for Software Quality: 28th International Working Conference, REFSQ 2022, Birmingham, UK, March 21–24, 2022, Proceedings;Birmingham, United Kingdom;2022;9783030984632;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-98464-9_15;http://dx.doi.org/10.1007/978-3-030-98464-9_15";10.1007/978-3-030-98464-9_15;[Context and motivation] Among all categories of non-functional requirements, requirements concerning security are those that are specified frequently and tackled with care. [Question/problem] Constant changes in technologies used to develop software products drive to new and changing security requirements, which requires adapting of the approaches used to investigate if the security requirements are satisfied. And, thus, the question arises if and how security requirements are tested. [Principal ideas/results] We conducted an online survey among software development practitioners. 190 respondents from a wide variety of countries shared with us their experience concerning testing security requirements. [Contribution] We learned that security requirements are tested in the majority of surveyed projects. However, in some having high impact (economic, human health, environment) the dedicated effort is small or none. There are different techniques used from automated ones like static code analysis, to manual ones like code reviews. Most developers, QAs and DevOps are testing security. The greatest challenges concern culture, knowledge, and difficulty in specifying tests.;Testing, Survey, Security, Security requirements;;;
Conference Paper;Sharma A,Thung F,Kochhar PS,Sulistya A,Lo D;Cataloging GitHub Repositories;;2017;;;314–319;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering;Karlskrona, Sweden;2017;9781450348041;;"https://doi-org.proxy.bnl.lu/10.1145/3084226.3084287;http://dx.doi.org/10.1145/3084226.3084287";10.1145/3084226.3084287;GitHub is one of the largest and most popular repository hosting service today, having about 14 million users and more than 54 million repositories as of March 2017. This makes it an excellent platform to find projects that developers are interested in exploring. GitHub showcases its most popular projects by cataloging them manually into categories such as DevOps tools, web application frameworks, and game engines. We propose that such cataloging should not be limited only to popular projects. We explore the possibility of developing such cataloging system by automatically extracting functionality descriptive text segments from readme files of GitHub repositories. These descriptions are then input to LDA-GA, a state-of-the-art topic modeling algorithm, to identify categories. Our preliminary experiments demonstrate that additional meaningful categories which complement existing GitHub categories can be inferred. Moreover, for inferred categories that match GitHub categories, our approach can identify additional projects belonging to them. Our experimental results establish a promising direction in realizing automatic cataloging system for GitHub.;Genetic Algorithm, Latent Dirichlet Allocation, GitHub;;;EASE'17
Book;Tankersley C;Docker for Developers: Php[Architect] Print Edition;;2016;;;;;php[architect];Alexandria, VA, USA;;;;2016;9781940111360;;;;Docker For Developers is designed for developers who are looking at Docker as a replacement for development environments like virtualization, or devops people who want to see how to take an existing application and integrate Docker into that workflow. This book covers not only how to work with Docker, but how to make Docker work with your application. You will learn how to work with containers, what they are, and how they can help you as a developer. You will learn how Docker can make it easier to build, test, and deploy distributed applications. By running Docker and separating out the different concerns of your application you will have a more robust, scalable application. You will learn how to use Docker to deploy your application and make it a part of your deployment strategy, helping not only ensure your environments are the same but also making it easier to package and deliver.;;;;
Conference Paper;Winter J,Aniche M,Cito J,van Deursen A;Monitoring-Aware IDEs;;2019;;;420–431;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Tallinn, Estonia;2019;9781450355728;;"https://doi-org.proxy.bnl.lu/10.1145/3338906.3338926;http://dx.doi.org/10.1145/3338906.3338926";10.1145/3338906.3338926;Engineering modern large-scale software requires software developers to not solely focus on writing code, but also to continuously examine monitoring data to reason about the dynamic behavior of their systems. These additional monitoring responsibilities for developers have only emerged recently, in the light of DevOps culture. Interestingly, software development activities happen mainly in the IDE, while reasoning about production monitoring happens in separate monitoring tools. We propose an approach that integrates monitoring signals into the development environment and workflow. We conjecture that an IDE with such capability improves the performance of developers as time spent continuously context switching from development to monitoring would be eliminated. This paper takes a first step towards understanding the benefits of a possible monitoring-aware IDE. We implemented a prototype of a Monitoring-Aware IDE, connected to the monitoring systems of Adyen, a large-scale payment company that performs intense monitoring in their software systems. Given our results, we firmly believe that monitoring-aware IDEs can play an essential role in improving how developers perform monitoring.;IDE, software engineering, systems monitoring, devops, Integrated Development Environment, runtime monitoring;;;ESEC/FSE 2019
Book;Rajani R;Testing Practitioner Handbook;;2017;;;;;Packt Publishing;;;;;2017;9781788299541;;;;Gain insights into the latest technology and business trends within testing domains About This Book This book covers the latest trends that every Testing and QA professional should keep up-to-date with given the advancements in digital technologies. Master cutting-edge testing techniques for emerging areas such as IOT, Machine Learning, Cognitive. Best practices for Testing and Quality Assurance within several industry domains. Who This Book Is For This book is targeted at those working in the QA and Testing areas. The book does not cover testing basics, which QA professional are already familiar withfor example, writing a test plan or test case, and so on. What You Will Learn Understand the TCOE model, managed services, the structure of testing in Agile/DevOps engagements, factory models, and crowdsourcing Implement testing processes, practices, and automation tools in the Agile/DevOps life cycle Adapt to current technologies in social media, mobile, analytics and the Cloud Leverage cognitive intelligence/machine-learning, robotics, and the Internet of Things in testingHow key industries/domains (consumer products and retail, energy and utilities, healthcare, telecom, and automotive) adapt to digital transformation Future directions for the QA industry, consulting careers, testing profession, and professionalsIn Detail The book is based on the author's experience in leading and transforming large test engagements and architecting solutions for customer testing requirements/bids/problem areas. It targets the testing practitioner population and provides them with a single go-to place to find perspectives, practices, trends, tools, and solutions to test applications as they face the evolving digital world. This book is divided into five parts where each part explores different aspects of testing in the real world. The first module explains the various testing engagement models. You will then learn how to efficiently test code in different life cycles. The book discusses the different aspects of Quality Analysis consideration while testing social media, mobile, analytics, and the Cloud. In the last module, you will learn about futuristic technologies to test software. By the end of the book, you will understand the latest business and IT trends in digital transformation and learn the best practices to adopt for business assurance. Style and approach This book is a compilation of the latest business and IT trends in digital transformation & Tools and Best Practices that QA professionals need to adopt for business assurance.;;;;
Book;Campbell B;The Definitive Guide to AWS Infrastructure Automation: Craft Infrastructure-as-Code Solutions;;2019;;;;1st;Apress;USA;;;;2019;9781484253977;;;;"Discover the pillars of AWS infrastructure automation, starting with API-driven infrastructure concepts and its immediate benefits such as increased agility, automation of the infrastructure life cycle, and flexibility in experimenting with new architectures. With this base established, the book discusses infrastructure-as-code concepts in a general form, establishing principled outcomes such as security and reproducibility. Inescapably, we delve into how these concepts enable and underpin the DevOps movement. The Definitive Guide to AWS Infrastructure Automation begins by discussing services and tools that enable infrastructure-as-code solutions; first stop: AWS's CloudFormation service. You'll then cover the ever-expanding ecosystem of tooling emerging in this space, including CloudFormation wrappers such as Troposphere and orchestrators such as Sceptre, to completely independent third-party tools such as Terraform and Pulumi. As a bonus, you'll also work with AWS' newly-released CDK (Cloud Development Kit). You'll then look at how to implement modular, robust, and extensible solutions across a few examples -- in the process building out each solution with several different tools to compare and contrast the strengths and weaknesses of each. By the end of the journey, you will have gained a wide knowledge of both the AWS-provided and third-party ecosystem of infrastructure-as-code/provisioning tools, and the strengths and weaknesses of each. You'll possess a mental framework for how to craft an infrastructure-as-code solution to solve future problems based on examples discussed throughout the book. You'll also have a demonstrable understanding of the hands-on operation of each tool, situational appropriateness of each tool, and how to leverage the tool day to day. What You Will Learn Discover the technological and organizational benefits to infrastructure-as-code solutions; Examine the overall landscape of infrastructure-as-code tooling and solutions available to consumers of AWS services; See the strengths and weaknesses of these tools relative to one another as examined through hands-on implementation of several solutions; Gain hands-on experience, best practices, and tips and tricks learned through several years' real-world experience delivering solutions using these very tools in a wide variety of scenarios; Engineer solid solutions that leave room for new requirements and changes without requiring needless refactoring; Who This Book Is For DevOps engineers, cloud engineers and architects focused on the AWS ecosystem, software engineers/developers working within the AWS ecosystem, and engineering leaders looking for best practices.";;;;
Book;Ratan A;Practical Network Automation: Leverage the Power of Python and Ansible to Optimize Your Network;;2017;;;;;Packt Publishing;;;;;2017;9781788299466;;;;Key FeaturesGet started with network automation (and different automation tasks) with relevant use casesApply software design principles such as Continuous Integration and DevOps to your network toolkitGuides you through some best practices in automationBook DescriptionNetwork automation is the use of IT controls to supervise and carry out every-day network management functions. It plays a key role in network virtualization technologies and network functions. The book starts by providing an introduction to network automation, SDN, and its applications, which include integrating DevOps tools to automate the network efficiently. It then guides you through different network automation tasks and covers various data digging and reporting methodologies such as IPv6 migration, DC relocations, and interface parsing, all the while retaining security and improving data center robustness. The book then moves on to the use of Python and the management of SSH keys for machine-to-machine (M2M) communication, all followed by practical use cases. The book also covers the importance of Ansible for network automation including best practices in automation, ways to test automated networks using different tools, and other important techniques. By the end of the book, you will be well acquainted with the various aspects of network automation. What you will learnGet the detailed analysis of Network automation Trigger automations through available data factors Improve data center robustness and security through specific access and data digging Get an Access to APIs from Excel for dynamic reporting Set up a communication with SSH-based devices using netmiko Make full use of practical use cases and best practices to get accustomed with the various aspects of network automationAbout the Author Abhishek Ratan has around 15 years of technical experience in networking, automation, and various ITIL processes, and has worked in various roles in different organizations. As a network engineer, security engineer, automation engineer, TAC engineer, tech lead, and content writer, he has gained a wealth of experience during the 15 years of his career. Abhishek also has a deep interest in strategy game playing, and if he is not working on technical stuff, he is busy spending time on his strategy games. He is currently working as a Sr Automation Engineer at Service Now, learning, and expanding his automation skills in the ServiceNow platform. His earlier experience includes working for companies such as Microsoft, Symantec, and Navisite,which has given him exposure to various environments.;;;;
Conference Paper;Sampedro Z,Holt A,Hauser T;Continuous Integration and Delivery for HPC: Using Singularity and Jenkins;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Practice and Experience on Advanced Research Computing;Pittsburgh, PA, USA;2018;9781450364461;;"https://doi-org.proxy.bnl.lu/10.1145/3219104.3219147;http://dx.doi.org/10.1145/3219104.3219147";10.1145/3219104.3219147;Continuous integration, delivery, and deployment (CICD) is widely used in DevOps communities, as it allows for teams of all sizes to deploy rapidly-changing hardware and software resources quickly and confidently. In this paper, we will describe how University of Colorado Boulder Research Computing has adopted these practices on the RMACC Summit supercomputer [17] to allow system engineers and researchers alike to capitalize on the benefits of CICD-centric development workflows. We will introduce the topic of CICD at a high level and describe how such practices can ease common software management challenges for High-Performance Computing (HPC) resources. We will then document the infrastructure deployed for Summit, and explain how software such as Jenkins and Singularity enabled adaptation for an HPC environment. We will conclude with two case studies discussing the use of our CICD infrastructure: one case study from the perspective of a system engineer maintaining user-facing resources, and the other case study from the perspective of a researcher developing, maintaining, and using the MFiX-Exa codebase.;continuous deployment, containers, MFIX-Exa, continuous delivery, software automation, Singularity, software builds, continuous integration;;;PEARC '18
Conference Paper;Loseva E,Obeid A,Richter H,Backes R,Eichhorn D;Fixit - A Semi-Automatic Software Deployment Tool for Arbitrary Targets;;2018;;;16–24;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2018 International Conference on Information Science and System;Jeju, Republic of Korea;2018;9781450364218;;"https://doi-org.proxy.bnl.lu/10.1145/3209914.3209938;http://dx.doi.org/10.1145/3209914.3209938";10.1145/3209914.3209938;"The deployment of software packages becomes more and more difficult. Thus Canonical Ltd. has created a framework called ""JuJu"" that serves as a DevOps toolchain. JuJu allows an integrated software development, deployment and operation of software packages. Additionally Canocial provided hundreds of open-source JuJu-maintained software packages in an own online store for download. However, our tests revealed that only 14 % of 35 picked packages from the Canonical's JuJu charm store really be installed as they are. The reason is that many of them are sensitive against mismatches of what is contained in the relevant JuJu files and what exists as target hardware at the customer. Because of that, a new concept and tool called Fixit was created by us for the semi-automatic software-deployment of JuJu software packages onto arbitrary hardware and software environments such as Windows and Linux operating systems. Fixit improves the quota of successful first-try installations from 14 to 69 %. This is accomplished by semi-automatic analysis and transformation of the package source codes.";Software deployment, DevOps, system configuration, JuJu, source code transformation;;;ICISS '18
Book;Rhett J;Learning Puppet 4: A Guide to Configuration Management and Automation;;2016;;;;1st;O'Reilly Media, Inc.;;;;;2016;9781491907665;;;;If youre a system administrator, developer, or site reliability engineer responsible for handling hundreds or even thousands of nodes in your network, the Puppet configuration management tool will make your job a whole lot easier. This practical guide shows you what Puppet does, how it works, and how it can provide significant value to your organization. Through hands-on tutorials, DevOps engineer Jo Rhett demonstrates how Puppet manages complex and distributed components to ensure service availability. Youll learn how to secure configuration consistency across servers, clients, your router, and even that computer in your pocket by setting up your own testing environment. Learn exactly what Puppet is, why it was created, and what problems it solvesTailor Puppet to your infrastructure with a design that meets your specific needsWrite declarative Puppet policies to produce consistency in your systemsBuild, test, and publish your own Puppet modulesManage network devices such as routers and switches with puppet device and integrated Puppet agentsScale Puppet servers for high availability and performanceExplore web dashboards and orchestration tools that supplement and complement Puppet;;;;
Book;Humble J,Molesky J,O'Reilly B;Lean Enterprise: How High Performance Organizations Innovate at Scale;;2015;;;;1st;O'Reilly Media, Inc.;;;;;2015;9781449368425;;;;How well does your organization respond to changing market conditions, customer needs, and emerging technologies when building software-based products? This practical guide presents Lean and Agile principles and patterns to help you move fast at scaleand demonstrates why and how to apply these methodologies throughout your organization, rather than with just one department or team.Through case studies, youll learn how successful enterprises have rethought everything from governance and financial management to systems architecture and organizational culture in the pursuit of radically improved performance. Adopting Lean will take time and commitment, but its vital for harnessing the cultural and technical forces that are accelerating the rate of innovation.Discover how Lean focuses on people and teamwork at every level, in contrast to traditional management practicesApproach problem-solving experimentally, by exploring solutions, testing assumptions, and getting feedback from real usersLead and manage large-scale programs in a way that empowers employees, increases the speed and quality of delivery, and lowers costsLearn how to implement ideas from the DevOps and Lean Startup movements even in complex, regulated environments;;;;
Conference Paper;Truong HL;Dynamic IoT Data, Protocol, and Middleware Interoperability with Resource Slice Concepts and Tools: Tutorial;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th International Conference on the Internet of Things;Santa Barbara, California, USA;2018;9781450365642;;"https://doi-org.proxy.bnl.lu/10.1145/3277593.3277642;http://dx.doi.org/10.1145/3277593.3277642";10.1145/3277593.3277642;Dealing with interoperability in the IoT domain is a complex matter that requires various techniques for tackling data, protocol and middleware interoperability. We cannot solve IoT interoperability problems by just developing (new) software components and (semantic) data models. In this tutorial, we will present interoperability techniques for complex IoT Cloud applications by leveraging dynamic solutions of provisioning and reconfiguring of IoT data processing pipelines, protocol bridges, IoT middleware and cloud services. First, the tutorial will examine cross-layered, cross-system inter-operability issues and present a DevOps IoT Interoperability approach for defining metadata, selecting resources and software artifacts, and provisioning and connecting resources to create various potential solutions for IoT Cloud interoperability using resource slice concepts. Second, the tutorial will present techniques for dynamically provisioning data pipelines, middleware services, protocol adapters and custom solutions to address cross-layered, cross-system interoperability for IoT Cloud applications. Such solutions also allow dynamic reconfiguration of resources to add/remove interoperability support. We will present the concepts and techniques with hands-on examples using our research tools rsiHub and IoTCloudSamples.;cloud computing, IoT interoperability, resource slice;;;IOT '18
Conference Paper;Atouani A,Kirchhof JC,Kusmenko E,Rumpe B;Artifact and Reference Models for Generative Machine Learning Frameworks and Build Systems;;2021;;;55–68;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 20th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences;Chicago, IL, USA;2021;9781450391122;;"https://doi-org.proxy.bnl.lu/10.1145/3486609.3487199;http://dx.doi.org/10.1145/3486609.3487199";10.1145/3486609.3487199;Machine learning is a discipline which has become ubiquitous in the last few years. While the research of machine learning algorithms is very active and continues to reveal astonishing possibilities on a regular basis, the wide usage of these algorithms is shifting the research focus to the integration, maintenance, and evolution of AI-driven systems. Although there is a variety of machine learning frameworks on the market, there is little support for process automation and DevOps in machine learning-driven projects. In this paper, we discuss how metamodels can support the development of deep learning frameworks and help deal with the steadily increasing variety of learning algorithms. In particular, we present a deep learning-oriented artifact model which serves as a foundation for build automation and data management in iterative, machine learning-driven development processes. Furthermore, we show how schema and reference models can be used to structure and maintain a versatile deep learning framework. Feasibility is demonstrated on several state-of-the-art examples from the domains of image and natural language processing as well as decision making and autonomous driving.;compiler, training, build systems, artifact models, reference models, artificial intelligence, machine learning, metamodeling;;;GPCE 2021
Conference Paper;Kersten M;Analyzing Flow to Measure Value in Software Delivery;;2019;;;3;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICSE-Companion.2019.00022;http://dx.doi.org/10.1109/ICSE-Companion.2019.00022";10.1109/ICSE-Companion.2019.00022;Projects, org charts, and software architecture are the best representations of value creation we have today. They are insufficient to support the scale and complexity of the software that is powering more and more of the world economy. In this talk, Dr. Kersten will propose a new set of abstractions for understanding and improving how software is built. He will introduce the concept of Value Stream Networks, which provide a set of models that span beyond the software architecture to include all of the artifacts involved in building software, from business idea to customer support. He will then show how we can visualize and operate on this new model in order to gain insights into the ground truth of what flows through organizations delivering software, and how we can improve that flow using the Flow Framework™. Kersten will summarize his experiences from open source, building a successful startup, and supporting some of the largest Agile and DevOps transformations in order to propose ideas for the research and practices still needed to better understand and manage software delivery at scale.;;;;ICSE '19
Book;Tankersley C;Docker for Developers, 2nd Edition: Php[Architect] Print Edition;;2017;;;;;php[architect];Alexandria, VA, USA;;;;2017;9781940111568;;;;Docker For Developers is designed for developers who are looking at Docker as a replacement for development environments like virtualization, or devops people who want to see how to take an existing application and integrate Docker into that workflow. This book covers not only how to work with Docker, but how to make Docker work with your application. This revised and expanded edition includes creating custom images, working with Docker Compose and Docker Machine, managing Logs, and 12-factor applications. You will learn how to work with containers, what they are, and how they can help you as a developer. You will learn how Docker can make it easier to build, test, and deploy distributed applications. By running Docker and separating out the different concerns of your application you will have a more robust, scalable application. You will learn how to use Docker to deploy your application and make it a part of your deployment strategy, helping not only ensure your environments are the same but also making it easier to package and deliver.;;;;
Conference Paper;Makki M,Van Landuyt D,Joosen W;Automated Workflow Regression Testing for Multi-Tenant SaaS: Integrated Support in Self-Service Configuration Dashboard;;2016;;;70–73;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation;Seattle, WA, USA;2016;9781450344012;;"https://doi-org.proxy.bnl.lu/10.1145/2994291.2994302;http://dx.doi.org/10.1145/2994291.2994302";10.1145/2994291.2994302;Single-instance multi-tenant SaaS applications allow tenant administrators to (extensively) customize the application according to the requirements of their organizations. In the specific case of workflow-driven applications, the SaaS provider may offer a set of pre-defined workflow activities and leave their composition to the tenant administrators. In such cases, the tenant administrator can instantiate new variants of the application without deploying new software. This effectively makes these tenant administrators part of the DevOps team, and in turn creates the need for the SaaS provider to provide them with Quality Assurance tool support. One such tool is a regression testing framework that allows them to make sure that a new version of a workflow can behave similarly as to a successful execution of a previous version. This paper highlights the potential and discusses the inherent challenges of running regression tests on workflows in the production environment of a multi-tenant SaaS application and outlines a solution in terms of architecture and automation techniques for mocking and regression detection under control of tenant administrators.;Software-as-a-Service, Application-level Multi-tenancy, Automated Regression Testing;;;A-TEST 2016
Conference Paper;Staples M,Zhu L,Grundy J;Continuous Validation for Data Analytics Systems;;2016;;;769–772;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 38th International Conference on Software Engineering Companion;Austin, Texas;2016;9781450342056;;"https://doi-org.proxy.bnl.lu/10.1145/2889160.2889207;http://dx.doi.org/10.1145/2889160.2889207";10.1145/2889160.2889207;From a future history of 2025: Continuous development is common for build/test (continuous integration) and operations (devOps). This trend continues through the lifecycle, into what we call 'devUsage': continuous usage validation. In addition to ensuring systems meet user needs, organisations continuously validate their legal and ethical use. The rise of end-user programming and multi-sided platforms exacerbate validation challenges. A separate trend is the specialisation of software engineering for technical domains, including data analytics. This domain has specific validation challenges. We must validate the accuracy of statistical models, but also whether they have illegal or unethical biases. Usage needs addressed by machine learning are sometimes not specifiable in the traditional sense, and statistical models are often 'black boxes'. We describe future research to investigate solutions to these devUsage challenges for data analytics systems. We will adapt risk management and governance frameworks previously used for software product qualities, use social network communities for input from aligned stakeholder groups, and perform cross-validation using autonomic experimentation, cyber-physical data streams, and online discursive feedback.;software validation, ethics, continuous development, devOps, machine learning, governance, data analytics;;;ICSE '16
Conference Paper;He X,Tu Z,Liu L,Xu X,Wang Z;Optimal Evolution Planning And Execution for Multi-Version Coexisting Microservice Systems;;2020;;;3–18;;Springer-Verlag;Berlin, Heidelberg;;Service-Oriented Computing: 18th International Conference, ICSOC 2020, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings;Dubai, United Arab Emirates;2020;9783030653095;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-65310-1_1;http://dx.doi.org/10.1007/978-3-030-65310-1_1";10.1007/978-3-030-65310-1_1;A microservice-based system is composed of a set of microservices that are developed and deployed independently for agile DevOps. Intensive and iterative adaptations/upgrades of microservices are essential for such systems to adapt to user requirement changes, and as a consequence, result in the phenomenon of “multi-version microservice coexistence” in a system. Besides traditional API-based functional dependencies between different microservices, there appear complicated dependencies between different versions of difference microservices. The complicated dependencies dramatically deteriorate the maintainability of microservice systems, especially when systems evolve to adapt to user requirement changes. To meet this challenge, a version dependency model is proposed for describing the complex dependencies between different versions of microservices, and a greedy-based optimization algorithm is developed for generating an optimal evolution plan. A programming framework (MF4MS) and cloud-edge based infrastructure (MI4MS) are implemented to facilitate microservice systems to automatically execute the evolution plan. Experiments show that the proposed approach performs well to cope with self-adaptation in the situation where complicated version dependencies exist.;Version dependency, Multi-version coexistence, Microservice systems, User requirement changes, Self adaptation;;;
Conference Paper;Farshchi M,Schneider JG,Weber I,Grundy J;Experience Report: Anomaly Detection of Cloud Application Operations Using Log and Cloud Metric Correlation Analysis;;2015;;;24–34;;IEEE Computer Society;USA;;Proceedings of the 2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE);;2015;9781509004065;;"https://doi-org.proxy.bnl.lu/10.1109/ISSRE.2015.7381796;http://dx.doi.org/10.1109/ISSRE.2015.7381796";10.1109/ISSRE.2015.7381796;Failure of application operations is one of the main causes of system-wide outages in cloud environments. This particularly applies to DevOps operations, such as backup, redeployment, upgrade, customized scaling, and migration that are exposed to frequent interference from other concurrent operations, configuration changes, and resources failure. However, current practices fail to provide a reliable assurance of correct execution of these kinds of operations. In this paper, we present an approach to address this problem that adopts a regression-based analysis technique to find the correlation between an operation's activity logs and the operation activity's effect on cloud resources. The correlation model is then used to derive assertion specifications, which can be used for runtime verification of running operations and their impact on resources. We evaluated our proposed approach on Amazon EC2 with 22 rounds of rolling upgrade operations while other types of operations were running and random faults were injected. Our experiment shows that our approach successfully managed to raise alarms for 115 random injected faults, with a precision of 92.3%.;;;;ISSRE '15
Journal Article;Kuhrmann M,O'Connor RV,Houston D,Hebig R,Raffo D;Summary of the International Conference on Software AndSystem Processes (ICSSP 2018);SIGSOFT Softw. Eng. Notes;2019;43;4;48–51;;Association for Computing Machinery;New York, NY, USA;;;;2019-01;;0163-5948;"https://doi-org.proxy.bnl.lu/10.1145/3282517.3302403;http://dx.doi.org/10.1145/3282517.3302403";10.1145/3282517.3302403;"The International Conference on Software and System Processes (ICSSP), continuing the success of Software Process Workshop (SPW), the Software Process Modeling and Simulation Workshop (ProSim) and the International Conference on Software Process (ICSP) conference series, has become the established premier event in the eld of software and systems engineering processes. It provides a leading forum for the exchange of research outcomes and industrial best-practices in process development from software and systems disciplines. ICSSP 2018 was held in Gothenburg, Sweden, 26-27 May 2018, co-located with the 40th International Conference on Software Engineering (ICSE). The theme of ICSSP 2018 was studying Demands on Processes, Processes on Demand"" by recognizing the demands on processes that include the need for both well-developed plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model-based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise-level architectures. Papers presented at ICSSP discussed these issues across di erent domains, providing concepts, evidence, and experiences.";hybrid systems development, continuous development, project management, agile methods, deployment, product quality, data science;;;
Journal Article;Kehrer S,Blochinger W;TOSCA-Based Container Orchestration on Mesos;Comput. Sci.;2018;33;3–4;305–316;;Springer-Verlag;Berlin, Heidelberg;;;;2018-08;;1865-2034;"https://doi-org.proxy.bnl.lu/10.1007/s00450-017-0385-0;http://dx.doi.org/10.1007/s00450-017-0385-0";10.1007/s00450-017-0385-0;Container virtualization evolved into a key technology for deployment automation in line with the DevOps paradigm. Whereas container management systems facilitate the deployment of cloud applications by employing container-based artifacts, parts of the deployment logic have been applied before to build these artifacts. Current approaches do not integrate these two deployment phases in a comprehensive manner. Limited knowledge on application software and middleware encapsulated in container-based artifacts leads to maintainability and configuration issues. Besides, the deployment of cloud applications is based on custom orchestration solutions leading to lock-in problems. In this paper, we propose a two-phase deployment method based on the TOSCA standard. We present integration concepts for TOSCA-based orchestration and deployment automation using container-based artifacts. Our two-phase deployment method enables capturing and aligning all the deployment logic related to a software release leading to better maintainability. Furthermore, we build a container management system, which is composed of a TOSCA-based orchestrator on Apache Mesos, to deploy container-based cloud applications automatically.;Two-phase deployment, DevOps, Apache Mesos, TOSCA, Container orchestration, Container-based artifacts;;;
Conference Paper;Osses F,Márquez G,Astudillo H;Exploration of Academic and Industrial Evidence about Architectural Tactics and Patterns in Microservices;;2018;;;256–257;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings;Gothenburg, Sweden;2018;9781450356633;;"https://doi-org.proxy.bnl.lu/10.1145/3183440.3194958;http://dx.doi.org/10.1145/3183440.3194958";10.1145/3183440.3194958;"Microservices are quickly becoming an outstanding architectural choice in the service-oriented software industry. This approach proposes to develop each application as a collection of small services, each running on its process and inter-communicating with lightweight mechanisms. Currently, there is still no clear perspective of emerging recurrent solutions (architectural patterns) or design decisions (architectural tactics) in microservices both in industry and academia. This article describes a systematic review of the academic and industrial literature on architectural patterns and tactics proposed for microservices. The study reported: 44 architectural patterns of microservices in academia and 80 in the industry; architectural tactics related to microservices dependent on other disciplines; and it was also found that most of architectural patterns and tactics are associated to five quality attributes: scalability, flexibility, testability, performance, and elasticity. Added to that results, it was noticed that most microservices in the academic area are reported in evidence related to DevOps and IoT, but the industry is not interested in associating disciplines. Finally, a new proposal of microservices pattern taxonomy is suggested.";architectural tactics, systematic literature review, industry, taxonomy, architectural patterns, academy, microservices;;;ICSE '18
Book;Huerga JR,Kovalevych A,Buchanan R,Lee D,Mooy C,Bruhiere X;Kong: Becoming a King of API Gateways;;2018;;;;;Bleeding Edge Press;;;;;2018;9781939902566;;;;This book is useful for IT architects, DevOps engineers, CTOs and security experts willing to understand how to use Kong to create and expose APIs. Even if you are not already familiar with Kong, it will only take a few minutes to create your first API. By the end of this book, you will understand how to: Use an API gateway to simplify and improve the security of your microservices architecture Write Kong plugins with Lua Deploy Kong and Cassandra in a multi-region environment Use load balancing features You dont need to know Kong to read this book! You only need to have a basic understanding of REST, JSON and HTTP, but you dont need an in-depth knowledge because Kongs mission is to provide easy API publishing. You will also need a modern browser: Google Chrome, Mozilla Firefox, Microsoft Edge or Apple Safari. All of the code for the sample project in this book can be found at: https://github.com/backstopmedia/kong-book-example;;;;
Book;Ryan M;AWS System Administration: Best Practices for Sysadmins in the Amazon Cloud;;2015;;;;1st;O'Reilly Media, Inc.;;;;;2015;9781449342579;;;;Building and deploying infrastructure with Amazon Web Services is simply not the same as dealing with static servers. With tools that let you automatically replace instances and scale up and down in response to demand, its actually more like programming than traditional system administrationand ideal for a DevOps environment. This comprehensive guide shows developers and system administrators alike how to configure and manage AWS services, such as Cloud Formation, OpsWorks, Elastic Load Balancing, and Route 53. System administrators will learn how to integrate their favorite tools and processes, while developers will pick up enough system administration knowledge to build a robust and resilient AWS application infrastructure. Launch instances with EC2 or Cloud Formation Apply AWS security tools at the beginning of your project Learn configuration management with OpsWorks and Puppet Deploy applications with Auto Scaling and Elastic Load Balancing Explore methods to deploy application and infrastructure updates Reuse resources to save time on development and operations Learn strategies for managing log files in AWSConfigure a cloud-aware DNS service with Route 53Use Cloud Watch or traditional tools to monitor your application;;;;
Book;Goasguen S;60 Recipes for Apache CloudStack: Using the CloudStack Ecosystem;;2014;;;;1st;O'Reilly Media, Inc.;;;;;2014;9781491910139;;;;Planning to deploy and maintain a public, private, or hybrid cloud service? This cookbooks handy how-to recipes help you quickly learn and install Apache CloudStack, along with several API clients, API wrappers, data architectures, and configuration management technologies that work as part of CloudStacks ecosystem.Youll learn how to use Vagrant, Ansible, Chef, Fluentd, Libcloud, and several other open source tools that let you build and operate CloudStack better and faster. If youre an experienced programmer, system administrator, or DevOps practitioner familiar with bash, Git, package management, and some Python, youre ready to go.Learn basic CloudStack installation from source, including features such as DevCloud, the CloudStack sandboxGet a step-by-step guide for installing CloudStack from packages on Ubuntu 14.04 using KVMWrite your own applications on top of the CloudStack API, using CloudMonkey, Libcloud, jclouds, and CloStackExpose different APIs on CloudStack with the EC2Stack, Boto, and Eutester API wrappersDeploy applications easily, using Puppet, Salt, Ansible, Chef, and VagrantDive into cloud monitoring and storage with RiakCS, Fluentd, and Apache Whirr;;;;
Book;Tanasseri N,Rai R;Microservices with Azure: Build Highly Maintainable and Scalable Enterprise-Grade Apps;;2017;;;;;Packt Publishing;;;;;2017;9781787121140;;;;Architect enterprise-grade, Microservice-based solutions using Microsoft Azure Service Fabric. About This Book Explore architectural patterns for building modern day Microservice-based systems Learn about Microsoft Service Fabric as a platform to host distributed Microservices Discover multiple options for hosting Microservices on heterogeneous, cross-platform environmentsLearn to configure Azure Service Fabric clusters for enterprise-grade service deployments Who This Book Is ForThe book is aimed at IT architects, system administrators, and DevOps engineers who have a basic knowledge of the Microsoft Azure platform and are working on, or are curious about, the concepts of Microservices and Microservice architecture. What You Will Learn Understand the basics of Microservices and how Microsoft Azure fits into the equation Master Azure Service Fabric architecture and services Explore Azure Service Fabric application programming models Comprehensive study of various architecture patterns for building enterprise-grade Microservices Manage and deploy Microservices on Azure Service Fabric An insight into the future of Microservices with containers and serverless computingIn Detail Microsoft Azure is rapidly evolving and is widely used as a platform on which you can build Microservices that can be deployed on-premise and on-cloud heterogeneous environments through Microsoft Azure Service Fabric. This book will help you understand the concepts of Microservice application architecture and build highly maintainable and scalable enterprise-grade applications using the various services in Microsoft Azure Service Fabric. We will begin by understanding the intricacies of the Microservices architecture and its advantages over the monolithic architecture and Service Oriented Architecture (SOA) principles. We will present various scenarios where Microservices should be used and walk you through the architectures of Microservice-based applications. Next, you will take an in-depth look at Microsoft Azure Service Fabric, which is the best-in-class platform for building Microservices. You will explore how to develop and deploy sample applications on Microsoft Azure Service Fabric to gain a thorough understanding of it. Building Microservice-based application is complicated. Therefore, we will take you through several design patterns that solve the various challenges associated with realizing the Microservices architecture in enterprise applications. Each pattern will be clearly illustrated with examples that you can keep referring to when designing applications. Finally, you will be introduced to advanced topics such as Serverless computing and DevOps using Service Fabric, to help you undertake your next venture with confidence. Style and approach This book introduces its readers to the concept of Microservices and Microsoft Azure Service Fabric as a distributed platform to host enterprise-grade Microservices. It then addresses common architectural challenges associated with the Microservice architecture, using proven architectural patterns.;;;;
Book;Odika C;Microsoft Operations Management Suite Cookbook: Enhance Your Management Experience and Capabilities across Your Cloud and on-Premises Environments with Microsoft OMS;;2018;;;;;Packt Publishing;;;;;2018;9781786469090;;;;Manage on-premises and cloud IT assets from one console Key Features Empower yourself with practical recipes to collect and analyze operational insights on Windows and Linux servers in your on premises datacenters and in any public cloud environments such as Azure and AWS. Build capabilities through practical tasks and techniques to collect and analyze machine dataAddress business challenges and discover means to accommodate workloads and instances in a low cost mannerBook Description Microsoft Operations Management Suite Cookbook begins with an overview of how to hit the ground running with OMS insights and analytics. Next, you will learn to search and analyze data to retrieve actionable insights, review alert generation from the analyzed data, and use basic and advanced Log search queries in Azure Log Analytics. Following this, you will explore some other management solutions that provide functionality related to workload assessment, application dependency mapping, automation and configuration management, and security and compliance. You will also become well versed with the data protection and recovery functionalities of OMS Protection and Recovery, and learn how to use Azure Automation components and features in OMS. Finally you will learn how to evaluate key considerations for using the Security and Audit solution, and working with Security and Compliance in OMS. By the end of the book, you will be able to configure and utilize solution offerings in OMS, understand OMS workflows, how to unlock insights, integrate capabilities into new or existing workflows, manage configurations, and automate tasks and processes. What you will learn Understand the important architectural considerations and strategies for OMS Use advanced search query commands and strategies to derive insights from indexed data Make use of alerting in OMS such as alert actions, and available options for the entire lifecycle of the alertDiscover some practical tips for monitoring Azure container service containers and clusters using OMS Review and use the backup options available through the Azure backup service, as well as data recovery options available through Azure Site Recovery (ASR) Understand how to advance important DevOps concepts within your IT organization Learn how to manage configurations and automate process Who This Book Is ForThis book is written for the IT professional and general reader who is interested in technology themes such as DevOps, Big Data Analytics, and digital transformation concepts. Azure and other cloud platform administrators, cloud professionals, and technology analysts who would like to solve everyday problems quickly and efficiently with hybrid management tools available in the Microsoft product ecosystem will derive much value from this book. Prior experience with OMS 2012 would be helpful.;;;;
Conference Paper;Cleveland SB,Dooley R,Perry D,Stubbs J,Fonner JM,Jacobs GA;Building Science Gateway Infrastructure in the Middle of the Pacific and Beyond: Experiences Using the Agave Deployer and Agave Platform to Build Science Gateways;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Practice and Experience on Advanced Research Computing;Pittsburgh, PA, USA;2018;9781450364461;;"https://doi-org.proxy.bnl.lu/10.1145/3219104.3219151;http://dx.doi.org/10.1145/3219104.3219151";10.1145/3219104.3219151;In order to increase support for diverse projects amongst a wide range of research areas in accessing advanced computational and data resources, both local and national, the University of Hawai'i at Manoa (UH) and the University of Melbourne, Australia (Melbourne) partnered with the Texas Advanced Computing Center (TACC) to utilize the Agave platform. However, due to distance and the unique geographical locations of Hawai'i and Australia it was necessary to setup local Agave platform instances to provide responsive and robust middleware against which flexible science gateways could be constructed. To lower the entry barrier, required staff, and time required to stand up a local infrastructure, UH became the first external site to use the Agave Deployer which provides a combination of DevOps automation tools and containers to deploy and maintain a functional local Agave authentication/authorization, core science, and data persistence API instances. UH worked with TACC on testing the initial release of the Agave Deployer to provision the local UH infrastructure and later assisted Melbourne in adopting the Agave Deployer to stand up their infrastructure. We present the experiences and lessons learned in deploying and developing science gateway infrastructure and applications at these two institutions.;ACM proceedings, HPC, Science Gateway;;;PEARC '18
Conference Paper;Császár A,John W,Kind M,Meirosu C,Pongrácz G,Staessens D,Takács A,Westphal FJ;Unifying Cloud and Carrier Network: EU FP7 Project UNIFY;;2013;;;452–457;;IEEE Computer Society;USA;;Proceedings of the 2013 IEEE/ACM 6th International Conference on Utility and Cloud Computing;;2013;9780769551524;;"https://doi-org.proxy.bnl.lu/10.1109/UCC.2013.89;http://dx.doi.org/10.1109/UCC.2013.89";10.1109/UCC.2013.89;"Telecom providers struggle with low service flexibility, increasing complexity and related costs. Although ""cloud"" has been an active field of research, there is currently little integration between the vast networking assets and data centres of telecom providers. UNIFY considers the entire network, from home networks up to data centre, as a ""unified production environment"" supporting virtualization, programmability and automation and guarantee a high level of agility for network operations and for deploying new, secure and quality services, seamlessly instantiatable across the entire infrastructure. UNIFY focuses on the required enablers and will develop an automated, dynamic service creation platform, leveraging fine-granular service chaining. A service abstraction model and a proper service creation language and a global orchestrator, with novel optimization algorithms, will enable the automatic optimal placement of networking, computing and storage components across the infrastructure. New management technologies based on experience from DCs, called Service Provider DevOps, will be developed and integrated into the orchestration architecture to cope with the dynamicity of services. The applicability of a universal node based on commodity hardware will be evaluated in order to support both network functions and traditional data centre workloads, with an investigation of the need of hardware acceleration.";SDN, service chaining, NFV, UNIFY;;;UCC '13
Book;Senthilvel G,Khan OM,Qureshi HA;Enterprise Application Architecture with .NET Core;;2017;;;;;Packt Publishing;;;;;2017;9781786468888;;;;Architect and design highly scalable, robust, clean and highly performant applications in .NET CoreAbout This BookIncorporate architectural soft-skills such as DevOps and Agile methodologies to enhance program-level objectives Gain knowledge of architectural approaches on the likes of SOA architecture and microservices to provide traceability and rationale for architectural decisions Explore a variety of practical use cases and code examples to implement the tools and techniques described in the book Who This Book Is ForThis book is for experienced .NET developers who are aspiring to become architects of enterprise-grade applications, as well as software architects who would like to leverage .NET to create effective blueprints of applications. What You Will LearnGrasp the important aspects and best practices of application lifecycle management Leverage the popular ALM tools, application insights, and their usage to monitor performance, testability, and optimization tools in an enterprise Explore various authentication models such as social media-based authentication, 2FA and OpenID Connect, learn authorization techniques Explore Azure with various solution approaches for Microservices and Serverless architecture along with Docker containers Gain knowledge about the recent market trends and practices and how they can be achieved with .NET Core and Microsoft tools and technologies In Detail If you want to design and develop enterprise applications using .NET Core as the development framework and learn about industry-wide best practices and guidelines, then this book is for you. The book starts with a brief introduction to enterprise architecture, which will help you to understand what enterprise architecture is and what the key components are. It will then teach you about the types of patterns and the principles of software development, and explain the various aspects of distributed computing to keep your applications effective and scalable. These chapters act as a catalyst to start the practical implementation, and design and develop applications using different architectural approaches, such as layered architecture, service oriented architecture, microservices and cloud-specific solutions. Gradually, you will learn about the different approaches and models of the Security framework and explore various authentication models and authorization techniques, such as social media-based authentication and safe storage using app secrets. By the end of the book, you will get to know the concepts and usage of the emerging fields, such as DevOps, BigData, architectural practices, and Artificial Intelligence. Style and approach Filled with examples and use cases, this guide takes a no-nonsense approach to show you the best tools and techniques required to become a successful software architect.;;;;
Book Chapter;Philippe J,Coullon H,Tisi M,Sunyé G;Towards Transparent Combination of Model Management Execution Strategies for Low-Code Development Platforms;;2020;;;;;Association for Computing Machinery;New York, NY, USA;Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings;;;2020;9781450381352;;https://doi-org.proxy.bnl.lu/10.1145/3417990.3420206;;Low-code development platforms are taking an important place in the model-driven engineering ecosystem, raising new challenges, among which transparent efficiency or scalability. Indeed, the increasing size of models leads to difficulties in interacting with them efficiently. To tackle this scalability issue, some tools are built upon specific computational strategies exploiting reactivity, or parallelism. However, their performances may vary depending on the specific nature of their usage. Choosing the most suitable computational strategy for a given usage is a difficult task which should be automated. Besides, the most efficient solutions may be obtained by the use of several strategies at the same time. This paper motivates the need for a transparent multi-strategy execution mode for model-management operations. We present an overview of the different computational strategies used in the model-driven engineering ecosystem, and use a running example to introduce the benefits of mixing strategies for performing a single computation. This example helps us present our design ideas for a multi-strategy model-management system. The code-related and DevOps challenges that emerged from this analysis are also presented.;;;;
Journal Article;Kuhrmann M,O'Connor RV,Houston D,Hebig R,Raffo D;Summary of the International Conference on Software and System Processes (ICSSP 2018);SIGSOFT Softw. Eng. Notes;2019;43;4;54;;Association for Computing Machinery;New York, NY, USA;;;;2019-01;;0163-5948;"https://doi-org.proxy.bnl.lu/10.1145/3282517.3302415;http://dx.doi.org/10.1145/3282517.3302415";10.1145/3282517.3302415;"The International Conference on Software and System Processes (ICSSP), continuing the success of Software Process Workshop (SPW), the Software Process Modeling and Simulation Workshop (ProSim) and the International Conference on Software Process (ICSP) conference series, has become the established premier event in the field of software and systems engineering processes. It provides a leading forum for the exchange of research outcomes and industrial best-practices in process development from software and systems disciplines. ICSSP 2018 was held in Gothenburg, Sweden, 26-27 May 2018, co-located with the 40th International Conference on Software Engineering (ICSE). The theme of ICSSP 2018 was studying Demands on Processes, Processes on Demand"" by recognizing the demands on processes that include the need for both welldeveloped plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model-based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise-level architectures. Papers presented at ICSSP discussed these issues across different domains, providing concepts, evidence, and experiences.";data science, hybrid systems development, project management, continuous development, deployment, product quality, agile methods;;;
Conference Paper;Hadar E,Hadar I;CURA: Complex-System Unified Reference Architecture;;2016;;;216–221;;SCITEPRESS - Science and Technology Publications, Lda;Setubal, PRT;;Proceedings of the 11th International Conference on Evaluation of Novel Software Approaches to Software Engineering;Rome, Italy;2016;9789897581892;;"https://doi-org.proxy.bnl.lu/10.5220/0005894302160221;http://dx.doi.org/10.5220/0005894302160221";10.5220/0005894302160221;Constructing enterprise-level solution requires integration of existing, modified, and new modular technologies. A customer specific solution is instantiated from a reference implementation owned by the services organization, as a result of multiple products and their reference design created by the R&D organization. Yet, the disciplines of R&D and enterprise architecture differ in their analysis and design processes, artifacts, and semantics, leading to a mismatch in product design, knowledge and requirements interpretation. The Complex-systems Unified Reference Architecture (CURA) was developed as a common platform for both field and R&D practices. This methodology binds a 4-layered structure and a 4-phased architecture process, controlling the solution architecture lifecycle from reference design to reference implementation and solution instantiation, and fits both agile and DevOps methodologies. The presented version of CURA was tested and implemented with several customers as a lean and minimal blueprinting approach, serving as part of the architectural deliverables. CURA can be adjusted to other visual binding notations such as UML and TOGAF modeling languages, and can scale up to system-of-systems design.;Reference Architecture, Solution Architecture, TOGAF, Enterprise IT.;;;ENASE 2016
Journal Article;Chen B,Jiang ZM;A Survey of Software Log Instrumentation;ACM Comput. Surv.;2021;54;4;;;Association for Computing Machinery;New York, NY, USA;;;;2021-05;;0360-0300;"https://doi-org.proxy.bnl.lu/10.1145/3448976;http://dx.doi.org/10.1145/3448976";10.1145/3448976;"Log messages have been used widely in many software systems for a variety of purposes during software development and field operation. There are two phases in software logging: log instrumentation and log management. Log instrumentation refers to the practice that developers insert logging code into source code to record runtime information. Log management refers to the practice that operators collect the generated log messages and conduct data analysis techniques to provide valuable insights of runtime behavior. There are many open source and commercial log management tools available. However, their effectiveness highly depends on the quality of the instrumented logging code, as log messages generated by high-quality logging code can greatly ease the process of various log analysis tasks (e.g., monitoring, failure diagnosis, and auditing). Hence, in this article, we conducted a systematic survey on state-of-the-art research on log instrumentation by studying 69 papers between 1997 and 2019. In particular, we have focused on the challenges and proposed solutions used in the three steps of log instrumentation: (1) logging approach; (2) logging utility integration; and (3) logging code composition. This survey will be useful to DevOps practitioners and researchers who are interested in software logging.";Systematic survey, instrumentation, software logging;;;
Book;Chandrasekara C,Herath P;Hands-On Functional Test Automation: With Visual Studio 2017 and Selenium;;2019;;;;1st;APress;;;;;2019;9781484244104;;;;Get started with functional testing of both web apps and Windows apps using different test frameworks. This book will take you on a deep dive into integrating functional automation testing with deployment pipelines. Hands-On Functional Test Automation contains step-by-step lessons that will give you an understanding of how to do functional test automation using Selenium with C# and Python. Also, you will learn how to enhance your test automation development with third-party frameworks. You will configure test clients, run functional tests through Azure DevOps release management, and carry out performance and load-testing to gain a good understanding of how to do cloud-based load testing. Each lesson comprises an introduction to the related concepts to help you understand how things work. This will broaden your knowledge so you can implement test automation in the correct way. At the end of each lesson alternative options and other enhancement possibilities are discussed to allow you to do further exploration. You will: · Implement functional test automation of Windows and web applications · Use Visual Studio for load and performance testing · Configure and run cloud-based load testing · Integrate testing with deployment pipelines;;;;
Book;Winn DC;Cloud Foundry: The Definitive Guide Develop, Deploy, and Scale;;2017;;;;1st;O'Reilly Media, Inc.;;;;;2017;9781491932438;;;;How can Cloud Foundry help you develop and deploy business-critical applications and tasks with velocity? This practical guide demonstrates how this open source, cloud-native application platform not only significantly reduces the develop-to-deploy cycle time, but also raises the value line for application operators by changing the way applications and supporting services are deployed and run. Learn how Cloud Foundry can help you improve your product velocity by handling many of essential tasks required to run applications in production. Author Duncan Winn shows DevOps and operations teams how to configure and run Cloud Foundry at scale. Youll examine Cloud Foundrys technical conceptsincluding how various platform components interrelateand learn how to choose your underlying infrastructure, define the networking architecture, and establish resiliency requirements. This book covers: Cloud-native concepts that make the app build, test, deploy, and scale faster How to deploy Cloud Foundry and the BOSH release engineering toolchain Concepts and components of Cloud Foundrys runtime architecture Cloud Foundrys routing mechanisms and capabilities The platforms approach to container tooling and orchestration BOSH concepts, deployments, components, and commands Basic tools and techniques for debugging the platform Recent and soon-to-emerge features of Cloud Foundry;;;;
Book;Miell I,Sayers AH;Docker in Practice;;2016;;;;1st;Manning Publications Co.;USA;;;;2016;9781617292729;;;;Summary An open source container system, Docker makes deploying applications painless and flexible. Docker is powerful and simple to use, and it makes life easier for developers and administrators alike providing shorter build times, fewer production bugs, and effortless application roll-out. About the Book Docker in Practice is a hands-on guide that covers 101 specific techniques you can use to get the most out of Docker. Following a cookbook-style Problem/Solution/Discussion format, this practical handbook gives you instantly useful solutions for important problems like effortless server maintenance and configuration, deploying microservices, creating safe environments for experimentation, and much more. As you move through this book, youll advance from basics to Docker best practices like using it with your Continuous Integration process, automating complex container creation with Chef, and orchestration with Kubernetes. Whats Inside Speeding up your DevOps pipeline Cheaply replacing VMs Streamlining your cloud workflow Using the Docker Hub Navigating the Docker ecosystem About the Reader For anyone interested in real-world Docker. About the Authors Ian Miell and Aidan Hobson Sayers have contributed to Docker and have extensive experience building and maintaining commercial Docker-based infrastructures in large-scale environments.;;;;
Conference Paper;Suneja S,Koller R,Isci C,de Lara E,Hashemi A,Bhattacharyya A,Amza C;Safe Inspection of Live Virtual Machines;;2017;;;97–111;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 13th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments;Xi'an, China;2017;9781450349482;;"https://doi-org.proxy.bnl.lu/10.1145/3050748.3050766;http://dx.doi.org/10.1145/3050748.3050766";10.1145/3050748.3050766;With DevOps automation and an everything-as-code approach to lifecycle management for cloud-native applications, challenges emerge from an operational visibility and control perspective. Once a VM is deployed in production it typically becomes a hands-off entity in terms of restrictions towards inspecting or tuning it, for the fear of negatively impacting its operation. We present CIVIC (Cloning and Injection based VM Inspection for Cloud), a new mechanism that enables safe inspection of unmodified production VMs on-the-fly. CIVIC restricts all impact and side-effects of inspection or analysis operations inside a live clone of the production VM. New functionality over the replicated VM state is introduced using code injection. In this paper, we describe the design and implementation of our solution over KVM/QEMU. We demonstrate four of its use-cases-(i) safe reuse of system monitoring agents, (ii) impact-heavy problem diagnostics and troubleshooting, (iii) attaching an intrusive anomaly detector to a live service, and (iv) live tuning of a webserver's configuration parameters. Our evaluation shows CIVIC is nimble and lightweight in terms of memory footprint as well as clone activation time (6.5s), and has a low impact on the original VM (< 10%).;Virtualization, Monitoring, DevOps, Virtual Machine, Data Center, Sandboxing, Cloud, Live Cloning, Inspection, Code Injection;;;VEE '17
Book;Morar M,Kumar A,Abbott M,Gautam GK,Corbould J,Bhambhani A;Robust Cloud Integration with Azure;;2017;;;;;Packt Publishing;;;;;2017;9781786465573;;;;Its an incredibly exciting time for cloud integration. In 2017, Microsoft Windows Azure has accelerated the development of logic apps, web apps for developers and IoT. Looking to build scalable app services in the cloud? With this essential installment in our Azure books series, find everything you need to design and implement cloud integration. Any software developers, architects, and technical managers lookng to learn about Azure IaaS essentials need look no further. This book is ideal for Microsoft Enterprise developers, DevOps or any IT professionals looking to connect cloud-based and on-premises systems with Azure. With this book, youll learn about: Building and supporting highly available and scalable API Apps Deploying and delivering applications that integrate and adapt seamlessly in the cloud Deploying hybrid applications that work and integrate on the cloud (using Logic Apps and BizTalk Server) Exploring new models of robust cloud integration in Microsoft Azure Creating your own connector and learn how to publish and manage it Building reliable, scalable, and secure business workflows using Azure Logic Apps Simplifying SaaS connectivity with Azure using Logic Apps Connecting your on-premises system to Azure securely;;;;
Conference Paper;Janes A,Lenarduzzi V,Stan AC;A Continuous Software Quality Monitoring Approach for Small and Medium Enterprises;;2017;;;97–100;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;L'Aquila, Italy;2017;9781450348997;;"https://doi-org.proxy.bnl.lu/10.1145/3053600.3053618;http://dx.doi.org/10.1145/3053600.3053618";10.1145/3053600.3053618;Context: SMEs cannot always afford the effort required for software quality assurance, and therefore there is the need of easy and affordable practices to prevent issues in the software they develop.Object: In this paper we propose an approach to allow SMEs to access SQA practices, using an SQA approach based on a continuous issue and error monitoring and a recommendation system that will suggest quality practices, recommending a set of quality actions based on the issues that previously created errors, so as to help SMEs to maintain quality above a minimum threshold. Method: First, we aim to identify a set of SQA practices applicable in SMEs, based on the main constraints of SMEs and a set of tools and practices to fulfill a complete DevOps pipeline. Second, we aim to define a recommendation system to provide software quality feedback to micro-teams, suggesting which action(s) they should take to maintain a certain quality level and allowing them to remove the most severe issues with the lowest possible effort. Our approach will be validated by a set of local SMEs. Moreover, the tools developed will be published as Open Source.;software maintenance, anti-patterns, code smells, software monitoring, continuous quality assurance;;;ICPE '17 Companion
Conference Paper;Peppard J;What about the Benefits? A Missing Perspective in Software Engineering;;2016;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Ciudad Real, Spain;2016;9781450344272;;"https://doi-org.proxy.bnl.lu/10.1145/2961111.2962642;http://dx.doi.org/10.1145/2961111.2962642";10.1145/2961111.2962642;"The software engineering community has always sought to build great software and continues to seek out ways and approaches for doing this. The UX movement emphasizes the usability of the developed product. Agile approaches like scrum focus on aligning the functionality and features of the final product more closely with user/customer/market requirements. The recent interest in DevOps has brought to the fore the need to address the challenges once software goes into production. Despite this, in an enterprise environment, great software does not necessarily translate into real business benefits; few investments fail because the software didn't work [1], [2]. The overwhelming evidence points to the need to actively manage to achieve the business benefits being sought [3], [4], [5], [6].This keynote presentation introduces the concepts and practices of benefits management and benefits realization that have emerged over the last 25 years. It highlights the issues and challenges in deploying software to deliver expected business outcomes. It suggests that this is a missing perspective in software engineering. Suggestions for how this perspective might be more closely integrated with software engineering are proposed.";;;;ESEM '16
Conference Paper;Wang R,Casale G,Filieri A;Service Demand Distribution Estimation for Microservices Using Markovian Arrival Processes;;2021;;;310–328;;Springer-Verlag;Berlin, Heidelberg;;Quantitative Evaluation of Systems: 18th International Conference, QEST 2021, Paris, France, August 23–27, 2021, Proceedings;Paris, France;2021;9783030851712;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-85172-9_17;http://dx.doi.org/10.1007/978-3-030-85172-9_17";10.1007/978-3-030-85172-9_17;Building performance models for microservices applications in DevOps is costly and error-prone. Accurate service demand distribution estimation is critical to performance model parameterization. However, traditional service demand estimation methods focus on capturing the mean service demand, disregarding higher-order moments of the distribution. To address this limitation, we propose to estimate higher moments of the service demand distribution for a microservice from monitoring traces. We first generate a closed queueing model to abstract a microservice and model the departure process at the queue node as a Markovian arrival process. This allows formulating the estimation of service demand as an optimization problem, which aims to find the optimal parameters of the first multiple moments of the service demand distribution based on the inter-departure times. We then estimate the service demand distribution with a novel maximum likelihood algorithm, and heuristics to mitigate the computational cost of the optimization process for scalability. We apply our method to real traces from a microservice-based application and demonstrate that its estimations lead to greater prediction accuracy than exponential distributions assumed in traditional service demand estimation approaches.;Performance, Queueing models, Maximum likelihood estimation, Markovian arrival process, Service demand distribution;;;
Conference Paper;Ashenden D,Ollis G;Putting the Sec in DevSecOps: Using Social Practice Theory to Improve Secure Software Development;;2020;;;34–44;;Association for Computing Machinery;New York, NY, USA;;New Security Paradigms Workshop 2020;Online, USA;2020;9781450389952;;"https://doi-org.proxy.bnl.lu/10.1145/3442167.3442178;http://dx.doi.org/10.1145/3442167.3442178";10.1145/3442167.3442178;Practices such as open source development, agile, DevOps and DevSecOps mean that cyber security professionals need to find ways to blend cyber security with software development practices. One way of approaching this is as an awareness, education and training problem and many organisations are focusing on training software developers in cyber security. In this paper, however, we make the case for looking more broadly at group rather than individual behaviours, by examining the social practices of software developers. Changing software development practices are shaping the lived experience of software developers and we argue that understanding these practices will enable us to improve secure software development. We use social practice theory as a framework to develop recommendations for aligning and blending cyber security and software development. To achieve this, we carried out a rapid review of research on software development practices and supplemented this with data from ten key informant interviews to ascertain what we need to consider when developing an intervention for secure software development. Finally, we outline how our research could be used to develop a workshop that would facilitate the co-creation of security practices for software development. We conclude with suggestions for future research.;Social Practice Theory, Secure Software Development, Cyber Security, DevSecOps;;;NSPW '20
Book;Morris K;Infrastructure as Code: Managing Servers in the Cloud;;2016;;;;1st;O'Reilly Media, Inc.;;;;;2016;9781491924358;;;;Virtualization, cloud, containers, server automation, and software-defined networking are meant to simplify IT operations. But many organizations adopting these technologies have found that it only leads to a faster-growing sprawl of unmanageable systems. This is where infrastructure as code can help. With this practical guide, author Kief Morris of Thought Works shows you how to effectively use principles, practices, and patterns pioneered through the DevOps movement to manage cloud age infrastructure. Ideal for system administrators, infrastructure engineers, team leads, and architects, this book demonstrates various tools, techniques, and patterns you can use to implement infrastructure as code. In three parts, youll learn about the platforms and tooling involved in creating and configuring infrastructure elements, patterns for using these tools, and practices for making infrastructure as code work in your environment. Examine the pitfalls that organizations fall into when adopting the new generation of infrastructure technologies Understand the capabilities and service models of dynamic infrastructure platforms Learn about tools that provide, provision, and configure core infrastructure resources Explore services and tools for managing a dynamic infrastructureLearn specific patterns and practices for provisioning servers, building server templates, and updating running servers;;;;
Book;Bumgardner VK;OpenStack in Action;;2015;;;;1st;Manning Publications Co.;USA;;;;2015;9781617292163;;;;In the cloud computing model, a cluster of physical computers hosts an environment that provides shared services (public and private) and offers the flexibility to easily add, remove, and expand virtual servers and applications. OpenStack is an open source framework that can be installed on individual physical servers to a cloud platform and enables the building of custom infrastructure (IaaS), platform (PaaS), and software (SaaS) services without the high cost and vendor lock-in associated with proprietary cloud platforms. OpenStack in Action offers real world use cases and step-by-step instructions to develop cloud platforms from inception to deployment. It explains the design of both the physical hardware cluster and the infrastructure services needed to create a custom cloud platform. It shows how to select and set up virtual and physical servers, implement software-defined networking, and the myriad other technical details required to design, deploy, and operate an OpenStack cloud in an enterprise. It also discusses the cloud operation techniques needed to establish security practices, access control, efficient scalability, and day-to-day DevOps practices. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications.;;;;
Journal Article;Tuma K,Calikli G,Scandariato R;Threat Analysis of Software Systems: A Systematic Literature Review;J. Syst. Softw.;2018;144;C;275–294;;Elsevier Science Inc.;USA;;;;2018-10;;0164-1212;"https://doi-org.proxy.bnl.lu/10.1016/j.jss.2018.06.073;http://dx.doi.org/10.1016/j.jss.2018.06.073";10.1016/j.jss.2018.06.073;;Systematic literature review (SLR), Risk assessment, Software systems, Threat analysis (modeling), Security-by-design;;;
Book Chapter;Zhang H,Li Y,Huang Y,Wen Y,Yin J,Guan K;MLModelCI: An Automatic Cloud Platform for Efficient MLaaS;;2020;;;4453–4456;;Association for Computing Machinery;New York, NY, USA;Proceedings of the 28th ACM International Conference on Multimedia;;;2020;9781450379885;;https://doi-org.proxy.bnl.lu/10.1145/3394171.3414535;;MLModelCI provides multimedia researchers and developers with a one-stop platform for efficient machine learning (ML) services. The system leverages DevOps techniques to optimize, test, and manage models. It also containerizes and deploys these optimized and validated models as cloud services (MLaaS). In its essence, MLModelCI serves as a housekeeper to help users publish models. The models are first automatically converted to optimized formats for production purpose and then profiled under different settings (e.g., batch size and hardware). The profiling information can be used as guidelines for balancing the trade-off between performance and cost of MLaaS. Finally, the system dockerizes the models for ease of deployment to cloud environments. A key feature of MLModelCI is the implementation of a controller, which allows elastic evaluation which only utilizes idle workers while maintaining online service quality. Our system bridges the gap between current ML training and serving systems and thus free developers from manual and tedious work often associated with service deployment. We release the platform as an open-source project on GitHub under Apache 2.0 license, with the aim that it will facilitate and streamline more large-scale ML applications and research projects.;;;;
Book;Bhat S;Practical Docker with Python: Build, Release and Distribute Your Python App with Docker;;2018;;;;1st;Apress;USA;;;;2018;9781484237830;;;;Learn the key differences between containers and virtual machines. Adopting a project based approach, this book introduces you to a simple Python application to be developed and containerized with Docker. After an introduction to Containers and Docker you'll be guided through Docker installation and configuration. You'll also learn basic functions and commands used in Docker by running a simple container using Docker commands. The book then moves on to developing a Python based Messaging Bot using required libraries and virtual environment where you'll add Docker Volumes to your project, ensuring your container data is safe. You'll create a database container and link your project to it and finally, bring up the Bot-associated database all at once with Docker Compose. What You'll Learn Build, run, and distribute Docker containers Develop a Python App and containerize it Use Dockerfile to run the Python App Define and run multi-container applications with Docker Compose Work with persisting data generated by and used by Docker containers Who This Book Is For Intermediate developers/DevOps practitioners who are looking to improve their build and release workflow by containerizing applications;;;;
Journal Article;Xu Q,Jin C,Rasid MF,Veeravalli B,Aung KM;Blockchain-Based Decentralized Content Trust for Docker Images;Multimedia Tools Appl.;2018;77;14;18223–18248;;Kluwer Academic Publishers;USA;;;;2018-07;;1380-7501;"https://doi-org.proxy.bnl.lu/10.1007/s11042-017-5224-6;http://dx.doi.org/10.1007/s11042-017-5224-6";10.1007/s11042-017-5224-6;It is feasible to deploy Docker containers in IoT (Internet of Things) devices because their runtime overhead is almost zero. Default Docker installation does not verify an image authenticity. Authentication is vital for users to trust that the image is not malicious or tampered with. As Docker is currently a popular choice for developers, tightening its security is a priority for system administrators and DevOps engineers. Docker recently deployed Notary as a solution to verify authenticity of their images. Notary is a viable solution, but it has some potential threats. This paper specifically addresses its vulnerability towards Denial-of-Service (DoS) attacks, and propose a potential solution: blockchain-based Decentralized Docker Trust (DDT). The proposed solution involves decentralizing the trust via a blockchain. The solution greatly reduces the risk of DoS and at the same time provides a signature verification service for Docker images. We demonstrate the proposed blockchain-based solution's scalability and efficiency by conducting performance evaluation. At the same time, we also implemented a system prototype of Decentralized Docker Trust (DDT), and conducted performance evaluation for it on Amazon Web Services (AWS) across multiple data centers.;Trust, Multimedia, Internet of things, Blockchain, Docker;;;
Book;Lowy J,Montgomery M;Programming WCF Services: Design and Build Maintainable Service-Oriented Systems;;2015;;;;4th;O'Reilly Media, Inc.;;;;;2015;9781491944837;;;;Programming WCF Services is the authoritative, bestselling guide to Microsofts unified platform for developing modern, service-oriented applications on Windows. Hailed as the definitive treatment of WCF, this guide provides unique insight, rather than documentation, to help you learn the topics and skills you need for building maintainable, extensible, and reusable WCF-based applications. Authors Juval Lwyone of the worlds top .NET expertsand Michael Montgomery have revised this edition to include the productivity-enhancing features of .NET Framework 4.6, along with the latest WCF ideas and techniques. By teaching you the why and the how of WCF programming, this book will help you master WCF and make you a better software engineer. Learn WCFs architecture and essential building blocks, including key concepts such as reliability and transport sessions Use built-in features such as service contracts, instance and concurrency management, transactions, queued services, and security Increase the quality of your WCF services by using design options, tips, and best practices in Lwys ServiceModelEx framework Understand the rationale behind particular design decisions, and rarely understood aspects of WCF development Learn why Azure Service Fabric is the killer app for modern DevOps;;;;
Conference Paper;Niedermaier S,Koetter F,Freymann A,Wagner S;On Observability and Monitoring of Distributed Systems – An Industry Interview Study;;;;;36–52;;Springer-Verlag;Berlin, Heidelberg;;Service-Oriented Computing;Toulouse France;;9783030337018;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-33702-5_3;http://dx.doi.org/10.1007/978-3-030-33702-5_3";10.1007/978-3-030-33702-5_3;Business success of companies heavily depends on the availability and performance of their client applications. Due to modern development paradigms such as DevOps and microservice architectural styles, applications are decoupled into services with complex interactions and dependencies. Although these paradigms enable individual development cycles with reduced delivery times, they cause several challenges to manage the services in distributed systems. One major challenge is to observe and monitor such distributed systems. This paper provides a qualitative study to understand the challenges and good practices in the field of observability and monitoring of distributed systems. In 28 semi-structured interviews with software professionals we discovered increasing complexity and dynamics in that field. Especially observability becomes an essential prerequisite to ensure stable services and further development of client applications. However, the participants mentioned a discrepancy in the awareness regarding the importance of the topic, both from the management as well as from the developer perspective. Besides technical challenges, we identified a strong need for an organizational concept including strategy, roles and responsibilities. Our results support practitioners in developing and implementing systematic observability and monitoring for distributed systems.;Monitoring, Observability, Cloud, Distributed systems, Industry;;;
Conference Paper;Li S,Xu Q,Hou P,Chen X,Wang Y,Zhang H,Rong G;Exploring the Challenges of Developing and Operating Consortium Blockchains: A Case Study;;2020;;;398–404;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Evaluation and Assessment in Software Engineering;Trondheim, Norway;2020;9781450377317;;"https://doi-org.proxy.bnl.lu/10.1145/3383219.3383276;http://dx.doi.org/10.1145/3383219.3383276";10.1145/3383219.3383276;Blockchain and smart contracts are being embraced by more and more industrial practitioners in multiple domains including agriculture, manufacturing, and healthcare. As a distributed, immutable, and partly public ledger, the consortium blockchain demonstrates its potential to enable trustworthy interoperability and collaboration between organizations. However, the mismatch between the unruled software engineering practices and the increased interest of the consortium blockchain technology may pose threats to the quality of systems implemented. To mitigate the possible threats, this study takes the angle of software engineering to systematically understand the challenges and possible solutions in terms of developing and operating a consortium blockchain-based system. For this purpose, we conducted a case study on a typical consortium blockchain-based system and exhaustively collected the data by two rounds in-depth interviews on practitioners of different roles in the case project. Based on the data analysis, eight pairs of challenges and potential solutions were identified, which cover the phases of the development and operation of consortium blockchains. Moreover, we also captured two implications after further analysis of the findings, which worth the special attention of researchers in the near future, i.e. DevOps and microservices for blockchain or smart contracts.;microservices, Consortium blockchain, smart contracts, DevOps;;;EASE '20
Conference Paper;Leite AF,Penciuc D;A Computing Environment Configuration Management Pattern Based on a Software Product Line Engineering Method;;2016;;;;;The Hillside Group;USA;;Proceedings of the 11th Latin-American Conference on Pattern Languages of Programming;Buenos Aires, Argentina;2016;;;;;This paper describes a pattern to configure computing environments based on a software product line engineering (SPLE) method. Configuring computing environment represents a challenging and time-consuming activity, even for skilled DevOps engineers. The challenges these users usually face include: (a) choosing a configuration management tool to write their configuration management scripts, (b) ensuring that their computing environments are correctly configured, (c) keeping configuration scripts' dependencies and relationships up-to-date, and (d) ensuring that their scripts are both reproducible and idempotent. Furthermore, configuration management tools offer different levels of abstraction to describe the tasks. Hence, they demand knowledge on various programming languages. Therefore, configuring a computing environment follows a pattern. The pattern is: (a) describe a target state for the computing environment, (b) identify the software packages and their required configuration files, (c) create the scripts with the commands to achieve the desired state, and then, (d) execute the scripts. Thus, a software product line (SPL) based strategy is ideal for this domain, as the products have common characteristics and variable parts. As a result, this approach demands much less time and effort than the traditional one.;software product line (SPL), infrastructure as code, pattern for computing environment configuration, DevOps;;;SugarLoafPLoP '16
Book;Atchison L;Architecting for Scale: High Availability for Your Growing Applications;;2016;;;;1st;O'Reilly Media, Inc.;;;;;2016;9781491943397;;;;"Every day, companies struggle to scale critical applications. As traffic volume and data demands increase, these applications become more complicated and brittle, exposing risks and compromising availability. This practical guide shows IT, devops, and system reliability managers how to prevent an application from becoming slow, inconsistent, or downright unavailable as it grows. Scaling isnt just about handling more users; its also about managing risk and ensuring availability. Author Lee Atchison provides basic techniques for building applications that can handle huge quantities of traffic, data, and demand without affecting the quality your customers expect. In five parts, this book explores:Availability: learn techniques for building highly available applications, and for tracking and improving availability going forward Risk management: identify, mitigate, and manage risks in your application, test your recovery/disaster plans, and build out systems that contain fewer risks Services and microservices: understand the value of services for building complicated applications that need to operate at higher scale Scaling applications: assign services to specific teams, label the criticalness of each service, and devise failure scenarios and recovery plans Cloud services: understand the structure of cloud-based services, resource allocation, and service distribution";;;;
Book;Carlson L;Programming for PaaS;;2013;;;;;O'Reilly Media, Inc.;;;;;2013;9781449334901;;;;Platform-as-a-Service (PaaS) is gaining serious traction among web and mobile developers, but as new PaaS providers emerge and existing vendors upgrade their features, its hard to keep track of what PaaS has to offer. This thorough introduction takes you through the PaaS model from a developers point of view, and breaks down the types of services that Google App Engine, Windows Azure, Heroku, Cloud Foundry, and others deliver. Whether youre an entrepreneur or part of a large enterprise development team, this book shows you how PaaS can help you focus on innovative applications, rather than spend your time worrying about technical operations.Track the clouds evolution from IaaS and DevOps to PaaS Learn how PaaS combines the simplicity of shared web hosting with the control of dedicated hosting Explore the benefits of both portable and non-portable PaaS options Apply best practices for moving legacy apps to PaaSand understand the challenges involved Write new applications for PaaS from scratch with RESTful meta-services Use PaaS to build mobile apps with backend services that scale Examine the core services that each major provider currently offers Learn the situations in which PaaS might not be advantageous;;;;
Book;Riti P;Practical Scala DSLs: Real-World Applications Using Domain Specific Languages;;2017;;;;1st;Apress;USA;;;;2017;9781484230350;;;;"Build domain specific languages (DSLs) using Java's most popular functional programming language: Scala. This book introduces the basics of Scala and DSLs using a series of practical examples. In Practical Scala DSLs, youll learn to create pragmatic and complete code examples that explain the actual use of DSLs with Scala: a web API and microservices; a custom language; a mobile app; a Forex system; a game; and cloud applications. At the end of this unique book, youll be able to describe the differences between external and internal DSLs; understand when and how to apply DSLs; create DSLs using Scala; and even create a DSL using another programming language. What You'll Learn Build DSLs in Scala Write a web API and microservices Create a custom language Apply DSLs to mobile apps development, a Forex trading system, game development, and more Discover the role of DSLs in cloud development Integrate DSLs as part of a DevOps program or structure Build internal and external DSLs Who This Book Is For Experienced Java coders with at least some prior experience with Scala. You may be new to DSLs.";;;;
Conference Paper;Tak B,Isci C,Duri S,Bila N,Nadgowda S,Doran J;Understanding Security Implications of Using Containers in the Cloud;;2017;;;313–319;;USENIX Association;USA;;Proceedings of the 2017 USENIX Conference on Usenix Annual Technical Conference;Santa Clara, CA, USA;2017;9781931971386;;;;"Container technology is being adopted as a mainstream platform for IT solutions because of high degree of agility, reusability and portability it offers. However, there are challenges to be addressed for successful adoption. First, it is difficult to establish the full pedigree of images downloaded from public registries. Some might have vulnerabilities introduced unintentionally through rounds of updates by different users. Second, non-conformance to the immutable software deployment policies, such as those promoted by the DevOps principles, introduces vulnerabilities and the loss of control over deployed software. In this study, we investigate containers deployed in a production cloud to derive a set of recommended approaches to address these challenges. Our analysis reveals evidences that (i), images of unresolved pedigree have introduced vulnerabilities to containers belonging to third parties; (ii), updates to live public containers are common, defying the tenet that deployed software is immutable; and (iii), scanning containers or images alone is insufficient to eradicate vulnerabilities from public containers. We advocate for better systems support for tracking image provenance and resolving disruptive changes to containers, and propose practices that container users should adopt to limit the vulnerability of their containers.";;;;USENIX ATC '17
Conference Paper;Jiménez M,Villegas NM,Tamura G,Müller HA;Deployment Specification Challenges in the Context of Large Scale Systems;;2017;;;220–226;;IBM Corp.;USA;;Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering;Markham, Ontario, Canada;2017;;;;;Traditionally, the focus of software deployment has been mainly on the infrastructure to realise deployment and configuration (D&C) of complex and distributed systems, with an increasing interest in deployment of internet of things and cyber-physical systems. Advances in job scheduling, storage orchestration, containerized applications, along with agile practices such as continuous integration and microservices architecture, have improved the state of the practice. However, little effort has been devoted to the need for D&C specifications to support the various levels of detail and abstraction present in large-scale systems. The understanding of the software components hierarchy has shifted from the comprehension of design artefacts, usually specified with static diagrams, to the understanding of runtime concepts. The DevOps movement has dramatically influenced how and when deployment is realised, but little has been done from the software perspective in terms of documentation and linkage between design and runtime artefacts in the sense of software specification as such. This paper presents an overview of the state of the art of deployment requirements for large-scale, distributed and complex software and its automation and characterises a set of deployment specification challenges intended as starting points for advancing the field of software deployment.;continuous integration continuous configuration, runtime artefacts, continuous software deployment, deployment specification, DevOps, models at runtime;;;CASCON '17
Book;Axelos;ITIL Practitioner Guidance;;2016;;;;;The Stationery Office;GBR;;;;2016;9780113314874;;;;ITIL Practitioner Guidance is the essential reference text which accompanies the ITIL Practitioner qualification. Fully integrated with the ITIL Practitioner syllabus, this publication is also a practical guide that helps IT service management (ITSM) professionals turn ITIL theory into practice through case studies, worksheets, templates and scenarios. The book assumes knowledge of ITIL and ITSM up to ITIL Foundation level, and begins with a discussion of the guiding principles of ITSM: Focus on value Start where you are Progress iteratively Be transparent Keep it simple Design for experience Work holistically Observe directly Collaborate It goes on to explain how these guiding principles are essential for ITSM and how they relate to philosophies, frameworks and methodologies such as DevOps, Lean, Agile etc. The publication shows how following the CSI (continual service improvement) approach, and how the core skills of organizational change management, communication, metrics and measurement, can underpin successful ITSM improvement initiatives. Assembled by the Practitioner Architect Team of Kevin Behr, Karen Ferris, Lou Hunnebeck, Stuart Rance, Barclay Rae and Paul Wilkinson, a team of renowned ITSM experts under the guidance of AXELOS' Kaimar Karu, ITIL Practitioner Guidance concludes with a practical toolkit containing templates, worksheets and assessments that will help ITSM professionals to improve the value of the service they provide to their customers.;;;;
Conference Paper;Bansal C,Renganathan S,Asudani A,Midy O,Janakiraman M;DeCaf: Diagnosing and Triaging Performance Issues in Large-Scale Cloud Services;;2020;;;201–210;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice;Seoul, South Korea;2020;9781450371230;;"https://doi-org.proxy.bnl.lu/10.1145/3377813.3381353;http://dx.doi.org/10.1145/3377813.3381353";10.1145/3377813.3381353;Large scale cloud services use Key Performance Indicators (KPIs) for tracking and monitoring performance. They usually have Service Level Objectives (SLOs) baked into the customer agreements which are tied to these KPIs. Dependency failures, code bugs, infrastructure failures, and other problems can cause performance regressions. It is critical to minimize the time and manual effort in diagnosing and triaging such issues to reduce customer impact. Large volume of logs and mixed type of attributes (categorical, continuous) in the logs makes diagnosis of regressions non-trivial.In this paper, we present the design, implementation and experience from building and deploying DeCaf, a system for automated diagnosis and triaging of KPI issues using service logs. It uses machine learning along with pattern mining to help service owners automatically root cause and triage performance issues. We present the learnings and results from case studies on two large scale cloud services in Microsoft where DeCaf successfully diagnosed 10 known and 31 unknown issues. DeCaf also automatically triages the identified issues by leveraging historical data. Our key insights are that for any such diagnosis tool to be effective in practice, it should a) scale to large volumes of service logs and attributes, b) support different types of KPIs and ranking functions, c) be integrated into the DevOps processes.;root causing, performance analysis, issue triaging, machine learning, cloud services;;;ICSE-SEIP '20
Book Chapter;Angermeir F,Voggenreiter M,Moyón F,Mendez D;Enterprise-Driven Open Source Software: A Case Study on Security Automation;;2021;;;278–287;;IEEE Press;;Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice;;;2021;9780738146690;;https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP52600.2021.00037;;Agile and DevOps are widely adopted by the industry. Hence, integrating security activities with industrial practices, such as continuous integration (CI) pipelines, is necessary to detect security flaws and adhere to regulators' demands early. In this paper, we analyze automated security activities in CI pipelines of enterprise-driven open source software (OSS). This shall allow us, in the long-run, to better understand the extent to which security activities are (or should be) part of automated pipelines. In particular, we mine publicly available OSS repositories and survey a sample of project maintainers to better understand the role that security activities and their related tools play in their CI pipelines. To increase transparency and allow other researchers to replicate our study (and to take different perspectives), we further disclose our research artefacts.Our results indicate that security activities in enterprise-driven OSS projects are scarce and protection coverage is rather low. Only 6.83% of the analyzed 8,243 projects apply security automation in their CI pipelines, even though maintainers consider security to be rather important. This alerts industry to keep the focus on vulnerabilities of 3rd Party software and it opens space for other improvements of practice which we outline in this manuscript.;;;;
Journal Article;Leotta M,Cerioli M,Olianas D,Ricca F;Two Experiments for Evaluating the Impact of Hamcrest and AssertJ on Assertion Development;Software Quality Journal;2020;28;3;1113–1145;;Kluwer Academic Publishers;USA;;;;2020-09;;0963-9314;"https://doi-org.proxy.bnl.lu/10.1007/s11219-020-09507-0;http://dx.doi.org/10.1007/s11219-020-09507-0";10.1007/s11219-020-09507-0;Test automation enables continuous testing, a cornerstone of agile methods, and DevOps. Assertions play a fundamental role in test automation, and recently competing assertion libraries for unit testing frameworks, such as, for example, JUnit or TestNG, emerged. Thus, it is imperative to gauge assertion libraries in terms of developer/tester productivity, allowing SQA managers and software testers to select the best. The goal of this work is comparing two assertion libraries having a different approach (matchers vs. fluent assertions) w.r.t. two dependent variables: correctness of developed assertions and time to develop them. We conducted two controlled experiments with Bachelor students in Computer Science and Master students in Computer Engineering. AssertJ (fluent assertions approach) is compared with Hamcrest (matchers), in a test development scenario with the Java language where 672 assertions were developed by 48 students overall. The results show that (a) adopting AssertJ improves the tester’s productivity significantly during the development of assertions only for Bachelor students, and (b) time of developing assertions is similar using AssertJ or Hamcrest in both the categories of participants. Testers and SQA managers selecting assertion libraries for their organizations should consider as first choice AssertJ in case of inexperienced developers/testers since our study shows that it increases the productivity of Bachelor students more than Hamcrest.;AssertJ methods, Tester productivity, Hamcrest matchers, Controlled experiment, Evidence-based Software Engineering, Assertion development;;;
Conference Paper;Ren Z,Wang W,Wu G,Gao C,Chen W,Wei J,Huang T;Migrating Web Applications from Monolithic Structure to Microservices Architecture;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Tenth Asia-Pacific Symposium on Internetware;Beijing, China;2018;9781450365901;;"https://doi-org.proxy.bnl.lu/10.1145/3275219.3275230;http://dx.doi.org/10.1145/3275219.3275230";10.1145/3275219.3275230;In the traditional software development and deployment, the centralized monolithic is always adopted, as the modules are tightly coupled, which caused many inconvenience in software DevOps. The modules with bottlenecks in monolithic application cannot be extend separately as the application is an integral part, and different module cannot use different technology stack. To prolong the lifecycle of the monolithic applications, its need to migrated it to microservice architecture. Due to the complex logic and large number of third party framework libraries depended, get an accurate comprehensive of the application characteristics is challenging. The existing research mostly based on the static characteristics, lack of consideration of the runtime dynamic characteristics, and the completeness and accuracy of the static analysis is inadequate. To resolve above problems, we combined static and dynamic analysis to get static structure and runtime behavior characteristics of monolithic application. We employed the coupling among functions to evaluate the degree of dependence, and through function clustering to achieve the migration of legacy monolithic applications and its data to microservices architecture. Through the empirical study of migrate the typical legacy project to microservices, it is proved that we proposed method can offer precise guidance and assistance in the migration procedure. Experiments show that the method has high accuracy and low performance cost.;application migration, monolithic application, microservices, function clustering;;;Internetware '18
Book;Mead NR,Woody C;Cyber Security Engineering: A Practical Approach for Systems and Software Assurance;;2016;;;;1st;Addison-Wesley Professional;;;;;2016;9780134189802;;;;Cyber Security Engineering is the definitive modern reference and tutorial on the full range of capabilities associated with modern cyber security engineering. Pioneering software assurance experts Dr. Nancy R. Mead and Dr. Carol C. Woody bring together comprehensive best practices for building software systems that exhibit superior operational security, and for considering security throughout your full system development and acquisition lifecycles. Drawing on their pioneering work at the Software Engineering Institute (SEI) and Carnegie Mellon University, Mead and Woody introduce seven core principles of software assurance, and show how to apply them coherently and systematically. Using these principles, they help you prioritize the wide range of possible security actions available to you, and justify the required investments. Cyber Security Engineering guides you through risk analysis, planning to manage secure software development, building organizational models, identifying required and missing competencies, and defining and structuring metrics. Mead and Woody address important topics, including the use of standards, engineering security requirements for acquiring COTS software, applying DevOps, analyzing malware to anticipate future vulnerabilities, and planning ongoing improvements. This book will be valuable to wide audiences of practitioners and managers with responsibility for systems, software, or quality engineering, reliability, security, acquisition, or operations. Whatever your role, it can help you reduce operational problems, eliminate excessive patching, and deliver software that is more resilient and secure.;;;;
Conference Paper;Syed MH,Fernandez EB;A Reference Architecture for the Container Ecosystem;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 13th International Conference on Availability, Reliability and Security;Hamburg, Germany;2018;9781450364485;;"https://doi-org.proxy.bnl.lu/10.1145/3230833.3232854;http://dx.doi.org/10.1145/3230833.3232854";10.1145/3230833.3232854;"Containers have gained immense popularity as a portable and lightweight virtualization solution. They facilitate application development, deployment and distribution across computing environments. Their success is also attributed to the support they offer for DevOps teams and for applications developed using a microservices architecture style. Containers are not the only components in the environment but work closely with other components for managing and supporting them, forming an ecosystem. Architectural modeling can be used as a powerful tool to represent ecosystems which helps understand, build and secure such complex systems. We describe in this paper several models we have created for container ecosystem components. These models are abstract, and they help generalize the systems to handle complexity and heterogeneity; they provide a common vocabulary and build holistic and unified views of the systems. The use of UML for modeling improves precision. This can lead to better implementations with respect to reliability, security and interoperability compared to ad hoc methods. A reference architecture will not just facilitate the work of developers and security engineers but also of anyone who aims to ensure compliance, privacy, safety, reliability and/or governance for container ecosystems and we show how to build one. We also describe relationships between container, cloud and IoT ecosystems. This paper is part of our work on developing a security reference architecture for container ecosystems.";Containers, container ecosystem, container manager;;;ARES 2018
Book;Gmez JM,Mora M,Raisinghani MS,Nebel W,O'Connor RV;Engineering and Management of Data Centers: An IT Service Management Approach;;2017;;;;1st;Springer Publishing Company, Incorporated;;;;;2017;9783319650814;;;;This edited volume covers essential and recent development in the engineering and management of data centers. Data centers are complex systems requiring ongoing support, and their high value for keeping business continuity operations is crucial. The book presents core topics on the planning, design, implementation, operation and control, and sustainability of a data center from a didactical and practitioner viewpoint. Chapters include: Foundations of data centers: Key Concepts and Taxonomies ITSDM: A Methodology for IT Services Design Managing Risks on Data Centers through Dashboards Risk Analysis in Data Center Disaster Recovery Plans Best practices in Data Center Management Case: KIO Networks QoS in NaaS (Network as a Service) using Software Defined Networking Optimization of Data Center Fault-Tolerance Design Energetic Data Centre Design Considering Energy Efficiency Improvements During Operation Demand-side Flexibility and Supply-side Management: The Use Case of Data Centers and Energy Utilities DevOps: Foundations and its Utilization in Data Centers Sustainable and Resilient Network Infrastructure Design for Cloud Data Centres Application Software in Cloud-Ready Data Centers This book bridges the gap between academia and the industry, offering essential reading for practitioners in data centers, researchers in the area, and faculty teaching related courses on data centers. The book can be used as a complementary text for traditional courses on Computer Networks, as well as innovative courses on IT Architecture, IT Service Management, IT Operations, and Data Centers.;;;;
Conference Paper;Van Heesch U,Theunissen T,Zimmermann O,Zdun U;Software Specification and Documentation in Continuous Software Development: A Focus Group Report;;2017;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 22nd European Conference on Pattern Languages of Programs;Irsee, Germany;2017;9781450348485;;"https://doi-org.proxy.bnl.lu/10.1145/3147704.3147742;http://dx.doi.org/10.1145/3147704.3147742";10.1145/3147704.3147742;We have been observing an ongoing trend in the software engineering domain towards development practices that rely heavily on verbal communication and small, closely-interacting teams. Among others, approaches like Scrum, Lean Software Development, and DevOps fall under this category. We refer to such development practices as Continuous Software Development (ConSD). Some core principles of ConSD are working in short iterations with frequent delivery, striving for an optimal balance between effectiveness and efficiency, and amplify learning in the development team. In such a context, many traditional patterns of software specification, documentation and knowledge preservation are not applicable anymore.To explore relevant topics, opinions, challenges and chances around specification, documentation and knowledge preservation in ConSD, we conducted a workshop at the 22nd European Conference on Pattern Languages of Programs (EuroPLoP), held in Germany in July 2017. The workshop participants came from the industry and academia.In this report, we present the results of the workshop. Among others, we elaborate on the difference between specification and documentation, the special role of architecture in ConSD in general, and architecture decision documentation in particular, and the importance of tooling that combines aspects of development, project management, and quality assurance. Furthermore, we describe typical issues with documentation and identify means to efficiently and effectively organize specification and documentation tasks in ConSD.;Agile, Specification, Software engineering, Continuous Software Development, Lean, DevOps;;;EuroPLoP '17
Conference Paper;Brito M,Cunha J,Saraiva J;Identification of Microservices from Monolithic Applications through Topic Modelling;;2021;;;1409–1418;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 36th Annual ACM Symposium on Applied Computing;Virtual Event, Republic of Korea;2021;9781450381048;;"https://doi-org.proxy.bnl.lu/10.1145/3412841.3442016;http://dx.doi.org/10.1145/3412841.3442016";10.1145/3412841.3442016;Microservices emerged as one of the most popular architectural patterns in the recent years given the increased need to scale, grow and flexibilize software projects accompanied by the growth in cloud computing and DevOps. Many software applications are being submitted to a process of migration from its monolithic architecture to a more modular, scalable and flexible architecture of microservices. This process is slow and, depending on the project's complexity, it may take months or even years to complete.This paper proposes a new approach on microservice identification by resorting to topic modelling in order to identify services according to domain terms. This approach in combination with clustering techniques produces a set of services based on the original software. The proposed methodology is implemented as an open-source tool for exploration of monolithic architectures and identification of microservices. A quantitative analysis using the state of the art metrics on independence of functionality and modularity of services was conducted on 200 open-source projects collected from GitHub. Cohesion at message and domain level metrics' showed medians of roughly 0.6. Interfaces per service exhibited a median of 1.5 with a compact interquartile range. Structural and conceptual modularity revealed medians of 0.2 and 0.4 respectively.Our first results are positive demonstrating beneficial identification of services due to overall metrics' results.;;;;SAC '21
Book;Goericke S;The Future of Software Quality Assurance;;2019;;;;1st;Springer Publishing Company, Incorporated;;;;;2019;9783030295080;;;;"This open access book, published to mark the 15th anniversary of the International Software Quality Institute (iSQI), is intended to raise the profile of software testers and their profession. It gathers contributions by respected software testing experts in order to highlight the state of the art as well as future challenges and trends. In addition, it covers current and emerging technologies like test automation, DevOps, and artificial intelligence methodologies used for software testing, before taking a look into the future. The contributing authors answer questions like: ""How is the profession of tester currently changing? What should testers be prepared for in the years to come, and what skills will the next generation need? What opportunities are available for further training today? What will testing look like in an agile world that is user-centered and fast-paced? What tasks will remain for testers once the most important processes are automated?"" iSQI has been focused on the education and certification of software testers for fifteen years now, and in the process has contributed to improving the quality of software in many areas. The papers gathered here clearly reflect the numerous ways in which software quality assurance can play a critical role in various areas. Accordingly, the book will be of interest to both professional software testers and managers working in software testing or software quality assurance.";;;;
Journal Article;Al-Surmi I,Raddwan B,Al-Baltah I;Next Generation Mobile Core Resource Orchestration: Comprehensive Survey, Challenges and Perspectives;Wirel. Pers. Commun.;2021;120;2;1341–1415;;Kluwer Academic Publishers;USA;;;;2021-09;;0929-6212;"https://doi-org.proxy.bnl.lu/10.1007/s11277-021-08517-w;http://dx.doi.org/10.1007/s11277-021-08517-w";10.1007/s11277-021-08517-w;Re-architecting mobile network functions and central office is one of the hottest topics of software defined networking (SDN) and network function virtualization (NFV). It is known as Next generation mobile network (NGMN). The main benefit of re-architecting is to bring cloud advantages to mobile operator networks. On the other hand, while the openness is one of the most wanted characteristics of NGMN, many open source implementations have been introduced to accelerate realizing the NGMN such as resource allocation management and orchestration which is considered as one of the hardest problems in SDN, NFV, and network virtualization. To that end, this article has comprehensively reviewed the mobile core architecture, resource management and orchestration evolutions in order to investigate the relay of the mobile operators on open source components, especially in developing countries, in order to build their future NGMN infrastructure for 4G/5G (fourth/fifth generations) access networks. Furthermore, the article shows a large number of open source infrastructure’ components that the operator needs to integrate them together, which is a challenging task. Moreover, the article addresses the integration framework challenges for resource management and orchestration based on continuous integration continuous development (DevOps) model. The outcomes of this work encourage mobile operators to involve and contribute to open source integration efforts as well as build and test their NGMN integration scenarios.;Resource allocation, Network function virtualization, Software defined networking, Service function chaining, Management and orchestration, Next generation mobile network;;;
Conference Paper;di Orio G,Maló P,Barata J;NOVAAS: A Reference Implementation of Industrie4.0 Asset Administration Shell with Best-of-Breed Practices from IT Engineering;;2019;;;5505–5512;;IEEE Press;Lisbon, Portugal;;IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/IECON.2019.8927081;http://dx.doi.org/10.1109/IECON.2019.8927081";10.1109/IECON.2019.8927081;The fundamental role played by “new technologies” to enhance the manufacturing infrastructure, products and services is confirmed by the strategies, roadmaps and initiatives established by the developed countries such as EU-28, US, China and Japan. Putting the light on Europe, the key priorities for manufacturing are aligned with the Industry 4.0 strategy/program where the proliferation of cyber-physical systems (CPSs) and technologies like predictive data analytics, cloud and edge computing are creating the foundation for smart factory, i.e. the efficient and effective connection between products, processes and their related services. However, even if the smart factory vision is quite clear, in practice, it is still unclear how it can be implemented in a way to allow the transparent data exchange between all the layers of a manufacturing company, as well as, between the manufacturing company and the value chain partners. Within the German Industrie4.0 program, the Asset Administration Shell concept is defined to create a standardized digital representation of the asset while ensuring interoperability between all the applications within the manufacturing ecosystem. In this paper, an implementation of the asset administration shell is provided – also called NOVAAS – based on the deep usage of internet technologies, languages and software engineering techniques and methods (such as DevOps, microservices, continuous integration, etc.). The main goal is to contribute towards a generic and extensible reference implementation of the concept.;;;;
Conference Paper;Guija D,Siddiqui MS;Identity and Access Control for Micro-Services Based 5G NFV Platforms;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 13th International Conference on Availability, Reliability and Security;Hamburg, Germany;2018;9781450364485;;"https://doi-org.proxy.bnl.lu/10.1145/3230833.3233255;http://dx.doi.org/10.1145/3230833.3233255";10.1145/3230833.3233255;The intrinsic use of SDN/NFV technologies in 5G infrastructures promise to enable the flexibility and programmability of networks to ensure lower cost of network and service provisioning and operation, however it brings new challenges and requirements due to new architectural changes. In terms of security, authentication and authorization functions need to evolve towards the new and emerging 5G virtualization platforms in order to meet the requirements of service providers and infrastructure operators. Over the years, a lot of authentication techniques have been used. Now, a wide range of options arise allowing to extend existing authentication and authorization mechanisms.This paper focuses on proposing and showcasing a 5G platform oriented solution among different approaches to integrate authentication and authorization functionalities, an adapted secure and stateless mechanism, providing identity and permissions management to handle not only users, but also system micro-services, in a network functions virtualization management and orchestration (NFV MANO) system, oriented to deploy virtualized services. The presented solution uses the NFV-based SONATA Service Platform which offers capabilities for a continuous integration and delivery DevOps methodology that allow high levels of programmability and flexibility to manage the entire life cycle of Virtual Network Functions, and enables the perfect scenario to showcase different approaches for authentication and authorization mechanisms for users and micro-services in a 5G platform.;DevOps, micro-services, Authentication, network services, NFV MANO, JSON Web Token, Authorization, virtual network functions, identity, 5G, Keycloak;;;ARES 2018
Book;Bai H;Programming Microsoft Azure Service Fabric (2nd Edition);;2018;;;;2nd;Microsoft Press;USA;;;;2018;9781509307098;;;;Build, operate, and orchestrate scalable microservices applications in the cloud This book combines a comprehensive guide to success with Microsoft Azure Service Fabric and a practical catalog of design patterns and best practices for microservices design, implementation, and operation. Haishi Bai brings together all the information youll need to deliver scalable and reliable distributed microservices applications on Service Fabric. He thoroughly covers the crucial DevOps aspects of utilizing Service Fabric, reviews its interactions with key cloud-based services, and introduces essential service integration mechanisms such as messaging systems and reactive systems. Leading Microsoft Azure expert Haishi Bai shows how to: Set up your Service Fabric development environment Program and deploy Service Fabric applications to a local or a cloud-based cluster Compare and use stateful services, stateless services, and the actor model Design Service Fabric applications to maximize availability, reliability, and scalability Improve management efficiency via scripting Configure network security and other advanced cluster settings Collect diagnostic data, and use Azure Operational Management Suite to interpret it Integrate microservices components developed in parallel Use containers to mobilize applications for failover, replication, scaling, and load balancing Streamline containerization with Docker in Linux and Windows environments Orchestrate containers to schedule workloads and maintain services at desired states Implement proven design patterns for common cloud application workloads Balance throughput, latency, scalability, and cost;;;;
Book;Chakraborty B,Karthikeyan SA;Understanding Azure Monitoring: Includes IaaS and PaaS Scenarios;;2019;;;;1st;Apress;USA;;;;2019;9781484251294;;;;Explore the architectural constructs of Azure monitoring capabilities and learn various design and implementation aspects for complex use cases. This book covers the different scenarios in a modern-day multi-cloud enterprise and the tools available in Azure for monitoring and securing these environments. Understanding Azure Monitoring starts by discussing the rapid changes happening in the cloud and the challenges faced by cloud architects. You will then look at the basics of Azure monitoring and the available tools, including service level agreements (SLAs), auditing, and security. Next, you will learn how to select the best tools for monitoring, operational strategy, and integration with on-premises SIEM systems. You'll work through some scenario-based examples to monitor the workload and respond to failures. Here, you will monitor a simple web application on Azure, a multi-region web application, and applications that include PaaS and IaaS services. Towards the end of the book, you will explore monitoring in DevOps and see why it is important to be aware of continuous changes. What You Will Learn, Work with Azure IaaS and PaaS resources and monitoring and diagnostics capabilities, Discover how the operational landscape changes on Azure, Look at cloud-only and on-premises hybrid integration, Study architectural constructs for design and implementation, Who This Book Is For Infrastructure and solution architects who want to integrate Azure-based monitoring solutions in a cloud native or hybrid-cloud architecture.;;;;
Journal Article;Makki M,Van Landuyt D,Lagaisse B,Joosen W;A Comparative Study of Workflow Customization Strategies: Quality Implications for Multi-Tenant SaaS;J. Syst. Softw.;2018;144;C;423–438;;Elsevier Science Inc.;USA;;;;2018-10;;0164-1212;"https://doi-org.proxy.bnl.lu/10.1016/j.jss.2018.07.014;http://dx.doi.org/10.1016/j.jss.2018.07.014";10.1016/j.jss.2018.07.014;;Software quality, Workflow automation, Multi-tenancy, Functional customization, Software-as-a-Service;;;
Book Chapter;Shetty M,Bansal C,Kumar S,Rao N,Nagappan N,Zimmermann T;Neural Knowledge Extraction from Cloud Service Incidents;;2021;;;218–227;;IEEE Press;;Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice;;;2021;9780738146690;;https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP52600.2021.00031;;The move from boxed products to services and the widespread adoption of cloud computing has had a huge impact on the software development life cycle and DevOps processes. Particularly, incident management has become critical for developing and operating large-scale services. Prior work on incident management has heavily focused on the challenges with incident triaging and de-duplication. In this work, we address the fundamental problem of structured knowledge extraction from service incidents. We have built SoftNER, a framework for unsupervised knowledge extraction from service incidents. We frame the knowledge extraction problem as a Named-Entity Recognition task for extracting factual information. SoftNER leverages structural patterns like key-value pairs and tables for bootstrapping the training data. Further, we build a novel multitask learning based BiLSTM-CRF model which leverages not just the semantic context but also the data-types for named-entity extraction. We have deployed SoftNER at Microsoft, a major cloud service provider and have evaluated it on more than 2 months of cloud incidents. We show that the unsupervised machine learning pipeline has a high precision of 0.96. Our multi-task learning based deep learning model also outperforms the state of the art NER models. Lastly, using the knowledge extracted by SoftNER we are able to build significantly more accurate models for important downstream tasks like incident triaging.;;;;
Conference Paper;Hensen B,Klamma R;VIAProMa: An Agile Project Management Framework for Mixed Reality;;2021;;;254–272;;Springer-Verlag;Berlin, Heidelberg;;Augmented Reality, Virtual Reality, and Computer Graphics: 8th International Conference, AVR 2021, Virtual Event, September 7–10, 2021, Proceedings;;2021;9783030875947;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-87595-4_19;http://dx.doi.org/10.1007/978-3-030-87595-4_19";10.1007/978-3-030-87595-4_19;With the COVID-19 pandemic, distributed and remote working became a necessity but in agile project management, social interactions like daily standup meetings in Scrum are vital for the project success. Mixed reality can provide a new way of combining remote collaboration with innovative 3D visualizations to analyze the project status. In this paper, we present a visual immersive analytics framework for project management (VIAProMa). It imports data from project management tools like the GitHub issue tracker for open-source projects. With these task data as the basis, it can generate three-dimensional visualizations, e.g. about the overall progress or the competences of individual developers. Developers, stakeholders and end users can meet in the collaborative virtual environment as avatars and establish a spatial structure with the task cards and visualizations. Therefore, VIAProMa with its adapted and customized mixed reality project management features supports both the shared meetings and the information flow in the project. The shared environment makes it a suitable tool for DevOpsUseXR, an extension to the DevOps workflow, where end users are able to participate in the development process in mixed reality. The resulting implementation is available as an open-source project with cross-platform capabilities targeting the Microsoft HoloLens, HTC VIVE and Android smartphones, as well as tablets. The framework is applied in university teaching classes to convey agile methodology in mixed reality programming practices.;Mixed reality, Project management, Agile methodology;;;
Book;Schwartz M;The Art of Business Value;;2016;;;;;IT Revolution Press;;;;;2016;9781942788041;;;;Do you really understand what business value is? Information technology can and should deliver business value. But the Agile literature has paid scant attention to what business value meansand how to know whether or not you are delivering it. This problem becomes ever more critical as you push value delivery toward autonomous teams and away from requirements tossed over the wall by business stakeholders. An empowered team needs to understand its goal!Playful and thought-provoking, The Art of Business Value explores what business value means, why it matters, and how it should affect your software development and delivery practices. More than any other IT delivery approach, DevOps (and Agile thinking in general) makes business value a central concern. This book examines the role of business value in software and makes a compelling case for why a clear understanding of business value will change the way you deliver software.This book will make you think deeply about not only what it means to deliver value but also the relationship of the IT organization to the rest of the enterprise. It will give you the language to discuss value with the business, methods to cut through bureaucracy, and strategies for incorporating Agile teams and culture into the enterprise. Most of all, this book will startle you into new ways of thinking about the cutting-edge of Agile practice and where it may lead.;;;;
Conference Paper;Harrer S,Röck C,Wirtz G;Automated and Isolated Tests for Complex Middleware Products: The Case of BPEL Engines;;2014;;;390–398;;IEEE Computer Society;USA;;Proceedings of the 2014 IEEE International Conference on Software Testing, Verification, and Validation Workshops;;2014;9781479957903;;"https://doi-org.proxy.bnl.lu/10.1109/ICSTW.2014.45;http://dx.doi.org/10.1109/ICSTW.2014.45";10.1109/ICSTW.2014.45;Today, a plethora of enterprise middleware solutions are available, leading to the problem of choosing the right tool for a specific use case. Automated tests can support the selection of such software by determining decision relevant metrics, like e.g., throughput or the degree of standard conformance. To avoid side effects between tests, test isolation, i.e., to provide fresh instances of the software for each test execution, is essential. However, middleware suites are inherently complex, provide a large range of configuration options, have tedious or sometimes manual installation procedures, and long startup times. These idiosyncrasies aggravate the creation of fresh instances of such middleware suites, leading to slower turnaround times and increasing the cost for ensuring test isolation. We aim to overcome these issues with methods and tools from the area of virtualization and devops. In this work, we focus on BPEL engines which are common middleware components in Web Service based SOAs. We applied our proposed method to the BPEL Engine Test System (betsy), a conformance test suite and testing tool for BPEL engines. Results reveal that our method a) enables automatic creation of fresh instances of software without manual installation steps, b) reduces the time to create these fresh instance dramatically, and c) introduces only a neglectable performance overhead, therefore, reducing the overall costs of testing complex software.;test isolation, virtualization, BPEL engines, test automation;;;ICSTW '14
Conference Paper;Xie Y,Tian G,Tao Y,Li G,Hu Q;"Research on Application Development and Implementation Method Based on ""Platform +APP"" Mode";;2021;;;689–694;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering;Xiamen, China;2021;9781450384322;;"https://doi-org.proxy.bnl.lu/10.1145/3501409.3501533;http://dx.doi.org/10.1145/3501409.3501533";10.1145/3501409.3501533;"With the rise of the Internet, Internet software process methods have been introduced into the field of enterprise informatization, hoping to adapt to the rapid change of business and deliver value quickly. However, the requirements of enterprise informatization on software quality and security are usually ignored, which makes the software insufficient to solve the problems that enterprises pay more attention to, such as business complexity and consistency. At present, enterprise digital transformation and upgrading needs to simultaneously solve the problems of complexity, consistency, variability and invisibility, and efficiently deliver high quality, high security software to realize business value. Focusing on this demand, this paper analyzes and studies software process methods such as software engineering quality system management, safety software development life cycle and Devops method, and puts forward the ""four-stages and twelve-nodes"" software development and implementation method based on ""Platform +APP"" mode. This method carries out APP research and development activities and manages the software development process based on the common capabilities provided by the Cloud platform based on the Internet mode. The overall idea of ""big agility, small waterfall"" is adopted to give consideration to reliability, security and development efficiency. This method has been applied to the application system construction of the digital transformation of a large enterprise, and the practice proves that this method can take into account the reliability, security and variability of software, and the improvement of software batch supply ability is remarkable.";Enterprise digitization, Devops, Software development process, Micro service;;;EITCE 2021
Book;Sawhney R;Beginning Azure Functions: Building Scalable and Serverless Apps;;2019;;;;1st;Apress;USA;;;;2019;9781484244432;;;;Create highly scalable apps and monitor Azure functions in production using Azure Functions 2.0. This book takes you through durable functions for statefulness and covers not only the basics, but also how to create bindings in durable functions. It is a deep dive into the Azure Functions serverless API and will guide you through the process of converting monolithic applications to use Azure functions. The author starts by giving an overview of serverless architecture and Azure functions along with Azure App Services. You will then learn to create basic Azure functions using the Azure portal and Visual Studio. Next, you will create a serverless API using Azure Functions and migrate an existing application to Azure Functions. Finally, you will deploy an Azure function and monitor it in production. Here you will deploy the Azure function using ARM templates and secure and configure CORS for Azure functions. After reading this book, you will be able to understand Azure functions and create them using the Azure portal and Visual Studio. What You Will Learn Understand and use triggers and bindings in an Azure function Create a serverless API using Azure Functions and OpenAPI Deploy an Azure function and monitor it in production Understand durable Azure functions, including scalability, disaster recovery, and geo-distribution Who This Book Is ForDevelopers who want to get started with Azure Functions. DevOps will also find value in the guidance for deploying and monitoring functions.;;;;
Conference Paper;Meixner K,Winkler D,Biffl S;Towards Combined Process & Tool Variability Management in Software Testing;;2019;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems;Leuven, Belgium;2019;9781450366489;;"https://doi-org.proxy.bnl.lu/10.1145/3302333.3302339;http://dx.doi.org/10.1145/3302333.3302339";10.1145/3302333.3302339;Context. Modern software engineering approaches that rely on continuous and automated testing, like Agile Software Engineering and the late DevOps movement, require integrated and fully functional testing tool chain environment, to efficiently identify defects in software artifacts. Such an environment includes the implementation of established testing processes that are utilized by the development teams. However, in practice, different testing tool chains and processes are implemented depending on particular project requirements such as programming language, selected testing tool, or system architecture. This variety of required technologies and processes frequently results in an environment of isolated test automation solutions. Thus, there is a need for a managed and controllable set of testing tool chain variants that consider structured methods to integrate variability. Goal. In this paper, we show ongoing work, as part of a flexible Test Automation Framework (TAF), with focus on requirements for the variability of testing tool chains, established testing processes, and candidate solution approaches. Method. We build on best practices from software and systems testing and variability management to implement variability in the TAF. Results. First results showed that several Test Automation (TA) solutions exist, which support variability in a limited manner and, therefore, increase the need for modeling variability in a flexible TAF. Conclusion. In the context of Software Test Automation, a combination of Variability Modeling (VM) methods for testing architectures, business processes, and a definition of common interface definitions is promising towards a TAF that enables a flexible tool and process integration.;Test automation, Test Architecture, Process Variability, Testing Tool Chain, Variability Modeling, Software Testing;;;VAMOS '19
Journal Article;Zimmermann O;Microservices Tenets;Comput. Sci.;2017;32;3–4;301–310;;Springer-Verlag;Berlin, Heidelberg;;;;2017-07;;1865-2034;"https://doi-org.proxy.bnl.lu/10.1007/s00450-016-0337-0;http://dx.doi.org/10.1007/s00450-016-0337-0";10.1007/s00450-016-0337-0;"Some microservices proponents claim that microservices form a new architectural style; in contrast, advocates of service-oriented architecture (SOA) argue that microservices merely are an implementation approach to SOA. This overview and vision paper first reviews popular introductions to microservices to identify microservices tenets. It then compares two microservices definitions and contrasts them with SOA principles and patterns. This analysis confirms that microservices indeed can be seen as a development- and deployment-level variant of SOA; such microservices implementations have the potential to overcome the deficiencies of earlier approaches to SOA realizations by employing modern software engineering paradigms and Web technologies such as domain-driven design, RESTful HTTP, IDEAL cloud application architectures, polyglot persistence, lightweight containers, a continuous DevOps approach to service delivery, and comprehensive but lean fault management. However, these paradigms and technologies also cause a number of additional design choices to be made and create new options for many ""distribution classics"" type of architectural decisions. As a result, the cognitive load for (micro-)services architects increases, as well as the design, testing and maintenance efforts that are required to benefit from an adoption of microservices. To initiate and frame the buildup of architectural knowledge supporting microservices projects, this paper compiles related practitioner questions; it also derives research topics from these questions. The paper concludes with a summarizing position statement: microservices constitute one particular implementation approach to SOA (service development and deployment).";Patterns, Systems management, Messaging, Service-oriented computing, Loose coupling, SOA, IDEAL cloud application architectures, Domain-driven design, DevOps, Architectural styles, REST, Architectural principles;;;
Journal Article;Herbst N,Bauer A,Kounev S,Oikonomou G,Van Eyk E,Kousiouris G,Evangelinou A,Krebs R,Brecht T,Abad CL,Iosup A;Quantifying Cloud Performance and Dependability: Taxonomy, Metric Design, and Emerging Challenges;ACM Trans. Model. Perform. Eval. Comput. Syst.;2018;3;4;;;Association for Computing Machinery;New York, NY, USA;;;;2018-08;;2376-3639;"https://doi-org.proxy.bnl.lu/10.1145/3236332;http://dx.doi.org/10.1145/3236332";10.1145/3236332;In only a decade, cloud computing has emerged from a pursuit for a service-driven information and communication technology (ICT), becoming a significant fraction of the ICT market. Responding to the growth of the market, many alternative cloud services and their underlying systems are currently vying for the attention of cloud users and providers. To make informed choices between competing cloud service providers, permit the cost-benefit analysis of cloud-based systems, and enable system DevOps to evaluate and tune the performance of these complex ecosystems, appropriate performance metrics, benchmarks, tools, and methodologies are necessary. This requires re-examining old system properties and considering new system properties, possibly leading to the re-design of classic benchmarking metrics such as expressing performance as throughput and latency (response time). In this work, we address these requirements by focusing on four system properties: (i) elasticity of the cloud service, to accommodate large variations in the amount of service requested, (ii) performance isolation between the tenants of shared cloud systems and resulting performance variability, (iii) availability of cloud services and systems, and (iv) the operational risk of running a production system in a cloud environment. Focusing on key metrics for each of these properties, we review the state-of-the-art, then select or propose new metrics together with measurement approaches. We see the presented metrics as a foundation toward upcoming, future industry-standard cloud benchmarks.;Metrics, benchmarking, elasticity, operational risk, performance variability, performance isolation, availability, cloud;;;
Conference Paper;Austel P,Chen H,Dube P,Mikalsen T,Rouvellou I,Sharma U,Silva-Lepe I,Subramanian R,Tan W,Wang Y;A PaaS for Composite Analytics Solutions;;2015;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 12th ACM International Conference on Computing Frontiers;Ischia, Italy;2015;9781450333580;;"https://doi-org.proxy.bnl.lu/10.1145/2742854.2747281;http://dx.doi.org/10.1145/2742854.2747281";10.1145/2742854.2747281;In their pursuit of market competitiveness and sustainable top line growth, enterprises are increasingly turning to sophisticated analytics solutions to derive insights and value from the deluge of data that are being generated from all sources. Leading practitioners of Big Data analytics have already moved past the stage of using single analytics modalities on siloed data sources. They are starting to create composite analytics solutions that take advantage of multiple analytics programming models and are also integrating them into their existing enterprise IT systems. At the same time, the CIOs have wholeheartedly embraced cloud computing as a means of reducing the capital and operational cost of their IT systems and streamlining their DevOps processes. Platform-as-a-Service (PaaS) as a cloud computing consumption model has seen wide acceptance by developers and IT administrators. Although there are PaaS platforms for individual workload types involved in these advanced composite analytics solutions, the composition aspect is not addressed by any of these individual PaaS platforms. Further, there is no lifecycle management support for the solution as a single logical entity. This paper argues for the need of a true PaaS for composite analytics solutions in order to accelerate their adoption by the industry and foster the creation of a healthy ecosystem. We present the design and prototype implementation of such a platform and our early experience of using it to deploy a Telco Fraud Detection solution.;solution composition, platform-as-a-service, big data analytics, cloud computing, solution lifecycle;;;CF '15
Book;Singh H;Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python;;2019;;;;1st;APress;;;;;2019;9781484241486;;;;Gain insights into image-processing methodologies and algorithms, using machine learning and neural networks in Python. This book begins with the environment setup, understanding basic image-processing terminology, and exploring Python concepts that will be useful for implementing the algorithms discussed in the book. You will then cover all the core image processing algorithms in detail before moving onto the biggest computer vision library: OpenCV. You'll see the OpenCV algorithms and how to use them for image processing. The next section looks at advanced machine learning and deep learning methods for image processing and classification. You'll work with concepts such as pulse coupled neural networks, AdaBoost, XG boost, and convolutional neural networks for image-specific applications. Later you'll explore how models are made in real time and then deployed using various DevOps tools. All the concepts in Practical Machine Learning and Image Processing are explained using real-life scenarios. After reading this book you will be able to apply image processing techniques and make machine learning models for customized application. What You Will Learn Discover image-processing algorithms and their applications using Python Explore image processing using the OpenCV library Use TensorFlow, scikit-learn, NumPy, and other libraries Work with machine learning and deep learning algorithms for image processing Apply image-processing techniques to five real-time projects Who This Book Is For Data scientists and software developers interested in image processing and computer vision.;;;;
Conference Paper;Hanappi O,Hummer W,Dustdar S;Asserting Reliable Convergence for Configuration Management Scripts;;2016;;;328–343;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications;Amsterdam, Netherlands;2016;9781450344449;;"https://doi-org.proxy.bnl.lu/10.1145/2983990.2984000;http://dx.doi.org/10.1145/2983990.2984000";10.1145/2983990.2984000;The rise of elastically scaling applications that frequently deploy new machines has led to the adoption of DevOps practices across the cloud engineering stack. So-called configuration management tools utilize scripts that are based on declarative resource descriptions and make the system converge to the desired state. It is crucial for convergent configurations to be able to gracefully handle transient faults, e.g., network outages when downloading and installing software packages. In this paper we introduce a conceptual framework for asserting reliable convergence in configuration management. Based on a formal definition of configuration scripts and their resources, we utilize state transition graphs to test whether a script makes the system converge to the desired state under different conditions. In our generalized model, configuration actions are partially ordered, often resulting in prohibitively many possible execution orders. To reduce this problem space, we define and analyze a property called preservation, and we show that if preservation holds for all pairs of resources, then convergence holds for the entire configuration. Our implementation builds on Puppet, but the approach is equally applicable to other frameworks like Chef, Ansible, etc. We perform a comprehensive evaluation based on real world Puppet scripts and show the effectiveness of the approach. Our tool is able to detect all idempotence and convergence related issues in a set of existing Puppet scripts with known issues as well as some hitherto undiscovered bugs in a large random sample of scripts.;Configuration Management, DevOps, Puppet, Declarative Language, Convergence, Idempotence, Testing, System Configuration Scripts;;;OOPSLA 2016
Book;Abbott ML,Fisher MT;The Art of Scalability: Scalable Web Architecture, Processes, and Organizations for the Modern Enterprise;;2015;;;;2nd;Addison-Wesley Professional;;;;;2015;9780134032801;;;;The Comprehensive, Proven Approach to IT Scalability Updated with New Strategies, Technologies, and Case Studies In The Art of Scalability, Second Edition, leading scalability consultants Martin L. Abbott and Michael T. Fisher cover everything you need to know to smoothly scale products and services for any requirement. This extensively revised edition reflects new technologies, strategies, and lessons, as well as new case studies from the authors pioneering consulting practice, AKF Partners. Writing for technical and nontechnical decision-makers, Abbott and Fisher cover everything that impacts scalability, including architecture, process, people, organization, and technology. Their insights and recommendations reflect more than thirty years of experience at companies ranging from eBay to Visa, and Salesforce.com to Apple. Youll find updated strategies for structuring organizations to maximize agility and scalability, as well as new insights into the cloud (IaaS/PaaS) transition, NoSQL, DevOps, business metrics, and more. Using this guides tools and advice, you can systematically clear away obstacles to scalabilityand achieve unprecedented IT and business performance. Coverage includes Why scalability problems start with organizations and people, not technology, and what to do about it Actionable lessons from real successes and failures Staffing, structuring, and leading the agile, scalable organization Scaling processes for hyper-growth environments Architecting scalability: proprietary models for clarifying needs and making choicesincluding 15 key success principles Emerging technologies and challenges: data cost, datacenter planning, cloud evolution, and customer-aligned monitoring Measuring availability, capacity, load, and performance;;;;
Book;Tejada Z,Bustamante ML,Ellis I;Exam Ref 70-532 Developing Microsoft Azure Solutions;;2015;;;;1st;Microsoft Press;USA;;;;2015;9780735697041;;;;"Prepare for Microsoft Exam 70-532--and help demonstrate your real-world mastery of Microsoft Azure solution development. Designed for experienced developers ready to advance their status, Exam Ref focuses on the critical-thinking and decision-making acumen needed for success at the Microsoft Specialist level. Focus on the expertise measured by these objectives: Design and implement Websites Create and manage Virtual Machines Design and implement Cloud Services Design and implement a storage strategy Manage application and network services This Microsoft Exam Ref: Organizes its coverage by exam objectives Features strategic, what-if scenarios to challenge you Will be valuable for Microsoft Azure developers, solution architects, DevOps engineers, and QA engineers Assumes you have experience designing, programming, implementing, automating, and monitoring Microsoft Azure solutions and that you are proficient with tools, techniques, and approaches for building scalable, resilient solutions Developing Microsoft Azure SolutionsAbout the Exam Exam 70-532 focuses on the skills and knowledge needed to develop Microsoft Azure solutions that include websites, virtual machines, cloud services, storage, application services, and network services. About Microsoft Certification Passing this exam earns you a Microsoft Specialist certification in Microsoft Azure, demonstrating your expertise with the Microsoft Azure enterprise-grade cloud platform. You can earn this certification by passing Exam 70-532, Developing Microsoft Azure Solutions; or Exam 70-533, Implementing Microsoft Azure Infrastructure Solutions; or Exam 70-534, Architecting Microsoft Azure Solutions. See full details at: microsoft.com/learning";;;;
Book;Papapetrou P,Lalou J;Android Application Development with Maven;;2015;;;;;Packt Publishing;;;;;2015;9781783986101;;;;Learn how to use and configure Maven to support all phases of the development of an Android application About This BookLearn how to effectively use Maven to create, test, and release Android applicationsCustomize Maven using a variety of suggested plugins for the most popular Android toolsDiscover new ways of accelerating the implementation, testing, and maintenance using this step-by-step simple tutorial approachWho This Book Is ForAndroid Application Development with Maven is intended for Android developers or devops engineers who want to use Maven to effectively develop quality Android applications. It would be helpful, but not necessary, if you have some previous experience with Maven. In Detail Android is an open source operating system used for smartphones and tablet computers. The Android market is one of the biggest and fastest growing platforms for application developers, with over a million apps uploaded every day.Right from the beginning, this book will cover how to set up your Maven development environment and integrate it with your favorite IDE. By sequentially working through the steps in each chapter, you will quickly master the plugins you need for every phase of the Android development process. You will learn how to use Maven to manage and build your project and dependencies, automate your Android application testing plans, and develop and maintain several versions of your application in parallel. Most significantly, you will learn how to integrate your project into a complete factory.;;;;
Book;Vijayakumar T;Practical Azure Application Development: A Step-by-Step Approach to Build Feature-Rich Cloud-Ready Solutions;;2017;;;;1st;Apress;USA;;;;2017;9781484228166;;;;Get started and learn a step-by-step approach to application development using Microsoft Azure. Select the right services to solve the problem at hand in a cost-effective manner and explore the potential different services and how they can help in building enterprise applications. Azure has an ample amount of resources and tutorials, but most of them focus on specific services and explain those services on their own and in a given context. Practical Azure Application Development focuses on building complete solutions on Azure using different services. This book gives you the holistic approach to Azure as a solutions development platform. This book:Covers Azure as a solution development platform for building applications Provides real-world examples to understand why and when an Azure service is required Discusses how Azure helps to achieve continuous improvement and expansion of an application Provides application development experience from purchasing Azure to integrating with core Azure services, including an introduction to DevOps with VSTS What You'll Learn Use Azure services to solve real-world software problems Define the usage of Azure services and select the right services to solve the problem at hand Make clear and less ambiguous decisions about using different Azure services Take a holistic approach to Azure as a solution platform Understand the basics of security, data protection, and cost controls in Azure Who This Book Is ForDevelopers, software engineers, and architects who have experience in .NET and web development, but have little or no knowledge in planning and developing an application on Azure;;;;
Book;Washam M,Rainey R;Exam Ref 70-533 Implementing Microsoft Azure Infrastructure Solutions;;2015;;;;1st;Microsoft Press;USA;;;;2015;9780735697065;;;;"Prepare for Microsoft Exam 70-533--and help demonstrate your real-world mastery of Microsoft Azure infrastructure solution implementation. Designed for experienced IT pros ready to advance their status, Exam Ref focuses on the critical-thinking and decision-making acumen needed for success at the Microsoft Specialist level. Focus on the expertise measured by these objectives: Deploy, configure, monitor, and scale websites Implement virtual machine workloads, images, disks, networking, and storage Configure, deploy, manage, and monitor cloud services Implement blobs, Azure files, SQL databases, and recovery services Manage access and configure diagnostics, monitoring, and analytics Implement an Azure Active Directory and integrate apps Configure and modify virtual networks, including multisite and hybrid networks This Microsoft Exam Ref: Organizes its coverage by exam objectives Features strategic, what-if scenarios to challenge you Will be valuable for IT pros, including enterprise architects; DevOps, network, server, virtualization, and identity engineers; and storage or security administrators Assumes you have experience implementing Microsoft Azure infrastructure solutions Implementing Microsoft Azure Infrastructure SolutionsAbout the Exam Exam 70-533 focuses on the skills and knowledge needed to implement web- sites, virtual machines, cloud services, storage, Azure Active Directory, and virtual networks with Microsoft Azure. About Microsoft Certification Passing this exam earns you a Microsoft Specialist certification in Microsoft Azure, demonstrating your expertise with the Microsoft Azure enterprise-grade cloud platform. You can earn this certification by passing Exam 70-532, Developing Microsoft Azure Solutions; or Exam 70-533, Imple- menting Microsoft Azure Infrastructure Solutions; or Exam 70-534, Architecting Microsoft Azure Solutions. See full details at: microsoft.com/learning";;;;
Book;Kumar A,Shelley D;OpenStack Trove;;2015;;;;1st;Apress;USA;;;;2015;9781484212226;;;;OpenStack Trove is your step-by-step guide to set up and run a secure and scalable cloud Database as a Service (DBaaS) solution. The book shows you how to set up and configure the Trove DBaaS framework, use prepackaged or custom database implementations, and provision and operate a variety of databasesincluding MySQL, PostgreSQL, MongoDB, Cassandra, and Redisin development and production environments. Authors Amrith Kumar and Douglas Shelley, both active technical contributors to the Trove project, describe common deployment scenarios such as single-node database instances and walk you through the setup, configuration, and ongoing management of complex database topics like replication, clustering, and high availability. The book provides detailed descriptions of how Trove works and gives you an in-depth understanding of its architecture. It also shows you how to avoid common errors and debug and troubleshoot Trove installations, and perform common tasks such as: What youll learn Install and configure Trove Install preconfigured database technologies or guest images Launch database instances using Trove Perform common administrative tasks Resize and reconfigure database instances Take backups, and launch instances from existing backups Manage groups of database instances with configuration groups Debug and troubleshoot a Trove installation Set up replication and clustering Build custom guest images for use with Trove Who this book is for OpenStack Trove is targeted at a broad spectrum of readers, including software engineers seeking development agility with database-driven applications, devops engineers tasked with operating a database infrastructure with numerous databases, and data analysts looking to improve velocity by being able to quickly provision and release database capacity.;;;;
Book;Indrasiri K,Siriwardena P;Microservices for the Enterprise: Designing, Developing, and Deploying;;2018;;;;1st;Apress;USA;;;;2018;9781484238578;;;;Understand the key challenges and solutions around building microservices in the enterprise application environment. This book provides a comprehensive understanding of microservices architectural principles and how to use microservices in real-world scenarios. Architectural challenges using microservices with service integration and API management are presented and you learn how to eliminate the use of centralized integration products such as the enterprise service bus (ESB) through the use of composite/integration microservices. Concepts in the book are supported with use cases, and emphasis is put on the reality that most of you are implementing in a brownfield environment in which you must implement microservices alongside legacy applications with minimal disruption to your business. Microservices for the Enterprisecovers state-of-the-art techniques around microservices messaging, service development and description, service discovery, governance, and data management technologies and guides you through the microservices design process. Also included is the importance of organizing services as core versus atomic, composite versus integration, and API versus edge, and how such organization helps to eliminate the use of a central ESB and expose services through an API gateway. What You'll Learn Design and develop microservices architectures with confidence Put into practice the most modern techniques around messaging technologies Apply the Service Mesh pattern to overcome inter-service communication challenges Apply battle-tested microservices security patterns to address real-world scenarios Handle API management, decentralized data management, and observability Who This Book Is ForDevelopers and DevOps engineers responsible for implementing applications around a microservices architecture, and architects and analysts who are designing such systems;;;;
Conference Paper;Florea R,Stray V;A Qualitative Study of the Background, Skill Acquisition, and Learning Preferences of Software Testers;;2020;;;299–305;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Evaluation and Assessment in Software Engineering;Trondheim, Norway;2020;9781450377317;;"https://doi-org.proxy.bnl.lu/10.1145/3383219.3383252;http://dx.doi.org/10.1145/3383219.3383252";10.1145/3383219.3383252;Context: There is an indisputable industrial need for highly skilled individuals in the role of software testers. However, little is known about the educational background of these professionals, their first contact with the role, their preferences in acquiring skills, the impediments they face, and their perception of the software testing role. Objective: In the current paper, we report on the background, skills, learning preferences, and role profiles as described by professionals in software testing, spanning over a significant number of industries, countries, and software development models. Method: We conducted 19 in-depth, semi-structured interviews with software testing practitioners, across eight industries. We performed a content and thematic analysis of the collected data. Results: The practitioners in software testing had diverse educational backgrounds, and their first contact with the testing role was accidental. Exploratory testing was the preferred testing technique, while curiosity was identified as the most important feature in their skill set. Our respondents collaborated extensively with the developers, whom they perceived as a learning source and symbiotic work partner. Conclusion: The professionals in software testing described their skills as a rather undefined heap of knowledge, increasing with each work task. They used mainly informal and hands-on learning approaches. They found it necessary for education providers to present information on software testing. Generally, companies assisted them well in their skill development but need to allocate sufficient time for the learning. We identified five specialties of the role: product owner in testing, UX tester, DevOps tester, test-script automator, and test-process coordinator.;Software Testing, Software Testing Profiles, Skill Acquisition, Hiring Software Testers, Software Tester;;;EASE '20
Conference Paper;Costa DI,Filho EP,Silva RF,de C. Quaresma Gama TD,Cortés MI;Microservice Architecture: A Tertiary Study;;2020;;;61–70;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse;Natal, Brazil;2020;9781450387545;;"https://doi-org.proxy.bnl.lu/10.1145/3425269.3425277;http://dx.doi.org/10.1145/3425269.3425277";10.1145/3425269.3425277;Context. The large-scale use of microservices and their increasing adoption in the industry in recent years has motivated researches on the most diverse aspects related to microservice-based development. However, as it is a relatively new topic, there is still no consolidated body of knowledge in the area. Objective. The present work intends to investigate the current state of research on microservices based on the formulation of six research questions covering fundamental aspects, such as: main interest topics and adopted standards, techniques and tools have been used and application areas. Method. From four digital libraries, 22 secondary studies were selected as a data source, which were analyzed and synthesized in the present study following the proposed research protocol. Results. Among the main topics of interest addressed, we highlight researches related to the applicability of microservice architecture, both by industry and academia. Results indicated that standards focus on challenges related to communication have been the most commonly considered by researchers of the area. Finally, the predominance in the use of the Docker container and the presence of DevOps practices in the automation of operations are noteworthy. Conclusions. The present mapping study points to some directions of research based on the identified gaps, such as modeling and testing of microservice applications, and addressing security aspects. Another promising point to be explored involves the combined use of microservice architecture with other related concepts such as IoT, smart cities, FOG computing and reactive systems, in order to reinforce the use of microservices, as well as creating new solutions and challenges to be researched.;Mapeamento sistemático, Industria, Arquitetura de software, Academia, Padrões de arquitetura, Microsserviços;;;SBCARS '20
Book;van Baarsen J;GitLab Cookbook;;2014;;;;;Packt Publishing;;;;;2014;9781783986842;;;;Over 60 hands-on recipes to efficiently self-host your own Git repository using GitLab About This BookGet hands-on with day-to-day tasks to effectively manage and administer your repository with GitLabCovers advanced topics like GitLab continuous integration and LDAP integrationAuthored by a member of the GitLab core team, this Cookbook gives practical insights into installing and self-hosting your own GitLab and GitLab CI serverWho This Book Is ForThis book is aimed at developers and devops that have a GitLab server running, and want to be sure they use it to its full potential. This book will also be useful for people looking for a great Git platform, and learn how to set it up successfully. Some system administrating experience on a UNIX-based system would be useful, but is not required. In Detail GitLab is a popular, open source Git hosting solution implemented by more than 50,000 organizations. This book has some carefully chosen recipes to help you decide on the type of GitLab installation that will fit your requirements. Along with covering some of the basic principles of Git, the book covers practical scenarios to show how you or your organization can effectively manage your proprietary code.You will learn how to manage multiple users, groups, and the permissions GitLab has for them. Updating your GitLab instance, creating backups, and restoring backups are a few of the important tasks described in detail to assist you in maintaining your GitLab server. Moreover, the GitLab API is extensively covered to guide you through the various operations to manage your project.;;;;
Book;Haff G;How Open Source Ate Software: Understand the Open Source Movement and So Much More;;2018;;;;1st;Apress;USA;;;;2018;9781484238936;;;;"Learn how free software became open source and how you can sell open source software. This book provides a historical context of how open source has thoroughly transformed how we write software, how we cooperate, how we communicate, how we organize, and, ultimately, how we think about business values. Youll look at project and community examples including Linux, BSD, Apache, and Kubernetes, understand the open source development model, and how open source has influenced approaches more broadly, even proprietary software, such as open betas. You'll also examine the flipside, the ""Second Machine Age,"" and the challenges of open source-based business models. Today, open source serves as shorthand for much broader trends and behaviors. Its not just about a free (in all senses of the word) alternative to commercial software. It increasingly is the new commercial software. How Open Source Ate Softwarereveals how open source has much in common, and is often closely allied, with many other trends in business and society. You'll see how it enables projects that go beyond any individual company. That makes open source not just a story about software, but a story about almost everything. What You'll Learn Understand open source opportunities and challenges Sell software if youre giving it away Apply open source principles more broadly to openorg, devops, etc. Review which organizational incentives you can implement Who This Book Is For Anyone who has an interest in what is happening in open source and the open source community, and anyone who is contemplating making a business that involves open source.";;;;
Book;Raj P,Raman A;Software-Defined Cloud Centers: Operational and Management Technologies and Tools;;2018;;;;1st;Springer Publishing Company, Incorporated;;;;;2018;9783319786360;;;;"This practical text/reference provides an exhaustive guide to setting up and sustaining software-defined data centers (SDDCs). Each of the core elements and underlying technologies are explained in detail, often supported by real-world examples. The text illustrates how cloud integration, brokerage, and orchestration can ensure optimal performance and usage of data resources, and what steps are required to secure each component in a SDDC. The coverage also includes material on hybrid cloud concepts, cloud-based data analytics, cloud configuration, enterprise DevOps and code deployment tools, and cloud software engineering. Topics and features: highlights how technologies relating to cloud computing, IoT, blockchain, and AI are revolutionizing business transactions, operations, and analytics; introduces the concept of Cloud 2.0, in which software-defined computing, storage, and networking are applied to produce next-generation cloud centers; examines software-defined storage for storage virtualization, covering issues of cloud storage, storage tiering, and deduplication; discusses software-defined networking for network virtualization, focusing on techniques for network optimization in data centers; reviews the qualities and benefits of hybrid clouds, that bridge private and public cloud environments; investigates the security management of a software-defined data center, and proposes a framework for managing hybrid IT infrastructure components; describes the management of multi-cloud environments through automated tools, and cloud brokers that aim to simplify cloud access, use and composition; covers cloud orchestration for automating application integration, testing, infrastructure provisioning, software deployment, configuration, and delivery. This comprehensive work is an essential reference for all practitioners involved with software-defined data center technologies, hybrid clouds, cloud service management, cloud-based analytics, and cloud-based software engineering.";;;;
Book;Young M;Implementing Cloud Design Patterns for AWS;;2015;;;;;Packt Publishing;;;;;2015;9781782177340;;;;Create highly efficient design patterns for scalability, redundancy, and high availability in the AWS Cloud About This BookCreate highly robust systems using cloud infrastructureMake web applications resilient against scheduled and accidental down-timeExplore and apply Amazon-provided services in unique ways to solve common problemsWho This Book Is ForThis book is aimed at architects, solution providers, and those of the DevOps community who are looking to implement repeatable patterns for deploying and maintaining services in the Amazon cloud infrastructure. Prior experience using AWS is required as the book focuses more on the patterns and not on the basics of using AWS.What You Will Learn Create and maintain server backups Implement scaling policies on schedules, influxes in traffic, and deep health checks Provision servers and data that persist through termination Make complete use of high availability storage and redundancy storage Design content delivery networks to improve user experience Optimize databases through caching and sharding Monitor and queue data for processing In DetailWhether you are just getting your feet wet in cloud infrastructure or already creating complex systems, this book aims at describing patterns that can be used to fit your system needs.The initial patterns will cover some basic processes such as maintaining and storing backups as well as handling redundancy. The book will then take you through patterns of high availability. Following this, the book will discuss patterns for processing static and dynamic data and patterns for uploading data. The book will then dive into patterns for databases and data processing. In the final leg of your journey, you will get to grips with advanced patterns on Operations and Networking and also get acquainted with Throw-away Environments.;;;;
Book;Sabharwal N,Wadhwa M;Automation through Chef Opscode: A Hands-on Approach to Chef;;2014;;;;1st;Apress;USA;;;;2014;9781430262954;;;;Automation through Chef Opscode provides an in-depth understanding of Chef, which is written in Ruby and Erlang for configuration management, cloud infrastructure management, system administration, and network management. Targeted at administrators, consultants, and architect, the book guides them through the advanced features of the tool which are necessary for infrastructure automation, devops automation, and reporting. The book presumes knowledge of Ruby and Erlang which are used as reference languages for creating recipes and cookbooks and as a refresher on them to help the reader get on speed with the flow of book. The book provides step by step instructions on installation and configuration of Chef, usage scenarios of Chef, in infrastructure automation by providing common scenarios like virtual machine provisioning, OS configuration for Windows, Linux, and Unix, provisioning and configuration of web servers like Apache along with popular databases like MySQL. It further elaborates on the creation of recipes, and cookbooks, which help in deployment of servers and applications to any physical, virtual, or cloud location, no matter the size of the infrastructure. The books covers advanced features like LWRPs and Knife and also contains several illustrative sample cookbooks on MySQL, Apache, and CouchDB deployment using a step by step approach. What youll learn Features and resources that power Chef as an optimum automation tool Installing and configuring Chef Managing your infrastructure using Chef How to develop cookbooks and recipes Real-time automation to deploy servers and applications to any physical, virtual, or cloud location Who this book is for IT administrators OS administrators Linux administrators Consultants Cloud architects Cloud computing consultants Infrastructure architects Automation consultants Automation architects;;;;
Book;Zecevic P,Bonaci M;Spark in Action;;2016;;;;1st;Manning Publications Co.;USA;;;;2016;9781617292606;;;;Summary Spark in Action teaches you the theory and skills you need to effectively handle batch and streaming data using Spark. Fully updated for Spark 2.0. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the Technology Big data systems distribute datasets across clusters of machines, making it a challenge to efficiently query, stream, and interpret them. Spark can help. It is a processing system designed specifically for distributed data. It provides easy-to-use interfaces, along with the performance you need for production-quality analytics and machine learning. Spark 2 also adds improved programming APIs, better performance, and countless other upgrades. About the Book Spark in Action teaches you the theory and skills you need to effectively handle batch and streaming data using Spark. You'll get comfortable with the Spark CLI as you work through a few introductory examples. Then, you'll start programming Spark using its core APIs. Along the way, you'll work with structured data using Spark SQL, process near-real-time streaming data, apply machine learning algorithms, and munge graph data using Spark Graph X. For a zero-effort startup, you can download the preconfigured virtual machine ready for you to try the book's code. What's Inside Updated for Spark 2.0 Real-life case studies Spark DevOps with Docker Examples in Scala, and online in Java and Python About the Reader Written for experienced programmers with some background in big data or machine learning. About the Authors Petar Zeevi and Marko Bonai are seasoned developers heavily involved in the Spark community.;;;;
Conference Paper;Alizadeh V,Ouali MA,Kessentini M,Chater M;RefBot: Intelligent Software Refactoring Bot;;2019;;;823–834;;IEEE Press;San Diego, California;;Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering;;2019;9781728125084;;"https://doi-org.proxy.bnl.lu/10.1109/ASE.2019.00081;http://dx.doi.org/10.1109/ASE.2019.00081";10.1109/ASE.2019.00081;"The adoption of refactoring techniques for continuous integration received much less attention from the research community comparing to root-canal refactoring to fix the quality issues in the whole system. Several recent empirical studies show that developers, in practice, are applying refactoring incrementally when they are fixing bugs or adding new features. There is an urgent need for refactoring tools that can support continuous integration and some recent development processes such as DevOps that are based on rapid releases. Furthermore, several studies show that manual refactoring is expensive and existing automated refactoring tools are challenging to configure and integrate into the development pipelines with significant disruption cost.In this paper, we propose, for the first time, an intelligent software refactoring bot, called RefBot. Integrated into the version control system (e.g. GitHub), our bot continuously monitors the software repository, and it is triggered by any ""open"" or ""merge"" action on pull requests. The bot analyzes the files changed during that pull request to identify refactoring opportunities using a set of quality attributes then it will find the best sequence of refactorings to fix the quality issues if any. The bot recommends all these refactorings through an automatically generated pull-request. The developer can review the recommendations and their impacts in a detailed report and select the code changes that he wants to keep or ignore. After this review, the developer can close and approve the merge of the bot's pull request. We quantitatively and qualitatively evaluated the performance and effectiveness of RefBot by a survey conducted with experienced developers who used the bot on both open source and industry projects.";quality, refactoring, Software bot;;;ASE '19
Conference Paper;Li H,Chen TH,Hassan AE,Nasser M,Flora P;Adopting Autonomic Computing Capabilities in Existing Large-Scale Systems: An Industrial Experience Report;;2018;;;1–10;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice;Gothenburg, Sweden;2018;9781450356596;;"https://doi-org.proxy.bnl.lu/10.1145/3183519.3183544;http://dx.doi.org/10.1145/3183519.3183544";10.1145/3183519.3183544;In current DevOps practice, developers are responsible for the operation and maintenance of software systems. However, the human costs for the operation and maintenance grow fast along with the increasing functionality and complexity of software systems. Autonomic computing aims to reduce or eliminate such human intervention. However, there are many existing large systems that did not consider autonomic computing capabilities in their design. Adding autonomic computing capabilities to these existing systems is particularly challenging, because of 1) the significant amount of efforts that are required for investigating and refactoring the existing code base, 2) the risk of adding additional complexity, and 3) the difficulties for allocating resources while developers are busy adding core features to the system. In this paper, we share our industrial experience of re-engineering autonomic computing capabilities to an existing large-scale software system. Our autonomic computing capabilities effectively reduce human intervention on performance configuration tuning and significantly improve system performance. In particular, we discuss the challenges that we encountered and the lessons that we learned during this re-engineering process. For example, in order to minimize the change impact to the original system, we use a variety of approaches (e.g., aspect-oriented programming) to separate the concerns of autonomic computing from the original behaviour of the system. We also share how we tested such autonomic computing capabilities under different conditions, which has never been discussed in prior work. As there are numerous large-scale software systems that still require expensive human intervention, we believe our experience provides valuable insights to software practitioners who wish to add autonomic computing capabilities to these existing large-scale software systems.;performance engineering, autonomic computing, software re-engineering, software testing;;;ICSE-SEIP '18
Conference Paper;Saha P,Beltre A,Uminski P,Govindaraju M;Evaluation of Docker Containers for Scientific Workloads in the Cloud;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the Practice and Experience on Advanced Research Computing;Pittsburgh, PA, USA;2018;9781450364461;;"https://doi-org.proxy.bnl.lu/10.1145/3219104.3229280;http://dx.doi.org/10.1145/3219104.3229280";10.1145/3219104.3229280;The HPC community is actively researching and evaluating tools to support execution of scientific applications in cloud-based environments. Among the various technologies, containers have recently gained importance as they have significantly better performance compared to full-scale virtualization, support for microservices and DevOps, and work seamlessly with workflow and orchestration tools. Docker is currently the leader in containerization technology because it offers low overhead, flexibility, portability of applications, and reproducibility. Singularity is another container solution that is of interest as it is designed specifically for scientific applications. It is important to conduct performance and feature analysis of the container technologies to understand their applicability for each application and target execution environment.This paper presents a (1) performance evaluation of Docker and Singularity on bare metal nodes in the Chameleon cloud (2) mechanism by which Docker containers can be mapped with InfiniBand hardware with RDMA communication and (3) analysis of mapping elements of parallel workloads to the containers for optimal resource management with container-ready orchestration tools. Our experiments are targeted toward application developers so that they can make informed decisions on choosing the container technologies and approaches that are suitable for their HPC workloads on cloud infrastructure. Our performance analysis shows that scientific workloads for both Docker and Singularity based containers can achieve near-native performance.Singularity is designed specifically for HPC workloads. However, Docker still has advantages over Singularity for use in clouds as it provides overlay networking and an intuitive way to run MPI applications with one container per rank for fine-grained resources allocation. Both Docker and Singularity make it possible to directly use the underlying network fabric from the containers for coarsegrained resource allocation.;Singularity, Docker, scientific workloads;;;PEARC '18
Book;Ljubuncic I,Litterer T;System Administration Ethics: Ten Commandments for Security and Compliance in a Modern Cyber World;;2019;;;;1st;Apress;USA;;;;2019;9781484249871;;;;"Successfully navigate through the ever-changing world of technology and ethics and reconcile system administration principles for separation of duty, account segmentation, administrative groups and data protection. As security breaches become more common, businesses need to protect themselves when facing ethical dilemmas in today's digital landscape. This book serves as a equitable guideline in helping system administrators, engineers - as well as their managers - on coping with the ethical challenges of technology and security in the modern data center by providing real-life stories, scenarios, and use cases from companies both large and small. You'll examine the problems and challenges that people working with customer data, security and system administration may face in the cyber world and review the boundaries and tools for remaining ethical in an environment where it is so easy to step over a line - intentionally or accidentally. You'll also see how to correctly deal with multiple ethical situations, problems that arise, and their potential consequences, with examples from both classic and DevOps-based environments. Using the appropriate rules of engagement, best policies and practices, and proactive ""building/strengthening"" behaviors, System Administration Ethics provides the necessary tools to securely run an ethically correct environment. What You'll Learn The concepts of Least Privilege and Need to Know Request change approval and conduct change communication Follow ""Break Glass"" emergency procedures Code with data breaches, hacking and security violations, and proactively embrace and design for failures Build and gain trust with employees and build the right ethical culture Review what managers can do to improve ethics and protect their employees Who This Book Is For This book's primary audience includes system administrators and information security specialists engaged with the creation, process and administration of security policies and systems. A secondary audience includes company leaders seeking to improve the security, privacy, and behavioral practices.";;;;
Conference Paper;de Lacerda AR,Aguiar CS;FLOSS FAQ Chatbot Project Reuse: How to Allow Nonexperts to Develop a Chatbot;;2019;;;;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the 15th International Symposium on Open Collaboration;Skövde, Sweden;2019;9781450363198;;"https://doi-org.proxy.bnl.lu/10.1145/3306446.3340823;http://dx.doi.org/10.1145/3306446.3340823";10.1145/3306446.3340823;FAQ chatbots possess the capability to provide answers to frequently asked questions of a particular service, platform, or system. Currently, FAQ chatbot is the most popular domain of use of dialog assistants. However, developing a chatbot project requires a full-stack team formed by numerous specialists, such as dialog designer, data scientist, software engineer, DevOps, business strategist and experts from the domain, which can be both time and resources consuming. Language processing can be particularly challenging in languages other than English due to the scarcity of training datasets.Most of the requirements of FAQ chatbots are similar, domain-specific, and projects could profit from Open Source Software (OSS) reuse. In this paper, we examine how OSS FAQ chatbot projects can benefit from reuse at the project level (black-box reuse). We present an experience report of a FLOSS FAQ chatbot project developed in Portuguese to an e-government service in Brazil. It comprises of the chatbot distribution service, as well as for analytics tool integrated and deployed on-premises. We identified assets that could be reused as a black-box and the assets that should be customized for a particular application. We categorized these assets in architecture, corpus, dialog flows, machine learning models, and documentation. This paper discusses how automation, pre-configuration, and templates can aid newcomers to develop chatbots in Portuguese without the need for specialized skills required from tools in chatbot architecture. Our main contribution is to highlight the issues non-English FAQ chatbots projects will likely face and the assets that can be reused. It allows non-chatbot experts to develop a quality-assured OSS FAQ chatbot in a shorter project cycle.;OSS, black-box reuse, e-government, conversational agents, FLOSS, experience report, FLOSS FAQ chatbot, portuguese chatbot, open source;;;OpenSym '19
Book;Fleming S;Blockchain Technology and Kubernetes: Non-Programmer?S Handbook;;2018;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2018;9781727447743;;;;"Are you a non-coder looking for insight into Blockchain Technology and Kubernetes? You may be a consultant, Advisor, Project Manager or a novice into IT/Consulting industry; looking for latest Technologies, Application Development methodologies and Service Oriented Architecture models. This book is a collection of my two manuscripts (Blockchain Technology & Kubernetes Handbook) which will provide you with insights into Blockchain Technology and Kubernetes. It also includes additional booklets with the latest case studies and interesting facts. Blockchain Questions Answered:- How would Blockchain Technology impact the day to day lives of common people?- How could the government leverage the Blockchain Technology to improve the service delivery?- How would the existing businesses be impacted and integrated with this new Technology?- How the current Businesses and Jobs would be transformed?- What are the other sectors where this Technology have been Implemented? Kubernetes Questions Answered:The Background of it? Why we needed this system in first place? How Kubernetes Operates? The Nuts and Bolts of the system. How it is deployed? Best Practices After going through this guide you would be able to appreciate related concepts like Blockchain Wallet, Distributed Ledger, Agile, SOA, Monolith Architecture, DevOps, Docker, Kubernetes etc. You would also get to know about the latest development and case studies in these fields. I am confident that after going through the book you would be able to navigate the discussion with any stakeholder and take your agenda ahead as per your role. Additionally, if you are new to the industry, and looking for a job in Technology Consulting, this book will help you to prepare with all the relevant information and understanding of the topics.";;;;
Book;Klaffenbach F,Klein M,Hoppe S,Michalski O,Damaschke JH;Implementing Azure Solutions: Deploy and Manage Azure Containers and Build Azure Solutions with Ease, 2nd Edition;;2018;;;;;Packt Publishing;;;;;2018;9781789343045;;;;Get up and running with Azure services and learn how to implement them in your organization Key Features Deploy Azure Services in a controlled and preconfigured environment Discover best practices and techniques for implementing Azure Solutions Build and deploy an app using Azure App Services Book Description Microsoft Azure offers numerous solutions that can shape the future of any business. However, the major challenge that architects and administrators face lies in implementing these solutions. Implementing Azure Solutions helps you overcome this challenge by enabling you to implement Azure Solutions effectively. The book begins by guiding you in choosing the backend structure for your solutions. You will then work with the Azure toolkit and learn how to use Azure Managed Apps to share your solutions with the Azure service catalog. The book then focuses on various implementation techniques and best practices such as implementing Azure Cloud Services by configuring, deploying, and managing cloud services. As you progress through the chapters, you'll learn how to work with Azure-managed Kubernetes and Azure Container Services. By the end of the book, you will be able to build robust cloud solutions on Azure. What you will learn Create and manage a Kubernetes cluster in Azure Kubernetes Service (AKS) Implement site-to-site VPN and Express Route connections in your environment Explore the best practices in building and deploying app services Use Telemetry to monitor your Azure Solutions Design an Azure IoT solution and learn how to operate in different scenarios Implement a Hybrid Azure Design using Azure Stack Who this book is for If you're an IT architect, IT professional, or DevOps engineer who plans to implement Azure Solutions for your organization, this book is for you.;;;;
Book;Patawari A,Aggarwal V;Ansible 2 Cloud Automation Cookbook: Write Ansible Playbooks for AWS, Google Cloud, Microsoft Azure, and OpenStack;;2018;;;;;Packt Publishing;;;;;2018;9781788295826;;;;Orchestrate your cloud infrastructure Key Features Recipe-based approach to install and configure cloud resources using AnsibleCovers various cloud-related modules and their functionalitiesIncludes deployment of a sample application to the cloud resources that we create Learn the best possible way to manage and automate your cloud infrastructure Book Description Ansible has a large collection of inbuilt modules to manage various cloud resources. The book begins with the concepts needed to safeguard your credentials and explain how you interact with cloud providers to manage resources. Each chapter begins with an introduction and prerequisites to use the right modules to manage a given cloud provider. Learn about Amazon Web Services, Google Cloud, Microsoft Azure, and other providers. Each chapter shows you how to create basic computing resources, which you can then use to deploy an application. Finally, you will be able to deploy a sample application to demonstrate various usage patterns and utilities of resources. What you will learn Use Ansible Vault to protect secrets Understand how Ansible modules interact with cloud providers to manage resources Build cloud-based resources for your applicationCreate resources beyond simple virtual machines Write tasks that can be reused to create resources multiple times Work with self-hosted clouds such as Open Stack and Docker Deploy a multi-tier application on various cloud providers Who This Book Is ForIf you are a system administrator, infrastructure engineer, or a DevOps engineer who wants to obtain practical knowledge about Ansible and its cloud deliverables, then this book is for you. Recipes in this book are designed for people who would like to manage their cloud infrastructures efficiently using Ansible, which is regarded as one of the best tools for cloud management and automation.;;;;
Journal Article;Satyal S,Weber I,Paik HY,Di Ciccio C,Mendling J;Business Process Improvement with the AB-BPM Methodology;Inf. Syst.;2019;84;C;283–298;;Elsevier Science Ltd.;GBR;;;;2019-09;;0306-4379;"https://doi-org.proxy.bnl.lu/10.1016/j.is.2018.06.007;http://dx.doi.org/10.1016/j.is.2018.06.007";10.1016/j.is.2018.06.007;;DevOps, AB testing, Trace simulation, Process performance indicators, Business process management;;;
Book;Kaewkasi C;Docker for Serverless Applications: Containerize and Orchestrate Functions Using OpenFaas, OpenWhisk, and Fn;;2018;;;;;Packt Publishing;;;;;2018;9781788835268;;;;Build applications and infrastructures that leverage Function-as-a-Service and Docker Key Features Implement containerization in Serverless/FaaS environments Utilize Docker as a functional unit of work for Serverless/FaaS platforms Use Docker as a portable infrastructure for Serverless Applications Book Description Serverless applications have gained a lot of popularity among developers and are currently the buzzwords in the tech market. Docker and serverless are two terms that go hand-in-hand. This book will start by explaining serverless and Function-as-a-Service (FaaS) concepts, and why they are important. Then, it will introduce the concepts of containerization and how Docker fits into the Serverless ideology. It will explore the architectures and components of three major Docker-based FaaS platforms, how to deploy and how to use their CLI. Then, this book will discuss how to set up and operate a production-grade Docker cluster. We will cover all concepts of FaaS frameworks with practical use cases, followed by deploying and orchestrating these serverless systems using Docker. Finally, we will also explore advanced topics and prototypes for FaaS architectures in the last chapter. By the end of this book, you will be in a position to build and deploy your own FaaS platform using Docker. What you will learn Learn what Serverless and FaaS applications areGet acquainted with the architectures of three major serverless systems Explore how Docker technologies can help develop Serverless applications Create and maintain FaaS infrastructures Set up Docker infrastructures to serve as on-premises FaaS infrastructures Define functions for Serverless applications with Docker containers Who This Book Is ForIf you are a Developer, a Docker Engineer, a DevOps Engineer, or any stakeholder interested in learning the use of Docker on Serverless environments then this book is for you.;;;;
Book;van Wyk KR,Graff MG,Peters DS,Burley DL;Enterprise Software Security: A Confluence of Disciplines;;2014;;;;1st;Addison-Wesley Professional;;;;;2014;9780321604118;;;;STRENGTHEN SOFTWARE SECURITY BY HELPING DEVELOPERS AND SECURITY EXPERTS WORK TOGETHER Traditional approaches to securing software are inadequate. The solution: Bring software engineering and network security teams together in a new, holistic approach to protecting the entire enterprise. Now, four highly respected security experts explain why this confluence is so crucial, and show how to implement it in your organization. Writing for all software and security practitioners and leaders, they show how software can play a vital, active role in protecting your organization. Youll learn how to construct software that actively safeguards sensitive data and business processes and contributes to intrusion detection/response in sophisticated new ways. The authors cover the entire development lifecycle, including project inception, design, implementation, testing, deployment, operation, and maintenance. They also provide a full chapter of advice specifically for Chief Information Security Officers and other enterprise security executives. Whatever your software security responsibilities, Enterprise Software Security delivers indispensable big-picture guidanceand specific, high-value recommendations you can apply right now. COVERAGE INCLUDES: Overcoming common obstacles to collaboration between developers and IT security professionals Helping programmers design, write, deploy, and operate more secure software Helping network security engineers use application output more effectively Organizing a software security team before youve even created requirements Avoiding the unmanageable complexity and inherent flaws of layered security Implementing positive software design practices and identifying security defects in existing designs Teaming to improve code reviews, clarify attack scenarios associated with vulnerable code, and validate positive compliance Moving beyond pentesting toward more comprehensive security testing Integrating your new application with your existing security infrastructure Ruggedizing DevOps by adding infosec to the relationship between development and operations Protecting application security during maintenance;;;;
Book;Helmke M;Ubuntu Unleashed 2013 Edition: Covering 12.10 and 13.04;;2012;;;;8th;Sams publishing;;;;;2012;9780672336249;;;;Ubuntu Unleashed 2013 Edition is filled with unique and advanced information for everyone who wants to make the most of the Ubuntu Linux operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 12.10 (Quantal Quetzal) and the forthcoming Ubuntu 13.04. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 12.10/13.04 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find new or improved coverage of navigation via Unity Dash, wireless networking, VPNs, software repositories, new NoSQL database options, virtualization and cloud services, new programming languages and development tools, monitoring, troubleshooting, and more. Configure and customize the Unity desktop and make the most of the Dash Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and run Ubuntu from the command line (with added coverage of stdin, stdout, sdterr, redirection, and file comparison) Automate tasks and use shell scripting Provide secure remote access and configure a secure VPN Manage kernels and modules Administer file, print, email, proxy, LDAP, and HTTP servers (Apache or alternatives) Learn about new options for managing large numbers of servers Work with databases (both SQL and the newest NoSQL alternatives) Get started with virtualization Build a private cloud with Juju and Charms Learn the basics about popular programming languages including Python, PHP, Perl, and new alternatives such as Go and Rust;;;;
Book;Aly B;Hands-On Enterprise Automation with Python: Automate Common Administrative and Security Tasks with Python;;2018;;;;;Packt Publishing;;;;;2018;9781788998512;;;;Invent your own Python scripts to automate your infrastructure Key Features Make the most of Python libraries and modules to automate your infrastructure Leverage Python programming to automate server configurations and administration tasks Efficiently develop your Python skill set Book Description Hands-On Enterprise Automation with Python starts by covering the set up of a Python environment to perform automation tasks, as well as the modules, libraries, and tools you will be using. We'll explore examples of network automation tasks using simple Python programs and Ansible. Next, we will walk you through automating administration tasks with Python Fabric, where you will learn to perform server configuration and administration, along with system administration tasks such as user management, database management, and process management. As you progress through this book, you'll automate several testing services with Python scripts and perform automation tasks on virtual machines and cloud infrastructure with Python. In the concluding chapters, you will cover Python-based offensive security tools and learn how to automate your security tasks. By the end of this book, you will have mastered the skills of automating several system administration tasks with Python. What you will learn Understand common automation modules used in Python Develop Python scripts to manage network devices Automate common Linux administration tasks with Ansible and Fabric Managing Linux processes Administrate VMware, Open Stack, and AWS instances with Python Security automation and sharing code on GitHub Who This Book Is For Hands-On Enterprise Automation with Python is for system administrators and DevOps engineers who are looking for an alternative to major automation frameworks such as Puppet and Chef. Basic programming knowledge with Python and Linux shell scripting is necessary.;;;;
Book;J. D. VQ;Getting Started with Tmux;;2014;;;;;Packt Publishing;;;;;2014;9781783985166;;;;Maximize your productivity by accessing several terminal sessions from a single window using tmux About This BookDiscover how tmux and its powerful features maximize your terminal usage in an easy and approachable mannerMinimize your mouse usage when switching between terminal windows to increase productivityPacked with real-world examples that give this concise guide an edge over the stock tmux documentationWho This Book Is ForThe book is intended for software developers, DevOps engineers, and other professionals who make heavy use of the terminal in their daily workflow. Some familiarity with the terminal is useful but no prior experience with tmux or other terminal multiplexers (such as GNU Screen) is required. In Detail We will begin with a simple introduction to tmux and learn some ways in which it can help increase productivity in your daily terminal usage. From there, we'll move on to configuring and customizing tmux to make it work, look, and feel the way that best suits your needs. Along the way, we have tutorials and screenshots aplenty so that you can follow along and avoid feeling lost. We'll also explain some of the core concepts of tmux, including the way it uses sessions, windows, and panes in order to divide content and running programs.We'll touch on how to perform basic manipulation of text to copy and paste text from one window to another or even from one file to another. We'll learn how to use tmux for fault-tolerant SSH sessions or pair programming, and we finish by discussing some other open source tools that can be used alongside tmux to help make it even more powerful.By the end of this book, we will have a much better understanding of tmux and its capabilities with the tools necessary to turbocharge our terminal experience.;;;;
Book;Butcher M,Farina M;Go in Practice: Includes 70 Techniques;;2016;;;;1st;Manning Publications Co.;USA;;;;2016;9781633430075;;;;"Summary Go in Practice guides you through 70 real-world techniques in key areas like package management, microservice communication, and more. Following a cookbook-style Problem/Solution/Discussion format, this practical handbook builds on the foundational concepts of the Go language and introduces specific strategies you can use in your day-to-day applications. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the Technology Go may be the perfect systems language. Built with simplicity, concurrency, and modern applications in mind, Go provides the core tool set for rapidly building web, cloud, and systems applications. If you know a language like Java or C#, it's easy to get started with Go; the trick is finding the practical dirt-under-the-fingernails techniques that you need to build production-ready code. About the Book Go in Practice guides you through dozens of real-world techniques in key areas. Following a cookbook-style Problem/Solution/Discussion format, this practical handbook builds on the foundational concepts of the Go language and introduces specific strategies you can use in your day-to-day applications. You'll learn techniques for building web services, using Go in the cloud, testing and debugging, routing, network applications, and much more. After finishing this book, you will be ready to build sophisticated cloud-native Go applications. What's Inside Dozens of specific, practical Golang techniquesUsing Go for devops and cloudops Writing RESTful web services and microservicesPractical web dev techniques About the Reader Written for experienced developers who have already started exploring Go and want to use it effectively in a production setting. About the Authors Matt Farina is a software architect at Deis. Matt Butcher is a Principal Engineer in the Advanced Technology Group at Hewlett Packard Enterprise. They are both authors, speakers, and regular open source contributors.";;;;
Book;Ambler SW,Lines M;Disciplined Agile Delivery: A Practitioner's Guide to Agile Software Delivery in the Enterprise;;2012;;;;1st;IBM Press;;;;;2012;9780132810135;;;;Master IBMs Breakthrough DAD Process Framework for Succeeding with Agile in Large, Complex, Mission-Critical IT Projects It is widely recognized that moving from traditional to agile approaches to build software solutions is a critical source of competitive advantage. Mainstream agile approaches that are indeed suitable for small projects require significant tailoring for larger, complex enterprise projects. In Disciplined Agile Delivery, Scott W. Ambler and Mark Lines introduce IBMs breakthrough Disciplined Agile Delivery (DAD) process framework, which describes how to do this tailoring. DAD applies a more disciplined approach to agile development by acknowledging and dealing with the realities and complexities of a portfolio of interdependent program initiatives. Ambler and Lines show how to extend Scrum with supplementary agile and lean strategies from Agile Modeling (AM), Extreme Programming (XP), Kanban, Unified Process (UP), and other proven methods to provide a hybrid approach that is adaptable to your organizations unique needs. They candidly describe what practices work best, why they work, what the trade-offs are, and when to consider alternatives, all within the context of your situation. Disciplined Agile Delivery addresses agile practices across the entire lifecycle, from requirements, architecture, and development to delivery and governance. The authors show how these best-practice techniques fit together in an end-to-end process for successfully delivering large, complex systems--from project initiation through delivery. Coverage includes Scaling agile for mission-critical enterprise endeavorsAvoiding mistakes that drive poorly run agile projects to chaosEffectively initiating an agile projectTransitioning as an individual to agileIncrementally building consumable solutionsDeploying agile solutions into complex production environmentsLeveraging DevOps, architecture, and other enterprise disciplinesAdapting your governance strategy for agile projects Based on facts, research, and extensive experience, this book will be an indispensable resource for every enterprise software leader and practitioner--whether theyre seeking to optimize their existing agile/Scrum process or improve the agility of an iterative process.;;;;
Book;Passmore E;Migrating Large-Scale Services to the Cloud;;2016;;;;1st;Apress;USA;;;;2016;9781484218723;;;;"This book reveals the technical challenges and successful implementation details of migrating MSN, Microsofts consumer content portal--a business with 450 million worldwide users--into the Cloud. Following a technique long used in aviation, medicine, and other fields, MSNs Chief Technical Officer, Eric Passmore, describes the set of release, deployment, monitoring, and mitigation checklists used to build cloud services supporting hundreds of millions of users on Azure, Microsofts Public Cloud. An undertaking of this scale--involving services supported by a large team of engineers--involves unique challenges and risks. This book demonstrates through personal experience how to cut through the theory and provides checklists as a surprisingly simple antidote to the competing methodologies. This book works at two levels. At a fundamental level, businesses need to be successful in the cloud if they want to seize new opportunities and transform their business to compete successfully. This book provides a framework for success by identifying the ""hidden"" work as part of moving to the cloud. At a more practical, level there is an incredible hunger for simple to follow, ""how-to"" information on Cloud migration. This book is a reference guide to reduce risk and achieve success without requiring the busy reader to wade through theory. It contains simple to follow, ""how-to"" information on cloud migration. It is a reference guide to achieving success, and any team can modify these tasks to fit the needs of their own organization. Who This Book is For: Technology professionals who deploy services in the cloud or are thinking of moving to the cloud. Professionals in the DevOps and Cloud services fields need these skills to succeed in their current jobs or advance their careers.";;;;
Book;Cochrane K,Chelladhurai JS,Khare NK;Docker Cookbook: Over 100 Practical and Insightful Recipes to Build Distributed Applications with Docker, 2nd Edition;;2018;;;;2nd;Packt Publishing;;;;;2018;9781788626866;;;;Leverage Docker to deploying software at scale Key Features Leverage practical examples to manage containers efficientlyIntegrate with orchestration tools such as Kubernetes for controlled deploymentsLearn to implement best practices on improving efficiency and security of containersBook DescriptionDocker is an open source platform for building, shipping, managing, and securing containers. Docker has become the tool of choice for people willing to work with containers. Since the market is moving toward containerization, Docker will definitely have a big role to play in the future tech market. This book starts with setting up Docker in different environment, and helps you learn how to work with Docker images. Then, you will take a deep dive into network and data management for containers. The book explores the RESTful APIs provided by Docker to perform different actions, such as image/container operations. The book then explores logs and troubleshooting Docker to solve issues and bottlenecks. You will gain an understanding of Docker use cases, orchestration, security, ecosystems, and hosting platforms to make your applications easy to deploy, build, and collaborate on. The book covers the new features of Docker 18.xx (or later), such as working with AWS and Azure, Docker Engine, Docker Swarm, Docker Compose, and so on. By the end of this book, you will have gained hands-on experience of finding quick solutions to different problems encountered while working with Docker. What you will learn Install Docker on various platforms Work with Docker images and containers Container networking and data sharing Docker APIs and language bindings Various PaaS solutions for Docker Implement container orchestration using Docker Swarm and Kubernetes Container security Docker on various clouds Who this book is for Book is targeted towards developers, system administrators, and DevOps engineers who want to use Docker in his/her development, QA, or production environments. It is expected that the reader has basic Linux/Unix skills such as installing packages, editing files, managing services, and so on. Any experience in virtualization technologies such as KVM, XEN, and VMware will be an added advantage.;;;;
Book;Marx B,Valim J,Tate B;Adopting Elixir: From Concept to Production;;2018;;;;1st;Pragmatic Bookshelf;;;;;2018;9781680502527;;;;Adoption is more than programming. Elixir is an exciting new language, but to successfully get your application from start to finish, you're going to need to know more than just the language. The case studies and strategies in this book will get you there. Learn the best practices for the whole life of your application, from design and team-building, to managing stakeholders, to deployment and monitoring. Go beyond the syntax and the tools to learn the techniques you need to develop your Elixir application from concept to production. Learn real-life strategies from the people who built Elixir and use it successfully at scale. See how Ben Marx and Bleacher Report maintain one of the highest-traffic Elixir applications by selling the concept to management and delivering on that promise. Find out how Bruce Tate and icanmakeitbetter hire and train Elixir engineers, and the techniques they've employed to design and ensure code consistency since Elixir's early days. Explore customer challenges in deploying and monitoring distributed applications with Elixir creator Jose Valim and Plataformatec. Make a business case and build a team before you finish your first prototype. Once you're in development, form strategies for organizing your code and learning the constraints of the runtime and ecosystem. Convince stakeholders, both business and technical, about the value they can expect. Prepare to make the critical early decisions that will shape your application for years to come. Manage your deployment with all of the knobs and gauges that good DevOps teams demand. Decide between the many options available for deployment, and how to best prepare yourself for the challenges of running a production application. This book picks up where most Elixir books leave off. It won't teach you to program Elixir, or any of its tools. Instead, it guides you through the broader landscape and shows you a holistic approach to adopting the language. What You Need: This book works with any version of Elixir.;;;;
Book;Weise T,Ramanath MV,Yan D,Knowles K;Learning Apache Apex: Real-Time Streaming Applications with Apex;;2017;;;;;Packt Publishing;;;;;2017;9781788296403;;;;Designing and writing a real-time streaming publication with Apache Apex About This BookGet a clear, practical approach to real-time data processing Program Apache Apex streaming applications This book shows you Apex integration with the open source Big Data ecosystem Who This Book Is For This book assumes knowledge of application development with Java and familiarity with distributed systems. Familiarity with other real-time streaming frameworks is not required, but some practical experience with other big data processing utilities might be helpful. What You Will LearnPut together a functioning Apex application from scratchScale an Apex application and configure it for optimal performance Understand how to deal with failures via the fault tolerance features of the platform Use Apex via other frameworks such as Beam Understand the DevOps implications of deploying Apex In Detail Apache Apex is a next-generation stream processing framework designed to operate on data at large scale, with minimum latency, maximum reliability, and strict correctness guarantees. Half of the book consists of Apex applications, showing you key aspects of data processing pipelines such as connectors for sources and sinks, and common data transformations. The other half of the book is evenly split into explaining the Apex framework, and tuning, testing, and scaling Apex applications. Much of our economic world depends on growing streams of data, such as social media feeds, financial records, data from mobile devices, sensors and machines (the Internet of Things - IoT). The projects in the book show how to process such streams to gain valuable, timely, and actionable insights. Traditional use cases, such as ETL, that currently consume a significant chunk of data engineering resources are also covered. The final chapter shows you future possibilities emerging in the streaming space, and how Apache Apex can contribute to it. Style and approach This book is divided into two major parts: first it explains what Apex is, what its relevant parts are, and how to write well-built Apex applications. The second part is entirely application-driven, walking you through Apex applications of increasing complexity.;;;;
Book;;ICSSP '18: Proceedings of the 2018 International Conference on Software and System Process;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;;Gothenburg, Sweden;2018;9781450364591;;;;"The ICSSP conference, continuing the success of the Software Process Workshop (SPW), the Workshop on Software Process Simulation Modeling (ProSim) and the International Conference on Software Process (ICSP) conference series, has become an established premier event in the field of software and systems engineering. It provides a leading forum for the exchange of academic research results and industrial best-practices in process development and evolution on software and systems disciplines.Software and system process decision-making is becoming more challenging for development organizations. These organizations are incorporating engineering advances, seeking to meet expectations of their customers, and responding to the economic pressures of markets. The resulting demands on processes include the need for both well-developed plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model-based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise-level architectures.In response to these demands, process stakeholders---process engineers responsible for designing and implementing processes, managers or coaches who staff and guide them, researchers who study and improve them, tools developers who support and facilitate them, and developers and sustainers who use and tailor them---are producing more varieties of processes and doing so more often. Just as agility is required more frequently in product development, it is also being demanded in processes while maintaining their essential purposes of coordination and communication. Demands on processes are requiring processes on demand. Providing processes on demand is challenging for process designers. They must be able to select compatible process elements for a specific set of situational factors, to assess the risks in and forecast outcomes of a process design or improvement, to specify methods of implementation, and to monitor an enacted process quantitatively and identify needs for modifications. These capabilities require specialized knowledge and engineering methods from researchers.ICSSP 2018 has the conference theme ""Demands on Processes, Processes on Demand"" and seeks to explore the demands on processes that are requiring more variety and responsiveness in process development.";;;Proceedings;
Book;Leonard A,Currie S,Alley J,Andersson M,Avenant P,Fellows B,Peck S,Smith R,Sondak R,Weissman B,Wilhelmsen C;The Biml Book: Business Intelligence and Data Warehouse Automation;;2017;;;;1st;Apress;USA;;;;2017;9781484231340;;;;Learn Business Intelligence Markup Language (Biml)for automating much of the repetitive, manual labor involved in data integration. We teach you how to build frameworks and use advanced Biml features to get more out of SQL Server Integration Services (SSIS), Transact-SQL (T-SQL), and SQL Server Analysis Services (SSAS) than you ever thought possible. The first part of the book starts with the basicsgetting your development environment configured, Biml syntax, and scripting essentials. Whether a beginner or a seasoned Biml expert, the next part of the book guides you through the process of using Biml to build a framework that captures both your design patterns and execution management. Design patterns are reusable code blocks that standardize the approach you use to perform certain types of data integration, logging, and other key data functions. Design patterns solve common problems encountered when developing data integration solutions. Because you do not have to build the code from scratch each time, design patterns improve your efficiency as a Biml developer. In addition to leveraging design patterns in your framework, you will learn how to build a robust metadata store and how to package your framework into Biml bundles for deployment within your enterprise. In the last part of the book, we teach you more advanced Biml features and capabilities, such as SSAS development, T-SQL recipes, documentation autogeneration, and Biml troubleshooting. The Biml Book: Provides practical and applicable examples Teaches you how to use Biml to reduce development time while improving quality Takes you through solutions to common data integration and BI challenges What You'll Learn Master the basics of Business Intelligence Markup Language (Biml) Study patterns for automating SSIS package generation Build a Biml Framework Import and transform database schemasAutomate generation of scripts and projects Who This Book Is For BI developers wishing to quickly locate previously tested solutions, Microsoft BI specialists, those seeking more information about solution automation and code generation, and practitioners of Data Integration Lifecycle Management (DILM) in the DevOps enterprise;;;;
Book;Klaffenbach F,Damaschke JH,Michalski O;Implementing Azure Solutions: Eliminate the Pain Point of Implementation;;2017;;;;;Packt Publishing;;;;;2017;9781786467850;;;;A practical guide that enhances your skills in implementing Azure solutions for your organization About This Book Confidently configure, deploy, and manage cloud services and virtual machines Implement a highly-secured environment and respond to threats with increased visibility This comprehensive guide is packed with exciting practical scenarios that enable you to implement Azure solutions with ease Who This Book Is For This book is for IT architects, system and network admins, and DevOps engineers who are aware of Azure solutions and want to implement them for their organization. What You Will Learn Implement virtual networks, network gateways, Site-to-Site VPN, Express Route, routing, and network devices Understand the working of different storage accounts in AzurePlan, deploy, and secure virtual machines Deploy and manage Azure Containers Get familiar with some common Azure usage scenarios In Detail Microsoft Azure has numerous effective solutions that shape the future of any business. However, the major challenge that architects and administrators face are implementing these solutions appropriately. Our book focuses on various implementation scenarios that will help overcome the challenge of implementing Azure's solutions in a very efficient manner and will also help you to prepare for Microsoft Architect exam. You will not only learn how to secure a newly deployed Azure Active Directory but also get to know how Azure Active Directory Synchronization could be implemented. To maintain an isolated and secure environment so that you can run your virtual machines and applications, you will implement Azure networking services. Also to manage, access, and secure your confidential data, you will implement storage solutions. Toward the end, you will explore tips and tricks to secure your environment. By the end, you will be able to implement Azure solutions such as networking, storage, and cloud effectively. Style and approach This step-by-step guide focuses on implementing various Azure solutions for your organization. The motive is to provide a comprehensive exposure and ensure they can implement these solutions with ease.;;;;
Book;;LT '15: Proceedings of the 4th International Workshop on Large-Scale Testing;;2015;;;;;Association for Computing Machinery;New York, NY, USA;;;Austin, Texas, USA;2015;9781450333375;;;;"It is our great pleasure to welcome you to the Fourth International Workshop on Large-Scale Testing (LT 2015), held in Austin, Texas, USA, on February 1st, 2015.Large-scale software systems must service thousands (e.g., enterprise applications) or even millions (e.g., e-commerce websites like Amazon) of concurrent users every day. Many field problems of these systems are due to their inability to scale to field workloads, rather than feature bugs. In addition to conventional functional testing (e.g., unit and integration testing), these systems must be tested with large volumes of concurrent requests (called the load) to ensure the quality of these systems. Large-scale testing includes all different objectives and strategies of testing large-scale software systems using load. Examples of large-scale testing include live upgrade testing, load testing, high availability testing, operational profile testing, performance testing, reliability testing, stability testing and stress testing.LT 2015 is a one-day workshop. The workshop participants consist of a mixture of academic and industrial researchers. A big emphasis of this workshop is to make the workshop interactive with many discussion slots assigned throughout the schedule. The workshop has two keynote talks: ""Load Testing Elasticity and Performance Isolation in Shared Execution Environments"" by Professor Samuel Kounev from University of Würzburg and ""Challenges, Benefits and Best Practices of Performance Focused DevOps"" by Wolfgang Gottesheim from Compuware. In addition, the workshop also includes presentations from technical papers and industrial talks. Finally, there is a panel, which brings together industrial practitioners and academic researchers to discuss the opportunities and challenges associated with large-scale testing.We hope you enjoy the technical and social program. If you are not able to attend our workshop, we hope you will find the papers and talks in this workshop simulating. This workshop would not happen without the efforts of the program committee members who helped with timely and constructive reviews. In addition, we want to extend our gratitude to each author and presenter who submitted their work to the LT 2015 workshop.";;;Proceedings;
Conference Paper;Bromberg YD,Gitzinger L;DroidAutoML: A Microservice Architecture to Automate the Evaluation of Android Machine Learning Detection Systems;;2020;;;148–165;;Springer-Verlag;Berlin, Heidelberg;;Distributed Applications and Interoperable Systems: 20th IFIP WG 6.1 International Conference, DAIS 2020, Held as Part of the 15th International Federated Conference on Distributed Computing Techniques, DisCoTec 2020, Valletta, Malta, June 15–19, 2020, Proceedings;Valletta, Malta;2020;9783030503222;;"https://doi-org.proxy.bnl.lu/10.1007/978-3-030-50323-9_10;http://dx.doi.org/10.1007/978-3-030-50323-9_10";10.1007/978-3-030-50323-9_10;The mobile ecosystem is witnessing an unprecedented increase in the number of malware in the wild. To fight this threat, actors from both research and industry are constantly innovating to bring concrete solutions to improve security and malware protection. Traditional solutions such as signature-based anti viruses have shown their limits in front of massive proliferation of new malware, which are most often only variants specifically designed to bypass signature-based detection. Accordingly, it paves the way to the emergence of new approaches based on Machine Learning (ML) technics to boost the detection of unknown malware variants. Unfortunately, these solutions are most often underexploited due to the time and resource costs required to adequately fine tune machine learning algorithms. In reality, in the Android community, state-of-the-art studies do not focus on model training, and most often go through an empirical study with a manual process to choose the learning strategy, and/or use default values as parameters to configure ML algorithms. However, in the ML domain, it is well known admitted that to solve efficiently a ML problem, the tunability of hyper-parameters is of the utmost importance. Nevertheless, as soon as the targeted ML problem involves a massive amount of data, there is a strong tension between feasibility of exploring all combinations and accuracy. This tension imposes to automate the search for optimal hyper-parameters applied to ML algorithms, that is not anymore possible to achieve manually. To this end, we propose a generic and scalable solution to automatically both configure and evaluate ML algorithms to efficiently detect Android malware detection systems. Our approach is based on devOps principles and a microservice architecture deployed over a set of nodes to scale and exhaustively test a large number of ML algorithms and hyper-parameters combinations. With our approach, we are able to systematically find the best fit to increase up to 11% the accuracy of two state-of-the-art Android malware detection systems.;Malware, Android, AutoML, Machine learning;;;
Book;Bell C;Introducing MySQL Shell: Administration Made Easy with Python;;2019;;;;1st;Apress;USA;;;;2019;9781484250822;;;;Use MySQL Shell, the first modern and advanced client for connecting to and interacting with MySQL. It supports SQL, Python, and JavaScript. That's right! You can write Python scripts and execute them within the shell interactively, or in batch mode. The level of automation available from Python combined with batch mode is especially helpful to those practicing DevOps methods in their database environments. Introducing MySQL Shell covers everything you need to know about MySQL Shell. You will learn how to use the shell for SQL, as well as the new application programming interfaces for working with a document store and even automating your management of MySQL servers using Python. The book includes a look at the supporting technologies and concepts such as JSON, schema-less documents, NoSQL, MySQL Replication, Group Replication, InnoDB Cluster, and more. MySQL Shell is the client that developers and database administrators have been waiting for. Far more powerful than the legacy client, MySQL Shell enables levels of automation that are useful not only for MySQL, but in the broader context of your career as well. Automate your work and build skills in one of the most in-demand languages. With MySQL Shell, you can do both! What You'll Learn Use MySQL Shell with the newest features in MySQL 8 Discover what a Document Store is and how to manage it with MySQL Shell Configure Group Replication and InnoDB Cluster from MySQL Shell Understand the new MySQL Python application programming interfaces Write Python scripts for managing your data and the MySQL high availability features Who This Book Is For Developers and database professionals who want to automate their work and remain on the cutting edge of what MySQL has to offer. Anyone not happy with the limited automation capabilities of the legacy command-line client will find much to like in this book on the MySQL Shell that supports powerful automation through the Python scripting language.;;;;
Book;Soni M,Gilchrist W;Designing AWS Environments: Architect Large-Scale Cloud Infrastructures with AWS;;2018;;;;;Packt Publishing;;;;;2018;9781789535549;;;;Design and create robust and resilient distributed solutions with AWS Key Features Design and secure virtual private network environments on the AWS cloud Deploy appropriate instance types and sizes based on performance and cost requirements Gain proficiency and confidence when designing virtual cloud environments Book Description Amazon Web Services (AWS) provides trusted,cloud-based solutions to help you meet your business needs. Running your solutions in the AWS Cloud can help you get your applications up and running faster while providing the security to meet your compliance requirements. This book begins by familiarizing you with the key capabilities to architect and host applications, websites, and services on AWS. We explain the available options for AWS free tier with virtual instances and demonstrate how you can launch and connect them. Using practical examples, you'll be able to design and deploy networking and hosting solutions for large deployments. Finally, the book focuses on security and important elements of scalability and high availability using AWS VPC, Elastic Load Balancing, and Auto scaling. By the end of this book, you will have handson experience of working with AWS instances, VPC, Elastic Load Balancing, and Auto scalingrelated tasks on Amazon Web Services. What you will learn Establish how to launch EC2 instances and log in Work with Linux and Windows instances Understand Amazon VPC networking creation with and without a wizard Design, create, and secure a Virtual Private Cloud Autoscale instances based on the increase and decrease in traffic Deploy applications in a highly available and fault-tolerant manner Load balance the requests with Elastic Load Balancing Make your applications highly available through load balancing, multi-AZ deployments, and auto scaling Who this book is for This book is for new and aspiring individuals who are preparing or gearing up for a solutions architect role. You'll also find this useful if you're an IT professional such as beginners, cloud architects, and cloud solution providers, or DevOps engineer who is preparing to design and deploy large solutions on AWS. No experience with AWS is required.;;;;
Book;Eadline D;Hadoop 2 Quick-Start Guide: Learn the Essentials of Big Data Computing in the Apache Hadoop 2 Ecosystem;;2015;;;;1st;Addison-Wesley Professional;;;;;2015;9780134049946;;;;Get Started Fast with Apache Hadoop 2, YARN, and Todays Hadoop Ecosystem With Hadoop 2.x and YARN, Hadoop moves beyond MapReduce to become practical for virtually any type of data processing. Hadoop 2.x and the Data Lake concept represent a radical shift away from conventional approaches to data usage and storage. Hadoop 2.x installations offer unmatched scalability and breakthrough extensibility that supports new and existing Big Data analytics processing methods and models. Hadoop 2 Quick-Start Guide is the first easy, accessible guide to Apache Hadoop 2.x, YARN, and the modern Hadoop ecosystem. Building on his unsurpassed experience teaching Hadoop and Big Data, author Douglas Eadline covers all the basics you need to know to install and use Hadoop 2 on personal computers or servers, and to navigate the powerful technologies that complement it. Eadline concisely introduces and explains every key Hadoop 2 concept, tool, and service, illustrating each with a simple beginning-to-end example and identifying trustworthy, up-to-date resources for learning more. This guide is ideal if you want to learn about Hadoop 2 without getting mired in technical details. Douglas Eadline will bring you up to speed quickly, whether youre a user, admin, devops specialist, programmer, architect, analyst, or data scientist. Coverage Includes Understanding what Hadoop 2 and YARN do, and how they improve on Hadoop 1 with MapReduce Understanding Hadoop-based Data Lakes versus RDBMS Data Warehouses Installing Hadoop 2 and core services on Linux machines, virtualized sandboxes, or clusters Exploring the Hadoop Distributed File System (HDFS) Understanding the essentials of MapReduce and YARN application programming Simplifying programming and data movement with Apache Pig, Hive, Sqoop, Flume, Oozie, and HBase Observing application progress, controlling jobs, and managing workflows Managing Hadoop efficiently with Apache Ambariincluding recipes for HDFS to NFSv3 gateway, HDFS snapshots, and YARN configuration Learning basic Hadoop 2 troubleshooting, and installing Apache Hue and Apache Spark;;;;
Book;Aggarwal M;Learn Apache Mesos: A Beginner's Guide to Scalable Cluster Management and Deployment;;2018;;;;;Packt Publishing;;;;;2018;9781789137385;;;;Scale applications with high availability and optimized resource management across data centers Key Features Create clusters and perform scheduling, logging, and resource administration with Mesos Explore practical examples of managing complex clusters at scale with real-world data Write native Mesos frameworks with Python Book Description Apache Mesos is an open source cluster manager that provides efficient resource isolation and sharing across distributed applications or frameworks. This book will help you build a strong foundation of Mesos' capabilities along with practical examples to support the concepts explained throughout the book. Learn Apache Mesos dives straight into how Mesos works. You will be introduced to the distributed system and its challenges and then learn how you can use Mesos and its framework to solve data problems. You will also gain a full understanding of Mesos' internal mechanisms and get equipped to use Mesos and develop applications. Furthermore, this book lets you explore all the steps required to create highly available clusters and build your own Mesos frameworks. You will also cover application deployment and monitoring. By the end of this book, you will have learned how to use Mesos to make full use of machines and how to simplify data center maintenance. What you will learn Deploy and monitor a Mesos cluster Set up servers on AWS to deploy Mesos components Explore Mesos resource scheduling and the allocation module Deploy Docker-based services and applications using Mesos Marathon Configure and use SSL to protect crucial endpoints of your Mesos cluster Debug and troubleshoot services and workloads on a Mesos cluster Who this book is for This book is for DevOps and data engineers and administrators who work with large data clusters. You'll also find this book useful if you have experience working with virtualization, databases, and platforms such as Hadoop and Spark. Some experience in database administration and design will help you get the most out of this book.;;;;
Book;McKendrick R,Raj P,Chelladhurai JS,Singh V;Docker Bootcamp;;2017;;;;;Packt Publishing;;;;;2017;9781787286986;;;;Fast, intensive, and effective Docker learning About This BookGet well-versed with Docker in 7 days Identify and resolve common problems faced by users while working with Docker A fast-paced guide that will focus on all the core Docker functionalities Who This Book Is ForThis book targets developers, IT professionals and DevOps engineers who like to gain intensive, hands-on knowledge and skills with Docker without spending hours and hours in learning. If you have been struggling to find the time to gain proficiency and confidence with Docker containers and everyday Docker tasks, you have come to the right place! What You Will Learn Use Docker Compose to make multi-container applications easier to launchLaunch Docker hosts in various public clouds Deploy and configure a Docker Swarm cluster. Work with third-party plugins to extend core Docker functionality Monitor containers and hosts and explore commands to troubleshoot DockerIn Detail Docker allows you to create a robust and resilient environment to generate portable, composable, scalable, and stable application containers. The book starts by installing the core Docker Engine on MacOS, Windows 10 and Linux desktops. We will then define multi-container applications and understand the advantages of using containers locally. Once this is done, we will deploy containers on a single Docker host which is publicly accessible. Furthermore, we will learn how to deploy and configure a Docker Swarm cluster and explore networking and storage third-party plugins to extend the core Docker functionality. Towards the end, the book will demonstrate how to monitor and troubleshoot day-to-day problems in addition to various real world examples of container deployments. Style and approach This book is all about fast and intensive learning. Thaxt means we don't waste time in helping readers get started. The content is about filling in with highly-effective examples to build new things, show solving problems in newer and unseen ways, and solve real-world examples.;;;;
Book;;ETX '14: Proceedings of the 2014 Workshop on Eclipse Technology EXchange;;2014;;;;;Association for Computing Machinery;New York, NY, USA;;;Portland, Oregon, USA;2014;9781450325301;;;;"It is our great pleasure to welcome you to the 2014 Eclipse Technology eXchange Workshop, sponsored by ACM SIGPLAN. This year's workshop continues the tradition of bringing together researchers and practitioners to discuss potential new uses of Eclipse in research and education as well as how Eclipse can leverage novel work in, e.g., programming languages and software engineering research. ETX has been a very successful workshop at OOPSLA from 2003-2007 and given that the Eclipse Ecosystem is still very relevant for research and education we felt that it was time to revive ETX at SPLASH.Due to the longer hiatus, the response to our call for papers was a little lower than what we had hoped for, but after a rigorous round of reviews we had three submissions that were accepted. We decided to complement the program with two invited talks and provided authors and attendees with an opportunity to showcase some of their Eclipse-related work in an open demonstration session. In the first invited talk, Anish Karmarkar from Oracle presented the standardization work on CAMP (Cloud Application Management for Platforms), a standard for managing software applications on PaaS cloud platforms. Since the cloud is an ongoing hot topic and has led to the proliferation of the DevOps model, his talk could provide interesting insights into the interrelation between development, deployment, and operation of software systems in the cloud, an area where IDEs could and arguably need to play a much stronger role in the future.Tamás Szabó from itemis AG was the second invited speaker and talked about mbeddr, a set of extensible and integrated languages for embedded software development. mbeddr is a customizable IDE that is built on the Meta Programming System (MPS) from JetBrains. MPS directly works on the Abstract Syntax Tree of the IDE contents and this model is projected to the user for editing. mbeddr utilizes the capabilities of the projectional editor by providing various notations (projections) for the developers; apart from the regular source code, developers can easily embed tables, complex mathematical formulas and diagrams right into to the text.";;;Proceedings;
Ph.D. Thesis;Casertano AE,Gulick D,Chmiel M,Kraus K,Wang P;An Autoethnographic Account of Innovation at the US Department of Veterans Affairs;;2020;;;;;University of Maryland, College Park;;;;;2020;;;;;The history of the U.S. Department of Veterans Affairs (VA) health information technology (HIT) has been characterized by both enormous successes and catastrophic failures. While the VA was once hailed as the way to the future of twenty-first-century health care, many programs have been mismanaged, delayed, or flawed, resulting in the waste of hundreds of millions of taxpayer dollars. Since 2015 the U.S. Government Accountability Office (GAO) has designated HIT at the VA as being susceptible to waste, fraud, and mismanagement. The timely central research question I ask in this study is, can healthcare IT at the VA be healed? To address this question, I investigate a HIT case study at the VA Center of Innovation (VACI), originally designed to be the flagship initiative of the open government transformation at the VA. The Open Source Electronic Health Record Alliance (OSEHRA) was designed to promote the open innovation ecosystem public-private-academic partnership. Based on my fifteen years of experience at the VA, I use an autoethnographic methodology to make a significant value-added contribution to understanding and modeling the VA's approach to innovation. I use several theoretical information system framework models including People, Process, and Technology (PPT), Technology, Organization and Environment (TOE), and Technology Adaptive Model (TAM) and propose a new adaptive theory to understand the inability of VA HIT to innovate. From the perspective of people and culture, I study retaliation against whistleblowers, organization behavioral integrity, and lack of transparency in communications. I examine the VA processes, including the different software development methodologies used, the development and operations process (DevOps) of an open-source application developed at VACI, the Radiology Protocol Tool Recorder (RAPTOR), a Veterans Health Information Systems and Technology Architecture (VistA) radiology workflow module. I find that the VA has chosen to migrate away from inhouse application software and buy commercial software. The impact of these People, Process, and Technology findings are representative of larger systemic failings and are appropriate examples to illustrate systemic issues associated with IT innovation at the VA. This autoethnographic account builds on first-hand project experience and literature-based insights.;;AAI27744168;Ph.D. Thesis;
Conference Paper;Kruchten P;The End of Agile as We Know It;;2019;;;104;;IEEE Press;Montreal, Quebec, Canada;;Proceedings of the International Conference on Software and System Processes;;2019;;;"https://doi-org.proxy.bnl.lu/10.1109/ICSSP.2019.00033;http://dx.doi.org/10.1109/ICSSP.2019.00033";10.1109/ICSSP.2019.00033;"It's been 20 years or so, but the end is in sight. We have successfully placed the adjective 'agile' in front of about every important noun in our software development / IT world: agile design, agile testing, agile management, agile database, agile architecture, agile user-interaction.... Agile has won the war. ""What is next?"" is the question I've been asked again and again. What is the future of software engineering? The next best thing? Is it DevOps, cloud-something, micro-services, AI? The adjective agile has lost some of its weight and novelty, only a few laggards are still asking ""what is it?""It is time to reflect on the fundamental aspects of agility: what does it really means, what are the fundamental principles behind it, that made its successes. The agile movement has had some tremendous impact in the way we work, putting the human being and human interaction more central in these processes, by using extensively iterations, direct interactions, and feedback loops. But at the same time, some aspects of agile have become dogmatic, fossilized, and the agile movement has not been always very agile in its application to itself. These dogmatic aspects have slowed the expansion of its own principles to some of the more complex or much larger software development endeavours.Now, the increasing need for speed, the availability of opensource software repositories, the shifts in technology, such as the cloud, the emergence of software ecosystems are creating new needs in terms of process and project management, that can exploit the fundamental principles of agile, beyond the dogma of this or that method, this or that practice. As the amount of software in use is growing and will outgrow the capacity of our industry to maintain and evolve it, the industry faces a massive amount of technical debt, which we do not know well how to mitigate or repay. Agile has been very valuable, but once its lessons are fully integrated in the way we work we have to look beyond and stop repeating it like a mantra. Agile is dead. Long live agility.";;;;ICSSP '19
Book;Helmke M;Ubuntu Unleashed 2015 Edition: Covering 14.10 and 15.04;;2014;;;;10th;Sams publishing;;;;;2014;9780672338373;;;;Ubuntu Unleashed 2015 Edition is filled with unique and advanced information for everyone who wants to make the most of the Linux-based Ubuntu operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 14.10 while including tons of information that will continue to apply to future editions. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 14.10 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find new or improved coverage of Ubuntus Unity interface, various types of servers, software repositories, database options, virtualization and cloud services, development tools, monitoring, troubleshooting, Ubuntus push into mobile and other touch screen devices, and much more. Detailed information on how to Configure and customize the Unity desktop Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and run Ubuntu from the command line Automate tasks and use shell scripting Provide secure remote access and configure a secure VPN Manage kernels and modules Administer file, print, email, proxy, LDAP, DNS, and HTTP servers (Apache, Nginx, or alternatives) Learn about new options for managing large numbers of servers Work with databases (both SQL and the newest NoSQL alternatives) Get started with virtualization Build a private cloud with Juju and Charms Learn the basics about popular programming languages including Python, PHP, Perl, and new alternatives such as Go and Rust Learn about Ubuntus work toward usability on touch-screen and phone devices Ubuntu 14.10 on DVD DVD includes the full Ubuntu 14.10 distribution for 64 bit computers (most desktop and notebooks systems today) as well as the complete LibreOffice office suite and hundreds of additional programs and utilities. Free Kick Start Chapter! Purchase this book and receive a free Ubuntu 15.04 Kick Start chapter after Ubuntu 15.04 is released. See inside back cover for details;;;;
Book;;ICPE '18: Companion of the 2018 ACM/SPEC International Conference on Performance Engineering;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;;Berlin, Germany;2018;9781450356299;;;;It is our great pleasure to welcome you to the 9th ACM/SPEC International Conference on Performance Engineering (ICPE 2018), being held in Berlin, Germany from April 9 to 13, 2018. The goal of the ACM/SPEC International Conference on Performance Engineering (ICPE) is to integrate theory and practice in the field of performance engineering by providing a forum for sharing ideas and experiences between industry and academia.The call for contributions solicited submissions for several tracks, namely for research papers, industry/experience papers, work-in-progress/vision papers, artifacts (for accepted full papers), posters and demonstrations, tutorials, and workshops.In the research track, 14 out of 59 papers were accepted as full papers. Hence, the full paper acceptance rate is 24 %. Two full papers received an ACM artifact badge after the subsequent review process in the newly introduced artifact evaluation track. Seven submissions were accepted as short research papers. In the industry/experience track, four out of 16 papers were accepted as full papers. Six submissions were accepted as short papers. The awards chairs selected three papers from the research track and two papers from the industry/experience track as candidates for the best paper award. The winner for both tracks will be announced during the banquet, after the candidates have presented their work during the conference. In the work-in-progress/vision track, ten out of 23 papers were accepted.The technical program features the following three invited keynotes: Peter Braam: Performance Engineering for the SKA TelescopeMichael R. Lyu: AI Techniques in Software Engineering ParadigmAad van Moorsel: Benchmarks and Models for BlockchainIn addition, the technical program includes three tutorials, the presentation of the SPEC Distinguished Dissertation Award, a poster and demonstration session, as well as six workshops on Performance Analysis of Big data Systems (PABS), Hot Topics in Cloud Computing Performance (HotCloudPerf), Challenges in Performance Methods for Software Development (WOSP-C), Load Testing and Benchmarking of Software Systems (LTB), Energy-aware Simulation and Modelling (ENERGY-SIM), and Quality-Aware DevOps (QUDOS).The program covers traditional ICPE topics such as performance modeling, prediction, optimization, monitoring, profiling, load testing, benchmarking, and runtime adaptation for fields such as cloud and high performance computing, big data, energy, and enterprise applications.;;;Proceedings;
Conference Paper;Ding Z,Chen J,Shang W;Towards the Use of the Readily Available Tests from the Release Pipeline as Performance Tests: Are We There Yet?;;2020;;;1435–1446;;Association for Computing Machinery;New York, NY, USA;;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering;Seoul, South Korea;2020;9781450371216;;"https://doi-org.proxy.bnl.lu/10.1145/3377811.3380351;http://dx.doi.org/10.1145/3377811.3380351";10.1145/3377811.3380351;Performance is one of the important aspects of software quality. Performance issues exist widely in software systems, and the process of fixing the performance issues is an essential step in the release cycle of software systems. Although performance testing is widely adopted in practice, it is still expensive and time-consuming. In particular, the performance testing is usually conducted after the system is built in a dedicated testing environment. The challenges of performance testing make it difficult to fit into the common DevOps process in software development. On the other hand, there exist a large number of tests readily available, that are executed regularly within the release pipeline during software development. In this paper, we perform an exploratory study to determine whether such readily available tests are capable of serving as performance tests. In particular, we would like to see whether the performance of these tests can demonstrate performance improvements obtained from fixing real-life performance issues. We collect 127 performance issues from Hadoop and Cassandra, and evaluate the performance of the readily available tests from the commits before and after the performance issue fixes. We find that most of the improvements from the fixes to performance issues can be demonstrated using the readily available tests in the release pipeline. However, only a very small portion of the tests can be used for demonstrating the improvements. By manually examining the tests, we identify eight reasons that a test cannot demonstrate performance improvements even though it covers the changed source code of the issue fix. Finally, we build random forest classifiers determining the important metrics influencing the readily available tests (not) being able to demonstrate performance improvements from issue fixes. We find that the test code itself and the source code covered by the test are important factors, while the factors related to the code changes in the performance issues fixes have a low importance. Practitioners may focus on designing and improving the tests, instead of fine-tuning tests for different performance issues fixes. Our findings can be used as a guideline for practitioners to reduce the amount of effort spent on leveraging and designing tests that run in the release pipeline for performance assurance activities.;performance testing, software performance, performance issues;;;ICSE '20
Book;Baier J,White J;Getting Started with Kubernetes: Extend Your Containerization Strategy by Orchestrating and Managing Large-Scale Container Deployments, 3rd Edition;;2018;;;;3rd;Packt Publishing;;;;;2018;9781788994729;;;;Schedule and run application containers using Kubernetes Key Features Get to grips with a wide range of tools to monitor and secure your deployments Manage your container clusters and networks using Kubernetes Get well-versed with the fundamentals of Kubernetes Book Description Kubernetes has continued to grow and achieve broad adoption across various industries, helping you to orchestrate and automate container deployments on a massive scale. Based on the recent release of Kubernetes 1.12, Getting Started with Kubernetes gives you a complete understanding of how to install a Kubernetes cluster. The book focuses on core Kubernetes constructs, such as pods, services, replica sets, replication controllers, and labels. You will understand cluster-level networking in Kubernetes, and learn to set up external access to applications running in the cluster. As you make your way through the book, you'll understand how to manage deployments and perform updates with minimal downtime. In addition to this, you will explore operational aspects of Kubernetes, such as monitoring and logging, later moving on to advanced concepts such as container security and cluster federation. You'll get to grips with integrating your build pipeline and deployments within a Kubernetes cluster, and be able to understand and interact with open source projects. In the concluding chapters, you'll orchestrate updates behind the scenes, avoid downtime on your cluster, and deal with underlying cloud provider instability within your cluster. By the end of this book, you'll have a complete understanding of the Kubernetes platform and will start deploying applications on it. What you will learn Download, install, and configure the Kubernetes code base Set up and access monitoring and logging for Kubernetes clusters Set up external access to applications running in the cluster Learn how to manage and scale kubernetes with hosted platforms on AWS, Azure, and GCP Run multiple clusters and manage them from a single control plane Discover top tools for deploying and managing a Kubernetes cluster Learn how to get production ready and harden Kubernetes operations, networking, and storage Who this book is for Getting Started with Kubernetes is for developers, system administrators, and DevOps engineers who want to automate the deployment process and scale their applications. No prior knowledge of Kubernetes is required.;;;;
Book;Vohra D;Amazon Fargate Quick Start Guide: Learn How to Use AWS Fargate to Run Containers with Ease;;2018;;;;;Packt Publishing;;;;;2018;9781789345018;;;;This book gets you started and gives you knowledge about AWS Fargate in order to successfully incorporate it in your ECS container application. Key Features Gives you a quick walk-through over the Amazon Elastic Container Services (ECS)Provides an in depth knowledge of the components that Amazon Fargate has to offer. Learn the practical aspects of Docker application development with a managed serviceBook Description Amazon Fargate is new launch type for the Amazon Elastic Container Service (ECS). ECS is an AWS service for Docker container orchestration. Docker is the de facto containerization framework and has revolutionized packaging and deployment of software. The introduction of Fargate has made the ECS platform serverless. The book takes you through how Amazon Fargate runs ECS services composed of tasks and Docker containers and exposes the containers to the user. Fargate has simplified the ECS platform. We will learn how Fargate creates an Elastic Network Interface (ENI) for each task and how auto scaling can be enabled for ECS tasks. You will also learn about using an IAM policy to download Docker images and send logs to Cloud Watch. Finally, by the end of this book, you will have learned about how to use ECS CLI to create an ECS cluster and deploy tasks with Docker Compose. What you will learn Running Docker containers with a managed service Use Amazon ECS in Fargate launch mode Configure Cloud Watch Logging with Fargate Use an IAM Role with Fargate Understand how ECS CLI is used with Fargate Learn how to use an Application Load Balancer with Fargate Learn about Auto Scaling with Fargate Who this book is for This book is for Docker users and developers who want to learn about the Fargate platform. Typical job roles for which the book is suitable are DevOps Architect, Docker Engineer, and AWS Cloud Engineer. Prior knowledge of AWS and ECS is helpful but not mandatory. Table of Contents Getting Started with Amazon ECS and Amazon Fargate Networking Using Cloud Watch Logs Using Auto Scaling Using IAM Using an Application Load Balancer Using Amazon ECS CLI;;;;
Book;Jackson KL,Goessling S;Architecting Cloud Computing Solutions: Build Cloud Strategies That Align Technology and Economics While Effectively Managing Risk;;2018;;;;;Packt Publishing;;;;;2018;9781788472425;;;;Accelerating Business and Mission Success with Cloud Computing. Key Features A step-by-step guide that will practically guide you through implementing Cloud computing services effectively and efficiently. Learn to choose the most ideal Cloud service model, and adopt appropriate Cloud design considerations for your organization. Leverage Cloud computing methodologies to successfully develop a cost-effective Cloud environment successfully. Book Description Cloud adoption is a core component of digital transformation. Scaling the IT environment, making it resilient, and reducing costs are what organizations want. Architecting Cloud Computing Solutions presents and explains critical Cloud solution design considerations and technology decisions required to choose and deploy the right Cloud service and deployment models, based on your business and technology service requirements. This book starts with the fundamentals of cloud computing and its architectural concepts. It then walks you through Cloud service models (IaaS, PaaS, and SaaS), deployment models (public, private, community, and hybrid) and implementation options (Enterprise, MSP, and CSP) to explain and describe the key considerations and challenges organizations face during cloud migration. Later, this book delves into how to leverage DevOps, Cloud-Native, and Serverless architectures in your Cloud environment and presents industry best practices for scaling your Cloud environment. Finally, this book addresses (in depth) managing essential cloud technology service components such as data storage, security controls, and disaster recovery. By the end of this book, you will have mastered all the design considerations and operational trades required to adopt Cloud services, no matter which cloud service provider you choose. What you will learn Manage changes in the digital transformation and cloud transition process Design and build architectures that support specific business cases Design, modify, and aggregate baseline cloud architectures Familiarize yourself with cloud application security and cloud computing security threats Design and architect small, medium, and large cloud computing solutions Who This Book Is ForIf you are an IT Administrator, Cloud Architect, or a Solution Architect keen to benefit from cloud adoption for your organization, then this book is for you. Small business owners, managers, or consultants will also find this book useful. No prior knowledge of Cloud computing is needed.;;;;
Book;;ICPE '18: Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering;;2018;;;;;Association for Computing Machinery;New York, NY, USA;;;Berlin, Germany;2018;9781450350952;;;;It is our great pleasure to welcome you to the 9th ACM/SPEC International Conference on Performance Engineering (ICPE 2018), being held in Berlin, Germany from April 9 to 13, 2018. The goal of the ACM/SPEC International Conference on Performance Engineering (ICPE) is to integrate theory and practice in the field of performance engineering by providing a forum for sharing ideas and experiences between industry and academia.The call for contributions solicited submissions for several tracks, namely for research papers, industry/experience papers, work-in-progress/vision papers, artifacts (for accepted full papers), posters and demonstrations, tutorials, and workshops.In the research track, 14 out of 59 papers were accepted as full papers. Hence, the full paper acceptance rate is 24 %. Two full papers received an ACM artifact badge after the subsequent review process in the newly introduced artifact evaluation track. Seven submissions were accepted as short research papers. In the industry/experience track, four out of 16 papers were accepted as full papers. Six submissions were accepted as short papers. The awards chairs selected three papers from the research track and two papers from the industry/experience track as candidates for the best paper award. The winner for both tracks will be announced during the banquet, after the candidates have presented their work during the conference. In the work-in-progress/vision track, ten out of 23 papers were accepted.The technical program features the following three invited keynotes: Peter Braam: Performance Engineering for the SKA TelescopeMichael R. Lyu: AI Techniques in Software Engineering ParadigmAad van Moorsel: Benchmarks and Models for BlockchainIn addition, the technical program includes three tutorials, the presentation of the SPEC Distinguished Dissertation Award, a poster and demonstration session, as well as six workshops on Performance Analysis of Big data Systems (PABS), Hot Topics in Cloud Computing Performance (HotCloudPerf), Challenges in Performance Methods for Software Development (WOSP-C), Load Testing and Benchmarking of Software Systems (LTB), Energy-aware Simulation and Modelling (ENERGY-SIM), and Quality-Aware DevOps (QUDOS).The program covers traditional ICPE topics such as performance modeling, prediction, optimization, monitoring, profiling, load testing, benchmarking, and runtime adaptation for fields such as cloud and high performance computing, big data, energy, and enterprise applications.;;;Proceedings;
Book;Helmke M;Ubuntu Unleashed 2016 Edition: Covering 15.10 and 16.04;;2015;;;;11th;Sams publishing;;;;;2015;9780134268118;;;;Ubuntu Unleashed 2016 Edition is filled with unique and advanced information for everyone who wants to make the most of the Linux-based Ubuntu operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 15.10 while including tons of information that will continue to apply to future editions. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 15.10 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find new or improved coverage of Ubuntus Unity interface, various types of servers, software repositories, database options, virtualization and cloud services, development tools, monitoring, troubleshooting, Ubuntus push into mobile and other touch screen devices, and much more. Configure and customize the Unity desktop Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and run Ubuntu from the command line Automate tasks and use shell scripting Provide secure remote access and configure a secure VPN Manage kernels and modules Administer file, print, email, proxy, LDAP, DNS, and HTTP servers (Apache, Nginx, or alternatives) Learn about new options for managing large numbers of servers Work with databases (both SQL and the newest NoSQL alternatives) Get started with virtualization Build a private cloud with Juju and Charms Learn the basics about popular programming languages including Python, PHP, Perl, and new alternatives such as Go and Rust Learn about Ubuntus work toward usability on touchscreen and phone devices Ubuntu 15.10 on DVD DVD includes the full Ubuntu 15.10 distribution for 64 bit computers (most desktop and notebooks systems today) as well as the complete LibreOffice office suite and hundreds of additional programs and utilities. Free Upgrade! Purchase this book and receive a free Ubuntu 16.04 Kick Start chapter after Ubuntu 16.04 is released. See inside back cover for details.;;;;
Book;Gregory J,Crispin L;More Agile Testing: Learning Journeys for the Whole Team;;2014;;;;1st;Addison-Wesley Professional;;;;;2014;9780321967053;;;;"Janet Gregory and Lisa Crispin pioneered the agile testing discipline with their previous work, Agile Testing. Now, in More Agile Testing, they reflect on all theyve learned since. They address crucial emerging issues, share evolved agile practices, and cover key issues agile testers have asked to learn more about. Packed with new examples from real teams, this insightful guide offers detailed information about adapting agile testing for your environment; learning from experience and continually improving your test processes; scaling agile testing across teams; and overcoming the pitfalls of automated testing. Youll find brand-new coverage of agile testing for the enterprise, distributed teams, mobile/embedded systems, regulated environments, data warehouse/BI systems, and DevOps practices. Youll come away understanding How to clarify testing activities within the team Ways to collaborate with business experts to identify valuable features and deliver the right capabilities How to design automated tests for superior reliability and easier maintenance How agile team members can improve and expand their testing skills How to plan just enough, balancing small increments with larger feature sets and the entire system How to use testing to identify and mitigate risks associated with your current agile processes and to prevent defects How to address challenges within your product or organizational context How to perform exploratory testing using personas and tours Exploratory testing approaches that engage the whole team, using test charters with session- and thread-based techniques How to bring new agile testers up to speed quicklywithout overwhelming them Janet Gregory is founder of DragonFire Inc., an agile quality process consultancy and training firm. Her passion is helping teams build quality systems. For almost fifteen years, she has worked as a coach and tester, introducing agile practices into companies of all sizes and helping users and testers understand their agile roles. She is a frequent speaker at agile and testing software conferences, and is a major contributor to the agile testing community. Lisa Crispin, an experienced agile testing practitioner and coach, regularly leads conference workshops on agile testing and contributes frequently to agile software publications. She enjoys collaborating as part of an awesome agile team to produce quality software. Since 1982, she has worked in a variety of roles on software teams, in a wide range of industries. She joined her first agile team in 2000 and continually learns from other teams and practitioners.";;;;
Book;Varghese S;Web Development with Go: Building Scalable Web Apps and RESTful Services;;2015;;;;1st;Apress;USA;;;;2015;9781484210536;;;;Go, the open-source programming language originally developed at Google, makes it easy to build simple, reliable, and efficient software. It's a fast, statically typed, compiled language that feels like a dynamically typed, interpreted language. Its concurrency mechanisms, coupled with modern hardware, makes Go an effective general purpose programming language for a wide range of applications such as, system programming and embedded systems, desktop development and distributed systems, backend services for mobile and web, DevOps, and cloud application development. Web Development with Go will teach you how to develop scalable real-world web apps, RESTful services, and backend systems with Go. The book starts off by covering Go programming language fundamentals as a prerequisite for web development. After a thorough understanding of the basics, the book delves into web development using the built-in package, net/http. With each chapter youll be introduced to new concepts for gradually building a real-world web system. The book further shows you how to integrate Go with other technologies. For example, it provides an overview of using MongoDB as a means of persistent storage, and providesan end-to-end REST API sample features MongoDB as well. Developers looking for a full-fledged web development framework for building web apps will be introduced to Beego. The book then moves on to demonstrate how to deploy web apps to the cloud using the Google Cloud platform. Finally, the book introduces Docker, a revolutionary container technology platform for deploying containerized Go web apps to the Cloud. Web Development with Go provides:Basic fundamentals for building real-world web apps in Go. Through coverage of prerequisites and practical code examples. Demo web apps for attaining a deeper understanding of web development A reference REST API app which can be used to build scalable real-world backend services in Go. A through demonstration of deploying web apps to the Cloud using the Google Cloud platform, and Docker for deploying Go Servers. In totality, Go is a high-performance language while providing greater level of developer productivity, therefore Web Development with Go equips you with the necessary skills and knowledge required for effectively building robust and efficient web apps by leveraging the features of Go, and find yourself become the sought after person on Go among your peers and employers alike, in no time.;;;;
Book;Morain JM,Mangione S;ISpeak Cloud: Crossing the Cloud Chasm Create a Cohesive Cloud Strategy;;2014;;;;1st;Coolmody, LLC;Gilbert, AZ, USA;;;;2014;9780984675722;;;;"iSpeak Cloud: Crossing the Cloud Chasm takes the reader through a realistic journey that many companies face when creating their overall cloud strategy. Join the executive team at Universal Kingdom as they apply best practices, lessons learned and practical intuition in overcoming many of the challenges faced in creating a cohesive cloud strategy. iSpeak Cloud is unique in that it takes the perspective across functional roles based on real world interviews to enable the reader to identify with real life challenges and best practices for overcoming them to cross the ""chasm"" between business and technology. iSpeak Cloud will challenge some of the conventional IT thinking that has led to the current state of Cloud Stall and Sprawl within the traditional enterprise. It will help you identify how to properly build your business case and strategy to insure the ""juice is worth the squeeze"" for maximum benefit with less costs to the business. Many have raced to the cloud only to be disappointed when it was unable to deliver the key benefits at a cost that made sense for the business. This has led to Consumerization of IT, Shadow IT, and general distrust from the Business with their counterparts. How do you cross the ""Cloud Chasm"" to create a cohesive Cloud strategy between business and technology? Although each company's journey will vary there will be certain challenges that impact nearly every customer out there. iSpeak Cloud highlights those challenges and best practice solutions for overcoming them based on over 100 interviews across functional roles from vendor to the customer. iSpeak Cloud enables the reader to transcend the gap between business and technology by walking them through a 3 Day Workshop that illustrates a typical day in the life of executives faced with creating a comprehensive cloud strategy. Join Charles the CIO of Universal Kingdom and Kayla Coletrain - his resident Cloud expert as they leverage templates and best practices that have been enhanced over 2 decades of implementation across small to large enterprise customers to address common challenges highlighted by interviewees. The step by step workshop enables you to envision key steps needed to cross the cloud chasm from addressing a cohesive DevOps, Agile, Costing, and Requirements gathering strategies. If you are looking to tame your Hybrid Cloud Hydra - look no further, iSpeak Cloud will enable you to identify challenges, address lessons learned and apply best practices to your Cohesive Cloud roadmap.";;;;
Book;Jakobczyk MT;Practical Oracle Cloud Infrastructure: Infrastructure as a Service, Autonomous Database, Managed Kubernetes, and Serverless;;2020;;;;1st;Apress;USA;;;;2020;9781484255056;;;;"Use this fast-paced and comprehensive guide to build cloud-based solutions on Oracle Cloud Infrastructure. You will understand cloud infrastructure, and learn how to launch new applications and move existing applications to Oracle Cloud. Emerging trends in software architecture are covered such as autonomous platforms, infrastructure as code, containerized applications, cloud-based container orchestration with managed Kubernetes, and running serverless workloads using open-source tools. Practical examples are provided. This book teaches you how to self-provision the cloud resources you require to run and scale your custom cloud-based applications using a convenient web console and programmable APIs, and you will learn how to manage your infrastructure as code with Terraform. You will be able to plan, design, implement, deploy, run, and monitor your production-grade and fault-tolerant cloud software solutions in Oracle's data centers across the world, paying only for the resources you actually use. Oracle Cloud Infrastructure is part of Oracle's new generation cloud that delivers a complete and well-integrated set of Infrastructure as a Service (IaaS) capabilities (compute, storage, networking), edge services (DNS, web application firewall), and Platform as a Service (PaaS) capabilities (such as Oracle Autonomous Database which supports both transactional and analytical workloads, the certified and fully managed Oracle Kubernetes Engine, and a serverless platform based on an open-source Fn Project). Oracle Autonomous Database which supports both transactional and analytical workloads), and Oracle's certified and managed Container Engine for Kubernetes. What You Will Learn, Build software solutions on Oracle Cloud; Automate cloud infrastructure with CLI and Terraform; Follow best practices for architecting on Oracle Cloud; Employ Oracle Autonomous Database to obtain valuable data insights; Run containerized applications on Oracle's Container Engine for Kubernetes; Understand the emerging Cloud Native ecosystem; Who This Book Is For, Cloud architects, developers, DevOps engineers, and technology students and others who want to learn how to build cloud-based systems on Oracle Cloud Infrastructure (OCI) leveraging a broad range of OCI Infrastructure as a Service (IAAS) capabilities, Oracle Autonomous Database, and Oracle's Container Engine for Kubernetes. Readers should have a working knowledge of Linux, exposure to programming, and a basic understanding of networking concepts. All exercises in the book can be done at no cost with a 30-day Oracle Cloud trial.";;;;
Book;Preston S;Using Chef with Microsoft Azure;;2016;;;;1st;Apress;USA;;;;2016;9781484214770;;;;This book is your hands-on guide to infrastructure provisioning and configuration management in the cloud using Chefs open source, cross-platform toolset. With over 10,000 customers joining the Microsoft Azure cloud platform each week and steadily increasing usage, the need for automation approaches has never been greater. This book provides both practical examples and a much needed strategic overview of how these two technologies can be combined. Using Chef with Microsoft Azure takes you through the process of writing recipes in Chef to describe your infrastructure as code, and simplify your configuration management processes. Youll also meet the Chef tools that can be used to provision complete environments within Microsoft Azure. There are now a wide variety of tools and approaches that can be taken to provision resources such as virtual machines within Microsoft Azure. This book demonstrates them, discusses the benefits and weaknesses of each approach, and shows how a continuous provisioning pipeline can be established as part of a reliable, repeatable, and robust provisioning process. Each chapter has practical exercises that highlight the capabilities of both Chef and Microsoft Azure from an automation perspective and can be executed on Windows, Mac, or Linux platforms. In this book, youll learn: The purpose and principles behind automated provisioning Microsoft Azure concepts and management options How to deploy Chef Azure Virtual Machine Extensions using PowerShell, Azure command-line tools, and Chef Provisioning Chef Provisioning techniques, including provisioning PaaS resources such as Key Vault How to integrate quality tooling into the Chef development lifecycle, including Test Kitchen and InSpec with Azure compute resources How to set up a pipeline for continuous provisioning with Chef and Azure Who This Book Is For This book is for infrastructure platform and operations engineers and DevOps specialists/practitioners working with infrastructure and platform provisioning on Microsoft's public cloud, Azure. An understanding of programming in any language would be beneficial, but not necessary as the examples are designed to be easily readable by anyone with general IT experience. While it is expected most users picking up this book will be on the Windows platform, a good proportion of compute workload on the Azure platform is Linux based. As a result the book includes examples that are relevant to both Windows and Linux platforms.;;;;
Book;Labouardy M;Hands-On Serverless Applications with Go: Build Real-World, Production-Ready Applications with AWS Lambda;;2018;;;;;Packt Publishing;;;;;2018;9781789134612;;;;"Learn to build, secure, deploy, and manage your serverless application in Golang with AWS Lambda Key Features Implement AWS lambda to build scalable and cost-efficient applications in Go Design and set the data flow between cloud services and custom business logicLearn to design Lambda functions using real-world examples and implementation scenarios Book Description Serverless architecture is popular in the tech community due to AWS Lambda. Go is simple to learn, straightforward to work with, and easy to read for other developers; and now it's been heralded as a supported language for AWS Lambda. This book is your optimal guide to designing a Go serverless application and deploying it to Lambda. This book starts with a quick introduction to the world of serverless architecture and its benefits, and then delves into AWS Lambda using practical examples. You'll then learn how to design and build a production-ready application in Go using AWS serverless services with zero upfront infrastructure investment. The book will help you learn how to scale up serverless applications and handle distributed serverless systems in production. You will also learn how to log and test your application. Along the way, you'll also discover how to set up a CI/CD pipeline to automate the deployment process of your Lambda functions. Moreover, you'll learn how to troubleshoot and monitor your apps in near real-time with services such as AWS Cloud Watch and X-ray. This book will also teach you how to secure the access with AWS Cognito. By the end of this book, you will have mastered designing, building, and deploying a Go serverless application. What you will learn Understand how AWS Lambda works and use it to create an application Understand how to scaleup serverless applications Design a cost-effective serverless application in AWS Build a highly scalable and fault-tolerant CI/CD pipeline Understand how to troubleshoot and monitor serverless apps in AWS Discover the working of APIs and single page applications Build a production-ready serverless application in Go Who this book is for This book is for Go developers who would like to learn about serverless architecture. Go programming knowledge is assumed. DevOps and Solution Architects who are interested in building serverless applications in Go can also choose this book.";;;;
Book;Baier J;Getting Started with Kubernetes: Orchestrate and Manage Large-Scale Docker Deployments, 2nd Edition;;2017;;;;2nd;Packt Publishing;;;;;2017;9781787283367;;;;Learn how to schedule and run application containers using Kubernetes. About This Book Get well-versed with the fundamentals of Kubernetes and get it production-ready for deploymentsConfidently manage your container clusters and networks using Kubernetes This practical guide will show you container application examples throughout to illustrate the concepts and features of Kubernetes Who This Book Is For This book is for developers, sys admins, and DevOps engineers who want to automate the deployment process and scale their applications. You do not need any knowledge about Kubernetes. What You Will Learn Download, install, and configure the Kubernetes codebase Understand the core concepts of a Kubernetes cluster Be able to set up and access monitoring and logging for Kubernetes clusters Set up external access to applications running in the cluster Understand how CoreOS and Kubernetes can help you achieve greater performance and container implementation agility Run multiple clusters and manage from a single control plane Explore container security as well as securing Kubernetes clusters Work with third-party extensions and tools In Detail Kubernetes has continued to grow and achieve broad adoption across various industries, helping you to orchestrate and automate container deployments on a massive scale. This book will give you a complete understanding of Kubernetes and how to get a cluster up and running. You will develop an understanding of the installation and configuration process. The book will then focus on the core Kubernetes constructs such as pods, services, replica sets, replication controllers, and labels. You will also understand how cluster level networking is done in Kubernetes. The book will also show you how to manage deployments and perform updates with minimal downtime. Additionally, you will learn about operational aspects of Kubernetes such as monitoring and logging. Advanced concepts such as container security and cluster federation will also be covered. Finally, you will learn about the wider Kubernetes ecosystem with OCP, CoreOS, and Tectonic and explore the third-party extensions and tools that can be used with Kubernetes. By the end of the book, you will have a complete understanding of the Kubernetes platform and will start deploying applications on it. Style and approach This straightforward guide will help you understand how to move your container applications into production through best practices and a step-by-step walkthrough tied to real-world operational strategies.;;;;
Book;Agarwal A;The Basics Of Kanban: A Popular Lean Framework;;2018;;;;;Independently published;;;;;2018;9781729181430;;;;Do you feel overwhelmed with multiple things that need your attention? Do you feel like youre always switching from one task to another, struggling to focus on any one thing for long enough to make progress? Do you feel that you work all day, but cant get anything to complete? Do you feel that you are not as productive as you would like to be? Does your team have enough visibility on work items that each member is working on? Does your team struggle to track external team dependencies? Does your team stay focused and motivated? Does your team meet its commitments? Kanban is a popular Lean framework and a workflow visualization approach to managing any professional or personal work in an effective and efficient manner. This book is written to provide you with a complete reference guide on Kanban to assist you on your journey towards success. Implementing Kanban is least disruptive. You can apply Kanban to your existing processes, embracing continuous improvement, improved results, optimized efficiency, and minimized waste. What will you learn with this book?-What Is Kanban?-Why Kanban?-Kanban Principles and Practices-Kanban Board-WIP Limits-Cumulative Flow Diagram-Lead Time Chart-Cycle Time Chart-Flow Efficiency-Blockers Clustering-Throughput or Velocity-Scrum Vs Kanban-Scrumban-DevOps and Kanban-Kaizen and Kanban-Kanban Tools-Practical Examples-Sample Kanban Boards Who Should Read This Book? Since Kanban can be applied at both work and your personal life, anyone can read this book. Here are a few roles and scenarios that will most likely benefit from this book.-Project Managers-Business Analysts-Scrum Masters-Product Managers-Product Owners-Engineers-Test Managers-Business Managers-Technology Leaders-Subject Matter Experts-System Administrators-Operations or Support teams-Sales and Marketing teams-Students seeking an IT job-A product development team with regular intake requests-Anyone who is looking to manage their personal or professional work-Anyone who is looking to adopt Kanban-Anyone who needs to understand when and when not to use Kanban-Anyone who wants to understand the differences between Kanban and Scrum-Anyone who needs to learn Kanban to expand ones career opportunities-Anyone who needs a simple and concise reference book on Kanban Grab your copy today. Learn how to effectively manage your personal and professional work with Kanban.;;;;
Book;Waghmare R;AWS Tools for PowerShell 6;;2017;;;;;Packt Publishing;;;;;2017;9781785884078;;;;Leverage the power of PowerShell to bring the best out of your AWS infrastructureAbout This BookA collection of real-world-tested Powershell scripts that can be used to manage your Windows server efficientlyFollow step-by-step processes to solve your problems with Windows servers using AWS tools Design examples that work in the Amazon free usage tier, which lets you run the Windows platform on cloud Who This Book Is ForThis book will be useful for (but not limited to) Windows System administrators, cloud engineers, architects, DevOps engineers, and all those who want to accomplish tasks on the AWS Public Cloud using PowerShell. What You Will Learn Install the AWS Tools for PowerShell 6 Understand key services provided by Amazon Web services (AWS) Understand the Virtual Private CloudUse PowerShell 6 for AWS Identity and Access Management (IAM) Use PowerShell 6 for AWS Elastic Compute Cloud (EC2)Use PowerShell 6 for AWS Simple Storage Service (S3)Use PowerShell 6 for AWS Relational Database Service (RDS) Build fault-tolerant and highly-available applications using PowerShell 6 In Detail AWS Tools for PowerShell 6 shows you exactly how to automate all the aspects of AWS. You can take advantage of the amazing power of the cloud, yet add powerful scripts and mechanisms to perform common tasks faster than ever before. This book expands on the Amazon documentation with real-world, useful examples and production-ready scripts to automate all the aspects of your new cloud platform. It will cover topics such as managing Windows with PowerShell, setting up security services, administering database services, and deploying and managing networking. You will also explore advanced topics such as PowerShell authoring techniques, and configuring and managing storage and content delivery. By the end of this book, you will be able to use Amazon Web Services to automate and manage Windows servers. You will also have gained a good understanding of automating the AWS infrastructure using simple coding. Style and approach This step-by-step guide starts with simple examples then expands to full-blown administrative tasks leading to the efficient management of Windows servers. Each topic covers a section related to Amazon Web Services products, and the examples are built on one another to deliver a comprehensive library of scripts for administrators.;;;;
Ph.D. Thesis;Sécio BP;Deteção Em Tempo Quase-Real de Anomalias No Comportamento de Administradores de Sistemas / Near-Real-Time Detection of System Administrator Behavior Anomalies;;2020;;;;;Universidade de Lisboa (Portugal);;;;;2020;;;;;;;AAI28760615;Ph.D. Thesis;
Book;Helmke M;Ubuntu Unleashed 2014 Edition: Covering 13.10 and 14.04;;2013;;;;9th;Sams publishing;;;;;2013;9780672336935;;;;Ubuntu Unleashed 2014 Edition is filled with unique and advanced information for everyone who wants to make the most of the Linux-based Ubuntu operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 13.10 and the forthcoming Ubuntu 14.04. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 13.10/14.04 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find new or improved coverage of Ubuntus Unity interface, various types of servers, software repositories, database options, virtualization and cloud services, development tools, monitoring, troubleshooting, Ubuntus push into mobile and other touch screen devices, and much more. Matthew Helmke served from 2006 to 2011 on the Ubuntu Forum Council, providing leadership and oversight of the Ubuntu Forums, and spent two years on the Ubuntu regional membership approval board for Europe, the Middle East, and Africa. He has written about Ubuntu for several magazines and websites and is the lead author of The Official Ubuntu Book. He works for Pearson Education writing technical documentation for educational testing software. Detailed information on how to Configure and customize the Unity desktop Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and run Ubuntu from the command line Automate tasks and use shell scripting Provide secure remote access and configure a secure VPN Manage kernels and modules Administer file, print, email, proxy, LDAP, DNS, and HTTP servers (Apache, Nginx, or alternatives) Learn about new options for managing large numbers of servers Work with databases (both SQL and the newest NoSQL alternatives) Get started with virtualization Build a private cloud with Juju and Charms Learn the basics about popular programming languages including Python, PHP, Perl, and new alternatives such as Go and Rust Learn about Ubuntus work toward usability on touch-screen and phone devices Ubuntu 13.10 on DVD DVD includes the full Ubuntu 13.10 distribution for Intel x86 computers as well as the complete LibreOffice office suite and hundreds of additional programs and utilities. Free Kick Start Chapter! Purchase this book and receive a free Ubuntu 14.04 Kick Start chapter after Ubuntu 14.04 is released. See inside back cover for details;;;;
Book;;ICPE '17 Companion: Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion;;2017;;;;;Association for Computing Machinery;New York, NY, USA;;;L'Aquila, Italy;2017;9781450348997;;;;"Welcome to the 8th ACM/SPEC International Conference on Performance Engineering (ICPE), taking place in L'Aquila, Italy, in April 22-26, 2017. The goal of ICPE is to integrate theory and practice in the field of performance engineering by providing a forum for sharing ideas and experiences between industry and academia. ICPE grew out of the ACM Workshop on Software Performance (WOSP Est. 1998) and the SPEC International Performance Engineering Workshop (SIPEW Est. 2008). It is a great pleasure to introduce the exciting program for this year's conference in which researchers and practitioners present their latest research, newest innovations, and vision for the future of performance engineering.We received 83 high quality submissions across the Research, Industry/Experience and Work-Inprogress/ Vision tracks. The Research Track attracted 65 submissions with 24 papers (22 full, 2 short) accepted for presentation. In the Work-In-Progress/Vision Track 14 out of 25 contributions were selected and the Industry/Experience track attracted 18 submissions of which 5 were accepted for presentation. Each paper received at least three reviews from program committee members. Four best paper award candidates were also selected. The best paper is to be announced during the ICPE 2017 social event, after all four papers are presented at the conference.We are excited to also present three keynote talks as part of the technical program. Micro-Benchmarking Considered Harmful; When the Whole is Faster or Slower Than the Sum of its Parts, by Thomas Wuerthinger (Oracle Labs)Performance is Also a Matter of Where You Live, by Francesco Quaglia (University of Rome La Sapienza)Autonomic storage management at scale, by Arif Merchant (Google)In addition, the program includes five tutorials, a poster and demo track, the SPEC Distinguished Dissertation Award, and eight interesting workshops on Autonomous Control for Performance and Reliability Trade-offs in Internet of Services (ACPROSS), on Performance Analysis of Big Data Systems (PABS), on Challenges in Performance Methods for Software Development (WOSP-C), on Energy-aware Simulation (ENERGY-SIM), on Load Testing and Benchmarking of Software Systems (LTB), on Monitoring in Large-Scale Software Systems (MoLS), on Education and Practice of Performance Engineering (WEPPE), and on Quality-aware DevOps (QUDOS).The program covers traditional ICPE topics such as design for performance and problem diagnosis, online performance management, analytic models, empirical studies, model building, and benchmarking, as well as application of performance engineering theory and techniques to several practical fields, including distributed systems, cloud computing, storage, energy, big data, virtualized systems, and hardware.";;;Proceedings;
Book;Atwal H;Practical DataOps: Delivering Agile Data Science at Scale;;2019;;;;1st;Apress;USA;;;;2019;9781484251034;;;;"Gain a practical introduction to DataOps, a new discipline for delivering data science at scale inspired by practices at companies such as Facebook, Uber, LinkedIn, Twitter, and eBay. Organizations need more than the latest AI algorithms, hottest tools, and best people to turn data into insight-driven action and useful analytical data products. Processes and thinking employed to manage and use data in the 20th century are a bottleneck for working effectively with the variety of data and advanced analytical use cases that organizations have today. This book provides the approach and methods to ensure continuous rapid use of data to create analytical data products and steer decision making. Practical DataOps shows you how to optimize the data supply chain from diverse raw data sources to the final data product, whether the goal is a machine learning model or other data-orientated output. The book provides an approach to eliminate wasted effort and improve collaboration between data producers, data consumers, and the rest of the organization through the adoption of lean thinking and agile software development principles. This book helps you to improve the speed and accuracy of analytical application development through data management and DevOps practices that securely expand data access, and rapidly increase the number of reproducible data products through automation, testing, and integration. The book also shows how to collect feedback and monitor performance to manage and continuously improve your processes and output. What You Will Learn, Develop a data strategy for your organization to help it reach its long-term goals; Recognize and eliminate barriers to delivering data to users at scale; Work on the right things for the right stakeholders through agile collaboration; Create trust in data via rigorous testing and effective data management; Build a culture of learning and continuous improvement through monitoring deployments and measuring outcomes; Create cross-functional self-organizing teams focused on goals not reporting lines; Build robust, trustworthy, data pipelines in support of AI, machine learning, and other analytical data products; Who This Book Is For Data science and advanced analytics experts, CIOs, CDOs (chief data officers), chief analytics officers, business analysts, business team leaders, and IT professionals (data engineers, developers, architects, and DBAs) supporting data teams who want to dramatically increase the value their organization derives from data. The book is ideal for data professionals who want to overcome challenges of long delivery time, poor data quality, high maintenance costs, and scaling difficulties in getting data science output and machine learning into customer-facing production.";;;;
Book;Rankin K;Linux Hardening in Hostile Networks: Server Security from TLS to Tor;;2017;;;;1st;Addison-Wesley Professional;;;;;2017;9780134173269;;;;Implement Industrial-Strength Security on Any Linux Server In an age of mass surveillance, when advanced cyberwarfare weapons rapidly migrate into every hackers toolkit, you cant rely on outdated security methodsespecially if youre responsible for Internet-facing services. In Linux Hardening in Hostile Networks, Kyle Rankin helps you to implement modern safeguards that provide maximum impact with minimum effort and to strip away old techniques that are no longer worth your time. Rankin provides clear, concise guidance on modern workstation, server, and network hardening, and explains how to harden specific services, such as web servers, email, DNS, and databases. Along the way, he demystifies technologies once viewed as too complex or mysterious but now essential to mainstream Linux security. He also includes a full chapter on effective incident response that both DevOps and SecOps can use to write their own incident response plan. Each chapter begins with techniques any sysadmin can use quickly to protect against entry-level hackers and presents intermediate and advanced techniques to safeguard against sophisticated and knowledgeable attackers, perhaps even state actors. Throughout, you learn what each technique does, how it works, what it does and doesnt protect against, and whether it would be useful in your environment. Apply core security techniques including 2FA and strong passwords Protect admin workstations via lock screens, disk encryption, BIOS passwords, and other methods Use the security-focused Tails distribution as a quick path to a hardened workstation Compartmentalize workstation tasks into VMs with varying levels of trust Harden servers with SSH, use apparmor and sudo to limit the damage attackers can do, and set up remote syslog servers to track their actions Establish secure VPNs with OpenVPN, and leverage SSH to tunnel traffic when VPNs cant be used Configure a software load balancer to terminate SSL/TLS connections and initiate new ones downstream Set up standalone Tor services and hidden Tor services and relays Secure Apache and Nginx web servers, and take full advantage of HTTPS Perform advanced web server hardening with HTTPS forward secrecy and ModSecurity web application firewalls Strengthen email security with SMTP relay authentication, SMTPS, SPF records, DKIM, and DMARC Harden DNS servers, deter their use in DDoS attacks, and fully implement DNSSEC Systematically protect databases via network access control, TLS traffic encryption, and encrypted data storage Respond to a compromised server, collect evidence, and prevent future attacks Normal 0 false false false EN-US X-NONE X-NONE Register your product at informit.com/register for convenient access to downloads, updates, and corrections as they become available. Normal 0 false false false EN-US X-NONE X-NONE;;;;
Book;Makam S;Mastering CoreOS;;2016;;;;;Packt Publishing;;;;;2016;9781785288128;;;;Key FeaturesConfidently deploy distributed applications and effectively manage distributed infrastructure using Containers and CoreOSBuild secure, scalable CoreOS clusters to deploy distributed applications using open source technologies and industry best practicesEvery concept and technology in this book is illustrated with practical examples that can be used in both development and production environments. Book DescriptionCoreOS makes Google and Amazon-style Cloud infrastructure available for anyone building their own private Cloud. This book covers the CoreOS internals and the technologies used in the deployment of container-based distributed applications. It starts with an overview of CoreOS and distributed application development while sharing knowledge on related technologies. Critical CoreOS services and networking and storage considerations for CoreOS are covered next. In latter half of the book, you will learn about Container runtime systems such as Docker and Rkt and Container Orchestration using Kubernetes. You will also find out about the integration of popular orchestration solutions such as OpenStack, the AWS Container service, and the Google Container Engine with CoreOS and Docker. Lastly, we cover troubleshooting as well as production considerations. What you will learnInstall CoreOS on a VM, on the Cloud, and bare metal, and find out how to keep your cluster secure and up to dateConfigure and troubleshoot key CoreOS services, such as etcd, systemd, and fleet, for distributed application deploymentStudy container networking using CoreOS Flannel and other solutions, such as Docker libnetwork, Weave, and CalicoExplore the container filesystem and container volume management using Docker volume, NFS, GlusterFS, and FlockerGet to know the internals of container technologies such as Docker, Rkt, and Container orchestration using Openstack, Kubernetes and Docker native solutionsTroubleshoot CoreOS cluster and Containers using monitoring and logging tools and master production techniques such as staging, security, and automationAbout the AuthorSreenivas Makam is currently working as a senior engineering manager at Cisco Systems, Bangalore. He has a masters in electrical engineering and around 18 years of experience in the networking industry. He has worked in both start-ups and big established companies. His interests include SDN, NFV, Network Automation, DevOps, and cloud technologies, and he likes to try out and follow open source projects in these areas. His blog can be found at https://sreeninet.wordpress.com/ and his hacky code at https://github.com/smakam. Sreenivas is part of the Docker bloggers forum and his blog articles have been published in Docker weekly newsletters. He has done the technical reviewing for Mastering Ansible, Packt Publishing and Ansible Networking Report, O'Reilly Publisher. He has also given presentations at Docker meetup in Bangalore. Sreenivas has one approved patent.;;;;
Book;Bentley W;OpenStack Administration with Ansible 2 - Second Edition;;2017;;;;2nd;Packt Publishing;;;;;2017;9781787121638;;;;"Key Features Automate real-world OpenStack cloud operator administrative tasksConstruct a collection of the latest automation code to save time on managing your OpenStack cloudManage containers on your cloud and check the health of your cloud using NagiosBook DescriptionMost organizations are seeking methods to improve business agility because they have realized just having a cloud is not enough. Being able to improve application deployments, reduce infrastructure downtime, and eliminate daily manual tasks can only be accomplished through some sort of automation. We start with a brief overview of OpenStack and Ansible 2 and highlight some best practices. Each chapter will provide an introduction to handling various Cloud Operator administration tasks such as managing containers within your cloud; setting up/utilizing open source packages for monitoring; creating multiple users/tenants; taking instance snapshots; and customizing your cloud to run multiple active regions. Each chapter will also supply a step-by-step tutorial on how to automate these tasks with Ansible 2. Packed with real-world OpenStack administrative tasks, this book will walk you through working examples and explain how these tasks can be automated using one of the most popular open source automation tools on the market today. What you will learn Efficiently execute OpenStack administrative tasksFamiliarize yourself with how Ansible 2 works and assess the defined best practicesCreate Ansible 2 playbooks and roles Automate tasks to customize your OpenStack cloudReview OpenStack automation considerations when automating administrative tasks Examine and automate advanced OpenStack tasks and designated use casesGet a high-level overview of Open Stack and current production-ready projectsExplore OpenStack CLI tools and learn how to use them About the Author Walter Bentley is a Rackspace Private Cloud Technical Marketing Engineer and author with a diverse background in production systems administration and solutions architecture. He has more than 15 years of experience in sectors such as online marketing, financial, insurance, aviation, the food industry, education, and now in technology. In the past, he was typically the requestor, consumer, and advisor to companies in the use of technologies such as OpenStack. Today, hes an OpenStack promoter and cloud educator. In his current role, Walter helps customers build, design, and deploy private clouds built on OpenStack. That includes professional services engagements around operating OpenStack clouds and DevOps engagements creating playbooks/roles with Ansible. He presents and speaks regularly at OpenStack Summits, AnsibleFest, and other technology conferences, plus webinars, blog posts and technical reviews. His first book, OpenStack Administration with Ansible, was released in 2016.";;;;
Book;Machiraju S;Learning Windows Server Containers;;2017;;;;;Packt Publishing;;;;;2017;9781785887932;;;;About This Book Discover the secret to building highly portable apps that run on any machine with Windows Server 2016 anywhere, from laptops, desktop servers, and public or private clouds, without any changes to the codeBuild your company cost-effective, container-based apps that support large-scale, virtual cloud environments The most up-to-date help on the market, offering developers expert guidance in building and shipping high-quality apps, and also helping admins create infrastructure that's simple to maintain Who This Book Is For This book is for application developers with a basic programming knowledge of C#, ASP.NET, and PowerShell. IT Administrators or DevOps engineers with basic PowerShell experience can benefit by extending their learning to use PowerShell to manage containers on Windows environments and use additional management tools. What You Will Learn Build and deploy ASP.NET web applications as Windows Containers on Windows 10 (Desktop) and Azure using Visual Studio 2015, Docker, and PowerShellBuild and manage custom images using Windows Server Core base OS image and Docker CLI, publish images to Docker, tag images, author Docker files, and so onCreate enterprise-scale, production-grade container environments using Redis Cache containers and SQL Server containers with storage volumes, set up custom container networks, continuous integration, and deployment pipelines using VSTS, Azure, and Git Deploy a composite container environment using Docker Compose on WindowsLearn to build applications using Microsofts thinnest server platform - Nano Servers. Build custom Nano Server images and Nano Containers using Windows PowerShell and configure using PowerShell Core, DSCIn Detail Learning Windows Server Containers teaches you to build simple to advanced production-grade, container-based application using ASP.NET Core, Visual Studio, Azure, Docker, and PowerShell technologies. This book teaches you to build and deploy simple web applications as Windows and Hyper-V Containers on Windows 10 and Windows Server 2016 on Azure. You will learn to build on top of Windows Container base OS images, integrate with existing images from Docker Hub, create custom images, and publish to the Hub. You will also learn to work with storage containers built using volumes and SQL Server as container, create and configure custom networks, integrate with Redis Cache containers, and configure continuous integration and deployment pipelines using VSTS and Git repository. Further, you can also learn to manage resources for a container, set up monitoring and diagnostics, deploy composite container environments using Docker Compose on Windows and manage container clusters using Docker Swarm. By the end of the end of the book, we focus on building applications using Microsofts new and thinnest server platform Nano Servers.;;;;
Book;;ICPE '17: Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering;;2017;;;;;Association for Computing Machinery;New York, NY, USA;;;L'Aquila, Italy;2017;9781450344043;;;;"Welcome to the 8th ACM/SPEC International Conference on Performance Engineering (ICPE), taking place in L'Aquila, Italy, in April 22-26, 2017. The goal of ICPE is to integrate theory and practice in the field of performance engineering by providing a forum for sharing ideas and experiences between industry and academia. ICPE grew out of the ACM Workshop on Software Performance (WOSP Est. 1998) and the SPEC International Performance Engineering Workshop (SIPEW Est. 2008). It is a great pleasure to introduce the exciting program for this year's conference in which researchers and practitioners present their latest research, newest innovations, and vision for the future of performance engineering.We received 83 high quality submissions across the Research, Industry/Experience and Work-Inprogress/ Vision tracks. The Research Track attracted 65 submissions with 24 papers (22 full, 2 short) accepted for presentation. In the Work-In-Progress/Vision Track 14 out of 25 contributions were selected and the Industry/Experience track attracted 18 submissions of which 5 were accepted for presentation. Each paper received at least three reviews from program committee members. Four best paper award candidates were also selected. The best paper is to be announced during the ICPE 2017 social event, after all four papers are presented at the conference.We are excited to also present three keynote talks as part of the technical program. Micro-Benchmarking Considered Harmful; When the Whole is Faster or Slower Than the Sum of its Parts, by Thomas Wuerthinger (Oracle Labs)Performance is Also a Matter of Where You Live, by Francesco Quaglia (University of Rome La Sapienza)Autonomic storage management at scale, by Arif Merchant (Google)In addition, the program includes five tutorials, a poster and demo track, the SPEC Distinguished Dissertation Award, and eight interesting workshops on Autonomous Control for Performance and Reliability Trade-offs in Internet of Services (ACPROSS), on Performance Analysis of Big Data Systems (PABS), on Challenges in Performance Methods for Software Development (WOSP-C), on Energy-aware Simulation (ENERGY-SIM), on Load Testing and Benchmarking of Software Systems (LTB), on Monitoring in Large-Scale Software Systems (MoLS), on Education and Practice of Performance Engineering (WEPPE), and on Quality-aware DevOps (QUDOS).The program covers traditional ICPE topics such as design for performance and problem diagnosis, online performance management, analytic models, empirical studies, model building, and benchmarking, as well as application of performance engineering theory and techniques to several practical fields, including distributed systems, cloud computing, storage, energy, big data, virtualized systems, and hardware.";;;Proceedings;
Book;Akula M,Mahajan A;Security Automation with Ansible 2: Leverage Ansible 2 to Automate Complex Security Tasks like Application Security, Network Security, and Malware Analysis;;2017;;;;;Packt Publishing;;;;;2017;9781788394512;;;;Automate security-related tasks in a structured, modular fashion using the best open source automation tool availableKey FeaturesLeverage the agentless, push-based power of Ansible 2 to automate security tasksLearn to write playbooks that apply security to any part of your system This recipe-based guide will teach you to use Ansible 2 for various use cases such as fraud detection, network security, governance, and more Book Description Security automation is one of the most interesting skills to have nowadays. Ansible allows you to write automation procedures once and use them across your entire infrastructure. This book will teach you the best way to use Ansible for seemingly complex tasks by using the various building blocks available and creating solutions that are easy to teach others, store for later, perform version control on, and repeat. We ll start by covering various popular modules and writing simple playbooks to showcase those modules. You ll see how this can be applied over a variety of platforms and operating systems, whether they are Windows/Linux bare metal servers or containers on a cloud platform. Once the bare bones automation is in place, you ll learn how to leverage tools such as Ansible Tower or even Jenkins to create scheduled repeatable processes around security patching, security hardening, compliance reports, monitoring of systems, and so on. Moving on, you ll delve into useful security automation techniques and approaches, and learn how to extend Ansible for enhanced security. While on the way, we will tackle topics like how to manage secrets, how to manage all the playbooks that we will create and how to enable collaboration using Ansible Galaxy. In the final stretch, we ll tackle how to extend the modules of Ansible for our use, and do all the previous tasks in a programmatic manner to get even more powerful automation frameworks and rigs. What you will learn Use Ansible playbooks, roles, modules, and templating to build generic, testable playbooks Manage Linux and Windows hosts remotely in a repeatable and predictable manner See how to perform security patch management, and security hardening with scheduling and automation Set up AWS Lambda for a serverless automated defense Run continuous security scans against your hosts and automatically fix and harden the gaps Extend Ansible to write your custom modules and use them as part of your already existing security automation programs Perform automation security audit checks for applications using Ansible Manage secrets in Ansible using Ansible Vault Who This Book Is ForIf you are a system administrator or a DevOps engineer with responsibility for finding loop holes in your system or application, then this book is for you. It s also useful for security consultants looking to automate their infrastructure s security model.;;;;
Book;Arundel J;Puppet 3 Beginner's Guide;;2013;;;;;Packt Publishing;;;;;2013;9781782161240;;;;"Start from scratch with the Puppet configuration management system, and learn how to fully utilize Puppet through simple, practical examples Overview Shows you step-by-step how to install Puppet and start managing your systems with simple examples Every aspect of Puppet is explained in detail so that you really understand what you're doing. Gets you up and running immediately, from installation to using Puppet for practical tasks in a matter of minutes. Written in a clear, friendly, jargon-free style which doesn't assume any previous knowledge and explains things in practical terms In Detail Everyone's talking about Puppet, the open-source DevOps technology that lets you automate your server setups and manage websites, databases, and desktops. Puppet can build new servers in seconds, keep your systems constantly up to date, and automate daily maintenance tasks. ""Puppet 3 Beginner's Guide"" gets you up and running with Puppet straight away, with complete real world examples. Each chapter builds your skills, adding new Puppet features, always with a practical focus. You'll learn everything you need to manage your whole infrastructure with Puppet. ""Puppet 3 Beginner's Guide"" takes you from complete beginner to confident Puppet user, through a series of clear, simple examples, with full explanations at every stage. Through a series of worked examples introducing Puppet to a fictional web company, you'll learn how to manage every aspect of your server setup. Switching to Puppet needn't be a big, long-term project; this book will show you how to start by bringing one small part of your systems under Puppet control and, little by little, building to the point where Puppet is managing your whole infrastructure. Presented in an easy-to-read guide to learning Puppet from scratch, this book explains simply and clearly all you need to know to use this essential IT power tool, all the time applying these solutions to real-world scenarios. What you will learn from this book Installing and configuring your Puppet environment. Running Puppet on multiple servers. Deploy configuration files and templates for lightning-fast installations. Creating and monitoring reports and information. Managing user accounts, security, access control, and scheduled jobs. Best practices for organizing your Puppet code using Git. Approach Presented in an easy-to-follow, step-by-step tutorial format, Puppet 3 Beginner's Guide will lead you through the basics of setting up your Puppet server with plenty of screenshots and real-world solutions. Who this book is written for This book is written for system administrators and developers, and anyone else who needs to manage computer systems. You will need to be able to edit text files and run a few commands on the command line, but otherwise no system administration or programming experience is required.";;;;
Book;Arundel J;Puppet 4.10 Beginner's Guide: From Newbie to pro with Puppet 4.10, 2nd Edition;;2017;;;;2nd;Packt Publishing;;;;;2017;9781787124004;;;;Puppet is great for developers, system administrators, IT professionals, and anyone laying the foundation for DevOps practices - this comprehensive guide will get you up to speed, all the way from installation to automation to the latest features of Puppet 4.10. About This Book Develop skills to run Puppet 4.10 on single or multiple servers without hiccups Use Puppet to spin up and manage cloud resources such as Amazon EC2 instances Take full advantage of the powerful new features of Puppet 4.10, including loops, data types, structured facts, R10K module management, control repos, and EPP templates Who This Book Is ForPuppet Beginner's Guide, Second Edition is designed for those who are new to Puppet, including system administrators and developers who are looking to manage computer server systems for configuration management. No prior programming or system administration experience is assumed. What You Will Learn Covers the latest Puppet 4.10 release Install and set up Puppet and discover the latest and most advanced features Configure, build, and run containers in production using Puppet's industry-leading Docker support Deploy configuration files and templates at super-fast speeds and manage user accounts and access control Automate your IT infrastructure Use the latest features in Puppet 4 onward and its official modules Manage clouds, containers, and orchestration Get to know the best practices to make Puppet more reliable and increase its performance In Detail Puppet 4.10 Beginner's Guide, Second Edition, gets you up and running with the very latest features of Puppet 4.10, including Docker containers, Hiera data, and Amazon AWS cloud orchestration. Go from beginner to confident Puppet user with a series of clear, practical examples to help you manage every aspect of your server setup. Whether you're a developer, a system administrator, or you are simply curious about Puppet, you'll learn Puppet skills that you can put into practice right away. With practical steps giving you the key concepts you need, this book teaches you how to install packages and config files, create users, set up scheduled jobs, provision cloud instances, build containers, and so much more. Every example in this book deals with something real and practical that you're likely to need in your work, and you'll see the complete Puppet code that makes it happen, along with step-by-step instructions for what to type and what output you'll see. All the examples are available in a GitHub repo for you to download and adapt for your own server setup. Style and approach This tutorial is packed with quick step-by-step instructions that are immediately applicable for beginners. This is an easy-to-read guide, to learn Puppet from scratch, that explains simply and clearly all you need to know to use this essential IT power tool, while applying these solutions to real-world scenarios.;;;;
Book;Helmke M;Ubuntu Unleashed 2012 Edition: Covering 11.10 and 12.04;;2012;;;;7th;SAMS;USA;;;;2012;9780672335785;;;;Ubuntu Unleashed is filled with unique and advanced information for everyone who wants to make the most of the Ubuntu Linux operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 11.10 (Oneiric Ocelot) and the forthcoming Ubuntu 12.04. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 11.10/12.04 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find brand-new coverage of the new Unity desktop, new NoSQL database support and Android mobile development tools, and many other Ubuntu 11.10/12.04 innovations. Whether youre new to Ubuntu or already a power user, youll turn to this book constantly: for new techniques, new solutions, and new ways to do even more with Ubuntu! Matthew Helmke served from 2006 to 2011 on the Ubuntu Forum Council, providing leadership and oversight of the Ubuntu Forums, and spent two years on the Ubuntu regional membership approval board for Europe, the Middle East, and Africa. He has written about Ubuntu for several magazines and websites, is a lead author of The Official Ubuntu Book. He works for The iPlant Collaborative, which is funded by the National Science Foundation and is building cyberinfrastructure for the biological sciences to support the growing use of massive amounts of data and computationally intensive forms of research. Quickly install Ubuntu, configure it, and get your hardware running right Configure and customize the new Unity desktop (or alternatives such as GNOME) Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and use Ubuntu from the command line Automate tasks and use shell scripting Provide secure remote access Manage kernels and modules Administer file, print, email, proxy, LDAP, and database services (both SQL and NoSQL) Use both Apache and alternative HTTP servers Support and use virtualization Use Ubuntu in cloud environments Learn the basics about popular programming languages including Python, PHP, and Perl, and how to use Ubuntu to develop in them Learn how to get started developing Android mobile devices Ubuntu 11.10 on DVD DVD includes the full Ubuntu 11.10 distribution for Intel x86 computers as well as the complete LibreOffice office suite and hundreds of additional programs and utilities. Free Upgrade! Purchase this book anytime in 2012 and receive a free Ubuntu 12.04 Upgrade Kit by mail (U.S. or Canada only) after Ubuntu 12.04 is released. See inside back cover for details.;;;;
Book;Santacroce F;Git Essentials - Second Edition: Create, Merge, and Distribute Code with Git, the Most Powerful and Flexible Versioning System Available;;2017;;;;2nd;Packt Publishing;;;;;2017;9781787120723;;;;"Dive and explore into the latest addons of the latest Git. About This Book Master all the basic concepts of Git to protect your code and make it easier to evolve Use Git proficiently, and learn how to resolve day-by-day challenges easily This step-by-step guide is packed with examples to help you learn and work with Gits internals Who This Book Is ForIf you are a software developer with little or no experience of versioning systems, or you are familiar with other centralized versioning systems, then this book is for you. If you have experience in server and system management and need to broaden your use of Git from a DevOps perspective, this book contains everything you need. What You Will Learn Master Git fundamentals Be able to ""visualize,"" even with the help of a valid GUI tool Write principal commands in a shell Figure out the right strategy to run change your daily work with few or no annoyances Explore the tools used to migrate to Git from the Subversion versioning system without losing your development history Plan new projects and repositories with ease, using online services, or local network resources In Detail Since its inception, Git has attracted skilled developers due to its robust, powerful, and reliable features. Its incredibly fast branching ability transformed a piece of code from a niche tool for Linux Kernel developers into a mainstream distributed versioning system. Like most powerful tools, Git can be hard to approach since it has a lot of commands, subcommands, and options that easily confuse newcomers. The 2nd edition of this very successful book will help you overcome this fear and become adept in all the basic tasks in Git. Building upon the success of the first book, we start with a brief step-by-step installation guide; after this, you'll delve into the essentials of Git. For those of you who have bought the first edition, this time we go into internals in far greater depth, talking less about theory and using much more practical examples. The book serves as a primer for topics to follow, such as branching and merging, creating and managing a GitHub personal repository, and fork and pull requests. Youll then learn the art of cherry-picking, taking only the commits you want, followed by Git blame. Finally, we'll see how to interoperate with a Subversion server, covering the concepts and commands needed to convert an SVN repository into a Git repository. To conclude, this is a collection of resources, links, and appendices to satisfy even the most curious. Style and approach This short guide will help you understand the concepts and fundamentals of GIT is a step-by-step manner.";;;;
Book;Sanchez CP,Vilarino PS;PHP Microservices;;2017;;;;;Packt Publishing;;;;;2017;9781787125377;;;;Transit from monolithic architectures to highly available, scalable, and fault-tolerant microservices About This BookBuild your own applications based on event-driven microservices and set them up on a production server. Successfully transform any monolithic application into a microservice. Monitor the health of your application, prevent downtime, and reduce costs. Who This Book Is For PHP developers who want to build scalable, highly available, and secure applications will find this book useful. No knowledge of microservices is assumed. What You Will LearnSet up a development environment using the right strategies and tools. Learn about application design and structure to start implementing your application. Transform a monolithic application into microservices. Explore the best way to start implementing your application using testing. Understand how to monitor your microservices, handle errors, and debug the application. Deploy your finished application into a production environment and learn how to solve common problems.Know how to scale your application based on microservices once it is upand-running. In DetailThe world is moving away from bulky, unreliable, and high-maintenance PHP applications, to small, easy-to-maintain and highly available microservices and the pressing need is for PHP developers to understand the criticalities in building effective microservices that scale at large. This book will be a reliable resource, and one that will help you to develop your skills and teach you techniques for building reliable microservices in PHP. The book begins with an introduction to the world of microservices, and quickly shows you how to set up a development environment and build a basic platform using Docker and Vagrant. You will then get into the different design aspects to be considered while building microservices in your favorite framework and you will explore topics such as testing, securing, and deploying microservices. You will also understand how to migrate a monolithic application to the microservice architecture while keeping scalability and best practices in mind. Furthermore you will get into a few important DevOps techniques that will help you progress on to more complex domains such as native cloud development, as well as some interesting design patterns. By the end of this book you will be able to develop applications based on microservices in an organized and efficient way. You will also gain the knowledge to transform any monolithic applications into microservices. Style and approach Filled with code that you can start typing straightaway, this book will take you through building, testing, securing, and deploying microservices in the most practical way possible. The focus of the book is more inclined towards showing you how it's done, rather than with what to do, although you will get a good idea of those tools most widely used to build microservices.;;;;
Book;Buenosvinos C,Soronellas C,Akbary K;Domain-Driven Design in PHP;;2017;;;;;Packt Publishing;;;;;2017;9781787284944;;;;Key Features Focuses on practical code rather than theoryFull of real-world examples that you can apply to your own projectsShows how to build PHP apps using DDD principles Book Description Domain-Driven Design (DDD) has arrived in the PHP community, but for all the talk, there is very little real code. Without being in a training session and with no PHP real examples, learning DDD can be challenging. This book changes all that. It details how to implement tactical DDD patterns and gives full examples of topics such as integrating Bounded Contexts with REST, and DDD messaging strategies. In this book, the authors show you, with tons of details and examples, how to properly design Entities, Value Objects, Services, Domain Events, Aggregates, Factories, Repositories, Services, and Application Services with PHP. They show how to apply Hexagonal Architecture within your application whether you use an open source framework or your own. What you will learnCorrectly design all design elements of Domain-Driven Design with PHPLearn all tactical patterns to achieve a fully worked-out Domain-Driven Design Apply hexagonal architecture within your application Integrate bounded contexts in your applicationsUse REST and Messaging approaches About the Author Carlos Buenosvinos is a PHP Extreme Programmer with more than 15 years of experience developing web applications and more than 10 years experience as a Tech Lead and CTO leading teams of between 20 and 100 people. He is a Certified ScrumMaster (CSM) and has coached and trained close to two dozen different companies in Agile practices, both as an employee and as a consultant. On the technical side, he is a Zend PHP Engineer, a Zend Framework Engineer, and MySQL certified. He is also a board member of the PHP Barcelona User Group. He has worked with e-commerce (Atrapalo and eBay), payment processing (Vendo), classifieds (Emagister), and B2B recruiting tools (XING). He is interested in JavaScript, DevOps, and Scala. He likes developing for mobile, Raspberry Pi, and games. Christian Soronellas is a passionate Software Developer, Software Journeyman, and Craftsman Apprentice. He's an Extreme Programmer soul with more than 10 years of experience in web development. He's also a Zend PHP 5.3 Certified Engineer, a Zend Framework Certified Engineer, and a SensioLabs Certified Symfony Developer. He has worked as a freelancer, as well as at Privalia, Emagister, Atrapalo, and Enalquiler as a Software Architect. Keyvan Akbary is a polyglot Software Developer who loves Software fundamentals, the Craftsmanship movement, Extreme Programming, SOLID principles, Clean Code, Design Patterns, and Testing. He's also a sporadic Functional Programmer. He understands technology as a medium for providing value. He has worked on countless projects as a freelancer, on video streaming (Youzee), and on an online marketplace (MyBuilder) - all in addition to founding a crowdfunding company (Funddy). Currently, Keyvan is working in FinTech as a Lead Developer at Transfer Wise London.;;;;
Book;Hamburger V;Building VMware Software-Defined Data Centers;;2017;;;;;Packt Publishing;;;;;2017;9781786464378;;;;Key FeaturesLearn how you can automate your data center operations and deploy and manage applications and services across your public, private, and hybrid infrastructure in minutesDrive great business results with cost-effective solutions without compromising on ease, security, and controlsTransform your business processes and operations in a way that delivers any application, anywhere, with complete peace of mindBook DescriptionVMware offers the industry-leading software-defined data center (SDDC) architecture that combines compute, storage, networking, and management offerings into a single unified platform. This book uses the most up-to-date, cutting-edge VMware products to help you deliver a complete unified hybrid cloud experience within your infrastructure. It will help you build a unified hybrid cloud based on SDDC architecture and practices to deliver a fully virtualized infrastructure with cost-effective IT outcomes. In the process, you will use some of the most advanced VMware products such as VSphere, VCloud, and NSX. You will learn how to use vSphere virtualization in a software-defined approach, which will help you to achieve a fully-virtualized infrastructure and to extend this infrastructure for compute, network, and storage-related data center services. You will also learn how to use EVO:RAIL. Next, you will see how to provision applications and IT services on private clouds or IaaS with seamless accessibility and mobility across the hybrid environment. This book will ensure you develop an SDDC approach for your datacenter that fulfills your organization's needs and tremendously boosts your agility and flexibility. It will also teach you how to draft, design, and deploy toolsets and software to automate your datacenter and speed up IT delivery to meet your lines of businesses demands. At the end, you will build unified hybrid clouds that dramatically boost your IT outcomes. What you will learnUnderstand and optimize end-to-end processes in your data centerTranslate IT processes and business needs into a technical designApply and create vRO workflow automation functionalities to servicesDeploy NSX in a virtual environmentTechnically accomplish DevOps offeringsSet up and use vROPs to master the SDDC resource demandsTroubleshoot all the components of SDDCAbout the AuthorValentin Hamburger was working at VMware for more than seven years. In his former role, he was a lead consulting architect and took care of the delivery and architecture of cloud projects in central EMEA. In his current role, he is EMEA solutions lead for VMware at Hitachi Data Systems (HDS). Furthermore he works as an advisor with HDS engineering on the Hitachi Enterprise Cloud, which is based on VMware vRealize technology. He holds many industry certifications in various areas such as VMware, Linux, and IBM Power compute environments. He serves as a partner and trusted advisor to HDS customers primarily in EMEA. His main responsibilities are ensuring that HDS's future innovations align with essential customer needs and translating customer challenges to opportunities focused on virtualization topics. Valentin enjoys sharing his knowledge as a speaker at national and international conferences such as VMworld.;;;;
Book;Neeraj N;Mastering Apache Cassandra;;2013;;;;;Packt Publishing;;;;;2013;9781782162681;;;;"Get comfortable with the fastest NoSQL database, its architecture, key programming patterns, infrastructure management, and more! Overview Complete coverage of all aspects of Cassandra Discusses prominent patterns, pros and cons, and use cases Contains briefs on integration with other software In Detail Apache Cassandra is the perfect choice for building fault tolerant and scalable databases. Implementing Cassandra will enable you to take advantage of its features which include replication of data across multiple datacenters with lower latency rates. This book details these features that will guide you towards mastering the art of building high performing databases without compromising on performance. Mastering Apache Cassandra aims to give enough knowledge to enable you to program pragmatically and help you understand the limitations of Cassandra. You will also learn how to deploy a production setup and monitor it, understand what happens under the hood, and how to optimize and integrate it with other software. Mastering Apache Cassandra begins with a discussion on understanding Cassandras philosophy and design decisions while helping you understand how you can implement it to resolve business issues and run complex applications simultaneously. You will also get to know about how various components of Cassandra work with each other to give a robust distributed system. The different mechanisms that it provides to solve old problems in new ways are not as twisted as they seem; Cassandra is all about simplicity. Learn how to set up a cluster that can face a tornado of data reads and writes without wincing. If you are a beginner, you can use the examples to help you play around with Cassandra and test the water. If you are at an intermediate level, you may prefer to use this guide to help you dive into the architecture. To a DevOp, this book will help you manage and optimize your infrastructure. To a CTO, this book will help you unleash the power of Cassandra and discover the resources that it requires. What you will learn from this book Write programs using Cassandras features more efficiently Learn how to get the most out of a given infrastructure and Improve performance, tweak JVM Manage clusters and perform housekeeping activities Keep an eye on Cassandra processes and machines that hold the data store get to know simple monitoring mechanisms, such as open sourced and proprietary ones Squeeze the value of the data that you hold in Cassandra Learn CQL 3 quickly and use Cassandra with Java, Python, NodeJS, Scala, and PHP Approach Mastering Apache Cassandra is a practical, hands-on guide with step-by-step instructions. The smooth and easy tutorial approach focuses on showing people how to utilize Cassandra to its full potential. Who this book is written for This book is aimed at intermediate Cassandra users. It is best suited for startups where developers have to wear multiple hats: programmer, DevOps, release manager, convincing clients, and handling failures. No prior knowledge of Cassandra is required.";;;;
Book;Weir LA,Bell A,Carrasco R,Viveros A;Oracle API Management 12c Implementation;;2015;;;;;Packt Publishing;;;;;2015;9781785283635;;;;Learn how to successfully implement API management using Oracle's API Management Solution 12cAbout This BookExplore the key concepts, goals, and objectives of API Management and learn how to implement it using the Oracle API Management SolutionUnderstand the concepts and objectives of the Application Service Governance (ASG), along with the governance framework that encompasses people, processes, and technologyGet to grips with API Management readiness assessments, gap analysis, digital reference architecture, and implementation roadmapsWho This Book Is ForThis book is for Enterprise Architects, Solution Architects, Technical Architects, and SOA and API consultants who want to successfully implement API Management using the Oracle API Management Solution products.What You Will LearnUnderstand how to manage a set of APIsDiscover the differences and similarities between API Management and SOA Governance, and where and how these two disciplines converge into Application Services Governance (ASG)Grasp information about ASG and how to define an ASG governance frameworkUnderstand the challenges for organizations looking to expose APIs to the external world. Identify common scenarios and how to solve themDefine an Oracle API management deployment topologyInstall and configure Oracle API Catalog (OAC), Oracle API Manager (OAPIM), and Oracle API Gateway (OAG)Learn about API subscriptions and API community management with the OAPIM portalImplement Oracle API Manager (OAPIM) including creation, publishing, management and deprecation of APIsIn DetailOracle SOA Governance is a comprehensive, service-orientated governance solution that is designed to make the transition to SOA easier. API management is the discipline that governs the software development lifecycle of APIs. It defines the tools and processes needed to build, publish and operate APIs including the management of the community of developers around it.This book illustrates how to successfully implement API Management in your organization. To achieve this, the importance of defining an API management strategy and implementation roadmap so that capabilities are implemented in the right order and timeframes is described.It starts by describing all of the fundamental concepts around API Management and related disciplines such as SOA Governance and DevOps in order to dispel the confusion surrounding these topics.The book then takes you on the journey of implementing API Management, using a realistic case study of an organization that needs an API Management solution. You will start by identifying the key business drivers to implement APIs and then create an API Management strategy and a roadmap to realize this strategy.You'll then go through a number of use cases, each focused on addressing specific business requirements. These will help you understand each of the Oracle API Management products, how they fit into an overall architecture, and how to implement them.The book concludes by providing some tips and guidelines around defining a deployment topology for the Oracle API Management products and the steps to install them.Style and approachThis book is a comprehensive guide to successfully implementing a complete API Management solution from inception to implementation. The initial chapters introduce you to Oracle SOA Governance and API Management and from there, chapters are mainly hands-on and provide a full step-by-step walkthrough of how to implement the products of the Oracle API management solution to address realistic use cases.;;;;
Book;Burgess M;In Search of Certainty: The Science of Our Information Infrastructure;;2013;;;;;CreateSpace Independent Publishing Platform;North Charleston, SC, USA;;;;2013;9781492389163;;;;"Ruling the Machines that Rule the World? Our planet's information systems have now reached a level of scale and complexity at which we can no longer simply decide how they will behave. They are so sophisticated and so interconnected that humans can neither steer nor comprehend them with certainty. Can we trust such an infrastructure to society? For more than twenty years, Mark Burgess has been one of the pioneers of the science and technology behind the operation of this information infrastructure. In this book, he explains how far we have come in our understanding of the systems, and whether we yet have the necessary knowledge to prevent them from spiralling out of control. In Search of Certainty takes the reader on a fascinating journey, from the beginnings of scientific thought to our present day, illuminating information technology as an integral part of our modern historical and cultural narrative. It lays out key challenges for the future and suggests a daring new way to think about the future governance of the vast cybernetic organism we are in process of creating. ""An instant classic in computer science! 'In Search of Certainty' is a brilliant piece of work by one of the most brilliant people I've ever met. Complex systems, like modern IT services, need to be understood from a perspective very different from traditional IT practice. The answers are rooted in science and Mark Burgess exposes this science like nobody else."" -- Glenn O'Donnell, Principal Analyst, Forrester Research ""An incredible journey by one of the [IT] industry's most important thinkers over the past 20 years. Like everything else he's done, this is unique and astonishing in its implications."" --Carolyn Rowland, NIST ""Mark brings together the digital microcosm and macrocosm, the mundane and the profound, the human and the technological, in a way that is important, wonderful, and truly mind-stretching."" -- Jeff Sussna, Ingineering.IT ""Mark Burgess practically invented modern IT infrastructure management software. Now he has produced a revolutionary work, part personal journey, part theoretical review, as he advances the state of infrastructure science -- and our comprehension -- again. IN SEARCH OF CERTAINTY is a must-read book from a true visionary."" --Christopher Little, BMC Software ""There are thought leaders, and then there are thought leaders. Mark Burgess is a scientist who can talk to the real world, and has been challenging it for 20 years, with the message of science."" -- Reynold Jabbour, J.P. Morgan-Chase ""Holy cow! ... Mark Burgess' pioneering work in the late-1990s presaged how large scale systems were designed and operated, and it has taken the world nearly two decades to catch up with him. Ignore the design principles and patterns described in this book at your peril -- in two decades, I'm sure that it will be embedded in how every architect, developers and operations professional talks about our craft, for practitioners, suppliers and researchers alike."" -- Gene Kim, Author of Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win ""To err is human, to explain is Mark Burgess."" -- Patrick Debois ""I only got through the Introduction and Chapter 1. I was so encouraged by just those that I started applying it to organization at Joyent and forgot to come back to the book."" -- Ben Rockwood, Joyent ""What I liked most about the book was the vast number of topics it drew on, there are examples from a very broad array of domains. This made it very fun. ... It really is a tour de force of most interesting things that have happened for the past 500 years..."" -- Sigurd Teigen, CFEngine ""The book is in parts a very personal description of the world we live in, and how it evolved... the book is about a journey, a personal one. I did like that part very much."" -- Sven van der Meer, Ericsson";;;;