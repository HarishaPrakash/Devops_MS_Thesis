"Item type","Authors","Title","Journal","Publication year","Volume","Issue","Pages","Publisher","Address","Proceedings title","Conference location","Date published","ISBN","ISSN","URLs","DOI","Abstract","Keywords","Series"
"Conference Paper","Bai X,Li M,Pei D,Li S,Ye D","Continuous Delivery of Personalized Assessment and Feedback in Agile Software Engineering Projects","","2018","","","58–67","Association for Computing Machinery","New York, NY, USA","Proceedings of the 40th International Conference on Software Engineering: Software Engineering Education and Training","Gothenburg, Sweden","2018","9781450356602","","https://doi-org.proxy.bnl.lu/10.1145/3183377.3183387;http://dx.doi.org/10.1145/3183377.3183387","10.1145/3183377.3183387","In recent years, Agile development has been adopted in project practices of Software Engineering (SE) courses. However, it is a great challenge to provide timely assessment and feedback to project teams and individual students with a frequency that catches up with iterative, incremental, and cooperative software development with continuous deliveries. Conventional project reviews are mostly dependent upon instructors and teaching assistants in a manual reviewing/mentoring approach, which are simply not scalable.In this paper, we argue that agile projects warrant a ""continuous delivery"" of personalized assessment and feedback. To this end, we propose an online-offline combined approach and built a system upon GitLab. An online platform was built by integrating DevOps tool chains so that personalized reports and assessments are delivered automatically to the teams/students, which serve as the very efficient trigger and basis for the close and targeted offline interactions between students and TAs: daily discussion over instant messaging and weekly in person meeting. This system has been in operation since 2014 for an undergraduate SE course, with over 500 students participating in over 130 project teams in total. Our results show that such a continuous assessment/feedback delivery system is very effective in educating Agile projects in SE courses.","project, devops, assessment, software engineering course, agile","ICSE-SEET '18"
"Conference Paper","Çalikli G,Staron M,Meding W","Measure Early and Decide Fast: Transforming Quality Management and Measurement to Continuous Deployment","","2018","","","51–60","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 International Conference on Software and System Process","Gothenburg, Sweden","2018","9781450364591","","https://doi-org.proxy.bnl.lu/10.1145/3202710.3203156;http://dx.doi.org/10.1145/3202710.3203156","10.1145/3202710.3203156","Continuous deployment has become software companies' inevitable response to the economic pressures of the market. At the same time, software quality is crucial in order to meet customers' expectations and hence succeed in the market. Therefore, current quality management processes require transformation in order to keep up with the fast pace of the market while at the same time meeting customers' expectations. In order to figure out how the current quality management process should be transformed to keep up with the fast pace of the market while ensuring both product quality and continuous deployment, we conducted a qualitative study at a large infrastructure provider company. During the interviews we conducted with the quality manager, developer and test architect, we used a metrics portfolio consisting of 59 candidate metrics that can be used in the transformed quality management process. Our findings show that, out of these candidate metrics, 9 metrics should be used in the internal quality measurement dashboard for quality check at the end of the software development life-cycle (SDLC) before the software is released to customer site, while 3 metrics should be used by quality manager to monitor earlier phases of SDLC and 5 metrics should also be delegated to earlier phases of SDLC but without the involvement of the quality manager. To summarize, our study support the claim that quality managers should not be only gatekeepers, but also proactive controllers of quality by monitoring earlier phases of the SDLC.","software quality, continuous deployment, metrics","ICSSP '18"
"Conference Paper","Perez-Palacin D,Ridene Y,Merseguer J","Quality Assessment in DevOps: Automated Analysis of a Tax Fraud Detection System","","2017","","","133–138","Association for Computing Machinery","New York, NY, USA","Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion","L'Aquila, Italy","2017","9781450348997","","https://doi-org.proxy.bnl.lu/10.1145/3053600.3053632;http://dx.doi.org/10.1145/3053600.3053632","10.1145/3053600.3053632","The paper presents an industrial application of a DevOps process for a Tax fraud detection system. In particular, we report the influence of the quality assessment during development iterations, with special focus on the fulfillment of performance requirements. We investigated how to guarantee quality requirements in a process iteration while new functionalities are added. The experience has been carried out by practitioners and academics in the context of a project for improving quality of data intensive applications.","devops, tax fraud detection, unified modeling language, data intensive applications, model-based quality of service","ICPE '17 Companion"
"Conference Paper","Yasar H","Implementing Secure DevOps Assessment for Highly Regulated Environments","","2017","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 12th International Conference on Availability, Reliability and Security","Reggio Calabria, Italy","2017","9781450352574","","https://doi-org.proxy.bnl.lu/10.1145/3098954.3105819;http://dx.doi.org/10.1145/3098954.3105819","10.1145/3098954.3105819","Secure DevOps has become a standard option for entities seeking to streamline and increase comprehensive participation by all stakeholders in their secure Security Development Lifecycle (SDLC)[1]. In most case in industry, academia, and government, applying DevOps is a straight forward process. There is a subset of entities in these three sectors where applying Secure DevOps is challenging. These are entities that are highly regulated (HRE) as mandated by policies for various reasons, the most often being general security and protection of intellectual property. Even if an entity is highly regulated, its secure SDLC can still benefit from implementing DevOps as long as the implementation does not break any policy[2].","Security Engineering, AppSec, Highly Regulated Environment, Secure DevOps assessment, Secure DevOps, DevSecOps, DevOps","ARES '17"
"Conference Paper","Avritzer A","Automated Scalability Assessment in DevOps Environments","","2020","","","10","Association for Computing Machinery","New York, NY, USA","Companion of the ACM/SPEC International Conference on Performance Engineering","Edmonton AB, Canada","2020","9781450371094","","https://doi-org.proxy.bnl.lu/10.1145/3375555.3384936;http://dx.doi.org/10.1145/3375555.3384936","10.1145/3375555.3384936","In this extended abstract, we provide an outline of the presentation planned for WOSP-C 2020. The goal of the presentation is to provide an overview of the challenges and approaches for automated scalability assessment in the context of DevOps and microservices. The focus of this presentation is on approaches that employ automated identification of performance problems because these approaches can leverage performance anti-pattern[5] detection technology. In addition, we envision extending the approach to recommend component refactoring. In our previous work[1,2] we have designed a methodology and associated tool support for the automated scalability assessment of micro-service architectures, which included the automation of all the steps required for scalability assessment. The presentation starts with an introduction to dependability, operational Profile Data, and DevOps. Specifically, we provide an overview of the state of the art in continuous performance monitoring technologies[4] that are used for obtaining operational profile data using APM tools. We then present an overview of selected approaches for production and performance testing based on the application monitoring tool (PPTAM) as introduced in [1,2]. The presentation concludes by outlining a vision for automated performance anti-pattern[5] detection. Specifically, we present the approach introduced for automated anti-pattern detection based on load testing results and profiling introduced in[6] and provide recommendations for future research.","","ICPE '20"
"Conference Paper","Jennings RA,Gannod G","DevOps - Preparing Students for Professional Practice","","2019","","","1–5","IEEE Press","Covington, KY, USA","2019 IEEE Frontiers in Education Conference (FIE)","","2019","","","https://doi-org.proxy.bnl.lu/10.1109/FIE43999.2019.9028598;http://dx.doi.org/10.1109/FIE43999.2019.9028598","10.1109/FIE43999.2019.9028598","This work in progress paper presents a course on DevOps which is a combination of software development skills and software operations skills. This new course is for sophomores and juniors in the computer science program who want to be prepared for professional software engineering careers. Introduction to DevOps Is a hands-on laboratory course that brings students through Git for source code management, Capybara for automated testing, AWS, Docker, and Ansible for automated virtual machine provisioning and configuration, and Jenkins for Continuous Integration. Unlike our current course offerings which primarily focus on the single developer context in a localized environment, this course prepares students for highly collaborative, team-based projects that use cloud resources to facilitate management of the software deployment pipeline. We developed this course based on feedback from our external advisory board and under consultation from a number of industrial partners. This is complementary to our current offerings in software engineering which focus on Agile software practices. In this paper we describe the core concepts, the design, learning experiences, technologies, and lessons learned through developing and conducting this course. In future work we hope to present student perceptions of learning and provide data collected through direct assessment of student outcomes.","",""
"Conference Paper","Adi Prakoso B,Kuswardono Budiardjo E","The Usage of Agile Adoption Framework to Assess Scrum Process and Recommend Improvements","","2021","","","28–32","Association for Computing Machinery","New York, NY, USA","2021 The 4th International Conference on Software Engineering and Information Management","Yokohama, Japan","2021","9781450388955","","https://doi-org.proxy.bnl.lu/10.1145/3451471.3451476;http://dx.doi.org/10.1145/3451471.3451476","10.1145/3451471.3451476","The Scrum framework is based on the values, principles, and practices that form the foundation for organizations to work. This case study examines an Indonesia-based technology on implementing software development using Scrum. The goal is to assess the process and recommend improvements so XYZ Company can achieve better results at delivering products and services using Scrum. Agile Adoption Framework is used as the assessment framework, evaluating 3 teams represented by its Manager, Product Owner, and Developers. Indicator assessment is done by using data collection methods such as questionnaires or observations. The assessment result shows that XYZ Company achieves Level 2, and the teams achieve Level 2, 4, and 5 respectively. Furthermore, 7 agile practices need improvements, such as evolutionary requirements, continuous delivery, risk-driven iterations, low process ceremony, agile project estimation, pair programming, and test-driven development.","software, software development, software process improvement, Agile Adoption Framework","ICSIM 2021"
"Journal Article","Perez-Palacin D,Merseguer J,Requeno JI,Guerriero M,Di Nitto E,Tamburri DA","A UML Profile for the Design, Quality Assessment and Deployment of Data-Intensive Applications","Softw. Syst. Model.","2019","18","6","3577–3614","Springer-Verlag","Berlin, Heidelberg","","","2019-12","","1619-1366","https://doi-org.proxy.bnl.lu/10.1007/s10270-019-00730-3;http://dx.doi.org/10.1007/s10270-019-00730-3","10.1007/s10270-019-00730-3","Big Data or Data-Intensive applications (DIAs) seek to mine, manipulate, extract or otherwise exploit the potential intelligence hidden behind Big Data. However, several practitioner surveys remark that DIAs potential is still untapped because of very difficult and costly design, quality assessment and continuous refinement. To address the above shortcoming, we propose the use of a UML domain-specific modeling language or profile specifically tailored to support the design, assessment and continuous deployment of DIAs. This article illustrates our DIA-specific profile and outlines its usage in the context of DIA performance engineering and deployment. For DIA performance engineering, we rely on the Apache Hadoop technology, while for DIA deployment, we leverage the TOSCA language. We conclude that the proposed profile offers a powerful language for data-intensive software and systems modeling, quality evaluation and automated deployment of DIAs on private or public clouds.","Apache Hadoop, Software design, UML, Model-driven deployment, Data-intensive applications, Performance assessment, TOSCA language, Big Data, Profile",""
"Conference Paper","Zhou P,Ali Khan AA,Liang P,Badshah S","System and Software Processes in Practice: Insights from Chinese Industry","","2021","","","394–401","Association for Computing Machinery","New York, NY, USA","Evaluation and Assessment in Software Engineering","Trondheim, Norway","2021","9781450390538","","https://doi-org.proxy.bnl.lu/10.1145/3463274.3463786;http://dx.doi.org/10.1145/3463274.3463786","10.1145/3463274.3463786","Software development processes play a key role in the software and system development life cycle. Processes are becoming complex and evolve rapidly due to the modern-day continuous software engineering (CSE) concepts, which are mainly based on continuous integration, continuous delivery, infrastructure-as-code, automation and more. The fast growing Chinese software development industry adopts various processes to achieve potential benefits offered in the international market. This study is conducted with the aim to investigate the trends of processes in practice in the Chinese industry. The survey questionnaire data is collected from 34 practitioners working in software development firms across the China and the results highlight that iterative and agile processes are extensively used in industrial setting. Furthermore, agile and traditional approaches are combined to develop the hybrid processes. Most of the participants are satisfied using the current development processes, however, they show interest to continuously improve the existing process models and methods. Finally, we noticed that majority of the software development organizations used the ISO 9001 standard for process assessment and improvement activities. The given results provide preliminary overview of processes deployed in the Chinese industry.","Survey, Process Improvement Standards, Software processes, Chinese industry","EASE 2021"
"Journal Article","Sabau AR,Hacks S,Steffens A","Implementation of a Continuous Delivery Pipeline for Enterprise Architecture Model Evolution","Softw. Syst. Model.","2021","20","1","117–145","Springer-Verlag","Berlin, Heidelberg","","","2021-02","","1619-1366","https://doi-org.proxy.bnl.lu/10.1007/s10270-020-00828-z;http://dx.doi.org/10.1007/s10270-020-00828-z","10.1007/s10270-020-00828-z","The discipline of enterprise architecture (EA) is an established approach to model and manage the interaction of business processes and IT in an organization. Thereby, the EA model as a central artifact of EA is subject to a continuous evolution caused by multiple sources of changes. The continuous evolution requires a lot of effort in controlling and managing the evolution of the EA model. This is especially true when merging the induced changes from different sources in the EA model. Additionally, the lack of tool and automation support makes this a very time-consuming and error-prone task. The evolutionary character and the automated quality assessment of artifacts is a well-known challenge in the software development domain as well. To meet these challenges, the discipline of continuous delivery (CD) has emerged to be very useful. The evolution of EA model artifacts shows similarities to the evolution of software artifacts. Therefore, we leveraged practices of CD to practices of EA maintenance. Thus, we created a conceptual framework for automated EA model maintenance. The concepts were realized in a first prototype and were evaluated in a fictitious case study against equivalence classes based on EA model metrics and a set of several requirements for automated EA model maintenance from research. Overall, the concepts prove to be a promising basis for further refinement, implementation, and evaluation in research in an industrial context.","Enterprise architecture model maintenance, Enterprise architecture model evolution, Continuous delivery",""
"Conference Paper","Morales JA,Yasar H,Volkman A","Implementing DevOps Practices in Highly Regulated Environments","","2018","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 19th International Conference on Agile Software Development: Companion","Porto, Portugal","2018","9781450364225","","https://doi-org.proxy.bnl.lu/10.1145/3234152.3234188;http://dx.doi.org/10.1145/3234152.3234188","10.1145/3234152.3234188","In this paper, we discuss implementing DevOps practices in highly regulated environments (HREs). DevOps has become a standard option for entities seeking to streamline and increase participation by all stakeholders in their Software Development Lifecycle (SDLC). For a large portion of industry, academia, and government, applying DevOps is a straight forward process. There is, however, a subset of entities in these three sectors where applying DevOps can be very challenging. These are entities mandated by policies to conduct all or a portion of their SDLC activities in HREs. Often, the reason for an HRE is general security and protection of intellectual property. Even if an entity is functioning in a highly regulated environment, its SDLC can still benefit from implementing DevOps as long as the implementation conforms to all imposed policies. In this paper, we discuss the process of performing a DevOps assessment and implementation in an HRE which we refer to as HRE-DevOps.","secure DevOps, DevOps, DevOps assessment, SDLC, highly regulated environment","XP '18"
"Journal Article","Bennett BT","Shifting Traditional Undergraduate Software Engineering Instruction to a DevOps Focus","J. Comput. Sci. Coll.","2021","36","5","129–138","Consortium for Computing Sciences in Colleges","Evansville, IN, USA","","","2021-01","","1937-4771","","","Classical Software Engineering education often includes traditional methodologies that do not adequately describe today's industry practice. DevOps is a culture that promotes fast delivery, continuous feedback, and an environment of learning. Its non-linear path requires a shift in software engineering pedagogy. This case study describes the redevelopment of a second-semester course in software engineering to focus on DevOps principles. The study evaluates student performance using formative and summative assessment through a team project tracked throughout the semester and final exam results. Results indicated that students developed DevOps skills during the course, but may have needed more reinforcement of some traditional Software Engineering topics.","",""
"Conference Paper","Pietrantuono R,Bertolino A,De Angelis G,Miranda B,Russo S","Towards Continuous Software Reliability Testing in DevOps","","2019","","","21–27","IEEE Press","Montreal, Quebec, Canada","Proceedings of the 14th International Workshop on Automation of Software Test","","2019","","","https://doi-org.proxy.bnl.lu/10.1109/AST.2019.00009;http://dx.doi.org/10.1109/AST.2019.00009","10.1109/AST.2019.00009","We introduce the DevOpRET approach for continuous reliability testing in DevOps. It leverages information monitored in operation to guide operational-profile based testing, which is conceived as part of the acceptance testing stage before each next release to production. We overview the envisaged test and monitoring pipeline, describe the approach and present a case-study evaluating how reliability assessment evolves over subsequent releases.","acceptance test, operational profile, quality gate, software reliability testing, DevOps","AST '19"
"Conference Paper","Pourmajidi W,Miranskyy A,Steinbacher J,Erwin T,Godwin D","Dogfooding: Using IBM Cloud Services to Monitor IBM Cloud Infrastructure","","2019","","","344–353","IBM Corp.","USA","Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering","Toronto, Ontario, Canada","2019","","","","","The stability and performance of Cloud platforms are essential as they directly impact customers' satisfaction. Cloud service providers use Cloud monitoring tools to ensure that rendered services match the quality of service requirements indicated in established contracts such as service-level agreements.Given the enormous number of resources that need to be monitored, highly scalable and capable monitoring tools are designed and implemented by Cloud service providers such as Amazon, Google, IBM, and Microsoft. Cloud monitoring tools monitor millions of virtual and physical resources and continuously generate logs for each one of them. Considering that logs magnify any technical issue, they can be used for disaster detection, prevention, and recovery. However, logs are useless if they are not assessed and analyzed promptly. Thus, we argue that the scale of Cloud-generated logs makes it impossible for DevOps teams to analyze them effectively. This implies that one needs to automate the process of monitoring and analysis (e.g., using machine learning and artificial intelligence). If the automation will witness an anomaly in the logs --- it will alert DevOps staff.The automatic anomaly detectors require a reliable and scalable platform for gathering, filtering, and transforming the logs, executing the detector models, and sending out the alerts to the DevOps staff. In this work, we report on implementing a prototype of such a platform based on the 7-layered architecture pattern, which leverages micro-service principles to distribute tasks among highly scalable, resources-efficient modules. The modules interact with each other via an instance of the Publish-Subscribe architectural pattern. The platform is deployed on the IBM Cloud service infrastructure and is used to detect anomalies in logs emitted by the IBM Cloud services, hence the dogfooding. In particular, we leverage IBM Cloud Functions to deploy the computing modules, IBM Event Streams to establish communication among the modules, and IBM Cloud Object Storage and IBM Cloudant for persistent storage.The prototype efficiency is promising: it takes the platform 17 seconds or less from the point of receiving a new log record to emitting an alert to the IBM Cloud DevOps team.","","CASCON '19"
"Conference Paper","Daoudagh S,Lonetti F,Marchetti E","Continuous Development and Testing of Access and Usage Control: A Systematic Literature Review","","2020","","","51–59","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 European Symposium on Software Engineering","Rome, Italy","2020","9781450377621","","https://doi-org.proxy.bnl.lu/10.1145/3393822.3432330;http://dx.doi.org/10.1145/3393822.3432330","10.1145/3393822.3432330","Context: Development and testing of access/usage control systems is a growing research area. With new trends in software development such as DevOps, the development of access/usage control also has to evolve. Objective: The main aim of this paper is to provide an overview of research proposals in the area of continuous development and testing of access and usage control systems. Method: The paper uses a Systematic Literature Review as a research method to define the research questions and answer them following a systematic approach. With the specified search string, 210 studies were retrieved. After applying the inclusion and exclusion criteria in two phases, a final set of 20 primary studies was selected for this review. Results: Results show that primary studies are mostly published in security venues followed by software engineering venues. Furthermore, most of the studies are based on the standard XACML access control language. In addition, a significant portion of the proposals for development and testing is automated with test assessment and generation the most targeted areas. Some general guidelines for leveraging continuous developing and testing of the usage and access control systems inside the DevOps process are also provided.","Access Control, XACML, DevOps, Systematic Literature Review, Testing","ESSE 2020"
"Conference Paper","Islam MS,Pourmajidi W,Zhang L,Steinbacher J,Erwin T,Miranskyy A","Anomaly Detection in a Large-Scale Cloud Platform","","2021","","","150–159","IEEE Press","Virtual Event, Spain","Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice","","2021","9780738146690","","https://doi-org.proxy.bnl.lu/10.1109/ICSE-SEIP52600.2021.00024;http://dx.doi.org/10.1109/ICSE-SEIP52600.2021.00024","10.1109/ICSE-SEIP52600.2021.00024","Cloud computing is ubiquitous: more and more companies are moving the workloads into the Cloud. However, this rise in popularity challenges Cloud service providers, as they need to monitor the quality of their ever-growing offerings effectively. To address the challenge, we designed and implemented an automated monitoring system for the IBM Cloud Platform. This monitoring system utilizes deep learning neural networks to detect anomalies in near-real-time in multiple Platform components simultaneously.After running the system for a year, we observed that the proposed solution frees the DevOps team's time and human resources from manually monitoring thousands of Cloud components. Moreover, it increases customer satisfaction by reducing the risk of Cloud outages.In this paper, we share our solutions' architecture, implementation notes, and best practices that emerged while evolving the monitoring system. They can be leveraged by other researchers and practitioners to build anomaly detectors for complex systems.","","ICSE-SEIP '21"
"Conference Paper","Kontogiannis K,Amyot D,Mylopoulos J","Software Techniques for Engineering Cyber-Physical Systems","","2021","","","289–290","IBM Corp.","USA","Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering","Toronto, Canada","2021","","","","","Cyber-Physical Systems (CPSs) refer to systems comprising software components, physical components, and social entities which monitor, control, and coordinate processes within a physical environment. CPSs apply to a wide range of mission-critical applications that span from the intelligent management of logistics in complex supply chains, advanced manufacturing systems, and smart contracts, all the way to autonomous systems, and systems that support the smart interactions between humans and machines (M2H), or between machines (M2M). In this respect, the engineering of CPSs goes beyond existing Software Engineering concepts, tools, and techniques because of the very nature of CPSs that spans three realms (cyber, physical, social) and therefore needs to address requirements that span these realms. During the workshop, the participants discussed and debated techniques and directions in six main thematic areas on engineering Cyber-Physical Systems. These thematic areas deal with specification and modeling, DevOps processes for CPSs, data management and analytics, infrastructure and event handling, run-time adaptivity, and finally security, trust, and traceability.","process metrics, software repositories, fault-proneness prediction, continuous software engineering","CASCON '21"
"Journal Article","Ali N,Daneth H,Hong J","A Hybrid DevOps Process Supporting Software Reuse: A Pilot Project","J. Softw. Evol. Process","2020","32","7","","John Wiley & Sons, Inc.","USA","","","2020-07","","2047-7473","https://doi-org.proxy.bnl.lu/10.1002/smr.2248;http://dx.doi.org/10.1002/smr.2248","10.1002/smr.2248","Large software development organizations manage reusable software components through a reusable software repository in order to reduce development time and cost and to improve software quality and productivity. This paper presents a hybrid DevOps process with a systematic reuse‐based software development and management process to reduce the effort and cost required for the rework and to increase productivity. The proposed approach promotes the systematic reuse of software components based on both information retrieval and ontology‐based retrieval techniques. The reusable assets are presented in different styles to ease and support the reuse process with fine‐grained reusable artifacts. To evaluate our proposed process, a pilot project, aiming to monitor the health of a patient, was developed and monitored the reuse activities throughout the whole experiment. The results revealed that our proposed process got an average gain of 35.2% in terms of developed function points by reusing 30.63% of reusable artifacts available in the reuse repository.We proposed a hybrid DevOps process with a systematic reuse‐based software development and management process to reduce the effort and cost required for the rework and to increase productivity. DevOps encourage tool support during the software delivery process for quick delivery. Therefore, we have developed a reuse repository to support rapid delivery by reusing artifacts during the development process. A pilot project—a health‐monitoring and management application—was developed to evaluate our proposed hybrid DevOps process. image","software reuse, software development process, DevOps, reuse repository",""
"Conference Paper","Castellanos C,Varela CA,Correal D","Measuring Performance Quality Scenarios in Big Data Analytics Applications: A DevOps and Domain-Specific Model Approach","","2019","","","165–172","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th European Conference on Software Architecture - Volume 2","Paris, France","2019","9781450371421","","https://doi-org.proxy.bnl.lu/10.1145/3344948.3344986;http://dx.doi.org/10.1145/3344948.3344986","10.1145/3344948.3344986","Big data analytics (BDA) applications use advanced analysis algorithms to extract valuable insights from large, fast, and heterogeneous data sources. These complex BDA applications require software design, development, and deployment strategies to deal with volume, velocity, and variety (3vs) while sustaining expected performance levels. BDA software complexity frequently leads to delayed deployments, longer development cycles and challenging performance monitoring. This paper proposes a DevOps and Domain Specific Model (DSM) approach to design, deploy, and monitor performance Quality Scenarios (QS) in BDA applications. This approach uses high-level abstractions to describe deployment strategies and QS enabling performance monitoring. Our experimentation compares the effort of development, deployment and QS monitoring of BDA applications with two use cases of near mid-air collisions (NMAC) detection. The use cases include different performance QS, processing models, and deployment strategies. Our results show shorter (re)deployment cycles and the fulfillment of latency and deadline QS for micro-batch and batch processing.","software architecture, performance quality scenarios, domain specific model, big data analytics, DevOps","ECSA '19"
"Conference Paper","Abdelkebir S,Maleh Y,Belaissaoui M","An Agile Framework for ITS Management In Organizations: A Case Study Based on DevOps","","2017","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Conference on Computing and Wireless Communication Systems","Larache, Morocco","2017","9781450353069","","https://doi-org.proxy.bnl.lu/10.1145/3167486.3167556;http://dx.doi.org/10.1145/3167486.3167556","10.1145/3167486.3167556","Agility means the capability to swiftly and efficiently respond to internal and environmental organization changes. For IT, it is the ability to provide new services and IT solutions to support the innovative business processes. In the ever-changing business world of today, improving agility is the best way to face future challenges. IT service management is the capacity to collect data, analyze, report and implement agile improvements. Successful IT must be efficient and agile to promote the traditional company transformation to a digital enterprise. The propose of this work is a holistic and practical strategic framework to improve ITSM service management processes with the additions of two drivers Agility management based on DevOps, and an agility Process Maturity Framework (APMF). This research will enable decision-makers to improve and measure agility enhancements and hence compare the agility of Information Systems before and after APMF deploying.","IT Service Management, Organization, Agility, DevOps","ICCWCS'17"
